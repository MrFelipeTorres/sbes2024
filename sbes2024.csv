"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Abstract","Author Keywords","Index Keywords","References","Editors","Publisher","Sponsors","Conference name","Conference date","Conference location","Conference code","Document Type","Publication Stage","Open Access","Source","EID"
"Chakraborty T.; Reddy K S U.; Naik S.M.; Panja M.; Manvitha B.","Chakraborty, Tanujit (57202199336); Reddy K S, Ujjwal (58861289300); Naik, Shraddha M (57200942684); Panja, Madhurima (57645670400); Manvitha, Bayapureddy (58630326400)","57202199336; 58861289300; 57200942684; 57645670400; 58630326400","Ten years of generative adversarial nets (GANs): a survey of the state-of-the-art","2024","Machine Learning: Science and Technology","5","1","011001","","","","1","10.1088/2632-2153/ad1f77","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183710089&doi=10.1088%2f2632-2153%2fad1f77&partnerID=40&md5=98108400bfb6b0371bc7d8aed9fdfd6f","Generative adversarial networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas, since their inception in 2014. Consisting of a discriminative network and a generative network engaged in a minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ‘Top Ten Global Breakthrough Technologies List’ issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, cycle-consistent GAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen-Shannon divergence while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as transformers, physics-informed neural networks, large language models, and diffusion models. Finally, we reveal several issues as well as future research outlines in this field. © 2024 The Author(s). Published by IOP Publishing Ltd.","adversarial learning; artificial intelligence.; deep learning; generative adversarial networks; image generation; model evaluation and selection","Deep learning; Network architecture; Adversarial learning; Artificial intelligence.; Deep learning; Discriminative networks; Generative model; Image generations; Minimax games; Model evaluation; Model Selection; State of the art; Generative adversarial networks","Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y, Generative adversarial nets, Advances in Neural Information Processing Systems, (2014); Mirza M, Osindero S, Conditional generative adversarial nets, (2014); Zhu J-Y, Park T, Isola P, Efros A A, Unpaired image-to-image translation using cycle-consistent adversarial networks, Proc. IEEE Int. Conf. on Computer Vision, 2223 32, pp. 2223-2232, (2017); Zhang H, Xu T, Li H, Zhang S, Wang X, Huang X, Metaxas D N, StackGAN: text to photo-realistic image synthesis with stacked generative adversarial networks, Proc. IEEE Int. Conf. on Computer Vision, 5907 15, (2017); Karras T, Aila T, Laine S, Lehtinen J, Progressive growing of GANs for improved quality, stability, and variation, (2017); Karras T, Laine S, Aila T, A style-based generator architecture for generative adversarial networks, Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition, 4401, 10, pp. 4401-4410, (2019); Liu X, Cheng M, Zhang H, Hsieh C-J, Towards robust neural networks via random self-ensemble, Proc. European Conf. on Computer Vision (ECCV), (2018); Yang L-C, Chou S-Y, Yang Y-H, MidiNet: a convolutional generative adversarial network for symbolic-domain music generation, (2017); Wu Y, Et al., Google’s neural machine translation system: bridging the gap between human and machine translation, (2016); Thottolil R, Kumar U, Chakraborty T, Prediction of transportation index for urban patterns in small and medium-sized Indian cities using hybrid RidgeGAN model, (2023); Smith K E, Smith A O, Conditional GAN for timeseries generation, (2020); Shin H-C, Roth H R, Gao M, Lu L, Xu Z, Nogues I, Yao J, Mollura D, Summers R M, Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning, IEEE Trans. Med. Imaging, 35, pp. 1285-981285, (2016); Togelius J, Shaker N, Nelson M J, Shaker M, Procedural Content Generation in Games: A Textbook and an Overview of Current Research, (2014); Chen X, Duan Y, Houthooft R, Schulman J, Sutskever I, Abbeel P, InfoGAN: interpretable representation learning by information maximizing generative adversarial nets, Advances in Neural Information Processing Systems, (2016); Arjovsky M, Bottou L, Towards principled methods for training generative adversarial networks, (2017); Wilby D, Aarts T, Tichit P, Bodey A, Rau C, Taylor G, Baird E, Using micro-CT techniques to explore the role of sex and hair in the functional morphology of bumblebee (Bombus terrestris) ocelli, Vis. Res, 158, pp. 100-8100, (2019); Buolamwini J, Gebru T, Gender shades: intersectional accuracy disparities in commercial gender classification, Conf. on Fairness, Accountability and Transparency PMLR, (2018); Zhao J, Wang T, Yatskar M, Ordonez V, Chang K-W, Gender bias in coreference resolution: evaluation and debiasing methods, (2018); Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, Kaiser L, Polosukhin I, Attention is all you need, Advances in Neural Information Processing Systems, (2017); Raissi M, Perdikaris P, Karniadakis G E, Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations, J. Comput. Phys, 378, pp. 686-707686, (2019); Radford A, Wu J, Amodei D, Amodei D, Clark J, Brundage M, Sutskever I, Better language models and their implications, (2019); Sohl-Dickstein J, Weiss E, Maheswaranathan N, Ganguli S, Deep unsupervised learning using nonequilibrium thermodynamics, Int. Conf. on Machine Learning PMLR, (2015); Radford A, Metz L, Chintala S, Unsupervised representation learning with deep convolutional generative adversarial networks, (2015); Zhang Y, Yin Z, Li Y, Yin G, Yan J, Shao J, Liu Z, CelebA-Spoof: large-scale face anti-spoofing dataset with rich annotations Computer Vision-ECCV 2020: 16th European Conf, (2020); Vondrick C, Shrivastava A, Fathi A, Guadarrama S, Murphy K, Tracking emerges by colorizing videos, Proc. European Conf. on Computer Vision (ECCV), (2018); Yu L, Zhang W, Wang J, Yu Y, SeqGAN: sequence generative adversarial nets with policy gradient, Proc. AAAI Conference on Artificial Intelligence, (2017); Tan J, Jing L, Huo Y, Li L, Akin O, Tian Y, LGAN: lung segmentation in CT scans using generative adversarial network, Comput. Med. Imaging Graph, 87, (2021); Nema S, Dudhane A, Murala S, Naidu S, RescueNet: an unpaired GAN for brain tumor segmentation, Biomed. Signal Process. Control, 55, (2020); Abouelnaga Y, Ali O S, Rady H, Moustafa M, CIFAR-10: KNN-based ensemble of classifiers 2016, Int. Conf. on Computational Science and Computational Intelligence (CSCI) IEEE, 1192 5, pp. 1192-1195, (2016); Recht B, Roelofs R, Schmidt L, Shankar V, Do ImageNet classifiers generalize to ImageNet?, Int. Conf. on Machine Learning PMLR, (2019); Jabbar A, Li X, Omar B, A survey on generative adversarial networks: variants, applications and training, ACM Comput. Surv, 54, 1, pp. 491-549, (2021); Xia W, Zhang Y, Yang Y, Xue J-H, Zhou B, Yang M-H, GAN inversion: a survey, IEEE Trans. Pattern Anal. Mach. Intell, 45, pp. 3121-383121, (2022); Durgadevi M, Et al., Generative adversarial network (GAN): a general review on different variants of GAN and applications 2021, 6th Int. Conf. on Communication and Electronics Systems (ICCES) IEEE, 1 8, pp. 1-8, (2021); Alom M Z, Taha T M, Yakopcic C, Westberg S, Sidike P, Nasrin M S, Hasan M, Van Essen B C, Awwal A A, Asari V K, A state-of-the-art survey on deep learning theory and architectures, Electronics, 8, (2019); Nandhini Abirami R, Durai Raj, Vincent P, Srinivasan K, Tariq U, Chang C-Y, Deep CNN and deep GAN in computational visual perception-driven image analysis, Complexity, 2021, 1 30, pp. 1-30, (2021); Kulkarni R, Gaikwad R, Sugandhi R, Kulkarni P, Kone S, Survey on deep learning in music using GAN, Int. J. Eng. Res. Technol, 8, pp. 646-8646, (2019); Sampath V, Maurtua I, Aguilar Martin J J, Gutierrez A, A survey on generative adversarial networks for imbalance problems in computer vision tasks, J. Big Data, 8, 1, pp. 591-659, (2021); Brophy E, Wang Z, She Q, Ward T, Generative adversarial networks in time series: a systematic literature review, ACM Comput. Surv, 55, pp. 1311-1331, (2023); Xun S, Et al., Generative adversarial networks in medical image segmentation: a review, Comput. Biol. Med, 140, (2022); Ji S, Yang X, Luo J, A survey on deep learning for symbolic music generation: representations, algorithms, evaluations and challenges, ACM Comput. Surv, 56, pp. 1391-1439, (2023); Wang Z, She Q, Ward T E, Generative adversarial networks in computer vision: a survey and taxonomy, ACM Comput. Surv, 54, 1, pp. 381-38, (2021); Gui J, Sun Z, Wen Y, Tao D, Ye J, A review on generative adversarial networks: algorithms, theory, and applications, IEEE Trans. Knowl. Data Eng, 35, pp. 3313-323313, (2021); Iglesias G, Talavera E, Diaz-Alvarez A, A survey on GANs for computer vision: recent research, analysis and taxonomy, Comput. Sci. Rev, 48, (2023); Li Y, Wang Q, Zhang J, Hu L, Ouyang W, The theoretical research of generative adversarial networks: an overview, Neurocomputing, 435, (2021); Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y, Generative adversarial networks, Commun. ACM, 63, pp. 139-44139, (2020); Goodfellow I, Bengio Y, Courville A, Deep Learning, (2016); Goodfellow I, NIPS 2016 tutorial: generative adversarial networks, (2016); Nash J, Non-cooperative games, Ann. Math, 54, pp. 286-95286, (1951); Heusel M, Ramsauer H, Unterthiner T, Nessler B, Hochreiter S, GANs trained by a two time-scale update rule converge to a local Nash equilibrium, Advances in Neural Information Processing Systems, (2017); Farnia F, Ozdaglar A, Do GANs always have Nash equilibria?, Int. Conf. on Machine Learning PMLR, (2020); Liu M-Y, Huang X, Yu J, Wang T-C, Mallya A, Generative adversarial networks for image and video synthesis: algorithms and applications, Proc. IEEE, 109, pp. 839-62839, (2021); Kim S W, Zhou Y, Philion J, Torralba A, Fidler S, Learning to simulate dynamic environments with GameGAN, Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition, (2020); Cao Y-J, Jia L-L, Chen Y-X, Lin N, Yang C, Zhang B, Liu Z, Li X-X, Dai H-H, Recent advances of generative adversarial networks in computer vision, IEEE Access, 7, (2018); Ma L, Jia X, Sun Q, Schiele B, Tuytelaars T, Van Gool L, Pose guided person image generation, Advances in Neural Information Processing Systems, (2017); Yu Y, Gong Z, Zhong P, Shan J, Unsupervised representation learning with deep convolutional neural network for remote sensing images Image and Graphics, 9th Int. Conf. (ICIG 2017), (2017); Wang Y, Bilinski P, Bremond F, Dantcheva A, Imaginator: conditional spatio-temporal gan for video generation, Proc. IEEE/CVF Winter Conf. on Applications of Computer Vision, 1160 9, pp. 1160-1169, (2020); Tulyakov S, Liu M-Y, Yang X, Kautz J, MoCoGAN: decomposing motion and content for video generation, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2018); Wang W, Yang H, Tuo Z, He H, Zhu J, Fu J, Liu J, VideoFactory: swap attention in spatiotemporal diffusions for text-to-video generation, (2023); Westerlund M, The emergence of deepfake technology: review, Technol. Innov. Manage. Rev, 9, (2019); Korshunov P, Marcel S, Vulnerability assessment and detection of deepfake videos 2019, Int. Conf. on Biometrics (ICB) IEEE pp 1 6, pp. 1-6, (2019); Yu P, Xia Z, Fei J, Lu Y, A survey on deepfake video detection, IET Biom, 10, pp. 607-24607, (2021); Xie Q, Dai Z, Hovy E, Luong T, Le Q, Unsupervised data augmentation for consistency training, Advances in Neural Information Processing Systems, 33, (2020); Bowman S R, Vilnis L, Vinyals O, Dai A M, Jozefowicz R, Bengio S, Generating sentences from a continuous space, (2015); Frid-Adar M, Klang E, Amitai M, Goldberger J, Greenspan H, Synthetic data augmentation using GAN for improved liver lesion classification 2018, IEEE 15th Int. Symp. on Biomedical Imaging (ISBI 2018) IEEE, (2018); Johnson J, Alahi A, Fei-Fei L, Perceptual losses for real-time style transfer and super-resolution Computer Vision-ECCV 2016: 14th European Conf, (2016); Gatys L A, Ecker A S, Bethge M, A neural algorithm of artistic style, (2015); Hochreiter S, Schmidhuber J, Long short-term memory, Neural Comput, 9, pp. 1735-1780, (1997); Zhang Y, Gan Z, Carin L, Generating text via adversarial training, NIPS Workshop on Adversarial Training, 21, (2016); Toshevska M, Gievska S, A review of text style transfer using deep learning, IEEE Trans. on Artificial Intelligence, (2021); Guo J, Lu S, Cai H, Zhang W, Yu Y, Wang J, Long text generation via adversarial training with leaked information, Proc. AAAI Conf. on Artificial Intelligence, (2018); Mu Z, Yang X, Dong Y, Review of end-to-end speech synthesis technology based on deep learning, (2021); Dong H-W, Hsiao W-Y, Yang L-C, Yang Y-H, MuseGAN: multi-track sequential generative adversarial networks for symbolic music generation and accompaniment, Proc. AAAI Conf. on Artificial Intelligence, (2018); Civit M, Civit-Masot J, Cuadrado F, Escalona M J, A systematic review of artificial intelligence-based music generation: scope, applications and future trends, Expert Syst. Appl, 209, (2022); Mao X, Wang S, Zheng L, Huang Q, Semantic invariant cross-domain image generation with generative adversarial networks, Neurocomputing, 293, pp. 55-6355, (2018); Guibas J T, Virdi T S, Li P S, Synthetic medical images from dual generative adversarial networks, (2017); Singh N K, Raza K, Medical image generation using generative adversarial networks: a review, Health Informatics: A Computational Perspective in Healthcare Springer, (2021); Wang C, Yang G, Papanastasiou G, Tsaftaris S A, Newby D E, Gray C, Macnaught G, MacGillivray T J, DiCyc: GAN-based deformation invariant cross-domain information fusion for medical image synthesis, Inf. Fusion, 67, pp. 147-60147, (2021); Kadurin A, Aliper A, Kazennov A, Mamoshina P, Vanhaelen Q, Khrabrov K, Zhavoronkov A, The cornucopia of meaningful leads: applying deep adversarial autoencoders for new molecule development in oncology, Oncotarget, 8, (2017); Kadurin A, Nikolenko S, Khrabrov K, Aliper A, Zhavoronkov A, druGAN: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico, Mol. Pharma, 14, pp. 3098-1043098, (2017); Zhao Y, Wang Y, Zhang J, Liu X, Li Y, Guo S, Yang X, Hong S, Surgical GAN: towards real-time path planning for passive flexible tools in endovascular surgeries, Neurocomputing, 500, pp. 567-80567, (2022); Ma S, Hu Z, Ye K, Zhang X, Wang Y, Peng H, Feasibility study of patient-specific dose verification in proton therapy utilizing positron emission tomography (PET) and generative adversarial network (GAN), Med. Phys, 47, pp. 5194-2085194, (2020); Albert A, Strano E, Kaur J, Gonzalez M C, Modeling urbanization patterns with generative adversarial networks, IGARSS 2018-2018 IEEE Int. Geoscience and Remote Sensing Symp, pp. 2095-2098, (2018); Albert A, Kaur J, Strano E, Gonzalez M, Spatial sensitivity analysis for urban land use prediction with physics-constrained conditional generative adversarial networks, (2019); Zhang W, Ma Y, Zhu D, Dong L, Liu Y, MetroGAN: simulating urban morphology with generative adversarial network, Proc. 28th ACM SIGKDD Conf. on Knowledge Discovery and Data Mining, (2022); Mosser L, Dubrule O, Blunt M J, Reconstruction of three-dimensional porous media using generative adversarial neural networks, Phys. Rev. E, 96, (2017); Zhang T-F, Tilke P, Dupont E, Zhu L-C, Liang L, Bailey W, Generating geologically realistic 3D reservoir facies models using deep learning of sedimentary architecture with generative adversarial networks, Pet. Sci, 16, pp. 541-9541, (2019); Wang T, Trugman D, Lin Y, SeismoGen: seismic waveform synthesis using GAN with application to seismic data augmentation, J. Geophys. Res. Solid Earth, 126, (2021); Gecer B, Bhattarai B, Kittler J, Kim T-K, Semi-supervised adversarial learning to generate photorealistic face images of new identities from 3D morphable model, Proc. European Conf. on Computer Vision (ECCV), (2018); Pan X, You Y, Wang Z, Lu C, Virtual to real reinforcement learning for autonomous driving, (2017); Shrivastava A, Pfister T, Tuzel O, Susskind J, Wang W, Webb R, Learning from simulated and unsupervised images through adversarial training, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, pp. 2107-2116, (2017); Zhang M, Zhang Y, Zhang L, Liu C, Khurshid S, DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems, Proc. 33rd ACM/IEEE Int. Conf. on Automated Software Engineering, 132 42, (2018); Jiang S, Fu Y, Fashion style generator, Int. Joint Conf. on Artificial Intelligence, 3721 7, (2017); Han X, Wu Z, Wu Z, Yu R, Davis L S, VITON: an image-based virtual try-on network, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2018); Liu L, Zhang H, Ji Y, Wu Q J, Toward AI fashion design: an attribute-GAN model for clothing match, Neurocomputing, 341, pp. 156-67156, (2019); Pandey N, Savakis A, Poly-GAN: multi-conditioned GAN for fashion synthesis, Neurocomputing, 414, pp. 356-64356, (2020); Chakraborty T, Chakraborty A K, Hellinger net: a hybrid imbalance learning model to improve software defect prediction, IEEE Trans. Reliab, 70, pp. 481-94481, (2020); Dam T, Ferdaus M M, Pratama M, Anavatti S G, Jayavelu S, Abbass H, Latent preserving generative adversarial network for imbalance classification 2022, IEEE Int. Conf. on Image Processing (ICIP) IEEE, 3712 6, pp. 3712-3716, (2022); Mariani G, Scheidegger F, Istrate R, Bekas C, Malossi C, BAGAN: data augmentation with balancing GAN, (2018); Suh S, Lee H, Lukowicz P, Lee Y O, CEGAN: classification enhancement generative adversarial networks for unraveling data imbalance problems, Neural Netw, 133, pp. 69-8669, (2021); Panja M, Chakraborty T, Kumar U, Liu N, Epicasting: an ensemble wavelet neural network for forecasting epidemics, Neural Netw, 165, pp. 185-212185, (2023); Li Y, Peng X, Zhang J, Li Z, Wen M, DCT-GAN: dilated convolutional transformer-based GAN for time series anomaly detection, IEEE Trans. on Knowledge and Data Engineering, (2021); Li Y, Peng X, Wu Z, Yang F, He X, Li Z, M3GAN: a masking strategy with a mutable filter for multidimensional anomaly detection, Knowl.-Based Syst, 271, (2023); Yang J, Shao Y, Li C-N, CNTS: cooperative network for time series, IEEE Access, 11, (2023); Geiger A, Liu D, Alnegheimish S, Cuesta-Infante A, Veeramachaneni K, TADGAN: time series anomaly detection using generative adversarial networks 2020, IEEE Int. Conf. on Big Data (Big Data) IEEE pp 33 43 pp 33-43, (2020); Liu Y, Peng J, James J, Wu Y, PPGAN: privacy-preserving generative adversarial network, 2019 IEEE 25th International Conf. on Parallel and Distributed Systems (ICPADS) IEEE, 985 9, pp. 985-989, (2019); Torfi A, Fox E A, CorGAN: correlation-capturing convolutional generative adversarial networks for generating synthetic healthcare records, (2020); Shokri R, Stronati M, Song C, Shmatikov V, Membership inference attacks against machine learning models 2017, IEEE Symp. on Security and Privacy (SP) IEEE, 3 18, pp. 3-18, (2017); Gatys L A, Ecker A S, Bethge M, Image style transfer using convolutional neural networks, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2414 23, pp. 2414-2423, (2016); Arjovsky M, Chintala S, Bottou L, Wasserstein generative adversarial networks, Int. Conf. on Machine Learning PMLR, (2017); Brock A, Donahue J, Simonyan K, Large scale GAN training for high fidelity natural image synthesis, (2018); Makhzani A, Shlens J, Jaitly N, Goodfellow I, Frey B, Adversarial autoencoders, (2015); Ghosh A, Bhattacharya B, Chowdhury S B R, SAD-GAN: synthetic autonomous driving using generative adversarial networks, (2016); Mao X, Li Q, Xie H, Lau R Y, Wang Z, Paul Smolley S, Least squares generative adversarial networks, Proc. IEEE Int. Conf. on Computer Vision, 2794 802, pp. 2794-2802, (2017); Ledig C, Et al., Photo-realistic single image super-resolution using a generative adversarial network, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 4681 90, pp. 4681-4690, (2017); Dong H, Supratak A, Mai L, Liu F, Oehmichen A, Yu S, Guo Y, TensorLayer: a versatile library for efficient deep learning development, ACM Int. Conf. on Multimedia, 1201, 4, pp. 1201-1204, (2017); Lai C, Han J, Dong H, Tensorlayer 3.0: a deep learning library compatible with multiple backends 2021, IEEE Int. Conf. on Multimedia & Expo Workshops (ICMEW) IEEE, 1 3, pp. 1-3, (2021); Gulrajani I, Ahmed F, Arjovsky M, Dumoulin V, Courville A C, Improved training of Wasserstein GANs, Advances in Neural Information Processing Systems, (2017); Zhu J-Y, Park T, Isola P, Efros A A, Unpaired image-to-image translation using cycle-consistent adversarial networks, Computer Vision (ICCV), 2017 IEEE Int. Conf. on, (2017); Miyato T, Kataoka T, Koyama M, Yoshida Y, Spectral normalization for generative adversarial networks, (2018); Jolicoeur-Martineau A, The relativistic discriminator: a key element missing from standard GAN, (2018); Esteban C, Hyland S L, Ratsch G, Real-valued (medical) time series generation with recurrent conditional GANs, (2017); Choi Y, Choi M, Kim M, Ha J-W, Kim S, Choo J, StarGAN: unified generative adversarial networks for multi-domain image-to-image translation, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2018); Iqbal T, Ali H, Generative adversarial network for medical images (MI-GAN), J. Med. Syst, 42, pp. 1111-1111, (2018); He Z, Zuo W, Kan M, Shan S, Chen X, AttGAN: facial attribute editing by only changing what you want, IEEE Trans. Image Process, 28, pp. 5464-785464, (2019); Zhang G, Kan M, Shan S, Chen X, Generative adversarial network with spatial attention for face attribute editing, Proc. European Conf. on Computer Vision (ECCV), (2018); Jordon J, Yoon J, Van Der Schaar M, PATE-GAN: generating synthetic data with differential privacy guarantees, Int. Conf. on Learning Representations, (2018); Zhu M, Pan P, Chen W, Yang Y, DM-GAN: dynamic memory generative adversarial networks for text-to-image synthesis, Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition, (2019); Shaham T R, Dekel T, Michaeli T, SinGAN: learning a generative model from a single natural image, Proc. IEEE/CVF Int. Conf. on Computer Vision, 4570 80, pp. 4570-4580, (2019); Pan Z, Yuan F, Lei J, Li W, Ling N, Kwong S, MIEGAN: mobile image enhancement via a multi-module cascade neural network, IEEE Trans. Multimedia, 24, pp. 519-33519, (2021); Esser P, Rombach R, Ommer B, Taming transformers for high-resolution image synthesis, Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition, 12873 12883, pp. 12873-12883, (2021); Razavi A, Van den Oord A, Vinyals O, Generating diverse high-fidelity images with VQ-VAE-2, Advances in Neural Information Processing Systems, (2019); Radford A, Wu J, Child R, Amodei D, Sutskever I, OpenAI Blog, (2021); Ramesh A, Pavlov M, Goh G, Gray S, Voss C, Radford A, Chen M, Sutskever I, Zero-shot text-to-image generation, Int. Conf. on Machine Learning PMLR, 8821 31, (2021); Odena A, Olah C, Shlens J, Conditional image synthesis with auxiliary classifier gans, Int. Conf. on Machine Learning PMLR, (2017); Ren W, Et al., Experimental quantum adversarial learning with programmable superconducting qubits, Nat. Comput. Sci, 2, pp. 711-7711, (2022); Szegedy C, Zaremba W, Sutskever I, Bruna J, Erhan D, Goodfellow I, Fergus R, Intriguing properties of neural networks, (2013); Xiao J, Zhang S, Yao Y, Wang Z, Zhang Y, Wang Y-F, Generative adversarial network with hybrid attention and compromised normalization for multi-scene image conversion, Neural Comput. Appl, 34, pp. 7209-257209, (2022); Denton E L, Chintala S, Fergus R, Et al., Deep generative image models using a Laplacian pyramid of adversarial networks, Advances in Neural Information Processing Systems, (2015); Krizhevsky A, Hinton G, Learning multiple layers of features from tiny images, (2009); Lucic M, Kurach K, Michalski M, Gelly S, Bousquet O, Are GANs created equal? A large-scale study, Advances in Neural Information Processing Systems, (2018); Bousmalis K, Silberman N, Dohan D, Erhan D, Krishnan D, Unsupervised pixel-level domain adaptation with generative adversarial networks, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 3722 31, pp. 3722-3731, (2017); Higgins I, Matthey L, Pal A, Burgess C, Glorot X, Botvinick M, Mohamed S, Lerchner A, Beta-VAE: learning basic visual concepts with a constrained variational framework, Int. Conf. on Learning Representations, (2017); Huang Z, Wang X, Huang L, Huang C, Wei Y, Liu W, CCNet: criss-cross attention for semantic segmentation, Proc. IEEE/CVF Int. Conf. on Computer Vision, 603 12, pp. 603-612, (2019); Wang Z, Bovik A C, Sheikh H R, Simoncelli E P, Image quality assessment: from error visibility to structural similarity, IEEE Trans. Image Process, 13, (2004); Mescheder L, Nowozin S, Geiger A, The numerics of GANs, Advances in Neural Information Processing Systems, (2017); Sergio Y C M W H, Colmenarejo G, Learning to learn for global optimization of black box functions, Stat, (2016); Yi Z, Zhang H, Tan P, Gong M, DualGAN: unsupervised dual learning for image-to-image translation, Proc. IEEE Int. Conf. on Computer Vision, pp. 2849-2857, (2017); Hashemi S R, Salehi S S M, Erdogmus D, Prabhu S P, Warfield S K, Gholipour A, Asymmetric loss functions and deep densely-connected networks for highly-imbalanced medical image segmentation: application to multiple sclerosis lesion detection, IEEE Access, 7, pp. 1721-351721, (2018); Zhang R, Isola P, Efros A A, Shechtman E, Wang O, The unreasonable effectiveness of deep features as a perceptual metric, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2018); Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, Kalchbrenner N, Senior A, Kavukcuoglu K, WaveNet: a generative model for raw audio, (2016); Chu H, Urtasun R, Fidler S, Song from pi: a musically plausible network for pop music generation, (2016); Gomez-de Segura G, Garcia-Mayoral R, Turbulent drag reduction by anisotropic permeable substrates-analysis and direct numerical simulations, J. Fluid Mech, 875, pp. 124-72124, (2019); Nguyen A, Yosinski J, Clune J, Multifaceted feature visualization: uncovering the different types of features learned by each neuron in deep neural networks, (2016); Tramer F, Kurakin A, Papernot N, Goodfellow I, Boneh D, McDaniel P, Ensemble adversarial training: attacks and defenses, (2017); Li Y, Fang C, Yang J, Wang Z, Lu X, Yang M-H, Universal style transfer via feature transforms, Advances in Neural Information Processing Systems, (2017); Huang X, Belongie S, Arbitrary style transfer in real-time with adaptive instance normalization, Proc. IEEE Int. Conf. on Computer Vision, 1501, 10, pp. 1501-1510, (2017); Isola P, Zhu J-Y, Zhou T, Efros A A, Image-to-image translation with conditional adversarial networks, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, pp. 1125-1134, (2017); Thies J, Zollhofer M, Stamminger M, Theobalt C, Niessner M, Face2Face: real-time face capture and reenactment of RGB videos, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2016); Karras T, Aittala M, Hellsten J, Laine S, Lehtinen J, Aila T, Training generative adversarial networks with limited data, Advances in Neural Information Processing Systems, 33, (2020); Franceschelli G, Musolesi M, Creativity and machine learning: a survey, (2021); Dumoulin V, Belghazi I, Poole B, Mastropietro O, Lamb A, Arjovsky M, Courville A, Adversarially learned inference, (2016); Mahmud M, Kaiser M S, McGinnity T M, Hussain A, Deep learning in mining biological data, Cogn. Comput, 13, pp. 1331-1333, (2021); Dai T, Feng Y, Chen B, Lu J, Xia S-T, Deep image prior based defense against adversarial examples, Pattern Recognit, 122, (2022); Hou X, Shen L, Sun K, Qiu G, Deep feature consistent variational autoencoder 2017, IEEE Winter Conf. on Applications of Computer Vision (WACV) IEEE, (2017); Reed S, Akata Z, Yan X, Logeswaran L, Schiele B, Lee H, Generative adversarial text to image synthesis, Int. Conf. on Machine Learning PMLR, 1060 9, (2016); Li K, Zhang T, Malik J, Diverse image synthesis from semantic layouts via conditional imle, Proc. IEEE/CVF Int. Conf. on Computer Vision, 4220, 9, pp. 4220-4229, (2019); Nair V, Hinton G E, Rectified linear units improve restricted Boltzmann machines, Proc. 27th Int. Conf. on Machine Learning (ICML-10), (2010); Bengio Y, Simard P, Frasconi P, Learning long-term dependencies with gradient descent is difficult, IEEE Trans. Neural Netw, 5, pp. 157-66157, (1994); Graves A, Wayne G, Danihelka I, Neural turing machines, (2014); Zeiler M D, Fergus R, Visualizing and understanding convolutional networks, Computer Vision-ECCV 2014: 13th European Conf, (2014); Berthelot D, Raffel C, Roy A, Goodfellow I, Understanding and improving interpolation in autoencoders via an adversarial regularizer, (2018); Brown T, Et al., Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, (2020); Rogez G, Weinzaepfel P, Schmid C, LCR-Net++: multi-person 2D and 3D pose detection in natural images, IEEE Trans. Pattern Anal. Mach. Intell, 42, pp. 1146-611146, (2019); Ronneberger O, Fischer P, Brox T, U-Net: convolutional networks for biomedical image segmentation Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015, 18th Int. Conf, (2015); He K, Zhang X, Ren S, Sun J, Deep residual learning for image recognition, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 770 8, pp. 770-778, (2016); Zhu S, Urtasun R, Fidler S, Lin D, Change Loy C, Be your own prada: fashion synthesis with structural coherence, Proc. IEEE International Conf. on Computer Vision, 1680 8, pp. 1680-1688, (2017); Mameli M, Paolanti M, Pietrini R, Pazzaglia G, Frontoni E, Zingaretti P, Deep learning approaches for fashion knowledge extraction from social media: a review, IEEE Access, 10, pp. 1545-761545, (2021); Wu Y, Liu H, Lu P, Zhang L, Yuan F, Design and implementation of virtual fitting system based on gesture recognition and clothing transfer algorithm, Sci. Rep, 12, (2022); Chaitanya K, Erdil E, Karani N, Konukoglu E, Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation, Med. Image Anal, 87, (2023); Kalchbrenner N, Oord A, Simonyan K, Danihelka I, Vinyals O, Graves A, Kavukcuoglu K, Video pixel networks, Int. Conf. on Machine Learning PMLR, pp. 1771-1779, (2017); Radford A, Et al., Learning transferable visual models from natural language supervision, Int. Conf. on Machine Learning PMLR, (2021); Singh G, Deng F, Ahn S, Illiterate DALL-E learns to compose, (2021); Marcus G, Davis E, Aaronson S, A very preliminary analysis of DALL-E 2, (2022); Rudin C, Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead, Nat. Mach. Intell, 1, pp. 206-15206, (2019); Ramesh A, Dhariwal P, Nichol A, Chu C, Chen M, Hierarchical text-conditional image generation with CLIP latents, (2022); Doshi-Velez F, Kim B, Towards a rigorous science of interpretable machine learning, (2017); Brigham E O, The Fast Fourier Transform and Its Applications, (1988); Percival D B, Walden A T, Wavelet Methods for Time Series Analysis, (2000); Schlegl T, Seebock P, Waldstein S M, Schmidt-Erfurth U, Langs G, Unsupervised anomaly detection with generative adversarial networks to guide marker discovery, Int. Conf. on Information Processing in Medical Imaging Springer, 27268, 86, pp. 27268-27286, (2017); Zhou T, Ma Z, Wen Q, Wang X, Sun L, Jin R, FEDformer: frequency enhanced decomposed transformer for long-term series forecasting, Int. Conf. on Machine Learning PMLR, (2022); Vovk V, Kernel ridge regression Empirical Inference: Festschrift in Honor of Vladimir N, 105 16, (2013); Murphy K P, Machine Learning: A Probabilistic Perspective, (2012); Biau G, Cadre B, Sangnier M, Tanielian U, Some theoretical properties of GANs, Ann. Stat, 48, pp. 1539-661539, (2020); Biau G, Sangnier M, Tanielian U, Some theoretical insights into Wasserstein GANs, The J. Mach. Learn. Res, 22, pp. 5287-3315287, (2021); Belomestny D, Moulines E, Naumov A, Puchkin N, Samsonov S, Rates of convergence for density estimation with GANs, (2021); Meitz M, Statistical inference for generative adversarial networks, (2021); Mbacke S D, Clerc F, Germain P, PAC-Bayesian generalization bounds for adversarial generative models, (2023); Liu S, Bousquet O, Chaudhuri K, Approximation and convergence properties of generative adversarial learning, Advances in Neural Information Processing Systems, (2017); Lin Z, Sekar V, Fanti G, On the privacy properties of GAN-generated samples, Int. Conf. on Artificial Intelligence and Statistics PMLR, (2021); Alvarez-Melis D, Garg V, Kalai A, Are GANs overkill for NLP?, Advances in Neural Information Processing Systems, 35, (2022); Borji A, Pros and cons of GAN evaluation measures, Comput. Vis. Image Underst, 179, pp. 41-6541, (2019); Xu J, Ren X, Lin J, Sun X, Diversity-promoting GAN: a cross-entropy based generative adversarial network for diversified text generation, Proc. 2018 Conf. on Empirical Methods in Natural Language Processing, 3940, 9, pp. 3940-3949, (2018); Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford A, Chen X, Improved techniques for training GANs, Advances in Neural Information Processing Systems, (2016); Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z, Rethinking the inception architecture for computer vision, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2818 26, pp. 2818-2826, (2016); Deng J, Dong W, Socher R, Li L-J, Li K, Fei-Fei L, ImageNet: a large-scale hierarchical image database 2009, IEEE Conf. on Computer Vision and Pattern Recognition IEEE, (2009); Gurumurthy S, Kiran Sarvadevabhatla R, Venkatesh Babu R, DeLiGAN: generative adversarial networks for diverse and limited data, Proc. IEEE Conf. on Computer Vision and Pattern Recognition, (2017); Nowozin S, Cseke B, Tomioka R, f-GAN: training generative neural samplers using variational divergence minimization, Advances in Neural Information Processing Systems, (2016); Daras G, Odena A, Zhang H, Dimakis A G, Your local GAN: designing two dimensional local attention mechanisms for generative models, Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognition, (2020)","","Institute of Physics","","","","","","Review","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85183710089"
"Khanfir A.; Jimenez M.; Papadakis M.; Traon Y.L.","Khanfir, Ahmed (57221813063); Jimenez, Matthieu (57191959513); Papadakis, Mike (57197295611); Traon, Yves Le (55884641800)","57221813063; 57191959513; 57197295611; 55884641800","CodeBERT-nt: Code Naturalness via CodeBERT","2022","IEEE International Conference on Software Quality, Reliability and Security, QRS","2022-December","","","936","947","11","0","10.1109/QRS57517.2022.00098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151453328&doi=10.1109%2fQRS57517.2022.00098&partnerID=40&md5=812fb6167294fe00a4f1842b8010e9c7","Much of recent software-engineering research has investigated the naturalness of code, the fact that code, in small code snippets, is repetitive and can be predicted using statistical language models like n-gram. Although powerful, training such models on large code corpus can be tedious, time consuming and sensitive to code patterns (and practices) encountered during training. Consequently, these models are often trained on a small corpus and thus only estimate the language naturalness relative to a specific style of programming or type of project. To overcome these issues, we investigate the use of pre-trained generative language models to infer code naturalness. Pre-trained models are often built on big data, are easy to use in an out-of-the-box way and include powerful learning associations mechanisms. Our key idea is to quantify code naturalness through its predictability, by using state-of-the-art generative pre-trained language models. Thus, we suggest to infer naturalness by masking (omitting) code tokens, one at a time, of code-sequences, and checking the models' ability to predict them. We explore three different predictability metrics; a) measuring the number of exact matches of the predictions, b) computing the embedding similarity between the original and predicted code, i.e., similarity at the vector space, and c) computing the confidence of the model when doing the token completion task regardless of the outcome. We implement this workflow, named CODEBERT-NT, and evaluate its capability to prioritize buggy lines over non-buggy ones when ranking code based on its naturalness. Our results, on 2,510 buggy versions of 40 projects from the SmartShark dataset, show that CODEBERTNT outperforms both, random-uniform and complexity-based ranking techniques, and yields comparable results to the n-gram models.  © 2022 IEEE.","Code Naturalness; CodeBERT; Pre-trained models","C (programming language); Codes (symbols); Computational linguistics; Natural language processing systems; Software engineering; Code naturalness; Code sequences; Code-patterns; CodeBERT; Language model; N-grams; Pre-trained model; Software engineering research; State of the art; Statistical language modelling; Vector spaces","Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On the naturalness of software, Proceedings of the 34th International Conference on Software Engineering, Ser. Icse '12., pp. 837-847, (2012); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, 2013 10th Working Conference on Mining Software Repositories (MSR)., pp. 207-216, (2013); Sharma T., Efstathiou V., Louridas P., Spinellis D., Code smell detection by deep direct-learning and transfer-learning, Journal of Systems and Software, 176, (2021); Lin B., Nagy C., Bavota G., Lanza M., On the impact of refactoring operations on code naturalness, 2019 Ieee 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 594-598, (2019); Posnett D., Hindle A., Devanbu P., Reflections on: A simpler model of software readability, Sigsoft Softw. Eng. Notes, 46, 3, pp. 30-32, (2021); Hellendoorn V.J., Devanbu P.T., Bacchelli A., Will they like this? Evaluating code contributions with language models, 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories, pp. 157-167, (2015); Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: Bug detection with n-gram language models, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, Ser. Ase 2016., pp. 708-719, (2016); Jimenez M., Maxime C., Le Traon Y., Papadakis M., On the impact of tokenizer and parameters on n-gram based code analysis, 2018 Ieee International Conference on Software Maintenance and Evolution (ICSME)., pp. 437-448, (2018); Allamanis M., Barr E.T., Devanbu P.T., Sutton C., A survey of machine learning for big code and naturalness, CoRR, (2017); Ray B., Hellendoorn V., Godhane S., Tu Z., Bacchelli A., Devanbu P., On the ""naturalness"" of buggy code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 428-439, (2016); Trautsch S.H.A., Trautsch F., The Smartshark Repository Mining Data, (2021); Chekam T.T., Papadakis M., Bissyande T.F., Traon Y.L., Sen K., Selecting fault revealing mutants, Empir. Softw. Eng., 25, 1, pp. 434-487, (2020); Kim J., Jeon J., Hong S., Yoo S., Predictive mutation analysis via natural language channel in source code, CoRR, (2021); Kang S., Yoo S., Language models can prioritize patches for practical program patching, 3rd IEEE/ACM International Workshop on Automated Program Repair, APR@ICSE 2022, pp. 8-15, (2022); Shannon C.E., Prediction and entropy of printed english, The Bell System Technical Journal, 30, 1, pp. 50-64, (1951); A mathematical theory of communication, The Bell System Technical Journal, 27, 3, pp. 379-423, (1948); Chen S.F., Goodman J., An empirical study of smoothing techniques for language modeling, Computer Speech & Language, 13, 4, pp. 359-394, (1999); Kneser R., Ney H., Improved backing-off for m-gram language modeling, 1995 International Conference on Acoustics, Speech, and Signal Processing, 1, 1, pp. 181-184, (1995); Github Copilot; Chen M., Tworek J., Jun H., Yuan Q., Pinto Oliveira De H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating Large Language Models Trained on code.(2021), (2021); Amazon Codewhisperer; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-Trained model for programming and natural languages, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings, Emnlp 2020, EMNLP 2020, pp. 1536-1547, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in Neural Information Processing Systems, 30, (2017); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding, (2018); Codebert; Sun Z., Zhang J.M., Xiong Y., Harman M., Papadakis M., Zhang L., Improving machine translation systems via isotopic replacement, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE), pp. 1181-1192, (2022); Pawlak R., Monperrus M., Petitprez N., Noguera C., Seinturier L., Spoon: A Library for Implementing Analyses and Transformations of Java Source Code, Software: Practice and Experience, 46, pp. 1155-1179, (2015); Pytorch; Thota M.K., Shajin F.H., Rajesh P., Survey on software defect prediction techniques, International Journal of Applied Science and Engineering, 17, pp. 331-344, (2020); Rahman M., Palani D., Rigby P.C., Natural software revisited, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 37-48, (2019); Jimenez M., Maxime C., Le Traon Y., Papadakis M., Tuna: Tuning naturalness-based analysis, 2018 Ieee International Conference on Software Maintenance and Evolution (ICSME), (2018); Leszak M., Perry D.E., Stoll D., Classification and evaluation of defects in a project retrospective, Journal of Systems and Software, 61, 3, pp. 173-187, (2002)","","Institute of Electrical and Electronics Engineers Inc.","","22nd IEEE International Conference on Software Quality, Reliability and Security, QRS 2022","5 December 2022 through 9 December 2022","Virtual, Online","187416","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85151453328"
"Siddiq M.L.; Majumder S.H.; Mim M.R.; Jajodia S.; Santos J.C.S.","Siddiq, Mohammed Latif (57694302400); Majumder, Shafayat H. (58080552100); Mim, Maisha R. (58080267100); Jajodia, Sourov (58080267200); Santos, Joanna C. S. (57188733292)","57694302400; 58080552100; 58080267100; 58080267200; 57188733292","An Empirical Study of Code Smells in Transformer-based Code Generation Techniques","2022","Proceedings - 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation, SCAM 2022","","","","71","82","11","10","10.1109/SCAM55253.2022.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141767392&doi=10.1109%2fSCAM55253.2022.00014&partnerID=40&md5=76859af914319c58ec34983055106f6e","Prior works have developed transformer-based language learning models to automatically generate source code for a task without compilation errors. The datasets used to train these techniques include samples from open source projects which may not be free of security flaws, code smells, and violations of standard coding practices. Therefore, we investigate to what extent code smells are present in the datasets of coding generation techniques and verify whether they leak into the output of these techniques. To conduct this study, we used Pylint and Bandit to detect code smells and security smells in three widely used training sets (CodeXGlue, APPS, and Code Clippy). We observed that Pylint caught 264 code smell types, whereas Bandit located 44 security smell types in these three datasets used for training code generation techniques. By analyzing the output from ten different configurations of the open-source fine-Tuned transformer-based GPT-Neo 125M parameters model, we observed that this model leaked the smells and non-standard practices to the generated source code. When analyzing GitHub Copilot's suggestions, a closed source code generation tool, we observed that it contained 18 types of code smells, including substandard coding patterns and 2 security smell types.  © 2022 IEEE.","code generation; code smell; GitHub copilot; pre-Trained model; security smell; transformer","Computer programming languages; Odors; Open systems; Code smell; Codegeneration; Empirical studies; Generation techniques; Github copilot; Language learning models; Pre-trained model; Security smell; Source codes; Transformer; Open source software","Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Computing Surveys (CSUR, 51, 4, pp. 1-37, (2018); Chen M., Tworek J., Jun H., Yuan Q., De Pinto Oliveira H.P., Et al., Evaluating Large Language Models Trained on Code, (2021); Izadi M., Gismondi R., Gousios G., Codefill: Multi-Token code completion by jointly learning from structure and naming sequences, 44th International Conference on Software Engineering (ICSE, (2022); Kim S., Zhao J., Tian Y., Chandra S., Code prediction by feeding trees to transformers, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 150-162, (2021); Svyatkovskiy A., Lee S., Hadjitofi A., Riechert M., Franco J.V., Allamanis M., Fast and memory-efficient neural code completion, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR, pp. 329-340, (2021); Gao Y., Lyu C., M2ts: Multi-scale multi-modal approach based on transformer for source code summarization, ArXiv Preprint arXiv:2203.09707, (2022); Barone A.V.M., Sennrich R., A parallel corpus of python functions and documentation strings for automated code documentation and code generation, ArXiv Preprint arXiv.1707.02275, (2017); Sun Z., Zhu Q., Xiong Y., Sun Y., Mou L., Zhang L., Treegen: A tree-based transformer architecture for code generation, Proceedings of the AAAI Conference on Artificial Intelligence, 34, 5, pp. 8984-8991, (2020); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., Intellicode compose: Code generation using transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1433-1443, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention Is All You Need, (2017); Tipirneni S., Zhu M., Reddy C.K., Structcoder: Structureaware Transformer for Code Generation, (2022); Sharma T., Fragkoulis M., Spinellis D., House of cards: Code smells in open-source c# repositories, 2017 ACM/ IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). IEEE, pp. 424-429, (2017); Palomba F., Bavota G., Penta M.D., Fasano F., Oliveto R., Lucia A.D., On the diffuseness and the impact on maintainability of code smells: A large scale empirical investigation, Empirical Software Engineering, 23, 3, pp. 1188-1221, (2018); Gudivada V., Apon A., Ding J., Data quality considerations for big data and machine learning: Going beyond data cleaning and transformations, International Journal on Advances in Software, 10, 7, pp. 1-20, (2017); Fowler M., Refactoring: Improving the Design of Existing Code, (1999); Ghafari M., Gadient P., Nierstrasz O., Security smells in android, 2017 IEEE 17th International Working Conference on Source Code Analysis and Manipulation (SCAM). IEEE, pp. 121-130, (2017); Rahman M.R., Rahman A., Williams L., Share, but be aware: Security smells in python gists, 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME, pp. 536-540, (2019); Rahman A., Parnin C., Williams L., The Seven Sins: Security Smells in Infrastructure as Code Scripts, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). Montreal, QC, Canada: IEEE, May 2019, pp. 164-175; Van Oort B., Cruz L., Aniche M., Van Deursen A., The prevalence of code smells in machine learning projects, 2021 IEEE/ACM 1st Workshop on AI Engineering-Software Engineering for AI (WAIN). IEEE, pp. 1-8, (2021); Simmons A.J., Barnett S., Rivera-Villicana J., Bajaj A., Vasa R., A large-scale comparative analysis of coding standard conformance in open-source data science projects, Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). ACM, (2020); Austin J., Odena A., Nye M., Bosma M., Michalewski H., Dohan D., Jiang E., Cai C.J., Terry M., Le Q.V., Sutton C., Program synthesis with large language models, ArXiv, Vol. abs/2108.07732, (2021); Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the keyboard? assessing the security of github copilot?s code contributions, 2022 2022 IEEE Symposium on Security and Privacy (SP) (SP). Los Alamitos, CA, USA: IEEE Computer Society, May 2022, pp. 980-994; Asare O., Nagappan M., Asokan N., Is github?s copilot as bad as humans at introducing vulnerabilities in code?, ArXiv Preprint arXiv:2204.04741, (2022); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Et al., Codexglue: A Machine Learning Benchmark Dataset for Code Understanding and Generation, (2021); Hendrycks D., Basart S., Kadavath S., Mazeika M., Arora A., Guo E., Burns C., Puranik S., He H., Song D., Steinhardt J., Measuring Coding Challenge Competence with Apps, (2021); Coooper N., Arutiunian A., Hincapie-Potes S., Trevett B., Raja A., Hossami E., Mathur M., Et al., Code Clippy Data: A Large Dataset of Code Data from Github for Research into Code Language Models, (2021); Coooper N., GPT Code Clippy: The Open Source Version of GitHub Copilot, (2021); Github Copilot : Your Ai Pair Programmer; Fowler M., CodeSmell; Pereira Dos Reis J., Brito Abreu E.F., Carneiro De Figueiredo G., Anslow C., Code Smells Detection and Visualization: A Systematic Literature Review, Archives of Computational Methods in Engineering, 29, 1, pp. 47-94; CWE-Common Weakness Enumeration, (2022); Rossum Van Guido N.C., Warsaw B., Pep 8-The Style Guide for Python Code; Sutskever I., Vinyals O., Le Q.V., Sequence to Sequence Learning with Neural Networks, (2014); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding, (2018); Brown T.B., Mann B., Ryder N., Et al., Language Models Are Few-shot Learners, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A Pre-Trained Model for Programming and Natural Languages, (2020); Wang Y., Wang W., Joty S., Hoi S.C.H., Codet5: Identifier-Aware Unified Pre-Trained Encoder-decoder Models for Code Understanding and Generation, (2021); OpenAI, (2021); Bandit; Pylint; Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet Challenge: Evaluating the State of Semantic Code Search, (2019); Gao L., Biderman S., Black S., Golding L., Hoppe T., Foster C., Phang J., He H., Thite A., Nabeshima N., Et al., The pile: An 800gb dataset of diverse text for language modeling, ArXiv Preprint arXiv:2101.00027, (2020); Chen Z., Chen L., Ma W., Zhou X., Zhou Y., Xu B., Understanding metric-based detectable smells in python software: A comparative study, Information and Software Technology, 94, pp. 14-29, (2018); Dufour C., How to Ensure Entropy and Proper Random Numbers Generation in Virtual Machines; Black S., Gao L., Wang P., Leahy C., Biderman S., GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, (2021); Gulwani S., Polozov O., Singh R., Et al., Program synthesis, Foundations and Trends® in Programming Languages, 4, 1-2, pp. 1-119, (2017); Green C., Application of theorem proving to problem solving, Proceedings of the 1st International Joint Conference on Artificial Intelligence, Ser. IJCAI?69. San Francisco, CA, USA, pp. 219-239, (1969); Manna Z., Waldinger R.J., Toward automatic program synthesis, Commun ACM, 14, 3, pp. 151-165, (1971); Yin P., Neubig G., A Syntactic Neural Model for General-purpose Code Generation, (2017); Li Y., Choi D.H., Chung J., Kushman N., Schrittwieser J., Et al., Competition-level code generation with alphacode, ArXiv, Vol. abs/2203.07814, (2022); Lanza M., Marinescu R., Object-oriented Metrics in Practice: Using Software Metrics to Characterize, Evaluate, and Improve the Design of Object-oriented Systems, (2007); Kessentini W., Kessentini M., Sahraoui H., Bechikh S., Ouni A., A cooperative parallel search-based software engineering approach for code-smells detection, IEEE Transactions on Software Engineering, 40, 9, pp. 841-861, (2014); Paiva T., Damasceno A., Figueiredo E., Santanna C., On the evaluation of code smells and detection tools, Journal of Software Engineering Research and Development, 5, 1, pp. 1-28, (2017); Caram F.L., Rodrigues B.R.D.O., Campanelli A.S., Parreiras F.S., Machine learning techniques for code smells detection: A systematic mapping study, International Journal of Software Engineering and Knowledge Engineering, 29, 2, pp. 285-316, (2019); Chen Z., Chen L., Ma W., Xu B., Detecting code smells in python programs, 2016 International Conference on Software Analysis, Testing and Evolution (SATE, pp. 18-23, (2016); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER, pp. 612-621, (2018); Lee T., Lee J.B., A Study of Different Coding Styles Affecting Code Readability, (2013); Elish M., Offutt J., The Adherence of Open Source Java Programmers to Standard Coding Practices, 1, (2002); Dasgupta S., Hooshangi S., Code Quality: Examining the Efficacy of Automated Tools, (2017)","","Institute of Electrical and Electronics Engineers Inc.","GrammaTech Inc.; IEEE Computer Society Technical Council on Software Engineering; Meta","22nd IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2022","3 October 2022 through 4 October 2022","Limassol","185992","Conference paper","Final","","Scopus","2-s2.0-85141767392"
"Bibaev V.; Kalina A.; Lomshakov V.; Golubev Y.; Bezzubov A.; Povarov N.; Bryksin T.","Bibaev, Vitaliy (57712650200); Kalina, Alexey (57928808100); Lomshakov, Vadim (57928857400); Golubev, Yaroslav (57214675419); Bezzubov, Alexander (57928749500); Povarov, Nikita (56285354600); Bryksin, Timofey (55916625600)","57712650200; 57928808100; 57928857400; 57214675419; 57928749500; 56285354600; 55916625600","All you need is logs: improving code completion by learning from anonymous IDE usage logs","2022","ESEC/FSE 2022 - Proceedings of the 30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering","","","","1269","1279","10","2","10.1145/3540250.3558968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143063920&doi=10.1145%2f3540250.3558968&partnerID=40&md5=7cb75587c772ea2e91de7500fcbd844d","In this work, we propose an approach for collecting completion usage logs from the users in an IDE and using them to train a machine learning based model for ranking completion candidates. We developed a set of features that describe completion candidates and their context, and deployed their anonymized collection in the Early Access Program of IntelliJ-based IDEs. We used the logs to collect a dataset of code completions from users, and employed it to train a ranking CatBoost model. Then, we evaluated it in two settings: on a held-out set of the collected completions and in a separate A/B test on two different groups of users in the IDE. Our evaluation shows that using a simple ranking model trained on the past user behavior logs significantly improved code completion experience. Compared to the default heuristics-based ranking, our model demonstrated a decrease in the number of typing actions necessary to perform the completion in the IDE from 2.073 to 1.832. The approach adheres to privacy requirements and legal constraints, since it does not require collecting personal information, performing all the necessary anonymization on the client's side. Importantly, it can be improved continuously: implementing new features, collecting new data, and evaluating new models - this way, we have been using it in production since the end of 2020.  © 2022 ACM.","A/B-testing; anonymous usage logs; code completion; integrated development environment; machine learning","Behavioral research; Codes (symbols); Data privacy; Integrodifferential equations; A/B-testing; Anonymous usage log; Code completions; Integrated development environment; Learning Based Models; Machine-learning; Ranking model; Sets of features; Simple++; User behaviors; Machine learning","Amann S., Proksch S., Nadi S., Mezini M., A Study of Visual Studio Usage in Practice, 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), 1, pp. 124-134, (2016); Ardimento P., Luca Bernardi M., Cimitile M., De Ruvo G., Mining Developer's Behavior from Web-Based IDE Logs, 2019 IEEE 28th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE), pp. 277-282, (2019); Ari Aye G., Kaiser G.E., Sequence Model Design for Code Completion in the Modern IDE, (2020); Ari Aye G., Kim S., Li H., Learning Autocompletion From Real-World Datasets, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE, pp. 131-139, (2021); Breiman L., Random forests, Machine learning, 45, 1, pp. 5-32, (2001); Bruch M., Monperrus M., Mezini M., Learning from Examples to Improve Code Completion Systems, ESEC-FSE'09-Proceedings of the Joint 12th European Software Engineering Conference and 17th ACM SIGSOFT Symposium on the Foundations of Software Engineering, pp. 213-222, (2009); Cao Z., Qin T., Liu T., Tsai M., Li H., Learning to Rank: From Pairwise Approach to Listwise Approach, Proceedings of the 24th international conference on Machine learning, pp. 129-136, (2007); QuerySoftMax Loss Function, (2018); Chen M., Tworek J., Jun H., Yuan Q., De Oliveira Pinto H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating Large Language Models Trained on Code, (2021); Ciniselli M., Pascarella L., Bavota G., To What Extent do Deep Learning-based Code Recommenders Generate Predictions by Cloning Code from the Training Set?, (2022); De Stefano M., Simone Gambardella M., Pecorelli F., Palomba F., De Lucia A., cASpER: A Plug-in for Automated Code Smell Detection and Refactoring, Proceedings of the International Conference on Advanced Visual Interfaces, pp. 1-3, (2020); Efron B., Bootstrap Methods: Another Look at the Jackknife, pp. 569-593, (1992); Hellendoorn V.J., Proksch S., Gall H.C., Bacchelli A., When Code Completion Fails: A Case Study on Real-World Completions, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 960-970, (2019); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the Naturalness of Software, Commun. ACM, 59, 5, pp. 122-131, (2016); Hou D., Pletcher D.M., An Evaluation of the Strategies of Sorting, Filtering, and Grouping API Methods for Code Completion, IEEE International Conference on Software Maintenance, ICSM, pp. 233-242, (2011); Hou D., Wang Y., An Empirical Analysis of the Evolution of User-Visible Features in an Integrated Development Environment, Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research, pp. 122-135, (2009); Ioannou C., Burattin A., Weber B., Mining Developers'Workflows from IDE usage, International Conference on Advanced Information Systems Engineering, pp. 167-179, (2018); Izadi M., Gismondi R., Gousios G., CodeFill: Multitoken Code Completion by Jointly Learning from Structure and Naming Sequences, (2022); Early Access Program (EAP), (2018); Essential Tools for Software Developers and Teams, (2018); Ke G., Meng Q., Finley T., Wang T., Chen W., Ma W., Ye Q., Liu T., LightGBM: A Highly Efficient Gradient Boosting Decision Tree, Advances in Neural Information Processing Systems, 30, (2017); Kurbatova Z., Golubev Y., Kovalenko V., Bryksin T., The IntelliJ Platform: A Framework for Building Plugins and Mining Software Data, 2021 36th IEEE/ACM International Conference on Automated Software EngineeringWorkshops (ASEW), pp. 14-17, (2021); Kurbatova Z., Veselov I., Golubev Y., Bryksin T., Recommendation of Move Method Refactoring Using Path-Based Representation of Code, Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops, pp. 315-322, (2020); Lambiase S., Cupito A., Pecorelli F., De Lucia A., Palomba F., Just-in-time Test Smell Detection and Refactoring: The DARTS project, Proceedings of the 28th International Conference on Program Comprehension, pp. 441-445, (2020); Young Lee Y., Chen N., Johnson R.E., Drag-and-Drop Refactoring: Intuitive and Efficient Program Transformation, 2013 35th International Conference on Software Engineering (ICSE), pp. 23-32, (2013); Li H., A Short Introduction to Learning to Rank, IEICE TRANSACTIONS on Information and Systems, 94, 10, pp. 1854-1862, (2011); Murphy-Hill E., Parnin C., Black A., HowWe Refactor, And How We Know It, IEEE Transactions on Software Engineering, 38, 1, pp. 5-18, (2011); Mulu K., Brun Y., Holmes R., Ernst M.D., Notkin D., Speculative Analysis of Integrated Development Environment Recommendations, ACM SIGPLAN Notices, 47, 10, pp. 669-682, (2012); Negara S., Chen N., Vakilian M., Johnson R.E., Dig D., A Comparative Study of Manual and Automated Refactorings, European Conference on Object-Oriented Programming, pp. 552-576, (2013); Thanh Nguyen T., Tuan Nguyen A., Anh Nguyen H., Nguyen T.N., A Statistical Semantic Language Model for Source Code, 2013 9th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE 2013-Proceedings, pp. 532-542, (2013); Oo T., Liu H., Nyirongo B., Dynamic Ranking of Refactoring Menu Items for Integrated Development Environment, IEEE Access, 6, pp. 76025-76035, (2018); Pletcher D.M., Hou D., BCC: Enhancing Code Completion for Better API Usability, 2009 IEEE International Conference on Software Maintenance, pp. 393-394, (2009); Prokhorenkova L., Gusev G., Vorobev A., Veronika Dorogush A., Gulin A., CatBoost: Unbiased Boosting with Categorical Features, Advances in Neural Information Processing Systems, 31, (2018); Proksch S., Amann S., Nadi S., Mezini M., Evaluating the Evaluations of Code Recommender Systems: A Reality Check, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering-ASE 2016, pp. 111-121, (2016); Proksch S., Lerch J., Mezini M., Intelligent Code Completion with Bayesian Networks, ACM Transactions on Software Engineering and Methodology, 25, 1, pp. 1-31, (2015); Raychev V., Vechev M., Yahav E., Code Completion with Statistical Language Models, Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 419-428, (2014); Robbes R., Lanza M., How Program History Can Improve Code Completion, ASE 2008-23rd IEEE/ACM International Conference on Automated Software Engineering, Proceedings, pp. 317-326, (2008); Snipes W., Murphy-Hill E., Fritz T., Vakilian M., Damevski K., Nair A.R., Shepherd D., A Practical Guide to Analyzing IDE Usage Data, The Art and Science of Analyzing Software Data, pp. 85-138, (2015); California Consumer Privacy Act, (2018); Svyatkovskiy A., Kun Deng S., Fu S., Sundaresan N., IntelliCode Compose: Code Generation Using Transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1433-1443, (2020); Svyatkovskiy A., Lee S., Hadjitofi A., Riechert M., Vicente Franco J., Allamanis M., Fast and Memory-Efficient Neural Code Completion, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, pp. 329-340, (2021); Svyatkovskiy A., Zhao Y., Fu S., Sundaresan N., Pythia: AI-Assisted Code Completion System, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 2727-2735, (2019); General Data Protection Regulation, (2018); Wang W., Shen S., Li G., Jin Z., Towards Full-line Code Completion with Neural Language Models, (2020)","Roychoudhury A.; Cadar C.; Kim M.","Association for Computing Machinery, Inc","ACM SIGSOFT; National University of Singapore","30th ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022","14 November 2022 through 18 November 2022","Singapore","184166","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85143063920"
"Bertolotti F.; Cazzola W.","Bertolotti, Francesco (57914120400); Cazzola, Walter (6602449966)","57914120400; 6602449966","CombTransformers: Statement-Wise Transformers for Statement-Wise Representations","2023","IEEE Transactions on Software Engineering","49","10","","4677","4690","13","1","10.1109/TSE.2023.3310793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171524299&doi=10.1109%2fTSE.2023.3310793&partnerID=40&md5=4fd7b22d796d3d545508cb5ad9a52043","This study presents a novel category of Transformer architectures known as comb transformers, which effectively reduce the space complexity of the self-attention layer from a quadratic to a subquadratic level. This is achieved by processing sequence segments independently and incorporating X-word embeddings to merge cross-segment information. The reduction in attention memory requirements enables the deployment of deeper architectures, potentially leading to more competitive outcomes. Furthermore, we design an abstract syntax tree (AST)-based code representation to effectively exploit comb transformer properties. To explore the potential of our approach, we develop nine specific instances based on three popular architectural concepts: funnel, hourglass, and encoder-decoder. These architectures are subsequently trained on three code-related tasks: method name generation, code search, and code summarization. These tasks encompass a range of capabilities: short/long sequence generation and classification. In addition to the proposed comb transformers, we also evaluate several baseline architectures for comparative analysis. Our findings demonstrate that the comb transformers match the performance of the baselines and frequently perform better.  © 1976-2012 IEEE.","code search and summarization; learning representations; machine learning; method name Gen; Programming languages","Codes (symbols); Computer architecture; Computer programming languages; Job analysis; Learning systems; Network architecture; Network coding; Code; Code search; Code search and summarization; Documentation; Learning representation; Machine-learning; Method name gen; Space complexity; Task analysis; Transformer; Neural networks","Ellis K., Et al., DreamCoder: Bootstrapping inductive program synthesis with wake-sleep library learning, Proc. PLDI, pp. 835-850, (2021); Amodio M., Chaudhuri S., Reps T., Neural attribute machines for programming generation, (2017); Murali V., Qi L., Chaudhuri S., Jermain C., Neural sketch learning for conditional program generation, Proc. ICLR, (2018); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proc. PLDI., pp. 419-428, (2014); Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, Proc. ICML., (2020); Chen M., Et al., Evaluating large language models trained on code, (2021); Alon U., Zilberstein M., Levy O., Yahav E., A general pathbased representation for predicting program properties, Proc. PLDI, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proc. POPL, pp. 401-4029, (2019); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, Proc. ICLR, (2019); Celik A., Sreepathi P., Khurshid S., Gligoric M., Bounded exhaustive test-input generation on GPUs, Proc. OOPSLA, pp. 941-9425, (2017); Donaldson A., Evrard H., Lascu A., Thomson P., Automated testing of graphics shader compilers, Proc. OOPSLA, pp. 931-9329, (2017); He J., Lee C.-C., Raychev V., Vechev M., Learning to find naming issues with big code and small supervision, Proc. PLDI, pp. 296-311; Dam H.K., Et al., Lessons learned from using a deep tree-based model for software defect prediction in practice, Proc. MSR, Montréal, QB, Canada., pp. 46-57, (2019); Pradel M., Sen K., DeepBugs: A learning approach to name-based bug detection, Proc. OOPSLA, pp. 1471-14725, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet challenge: Evaluating the state of semantic code search, (2019); Wu C., Yan M., Learning deep semantic model for code search using CodeSearchNet corpus, (2022); Fowler M., Refactoring: Improving the Design of Existing Code, (1999); Host E.W., Ostvold B.M., Debugging method names, Proc. ECOOP, pp. 294-317, (2009); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proc. FSE, pp. 38-49, (2015); Bertolotti F., Cazzola W., Fold2Vec: Towards a statement based representation of code for code comprehension, Trans. Softw. Eng. Methodol., 32, 1, pp. 61-631, (2023); Gu X., Zhang H., Kim S., Deep code search, Proc. ICSE, pp. 933-944, (2018); Liu Y., Et al., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proc. NAACL-HLT, pp. 4171-4186, (2019); Mastropaolo A., Et al., Studying the usage of text-to-text transfer transformer to support code-related tasks, Proc. ICSE, Madrid, Spain., pp. 336-347, (2021); Wang Y., Wang W., Joty S., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proc. EMNLP, pp. 8696-8708, (2021); Liu Q., Kusner M.J., Blunsom P., A survey on contextual embeddings, (2020); Luong M.-T., Pham H., Manning C.D., Effective approaches to attention-based neural machine translation, Proc. EMNLP; Vaswani A., Et al., Attention is all you need, Proc. NIPS, pp. 6000-6010, (2017); Lan Z., Chen M., Goodman S., Gimpel K., Sharma P., Soricut R., ALBERT: A lite BERT for self-supervised learning of language representations, Proc. ICLR, (2020); Child R., Gray S., Radford A., Sutskever I., Generating long sequences with sparse transformers, (2019); Beltagy I., Peters M.E., Cohan A., Longformer: The longdocument transformer, pp. 1-17, (2021); Hucka M., Spiral: Splitters for identifiers in source code files, J. Open Source Softw., 3, 24, pp. 6531-6533, (2018); Hill E., Binkley D., Lawrie D., Pollock L., Vujay-Shanker K., An empirical study of identifier splitting techniques, Empirical Softw. Eng., 19, 6, pp. 1754-1780, (2014); Butler S., Wermelinger M., Yu Y., Sharp H., Improving the tokenisation of identifier names, Proc. ECOOP, pp. 130-154, (2011); Smith N., Van Bruggen D., Tomasetti F., javaParser: Visited, (2019); Burtsev M.S., Kuratov Y., Peganov A., Sapunov G., Memory transformer, (2020); Dai Z., Lai G., Yang Y., Le Q.V., Funnel-transformer: Filtering out sequential redundancy for efficient language processing, Proc. NeurIPS, Vancouver, Canada, pp. 4271-4282, (2020); Melekhov I., Ylioinas J., Kannala J., Rahtu E., Image-based localization using hourglass networks, (2017); Yang J., Liu Q., Zhang K., Stacked hourglass network for robust landmark localisation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 2025-2033, (2017); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 770-778, (2016); Li H., Xu Z., Taylor G., Studer C., Goldstein T., Visualizing the loss landscape of neural nets, Proc. NeurIPS, (2018); Burtsev M.S., Kuratov Y., Peganov A., Sapunov G.V., Memory transformer, pp. 1-17, (2021); Bergstra J., Bardenet R., Bengio Y., Kegi B., Algorithms for hyperparameter optimization, Proc. NIPS, pp. 2546-2554, (2011); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proc. ICLR, (2015); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, Proc. ACL, pp. 1715-1725, (2016); Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages, Proc. EMNLP, pp. 1536-1547, (2020); Raffel C., Et al., Exploring the limits of transfer learning with a unified text-to-text transformer, J. Mach. Learn. Res., 21, 1, pp. 5485-5551, (2020); Papineni K., Roukos S., Ward T., Zhu W.-J., BLEU: A method for automatic evaluation of machine translation, Proc. ACL, pp. 311-318, (2002); LeClair A., McMillian C., Recommendations for datasets for source code summarization, Proc. HLT-NAACL, (2019); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Proc. MSR, Seoul, South Korea., pp. 300-310, (2020); Kovaleva O., Romanov A., Rogers A., Rumshisky A., Revealing the dark secrets of BERT, Proc. EMNLP, pp. 4365-4374, (2019); Roy A., Saffar M., Vaswani A., Grangier D., Efficient contentbased sparse attention with routing transformers, Trans. Assoc. Comput. Ling., 9, pp. 53-68, (2021); Zaheer M., Et al., BigBird: Transformers for longer sequences, Proc. NeurIPS, (2020); Wang S., Li B.Z., Khabsa M., Fang H., Ma H., Linformer: Selfattention with linear complexity, (2017); Kitaev N., Kaiser L., Levskaya A., Reformer: The efficient transformer, Proc. ICLR, (2020); Tay Y., Bahri D., Yang L., Metzler D., Juan D.-C., Sparse Sinkhorn Attention, Proc. ICML, pp. 9438-9447, (2020); Tay Y., Et al., Long range arena: A benchmark for efficient transformers, (2017); Ott M., Et al., FAIRSEQ: A fast, extensible toolkit for sequence modeling, Proc. HLT-NAACL, pp. 48-53, (2019); Wolf T., Et al., Transformers: State-of-the-art natural language processing, Proc. EMNLP. ACL, pp. 38-45, (2020); Choromanski K., Et al., Rethinking attention with performers, Proc. ICLR, pp. 1-38, (2021); Yang L., Zhang M., Li C., Bendersky M., Najork M., Beyond 512 tokens: Siamese multi-depth transformer-based hierarchical encoder for long-form documentmatching, Proc.CIKM, pp. 1725-1734, (2020); Li H., Kadav A., Durdanovic I., Samet H., Graf H.P., Pruning filters for efficient ConvNets, Proc. ICLR, (2017); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, Proc. NeurIPS, pp. 2552-2562, (2018); Huang T., You S., Wang F., Qian C., Xu C., Knowledge distillation from a stronger teacher, Proc. NeurIPS, (2022); Jacob B., Et al., Quantization and training of neural networks for efficient integer-arithmetic-only inference, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2704-2713; Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, Proc. ICML, pp. 2091-2100, (2016); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical and attention networks, Proc. PEPM, Cascais, pp. 10-21, (2019); Movshovitz-Attias D., Cohen W.W., Natural language models for predicting programming comments, Proc. ACL, pp. 35-40, (2013); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proc. ACL, pp. 2073-2083, (2016); Shi K., Lu Y., Chang J., Weu Z., PathPair2Vec: An AST path pair-based code representation method for defect prediction, J. Comput. Lang., 59, (2020); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., An empirical study on learning bug-fixing patches in the wild via neural machine translation, ACM Trans. Softw. Eng. Method., 28, 4, pp. 191-229, (2019)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85171524299"
"Lertbanjongngam S.; Chinthanet B.; Ishio T.; Kula R.G.; Leelaprute P.; Manaskasemsak B.; Rungsawang A.; Matsumoto K.","Lertbanjongngam, Sila (58045051200); Chinthanet, Bodin (57189901823); Ishio, Takashi (8381338700); Kula, Raula Gaikovina (57188638536); Leelaprute, Pattara (6505724430); Manaskasemsak, Bundit (8680996100); Rungsawang, Arnon (6506615609); Matsumoto, Kenichi (55378267900)","58045051200; 57189901823; 8381338700; 57188638536; 6505724430; 8680996100; 6506615609; 55378267900","An Empirical Evaluation of Competitive Programming AI: A Case Study of AlphaCode","2022","Proceedings - 2022 IEEE 16th International Workshop on Software Clones, IWSC 2022","","","","10","15","5","3","10.1109/IWSC55060.2022.00010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145783649&doi=10.1109%2fIWSC55060.2022.00010&partnerID=40&md5=8fdb7b0f8f2c867f674469481d834881","AlphaCode is a code generation system for assisting software developers in solving competitive programming problems using natural language problem descriptions. Despite the advantages of the code generating system, the open source com-munity expressed concerns about practicality and data licensing. However, there is no research investigating generated codes in terms of code clone and performance. In this paper, we conduct an empirical study to find code similarities and performance differences between AlphaCode-generated codes and human codes. The results show that (i) the generated codes from AlphaCode are similar to human codes (i.e., the average maximum similarity score is 0.56) and (ii) the generated code performs on par with or worse than the human code in terms of execution time and memory usage. Moreover, AlphaCode tends to generate more similar codes to humans for low-difficulty problems (i.e., four cases have the exact same codes). It also employs excessive nested loops and unnecessary variable declarations for high-difficulty problems, which cause low performance regarding our manual investigation.  © 2022 IEEE.","code generation; code performance; code similarity","Codes (symbols); Open systems; Case-studies; Code performance; Code similarities; Codegeneration; Empirical evaluations; Generation systems; Language problems; Natural languages; Programming problem; Software developer; Open source software","Tantithamthavorn C.K., Jiarpakdee J., Explainable ai for software engineering, IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1-2, (2021); Tantithamthavorn C., McIntosh S., Hassan A.E., Matsumoto K., Automated parameter optimization of classification techniques for defect prediction models, International Conference on Software Engineering (ICSE), pp. 321-332, (2016); Okutan A., Yildiz O.T., Software defect prediction using bayesian networks, Empirical Software Engineering (EMSE), 19, 1, pp. 154-181, (2014); Samson B., Ellison D., Dugard P., Software cost estimation using an albus perceptron (cmac), Information and Software Technology (IST), 39, 1, pp. 55-60, (1997); Huang J., Li Y.-F., Xie M., An empirical analysis of data preprocessing for machine learning-based software cost estimation, Information and Software Technology (IST), 67, pp. 108-127, (2015); Perini A., Susi A., Avesani P., A machine learning approach to software requirements prioritization, IEEE Transactions on Software Engineering (TSE), 39, 4, pp. 445-461, (2012); Xuan J., Jiang H., Ren Z., Zou W., Developer prioritization in bug repositories, International Conference on Software Engineering (ICSE), pp. 25-35, (2012); Zheng Y., Pujar S., Lewis B., Buratti L., Epstein E., Yang B., Laredo J., Morari A., Su Z., D2a: a dataset built for aibased vulnerability detection methods using differential analysis, International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP), pp. 111-120, (2021); Nguyen T.N., Choo R., Human-in-the-loop xai-enabled vulnerability detection, investigation, and mitigation, IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1210-1212, (2021); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating Large Language Models Trained on Code, (2021); Li Y., Choi D., Chung J., Kushman N., Schrittwieser J., Leblond R., Eccles T., Keeling J., Gimeno F., Lago A.D., Et al., Competition-level code generation with alphacode, (2022); Allamanis M., The adverse effects of code duplication in machine learning models of code, ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward!), pp. 143-153, (2019); Github copilot - your ai pair programmer; Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the keyboard? assessing the security of github copilot's code contributions, IEEE Symposium on Security and Privacy (SP), pp. 980-994, (2022); Nguyen N., Nadi S., An empirical evaluation of github copilot's code suggestions, IEEE/ACM Mining Software Repositories Conference (MSR), pp. 1-5, (2022); Carlini N., Tramer F., Wallace E., Jagielski M., Herbert-Voss A., Lee K., Roberts A., Brown T., Song D., Erlingsson U., Oprea A., Raffel C., Extracting training data from large language models, USENIX Security Symposium (USENIX Security 21), pp. 2633-2650, (2021); Github copilot research recitation - the github blog; Alphacode attention visualization, 2, (2022); Hata H., Kula R.G., Ishio T., Treude C., Same File, Different Changes: The Potential of Meta-Maintenance on GitHub, International Conference on Software Engineering (ICSE), pp. 773-784, (2021); Leelaprute P., Chinthanet B., Wattanakriengkrai S., Kula R.G., Jaisri P., Ishio T., Does coding in pythonic zen peak performance? preliminary experiments of nine pythonic idioms at scale, International Conference on Program Comprehension (ICPC), pp. 575-579, (2022); Problem - 1574A - Codeforces; Halim S., Halim F., Skiena S.S., Revilla M.A., Competitive programming 3, (2013); Code Jam - Google's Coding Competitions; Meta Hacker Cup; The ICPC International Collegiate Programming Contest; Mirzayanov M., Codeforces: Results of 2020 [Annual Report] - Codeforces, (2021); Juergens E., Deissenboeck F., Hummel B., Code similarities beyond copy & paste, European Conference on Software Maintenance and Reengineering (CSMR), (2010); Memory-profiler · pypi, (2022); Ross A., Willson V.L., Independent Samples T-Test, pp. 13-16, (2017); Cohen J., Statistical Power Analysis for the Behavioral Sciences, (1988); Harris C.R., Millman K.J., Walt Der Van S.J., Gommers R., Virtanen P., Cournapeau D., Wieser E., Et al., Array programming with NumPy, Nature, 585, 7825, pp. 357-362, (2020); Virtanen P., Gommers R., Oliphant T.E., Haberland M., Reddy T., Cournapeau D., Burovski E., Peterson P., Et al., SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python, Nature Methods, 17, pp. 261-272, (2020); Researchpy - pypi, (2022); Deepmind/code contests; Rahman M., Palani D., Rigby P.C., Natural Software Revisited, International Conference on Software Engineering (ICSE), pp. 37-48, (2019)","","Institute of Electrical and Electronics Engineers Inc.","","16th IEEE International Workshop on Software Clones, IWSC 2022","2 October 2022 through 7 October 2022","Limassol","185150","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85145783649"
"Siksna M.; Berzina I.; Romanovs A.","Siksna, Markuss (58766633700); Berzina, Ilze (58766694600); Romanovs, Andrejs (24438402800)","58766633700; 58766694600; 24438402800","Machine Learning Powered Code Smell Detection as a Business Improvement Tool","2023","2023 IEEE 64th International Scientific Conference on Information Technology and Management Science of Riga Technical University, ITMS 2023 - Proceedings","","","","","","","0","10.1109/ITMS59786.2023.10317724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179895007&doi=10.1109%2fITMS59786.2023.10317724&partnerID=40&md5=0f270196aee73ed9d2b84bfb9c1e00b8","Code smell represents the level of human interpretability in a software project, which becomes increasingly challenging as modern-day software projects grow in complexity. Machine learning has promising signs of solving the problem of code smell detection but will ultimately be limited by the training dataset of the model. This paper investigates some machine learning approaches for code smell detection, the implications of using such a system, integration with business processes and how such a system would fit into IT governance using Latvia as an example.  © 2023 IEEE.","business improvement; code smells; machine learning; technical debt","Codes (symbols); Odors; Business improvements; Code smell; Improvement tools; Interpretability; Machine learning approaches; Machine-learning; Software project; System integration; Technical debts; Training dataset; Machine learning","Lewowski T., Madeyski L., Code smells detection using artificial intelligence techniques: A business-driven systematic review, Developments in Information & Knowledge Management for Business Applications, 377, pp. 285-319, (2022); Mantyla M.V., Vanhanen J., Lassenius C., Bad smells - humans as code critics, 20th IEEE International Conference on Software Maintenance, 2004. Proceedings., pp. 399-408, (2004); Lafi M., Botros J.W., Kafaween H., Al-Dasoqi A.B., Al-Tamimi A., Code smells analysis mechanisms, detection issues, and effect on software maintainability, 2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT), pp. 663-666, (2019); Yamashita A., Moonen L., To what extent can maintenance problems be predicted by code smell detection? - An empirical study, Information and Software Technology, 55, 12, pp. 2223-2242, (2013); Bessghaier N., Ouni A., Mkaouer M.W., On the diffusion and impact of code smells in web applications, Services Computing - SCC 2020, pp. 67-84, (2020); Aniche M., Bavota G., Treude C., Et al., Code smells for Model-View- Controller architectures, Empir. Software Eng., 23, pp. 2121-2157, (2018); Khomh F., Di Penta M., Gueheneuc Y.-G., An exploratory study of the impact of code smells on software change-proneness, 2009 16th Working Conference on Reverse Engineering, pp. 75-84, (2009); Vashisht R., An empirical analysis of code smell and code restructuring in python, Virtual Technologies and E-Collaboartion for the Future of Global Businesses, pp. 203-213, (2023); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 612-621, (2018); Azeem M.I., Palomba F., Shi L., Wang Q., Machine learning techniques for code smell detection: A systematic literature review and meta-analysis, Information and Software Technology, 108, pp. 115-138, (2019); Haidabrus B., Druzhinin E., Psarov O., Taxonomy of risks in software development projects, 2022 63rd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS), pp. 1-7, (2022); Bhandari G.P., Gupta R., Measuring the fault predictability of software using deep learning techniques with software metrics, 2018 5th IEEE Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON), pp. 1-6, (2018); Tarwani S., Chug A., Application of deep learning models for code smell prediction, 2022 10th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), pp. 1-5, (2022); Zhang Y., Ge C., Hong S., Tian R., Dong C., Liu J., DeleSmell: Code smell detection based on deep learning and latent semantic analysis, Knowledge-Based Systems, 255, (2022); Codabux Z., Williams B., Managing technical debt: An industrial case study, 2013 4th International Workshop on Managing Technical Debt (MTD), pp. 8-15, (2013); Tufano M., Et al., When and why your code starts to smell bad (and whether the smells go away), IEEE Transactions on Software Engineering, 43, 11, pp. 1063-1088, (2017); Seaman C., Et al., Using technical debt data in decision making: Potential decision approaches, 2012 Third International Workshop on Managing Technical Debt (MTD), pp. 45-48, (2012); Guo Y., Et al., Tracking technical debt - An exploratory case study, 2011 27th IEEE International Conference on Software Maintenance (ICSM), pp. 528-531, (2011); Osman M., The Business Consequences of Lousy Code, (2023); Buse R.P.L., Weimer W.R., Learning a metric for code readability, IEEE Transactions on Software Engineering, 36, 4, pp. 546-558, (2010); Goncarovs P., Active learning svm classification algorithm for complaints management process automatization, 2019 60th International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS), pp. 1-3, (2019); Podzins O., Romanovs A., It risk identification and assessment methodology, Environment. Technology. Resources: Proceedings of the 11th International Scientific and Practical Conference, pp. 124-127, (2017); The cost of poor software quality in the US: A 2020 report, (2020); The cost of poor software quality in the US: A 2022 report, (2022); Fontana F.A., Zanoni M., Marino A., Mantyla M.V., Code smell detection: Towards a machine learning-based approach, 2013 IEEE International Conference on Software Maintenance, pp. 396-399, (2013); Lu S., Et al., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, (2021); Tempero E., Et al., The qualitas corpus: A curated collection of java code for empirical studies, 2010 Asia Pacific Software Engineering Conference, pp. 336-345, (2010); Lear A.M., Dada E.G., Oyewola D., Joseph S., Ensemble machine learning model for software defect prediction, 2nd International Conference on Software Engineering and Intelligent Systems, pp. 11-21, (2021); Carlini N., Tramer F., Wallace E., Jagielski M., Herbert-Voss A., Lee K., Roberts A., Brown T., Song D., Erlingsson U., Oprea A., Raffel C., Extracting Training Data from Large Language Models, (2021); Xu F.F., Alon U., Neubig G., Hellendoorn V.J., A Systematic Evaluation of Large Language Models of Code, (2022); Siddiq M.L., Majumder S.H., Mim M.R., Jajodia S., Santos J.C.S., An empirical study of code smells in transformer-based code generation techniques, 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM), pp. 71-82, (2022); Dos Reis J.P., Abreu F.B., De Figueiredo C.G., Et al., Code smells detection and visualization: A systematic literature review, Arch Computat Methods Eng, 29, pp. 47-94, (2022); Madeyski L., Lewowski T., Detecting code smells using industryrelevant data, Information and Software Technology, 155, pp. 107-112, (2023); Yamashita A., Moonen L., Do developers care about code smells? An exploratory survey, 2013 20th Working Conference on Reverse Engineering (WCRE), pp. 242-251, (2013); Palomba F., Bavota G., Di Penta M., Oliveto R., De Lucia A., Do they really smell bad? A study on developers' perception of bad code smells, 2014 IEEE International Conference on Software Maintenance and Evolution, pp. 101-110, (2014); Walker A., Das D., Cerny T., Automated code-smell detection in microservices through static analysis: A case study, Applied Sciences, 10, 21, (2020); Yamashita A., Moonen L., Do code smells reflect important maintainability aspects?, 2012 28th IEEE International Conference on Software Maintenance (ICSM), pp. 306-315, (2012); Gaybrick W., Tech's ultimate success: Software developers are now more valuable to companies than money, (2018); Hacks S., Hofert H., Salentin J., Yeong Y.C., Lichter H., Towards the definition of enterprise architecture debts, 2019 IEEE 23rd International Enterprise Distributed Object Computing Workshop (EDOCW), pp. 9-16, (2019); Lehmann B.D., Alexander P., Lichter H., Hacks S., Towards the identification of process anti-patterns in enterprise architecture models, CEUR Workshop Proceedings, 2757(QuASoQ), pp. 47-54, (2020); Salentin J., Hacks S., Towards a catalog of enterprise architecture smells, WI2020 Community Tracks, (2020); Fogen K., Lichter H., An industrial case study on fault detection effectiveness of combinatorial robustness testing, CEUR Workshop Proceedings, 2767, pp. 29-36, (2020); Use of ICT in households (EPD010). Central Statistical Bureau of Latvia., (2022); Percentage of the ICT sector on GDP [TIN00074__custom_6367106]., (2023); Tom E., Aurum A., Vidgen R., An exploration of technical debt, Journal of Systems and Software, 86, 6, pp. 1498-1516, (2013); Tufano M., Et al., When and why your code starts to smell bad (and whether the smells go away), IEEE Transactions on Software Engineering, 43, 11, pp. 1063-1088, (2017); Sharma T., Jatain A., Bhaskar S., Pabreja K., Ensemble machine learning model for software defect prediction, Procedia Computer Science, 218, pp. 199-209, (2023); Teilans A., Romanovs A., Merkurjevs J., Dorogovs P., Kleins A., Potryasaev S., Assessment of cyber physical system risks with domain specific modelling and simulation, SPIIRAS Proceedings, 4, 1, pp. 115-139, (2018)","Grabis J.; Romanovs A.; Kulesova G.","Institute of Electrical and Electronics Engineers Inc.","Riga Technical University","2023 IEEE 64th International Scientific Conference on Information Technology and Management Science of Riga Technical University, ITMS 2023","5 October 2023 through 6 October 2023","Riga","194564","Conference paper","Final","","Scopus","2-s2.0-85179895007"
"Sarkar A.","Sarkar, Advait (56369758900)","56369758900","Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models","2023","Onward! 2023 - Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Co-located with: SPLASH 2023","","","","153","167","14","1","10.1145/3622758.3622882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174877165&doi=10.1145%2f3622758.3622882&partnerID=40&md5=dc9b77c8e72a9082502870dabc2964d2","The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which ""traditional""programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the ""generative shift hypothesis"": That generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.  © 2023 ACM.","attention investment model; end-user software customization; generative shift hypothesis; learning barriers; live programming; prompt engineering; self-efficacy","Codes (symbols); Learning systems; Attention investment model; End-user software customization; End-user softwares; Generative shift hypothesis; Investment models; Learning barriers; Live programming; Prompt engineering; Self efficacy; Software customization; User interfaces","Aghaee S., Blackwell A.F, Stillwell D., Kosinski M., 2015. Personality and intrinsic motivational factors in end-user programming, 2015 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, pp. 29-36; Alcott B., 2005 Jevons paradox, Ecological Economics, 54, 1, pp. 9-21, (2005); Arawjo I., 2020. to write code: The cultural fabrication of programming notation and practice, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-15; Austin J., Odena A., Nye M., Bosma M., Michalewski H., Dohan D., Jiang E., Cai C., Terry Quoc Le M., Et al., Program Synthesis with Large Language Models, 2021, (2021); Basman A., Church L., Nylandsted Klokmose C., Clark C.Bd, 2016. Software and How it Lives On-Embedding Live Programs in the World Around Them, PPIG, 19; Becker B.A, Denny P., Finnie-Ansley J., Luxton-Reilly A., Prather J., Antonio Santos E., 2023. Programming is hard-or at least it used to be: Educational opportunities and challenges of ai code generation, Proceedings of the 54th ACM Technical Symposium on Computer Science Education, 1, pp. 500-506; Beckwith L., Kissinger C., Burnett M., Wiedenbeck S., Lawrance J., Blackwell A., Cook C., Tinkering and gender in end-user programmers debugging, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 231-240, (2006); Bender E.M, Gebru T., McMillan-Major A., Shmitchell S., 2021. on the dangers of stochastic parrots: Can language models be too big, Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, pp. 610-623; Blackwell A., Chapter 13: Conclusion, MIT Press, (2022); Alan F.B., First steps in programming: A rationale for attention investment models, Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments. IEEE, pp. 2-10, (2002); Alan F.B., What is programming, PPIG. Citeseer, 20, (2002); Bommasani R., Hudson D.A, Adeli E., Altman R., Arora S., Von Arx S., Bernstein M.S, Bohg J., Bosselut A., Brunskill E., Et al., On the Opportunities and Risks of Foundation Models, 2021, (2021); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D, Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., 2020 Language models are few-shot learners, Advances in Neural Information Processing Systems, 33, 2020, pp. 1877-1901; Burnett M., Stumpf S., Macbeth J., Makri S., Beckwith L., Kwan I., Peters A., Jernigan W., 2016 GenderMag: A method for evaluating softwares gender inclusiveness, Interacting with Computers, 28, 6, pp. 760-787, (2016); Cai L., 2012 Latent variable modeling Shanghai Arch, Psychiatry, 24, 2, pp. 118-120; Chalhoub G., Sarkar A., 2022 Its Freedom to Put Things Where My Mind Wants"": Understanding and Improving the User Experience of Structuring Data in Spreadsheets, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, pp. 1-24; Collins N., McLean A., Rohrhuber J., Ward A., 2003 Live coding in laptop performance, Organised Sound, 8, 3, pp. 321-330, (2003); Coyle D., Moore J., Ola Kristensson P., Fletcher P., Blackwell A., 2012. i did that! Measuring users experience of agency in their own actions, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 2025-2034; Cypher A., Eager: Programming repetitive tasks by example, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 33-39, (1991); Cypher A., Conrad Halbert D., Watch What i Do: Programming by Demonstration, (1993); Peter J.D., 2017 Remaining trouble spots with computational thinking, Commun ACM, 60, 6, pp. 33-39, (2017); Denny P., Kumar V., Giacaman N., 2023. Conversing with copilot: Exploring prompt engineering for solving cs1 problems using natural language, Proceedings of the 54th ACM Technical Symposium on Computer Science Education, 1, pp. 1136-1142; Denny P., Prather J., Becker B.A, Finnie-Ansley J., Hellas A., Leinonen J., Luxton-Reilly A., Reeves B.N, Antonio Santos E., Sarsa S., Computing Education in the Era of Generative AI, 2023, (2023); Devlin J., Chang M., Lee K., Toutanova K., Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding, 2018, (2018); Eco U., The Search for the Perfect Language, (1997); Everitt B.S., An Introduction to Latent Variable Models 1 Ed, (1984); Fan Z., Gao X., Roychoudhury A., Hwei Tan S., Improving Automatically Generated Code from Codex Via Automated Program Repair, 2022, (2022); Fincher S., Petre M., Computer Science Education Research, (2004); Foucault M., Les Mots et les Choses: Une Archéologie des Sciences Humaines, (1966); Gorinova M.I, Sarkar A., Blackwell A.F, Syme D., 2016. A live, multiple-representation probabilistic programming environment for novices, Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp. 2533-2537; Green G T.R., Petre M., 1996. Usability analysis of visual programming environments: A cognitive dimensions framework, Journal of Visual Languages & Computing, 7, 2, pp. 131-174, (1996); Gulwani S., 2011. Automating string processing in spreadsheets using input-output examples, ACM Sigplan Notices, 46, 1, pp. 317-330, (2011); Hagiu A., Wright J., A Practical Guide to Building Ethical AI, (2020); Harrer S., 2023 Attention is not all you need: The complicated case of ethically using large language models in healthcare and medicine, EBioMedicine, 90, (2023); Hermans F., Pinzger M., Van Deursen A., 2011. Supporting professional spreadsheet users by generating leveled dataflow diagrams, Proceedings of the 33rd International Conference on Software Engineering, pp. 451-460; Hermans F., Pinzger M., Van Deursen A., 2015 Detecting and refactoring code smells in spreadsheet formulas, Empirical Software Engineering, 20, pp. 549-575, (2015); Jachimowicz J.M, Duncan S., Weber E.U., Johnson E.J., 2019 When and why defaults influence decisions: A meta-Analysis of default effects, Behavioural Public Policy, 3, 2, pp. 159-186, (2019); Jaimovitch-Lopez G., Ferri C., Hernandez-Orallo J., Martinez-Plumed F., Jose Ramirez-Quintana M., 2022 Can language models automate data wrangling, Machine Learning, pp. 1-30, (2022); Jain K., Tanimoto S.L, 2020. Integrating a Live Programming Role into Games, PPIG; Jakubovic J., Edwards J., Petricek T., Technical Dimensions of Programming Systems, 2023, (2023); Jernigan W., Horvath A., Lee M., Burnett M., Cuilty T., Kuttal S., Peters A., Kwan I., Bahmani F., Ko A., 2015. A principled evaluation for a principled Idea Garden, 2015 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, pp. 235-243; Jiang S., Wang Y., Wang Y., SelfEvolve: A Code Evolution Framework Via Large Language Models, 2023, (2023); Joharizadeh N., Sarkar A., Gordon A.D, Williams J., 2020. Gridlets: Reusing spreadsheet grids, Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-7; Kang S., Chen B., Yoo S., Lou J., Explainable Automated Debugging Via Large Language Model-driven Scientific Debugging, 2023, (2023); Kaplan J., McCandlish S., Henighan T., Brown T.B, Chess B., Child R., Gray S., Radford A., Wu J., Amodei D., Scaling Laws for Neural Language Models, 2020, (2020); Martin Katz D., James Bommarito M., Gao S., Arredondo P., Gpt-4 Passes the Bar Exam, (2023); Kautz H., 2022 the third AI summer: AAAI Robert S, Engelmore Memorial Lecture. AI Magazine, 43, 1, pp. 105-125, (2022); Beth Kery M., Myers B.A, 2017. Exploring exploratory programming, 2017 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, pp. 25-29; Kesan J.P, Shah R.C, 2006 Setting software defaults: Perspectives from law, computer science and behavioral economics, Notre Dame L. Rev, 82, (2006); Khatry A., Cahoon J., Henkel J., Deep S., Emani V., Floratou A., Gulwani S., Le Mohammad Raza V., Shi S., Et al., From Words to Code: Harnessing Data for Program Synthesis from Natural Language, (2023); Klasnja-Milicevic A., Vesin B., Ivanovic M., Budimac Z., 2011 Integration of recommendations and adaptive hypermedia into Java tutoring system, Computer Science and Information Systems, 8, 1, pp. 211-224, (2011); Klokmose C.N, Eagan J.R, Baader S., Mackay W., Beaudouin-Lafon M., 2015. Webstrates: Shareable dynamic media, Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology, pp. 280-290; Ko A.J, Abraham R., Beckwith Alan L., Margaret Burnett B., Erwig M., Scaffidi C., Lawrance J., Lieberman H., Myers B., Et al., The state of the art in end-user software engineering, ACM Computing Surveys (CSUR), 43, 3, pp. 1-44, (2011); Ko A.J, Myers B.A, Designing the whyline: A debugging interface for asking questions about program behavior, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 151-158, (2004); Ko A.J, Myers B.A, Htet Aung H., Six learning barriers in end-user programming systems, 2004 IEEE Symposium on Visual Languages-Human Centric Computing. IEEE, pp. 199-206, (2004); Krizhevsky A., Sutskever I., Hinton G.E, 2017 Imagenet classification with deep convolutional neural networks, Commun ACM, 60, 6, pp. 84-90, (2017); Kulesza T., Burnett M., Wong W., Stumpf S., 2015. Principles of explanatory debugging to personalize interactive machine learning, Proceedings of the 20th International Conference on Intelligent User Interfaces, pp. 126-137; Lasserre J.A, Bishop C.M, Minka T.P, Principled hybrids of generative and discriminative models, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR06, 1, pp. 87-94, (2006); Lau S., Srinivasa S., Ragavan S., Milne K., Barik T., Sarkar A., 2021. Tweakit: Supporting end-user programmers who transmogrify code, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-12; Lecun Y., Bengio Y., Hinton G., 2015 Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Liblit B., Begel A., Sweetser E., Cognitive Perspectives on the Role of Naming in Computer Programs, PPIG, 11, (2006); Lieberman H., Your Wish Is My Command: Programming by Example, (2001); Limerick H., Coyle D., Moore J.W., 2014 the experience of agency in human-computer interactions: A review, Frontiers in Human Neuroscience, 8, (2014); Xieyang Liu M., Sarkar A., Negreanu C., Zorn B., Williams J., Toronto N., Gordon A.D., 2023 What It Wants Me to Say"": Bridging the Abstraction Gap between End-User Programmers and Code-Generating Large Language Models, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (Hamburg, Germany) (CHI 23); Liu V., Chilton L.B, 2022. Design guidelines for prompt engineering text-To-image generative models, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, pp. 1-23; Wendy E.M., Triggers and barriers to customizing software, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 153-160, (1991); Mackenzie A., Machine Learners: Archaeology of A Data Practice, (2017); Macneil S., Tran A., Hellas A., Kim J., Sarsa S., Denny P., Bernstein S., Leinonen J., 2023. Experiences from using code explanations generated by large language models in a web software development e-book, Proceedings of the 54th ACM Technical Symposium on Computer Science Education, 1, pp. 931-937; Macneil S., Tran A., Leinonen J., Denny P., Kim J., Hellas A., Bernstein S., Sarsa S., Automatically Generating CS Learning Materials with Large Language Models, 2022, (2022); Manna Z., Waldinger R.J, 1971 Toward automatic program synthesis, Commun ACM, 14, 3, pp. 151-165, (1971); Metz D., 2021 Economic benefits of road widening: Discrepancy between outturn and forecast, Transportation Research Part A: Policy and Practice, 147, 2021, pp. 312-319; Donna J.M., 2018 Delusion of Control: Pushing Buttons, Medsurg Nursing, 27, 6, (2018); Miller T., 2019 Explanation in artificial intelligence: Insights from the social sciences, Artificial Intelligence, 267, pp. 1-38, (2019); Mishra S., Khashabi D., Baral C., Choi Y., Hajishirzi H., Reframing Instructional Prompts to GPTks Language, 2021, (2021); Morch A., Three levels of end-user tailoring: Customization, integration, and extension, Computers and Design in Context, 1997, 1997, (1997); Morgenthaler S., 2009. Exploratory data analysis, Wiley Interdisciplinary Reviews: Computational Statistics, 1, 1, pp. 33-44, (2009); Nouwens M., Nylandsted Klokmose C., 2018. the application and its consequences for non-standard knowledge work, Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 1-12; Okrent A., The Land of Invented Languages: Esperanto Rock Stars, Klingon Poets, Loglan Lovers, and the Mad Dreamers Who Tried to Build A Perfect Language, (2009); OpenAI, (2023); Ouyang L., Wu J., Jiang X., Almeida D., Wainwright C., Mishkin P., Zhang C., Agarwal S., Slama K., Ray A., Et al., 2022 Training language models to follow instructions with human feedback, Advances in Neural Information Processing Systems, 35, pp. 27730-27744, (2022); Pandita R., Parnin C., Hermans F., Murphy-Hill E., 2018. No half-measures: A study of manual and toolassisted end-user programming tasks in Excel, 2018 Ieee Symposium on Visual Languages and Human-centric Computing (Vl/hcc). IEEE, pp. 95-103; Petricek T., 2016. Programming language theory: Thinking the unthinkable (Work in progress, Proceedings of the Annual Conference of the Psychology of Programming Interest Group (PPIG; Petricek T., No-code, No Thought Substrates for Simple Programming for All, (2022); Potthast M., Hagen M., Stein B., 2021. the dilemma of the direct answer. in, Acm Sigir Forum, 54, pp. 1-12; Ramesh A., Pavlov M., Goh G., Gray S., Voss C., Radford A., Chen M., Sutskever I., 2021. Zero-shot text-To-image generation, International Conference on Machine Learning. PMLR, pp. 8821-8831; Resnick M., Maloney J., Monroy-Hernandez A., Rusk N., Eastmond E., Brennan K., Millner A., Rosenbaum E., Silver J., Silverman B., Et al., Scratch: Programming for all, Commun ACM, 52, 11, pp. 60-67, (2009); Revow M., Williams C.Ki, Hinton G.E, 1996. Using generative models for handwritten digit recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence, 18, 6, pp. 592-606, (1996); Rogers A., Kovaleva O., Rumshisky A., 2021 A primer in BERTology: What we know about how BERT works, Transactions of the Association for Computational Linguistics, 8, pp. 842-866, (2021); Sarkar A., 2022. Is explainable AI a race against model complexity, Workshop on Transparency and Explanations in Smart Systems (TeXSS), in Conjunction with, pp. 192-199; Sarkar A., 2023. Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots, Annual Symposium on Human-Computer Interaction for Work 2023 (CHIWORK 2023; Sarkar A., 2023. Should Computers Be Easy to Use Questioning the Doctrine of Simplicity in User Interface Design, Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems; Sarkar A., Gordon A.D, 2018. How do people learn to use spreadsheets (Work in progress, Proceedings of the 29th Annual Conference of the Psychology of Programming Interest Group (PPIG 2018, pp. 28-35; Sarkar A., Gordon A.D, 2018. How do people learn to use spreadsheets(Work in progress), PPIG; Sarkar A., Gordon A.D., Negreanu C., Poelitz C., Srinivasa Ragavan S., Zorn B., 2022. What is it like to program with artificial intelligence, Proceedings of the 33rd Annual Conference of the Psychology of Programming Interest Group (PPIG 2022; Sarkar A., Srinivasa Ragavan S., Williams J., Gordon A.D, 2022. End-user encounters with lambda abstraction in spreadsheets: Apollos bow or Achilles heel, 2022 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, pp. 1-11; Sarkar A., Spott M., Blackwell A.F, Jamnik M., 2016. Visual discovery and model-driven explanation of time series patterns, 2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). IEEE, pp. 78-86; Scaffidi C., Shaw M., Myers B., Estimating the numbers of end users and end user programmers, 2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC05). IEEE, pp. 207-214, (2005); Serban F., Vanschoren J., Kietz J., Bernstein A., A survey of intelligent assistants for data analysis, ACM Computing Surveys (CSUR), 45, 3, pp. 1-35, (2013); Sevilla J., Heim L., Ho A., Besiroglu T., Hobbhahn M., Villalobos P., 2022. Compute trends across three eras of machine learning, 2022 International Joint Conference on Neural Networks (IJCNN, pp. 1-8; Silver D., Huang A., Maddison C.J, Guez A., Sifre L., Van Den Driessche G., Schrittwieser J., Antonoglou I., Panneershelvam V., Lanctot M., Et al., 2016 Mastering the game of Go with deep neural networks and tree search, Nature, 529, 7587, pp. 484-489, (2016); Singh N., Bernal G., Savchenko D., Glassman E.L, 2022. Where to hide a stolen elephant: Leaps in creative writing with multimodal machine intelligence, ACM Transactions on Computer-Human Interaction, (2022); Solaiman I., Brundage M., Clark J., Askell A., Herbert-Voss A., Wu J., Radford A., Krueger G., Wook Kim J., Kreps S., Et al., Release Strategies and the Social Impacts of Language Models, 2019, (2019); Srinivasa Ragavan S., Kaur Kuttal S., Hill C., Sarma A., Piorkowski D., Burnett M., 2016. Foraging among an overabundance of similar variants, Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems, pp. 3509-3521; Srinivasa Ragavan S., Sarkar A., Gordon A.D, 2021. Spreadsheet comprehension: Guesswork, giving up and going back to the author, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, pp. 1-21; Stead A., Blackwell A.F, 2014. Learning syntax as notational expertise when using drawbridge, Proceedings of the Psychology of Programming Interest Group Annual Conference (PPIG 2014, pp. 41-52; Strobelt H., Webson A., Sanh V., Hoover B., Beyer J., Pfister H., Rush A.M, 2022. Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models, IEEE Transactions on Visualization and Computer Graphics, 29, 1, pp. 1146-1156, (2022); Sumner T., Stolze M., Evolution, Not Revolution: Participatory Design in the Toolbelt Era, (1997); Tafur B., Sarkar A., User Perceptions of Automatic Fake News Detection: Can Algorithms Fight Online Misinformation, (2023); Tamkin A., Brundage M., Clark J., Ganguli D., Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models, 2021, (2021); Steven L.T., 2013. A perspective on the evolution of live programming, 2013 1st International Workshop on Live Programming (LIVE, pp. 31-34; Steven L.T., 2020. Multiagent live programming systems: Models and prospects for critical applications, Companion Proceedings of the 4th International Conference on Art, Science, and Engineering of Programming, pp. 90-96; Touvron H., Lavril T., Izacard G., Martinet X., Lachaux M., Lacroix T., Roziere B., Goyal N., Hambro E., Azhar F., Et al., Llama: Open and Efficient Foundation Language Models, 2023, (2023); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N, Kaiser L., Polosukhin I., 2017 Attention is all you need, Advances in Neural Information Processing Systems, 30, (2017); Villalobos P., Sevilla J., Heim L., Besiroglu T., Hobbhahn M., Ho A., Will We Run out of Data An Analysis of the Limits of Scaling Datasets in Machine Learning, 2022, (2022); Vos D., Dohmen T., Schelter S., 2022. Towards Parameter-Efficient Automation of DataWrangling Tasks with Prefix-Tuning, NeurIPS 2022 First Table Representation Workshop; Wang Y., Wang W., Joty S., Ch Hoi S., Codet5: Identifier-Aware Unified Pre-Trained Encoder-decoder Models for Code Understanding and Generation, (2021); Weidinger L., Mellor J., Rauh M., Griffin C., Uesato J., Huang P., Cheng M., Glaese M., Balle B., Kasirzadeh A., Et al., Ethical and Social Risks of Harm from Language Models, 2021, (2021); White J., Fu Q., Hays S., Sandborn M., Olea C., Gilbert H., Elnashar A., Spencer-Smith J., Schmidt D.C, A Prompt Pattern Catalog to Enhance Prompt Engineering with Chatgpt, 2023, (2023); Wiedenbeck S., Labelle D., Kain V.N.R., Factors affecting course outcomes in introductory programming, PPIG, 11, (2004); Wilson A., Burnett M., Beckwith L., Granatir O., Casburn L., Cook C., Durham M., Rothermel G., Harnessing curiosity to increase correctness in end-user programming, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 305-312, (2003); Jeannette M.W., Computational thinking, Commun ACM, 49, 3, pp. 33-35, (2006); Zhang N., Huang G., Zhang Y., Jiang N., Mei H., 2010. Towards Automated Synthesis of Executable Eclipse Tutorials, SEKE, pp. 591-598","van der Storm T.; Hirschfeld R.","Association for Computing Machinery, Inc","ACM SIGAda; ACM SIGPLAN","2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, Onward! 2023, co-located with SPLASH 2023","25 October 2023 through 27 October 2023","Cascais","193980","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85174877165"
"Bock M.; Habchi S.; Nayrolles M.; Cito J.","Bock, Markus (58515926500); Habchi, Sarra (57195317140); Nayrolles, Mathieu (55448059500); Cito, Jurgen (56495364200)","58515926500; 57195317140; 55448059500; 56495364200","Performance Prediction from Source Code Is Task and Domain Specific","2023","IEEE International Conference on Program Comprehension","2023-May","","","35","42","7","0","10.1109/ICPC58990.2023.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166377472&doi=10.1109%2fICPC58990.2023.00015&partnerID=40&md5=a4ff9ecd6a9fa70c2f2a2596f50c3635","Performance is key to the success and adoption of software systems. In video games, performance is commonly highlighted as one of the top quality concerns raised by players. To check the performance of their systems, development teams tend to rely on profiling and monitoring tools, which observe program executions to identify regressions. The usage of static analysis tools for this purpose has been so far limited. Lately, the success of Large Language Models in many code analytics tools led to attempts to leverage them in static performance analysis. These studies showed promising results in predicting runtime and regressions on large public datasets. In this paper, we evaluate the usability of such models in practice, and particularly in the domain of video games. We train a state-of-the-art neural network on the Code4Bench dataset to predict runtime regressions for programming competition programs, then evaluate its ability to generalize to new domains. Our results show that these models achieve great results (e.g. 95.73% accuracy for performance comparison) on the original domain for programs solving in-sample programming tasks, yet fail to generalize to out-of-sample tasks. Furthermore, we show that transfer techniques such as domain adversarial adaptation and model fine-tuning are not sufficient to transfer these models to the target industrial domain of AAA games.  © 2023 IEEE.","Deep Learning; Defect Prediction; Repository Mining; Software performance","Codes (symbols); Deep learning; Forecasting; Human computer interaction; Large dataset; Regression analysis; Deep learning; Defect prediction; Domain specific; Performance; Performance prediction; Repository mining; Runtimes; Software performance; Source codes; Video-games; Static analysis","Balsamo S., Marco A., Inverardi P., Model-based performance prediction in software development: A survey, Software Engineering, IEEE Transactions on, 30, pp. 295-310, (2004); Thota M.K., Shajin F.H., Rajesh P., Et al., Survey on software defect prediction techniques, International Journal of Applied Science and Engineering, 17, 4, pp. 331-344, (2020); Kamei Y., Shihab E., Adams B., Hassan A.E., Mockus A., Sinha A., Ubayashi N., A large-scale empirical study of just-in-time quality assurance, IEEE Transactions on Software Engineering, 39, 6, pp. 757-773, (2012); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Transactions on Software Engineering, 46, 12, pp. 1267-1293, (2018); Nayrolles M., Hamou-Lhadj A., Clever: Combining code metrics with clone detection for just-in-time fault prevention and resolution in large industrial projects, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 153-164, (2018); Beller M., Li H., Nair V., Murali V., Ahmad I., Cito J., Carlson D., Aye A., Dyer W., Learning to learn to predict performance regressions in production at meta, (2022); Ha H., Zhang H., Deepperf: Performance prediction for configurable software with deep sparse neural network, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 1095-1106, (2019); Cito J., Leitner P., Bosshard C., Knecht M., Mazlami G., Gall H.C., Performancehat: Augmenting source code with runtime performance traces in the ide, Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings, pp. 41-44, (2018); Yang C., Accelerating redundancy-based program repair via code representation learning and adaptive patch filtering, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1672-1674, (2021); Shi Y., Mao T., Barnes T., Chi M., Price T.W., More with less: Exploring how to use deep learning effectively through semisupervised learning for automatic bug detection in student code, Proceedings of the 14th International Conference on Educational Data Mining (EDM) 2021, (2021); Fokam M.A., Ajoodha R., Influence of contrastive learning on source code plagiarism detection through recursive neural networks, 2021 3rd International Multidisciplinary Information Technology and Engineering Conference (IMITEC). IEEE, pp. 1-6, (2021); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019); Ganin Y., Ustinova E., Ajakan H., Germain P., Larochelle H., Laviolette F., Marchand M., Lempitsky V., Domain-adversarial training of neural networks, The journal of machine learning research, 17, 1, pp. 2096-2130, (2016); Torrey L., Shavlik J., Transfer learning, Handbook of research on machine learning applications and trends: Algorithms, methods, and techniques., pp. 242-264, (2010); Radjenovic D., Hericko M., Torkar R., Zivkovic A., Software fault prediction metrics: A systematic literature review, Information and software technology, 55, 8, pp. 1397-1418, (2013); Shivaji S., Whitehead E.J., Akella R., Kim S., Reducing features to improve code change-based bug prediction, IEEE Transactions on Software Engineering, 39, 4, pp. 552-569, (2012); Sliwerski J., Zimmermann T., Zeller A., When do changes induce fixes?, ACM sigsoft software engineering notes, 30, 4, pp. 1-5, (2005); Tan M., Tan L., Dara S., Mayeux C., Online defect prediction for imbalanced data, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 2, pp. 99-108, (2015); Dipietro S., Casale G., Serazzi G., A queueing network model for performance prediction of apache cassandra, (2017); King P., Pooley R., Derivation of petri net performance models from uml specifications of communications software, International Conference on Modelling Techniques and Tools for Computer Performance Evaluation., pp. 262-276, (2000); Hermanns H., Herzog U., Katoen J.-P., Process algebra for performance evaluation, Theor. Comput. Sci., 274, pp. 43-87, (2002); Arief L., Speirs N., A uml tool for an automatic generation of simulation programs., pp. 71-76, (2000); Shang W., Hassan A.E., Nasser M., Flora P., Waterloo B., Ontario C., Automated detection of performance regressions using regression models on clustered performance counters, (2015); Didona D., Quaglia F., Romano P., Torre E., Enhancing performance prediction robustness by combining analytical modeling and machine learning, (2015); Zhou M., Chen J., Hu H., Yu J., Li Z., Hu H., Deeptle: Learning code-level features to predict code performance before it runs, 2019 26th Asia-Pacific Software Engineering Conference (APSEC). IEEE, pp. 252-259, (2019); Ramadan T., Islam T.Z., Phelps C., Pinnow N., Thiagarajan J.J., Comparative code structure analysis using deep learning for performance prediction, 2021 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS). IEEE, pp. 151-161, (2021); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI conference on artificial intelligence, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code., IJCAI, pp. 3034-3040, (2017); Samoaa H.P., Bayram F., Salza P., Leitner P., A systematic mapping study of source code representation for deep learning in software engineering, IET Software, (2022); Majd A., Vahidi-Asl M., Khalilian A., Baraani-Dastjerdi A., Zamani B., Code4bench: A multidimensional benchmark of codeforces data for different program analysis techniques, Journal of Computer Languages, 53, pp. 38-52, (2019); Bahdanau D., Cho K., Bengio Y., Neural machine translation by jointly learning to align and translate, (2014); Bergmeir C., Benitez J.M., On the use of cross-validation for time series predictor evaluation, Information Sciences, 191, pp. 192-213, (2012); Hossin M., A review on evaluation metrics for data classification evaluations, International Journal of Data Mining & Knowledge Management Process, 5, pp. 1-11, (2015); Song Q., Guo Y., Shepperd M., A comprehensive investigation of the role of imbalanced learning for software defect prediction, IEEE Transactions on Software Engineering, 45, 12, pp. 1253-1269, (2018); Hanley J.A., McNeil B.J., The meaning and use of the area under a receiver operating characteristic (roc) curve, Radiology, 143, 1, pp. 29-36, (1982); Bishop C.M., Pattern recognition, Machine learning, 128, 9, (2006)","","IEEE Computer Society","","31st IEEE/ACM International Conference on Program Comprehension, ICPC 2023","15 May 2023 through 16 May 2023","Melbourne","190686","Conference paper","Final","","Scopus","2-s2.0-85166377472"
"Liventsev V.; Grishina A.; Härmä A.; Moonen L.","Liventsev, Vadim (57211206632); Grishina, Anastasiia (57205678390); Härmä, Aki (6701367190); Moonen, Leon (7003285889)","57211206632; 57205678390; 6701367190; 7003285889","Fully Autonomous Programming with Large Language Models","2023","GECCO 2023 - Proceedings of the 2023 Genetic and Evolutionary Computation Conference","","","","1146","1155","9","2","10.1145/3583131.3590481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167675554&doi=10.1145%2f3583131.3590481&partnerID=40&md5=f29a3409330818628b6cd1f2ca13f55a","Current approaches to program synthesis with Large Language Models (LLMs) exhibit a ""near miss syndrome"": They tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade-offs empirically, comparing replace-focused, repair-focused, and hybrid debug strategies, as well as different template-based and model-based prompt-generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches.  © 2023 Owner/Author(s).","automatic programming; large language models; program repair","Automatic programming; Computational linguistics; Economic and social effects; Genetic algorithms; Program debugging; Repair; Software testing; 'current; Language model; Large language model; Metric evaluation; Near-misses; Program repair; Program synthesis; Repair phasis; Similarity metrics; Text similarity; Genetic programming","Manna Z., Waldinger R.J., Toward Automatic Program Synthesis, Communications of the ACM, 14, 3, pp. 151-165, (1971); Bastani O., Inala J.P., Solar-Lezama A., Interpretable, Verifiable, and Robust Reinforcement Learning Via Program Synthesis, pp. 207-228, (2022); Dhar S., Guo J., Liu J., Tripathi S., Kurup U., Shah M., A Survey of On-Device Machine Learning: An Algorithms and Learning Theory Perspective, ACM Transactions on Internet of Things, 2, 3, pp. 1-49, (2021); Connolly T.M., Soflano M., Papadopoulos P., Systematic Literature Review: XAI and Clinical Decision Support, Diverse Perspectives and State-of-The-Art Approaches to the Utilization of Data-Driven Clinical Decision Support Systems. IGI Global, pp. 161-188, (2023); Jia Y., McDermid J., Lawton T., Habli I., The Role of Explainability in Assuring Safety of Machine Learning in Healthcare, IEEE Transactions on Emerging Topics in Computing, 10, 4, pp. 1746-1760; Manna Z., Waldinger R., Fundamentals of Deductive Program Synthesis, IEEE Transactions on Software Engineering, 18, 8, pp. 674-704, (1992); Alur R., Et al., Syntax-Guided Synthesis, Dependable Software Systems Engineering, pp. 1-25, (2015); Ahvanooey M.T., Li Q., Wu M., Wang S., A Survey of Genetic Programming and Its Applications, KSII Transactions on Internet and Information Systems (TIIS, 13, 4, pp. 1765-1794, (2019); Chen M., Et al., Evaluating Large Language Models Trained on Code; Li Y., Et al., Competition-Level Code Generation with AlphaCode, Science, 378, 6624, pp. 1092-1097; Ren S., Et al., CodeBLEU: A Method for Automatic Evaluation of Code Synthesis, ArXiv 2009 10297, (2020); Bavishi R., Joshi H., Cambronero J., Fariha A., Gulwani S., Le V., Radicek I., Tiwari A., Neurosymbolic Repair for Low-Code Formula Languages, OOPSLA, (2022); Allamanis M., Barr E.T., Devanbu P., Sutton C., A Survey of Machine Learning for Big Code and Naturalness, ACMComputing Surveys, 51, 4, pp. 811-8137, (2018); Chen X., Song D., Tian Y., Latent Execution for Neural Program Synthesis beyond Domain-Specific Languages, Advances in Neural Information Processing Systems, 34, pp. 22196-22208, (2021); Polozov O., Gulwani S., FlashMeta: A Framework for Inductive Program Synthesis OOPSLA. OOPSLA, pp. 107-126, (2015); Liventsev V., Ha A., Petkovi M., BF++: A Language for General-Purpose Program Synthesis, arXiv.2101.09571; Grigorescu S., Trasnea B., Cocias T., Macesanu G., A Survey of Deep Learning Techniques for Autonomous Driving, Journal of Field Robotics, 37, 3, pp. 362-386, (2020); Marcano M., Di S., Perez J., Irigoyen E., A Review of Shared Control for Automated Vehicles: Theory and Applications, IEEE Transactions on Human-Machine Systems, 50, 6, pp. 475-491, (2020); Lu S., Et al., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, (2021); Niu C., Li C., Ng V., Luo B., CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code Models, ArXiv 2302.04030; Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet Challenge: Evaluating the State of Semantic Code Search, ArXiv 1909 09436, (2020); Roziere B., Lachaux M.-A., Lample G., Chanussot L., Unsupervised Translation of Programming Languages, 34th Conference on Neural Information Processing Systems, (2020); Fernandes E., Oliveira J., Vale G., Paiva T., Figueiredo E., A Review-Based Comparative Study of Bad Smell Detection Tools, Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering, pp. 1-12, (2016); Chakraborty S., Krishna R., Ding Y., Ray B., Deep Learning Based Vulnerability Detection: Are We There Yet, IEEE Transactions on Software Engineering, 48, 9, pp. 3280-3296; Petke J., Haraldsson S.O., Harman M., Langdon W.B., White D.R., Woodward J.R., Genetic Improvement of Software: A Comprehensive Survey, IEEE Transactions on Evolutionary Computation, 22, 3, pp. 415-432, (2018); Le Goues C., Pradel M., Roychoudhury A., Automated Program Repair, Communications of the ACM, 62, 12, pp. 56-65, (2019); Gupta K., Christensen P.E., Chen X., Song D., Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis, Advances in Neural Information Processing Systems, 33, pp. 17685-17695, (2020); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Mapping Language to Code in Programmatic Context, ArXiv 1808 09588, (2018); Halbert D.C., Programming by Example, (1984); Gulwani S., Programming by Examples And Its Applications in Data Wrangling, (2016); Zavershynskyi M., Skidanov A., Polosukhin I., NAPS: Natural Program Synthesis Dataset, ArXiv 1807 0316, (2018); Ouyang L., Et al., Training Language Models to Follow Instructions with Human Feedback, arXiv.2203.02155; Fan Z., Gao X., Mirchev M., Roychoudhury A., Tan S.H., Automated Repair of Programs from Large Language Models, arXiv.2205.10583; Blain J., Nine Worlds of Seid-magic: Ecstasy and Neo-shamanism in North European Paganism, (2002); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser A., Polosukhin I., Attention Is All You Need, International Conference on Neural Information Processing Systems (NeurIPS), pp. 5998-6008, (2017); De Bruin S., Liventsev V., Petkovi M., Autoencoders as Tools for Program Synthesis, ArXiv 2108.07129; Koza J.R., Genetic Programming II, 17, (1994); Jack N., Van Der Schouten D.F., Optimal Repair-Replace Strategies for a Warranted Product, International Journal of Production Economics, 67, 1, pp. 95-100, (2000); Russell S.J., Artificial Intelligence A Modern Approach, (2010); Joshi H., Cambronero J., Gulwani S., Le V., Radicek I., Verbruggen G., Repair Is Nearly Generation: Multilingual Program Repair with LLMs, ArXiv 2208.11640; Shrivastava D., Larochelle H., Tarlow D., Repository-Level Prompt Generation for Large Language Models of Code, arXiv.2206.12839; Huang Q., Yuan Z., Xing Z., Xu X., Zhu L., Lu Q., Prompt-Tuned Code Language Model as a Neural Knowledge Base for Type Inference in Statically-Typed Partial Code, arXiv.2208.05361; Ahmad B., Thakur S., Tan B., Karri R., Pearce H., Fixing Hardware Security Bugs with Large Language Models, ArXiv 2302 01215; Lin D., Koppel J., Chen A., Solar-Lezama A., QuixBugs: A Multi-Lingual Program Repair Benchmark Set Based on the Quixey Challenge, Companion of the SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity. Vancouver BC Canada ACM, pp. 55-56, (2017); Prenner J.A., Babii H., Robbes R., Can OpenAI?s Codex Fix Bugs: An Evaluation on QuixBugs, IEEE/ACM International Workshop on Automated Program Repair (APR), pp. 69-75, (2022); Sobania D., Briesch M., Hanna C., Petke J., An Analysis of the Automatic Bug Fixing Performance of ChatGPT, ArXiv 2301 08653; Kuznia K., Mishra S., Parmar M., Baral C., Less Is More: Summary of Long Instructions Is Better for Program Synthesis, arXiv.2203.08597; Helmuth T., Kelly P., Applying Genetic Programming to PSB2: The next Generation Program Synthesis Benchmark Suite, Genetic Programming and Evolvable Machines, 23, 3, pp. 375-404; Helmuth T., Spector L., Problem-Solving Benefits of Down-Sampled Lexicase Selection, Artificial Life, 27, 3-4, pp. 183-203; Helmuth T., Spector L., General Program Synthesis Benchmark Suite, Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation. Madrid Spain, pp. 1039-1046; Sobania D., Briesch M., Rothlauf F., Choose Your Programming Copilot: A Comparison of the Program Synthesis Performance of Github Copilot and Genetic Programming, Proceedings of the Genetic and Evolutionary Computation Conference, pp. 1019-1027; Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the Keyboard Assessing the Security of GitHub Copilot?s Code Contributions, arXiv.2108.09293","","Association for Computing Machinery, Inc","ACM SIGEVO","2023 Genetic and Evolutionary Computation Conference, GECCO 2023","15 July 2023 through 19 July 2023","Lisbon","190712","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85167675554"
"del-Hoyo-Gabaldon J.-A.; Moreno-Cediel A.; Garcia-Lopez E.; Garcia-Cabot A.; de-Fitero-Dominguez D.","del-Hoyo-Gabaldon, Jesus-Angel (58868411800); Moreno-Cediel, Antonio (58868517100); Garcia-Lopez, Eva (55841353100); Garcia-Cabot, Antonio (55037309200); de-Fitero-Dominguez, David (58813960500)","58868411800; 58868517100; 55841353100; 55037309200; 58813960500","Automatic dataset generation for automated program repair of bugs and vulnerabilities through SonarQube","2024","SoftwareX","26","","101664","","","","0","10.1016/j.softx.2024.101664","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185720307&doi=10.1016%2fj.softx.2024.101664&partnerID=40&md5=fea436f6f025a2e818003f2124680192","Software maintenance is an important and expensive stage during software development. Most of these tasks are done manually with static code analyzers, but this might change if new Artificial Intelligence approaches were used. For this purpose, huge amounts of data are extremely necessary to achieve a good performance by using traditional Data Science and Deep Learning techniques. Accordingly, this paper presents a software capable of creating, automatically, customizable coding error datasets in JSON format by using the SonarQube static analyzer. Consequently, coding error datasets could be easily created, encouraging new maintenance approaches (e.g., automated program repair through Deep Learning Models). © 2024 The Author(s)","Artificial intelligence; Automated program repair; Automatic dataset generation; Machine learning; Natural language processing; SonarQube","Automation; Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Program debugging; Repair; Automated program repair; Automatic dataset generation; Language processing; Learning techniques; Machine-learning; Natural language processing; Natural languages; Performance; Sonarqube; Static codes; Software design","Bourque P., Fairley R.E., SWEBOK: guide to the software engineering body of knowledge, (2014); ISO/IEC/IEEE international standard - Systems and software engineering – software life cycle processes, pp. 1-157, (2017); Louridas P., Static code analysis, IEEE Softw, 23, 4, pp. 58-61, (2006); Novak J., Krajnc A., Zontar R., Taxonomy of static code analysis tools, The 33rd International Convention MIPRO, pp. 418-422, (2010); Johnson S.C., Hill M., (1978); Avizienis A., Laprie J.-C., Randell B., Landwehr C., Basic concepts and taxonomy of dependable and secure computing, IEEE Trans Dependable Secure Comput, 1, 1, pp. 11-33, (2004); Zeller A., Automated debugging: are we close, Computer (Long Beach Calif), 34, 11, pp. 26-31, (2001); Renieres M., Reiss S.P., Fault localization with nearest neighbor queries, 18th IEEE International Conference on Automated Software Engineering, pp. 30-39, (2003); Arcuri A., On the automation of fixing software bugs, Companion of the 30th international conference on Software engineering, pp. 1003-1006, (2008); Forrest S., Nguyen T., Weimer W., Goues C.L., A genetic programming approach to automated software repair, Proceedings of the 11th Annual conference on Genetic and evolutionary computation, pp. 947-954, (2009); ISO/IEC 23643:2020, Software and systems engineering — capabilities of software safety and security verification tools, (2023); Security hotspot, (2023); Fowler M., Refactoring : improving the design of existing code, The Addison-Wesley object technology series, (1999); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., VulPecker: an automated vulnerability detection system based on code similarity analysis, Proceedings of the 32nd Annual Conference on Computer Security Applications, in ACSAC ’16, pp. 201-213, (2016); Harer J.A., Kim L.Y., Russell R.L., Ozdemir O., Kosta L.R., Rangamani A., Et al., Automated software vulnerability detection with machine learning, (2018); Harer J., Ozdemir O., Lazovich T., Reale C., Russell R., Kim L., Et al., Learning to repair software vulnerabilities with generative adversarial networks, Advances in neural information processing systems, (2018); Fu M., Tantithamthavorn C., Le T., Nguyen V., Phung D., VulRepair: a T5-based automated software vulnerability repair, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 935-947, (2022); Liu H., Jin J., Xu Z., Zou Y., Bu Y., Zhang L., Deep learning based code smell detection, IEEE Trans Softw Eng, 47, 9, pp. 1811-1837, (2021); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: are we there yet?, IEEE Trans Softw Eng, 48, 9, pp. 3280-3296, (2022); Lewowski T., Madeyski L., Code smells detection using artificial intelligence techniques: a business-driven systematic review, Developments in information & knowledge management for business applications, pp. 285-319, (2022); (2023); Workshop B., Scao T.L., Fan A., Akiki C., Pavlick E., Ilic S., Et al., BLOOM: a 176B-parameter open-access multilingual language model, (2023); Touvron H., Lavril T., Izacard G., Martinet X., Lachaux M.-A., Lacroix T., Et al., LLaMA: open and efficient foundation language models, (2023); Touvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei Y., Et al., Llama 2: open foundation and fine-tuned chat models, (2023); Zhang J., Cambronero J., Gulwani S., Le V., Piskac R., Soares G., Et al., Repairing bugs in python assignments using large language models, (2022); Chen M., Tworek J., Jun H., Yuan Q., de H.P., Pinto O., Kaplan J., Et al., Evaluating large language models trained on code, (2021); Pearce H., Tan B., Ahmad B., Karri R., Dolan-Gavitt B., Examining zero-shot vulnerability repair with large language models, 2023 IEEE Symposium on Security and Privacy (SP), pp. 2339-2356, (2023); Kassianik P., Nijkamp E., Pang B., Zhou Y., Xiong C., BigIssue: a realistic bug localization benchmark, (2023); Lenarduzzi V., Sillitti A., Taibi D., A survey on code analysis tools for software maintenance prediction, Proceedings of 6th International Conference in Software Engineering for Defence Applications, pp. 165-175, (2020); Marcilio D., Bonifacio R., Monteiro E., Canedo E., Luz W., Pinto G., Are static analysis violations really fixed? A closer look at realistic usage of SonarQube, 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC), pp. 209-219, (2019); Wang J., Huang Y., Wang S., Wang Q., Find bugs in static bug finders, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, in ICPC ’22, pp. 516-527, (2022); Lenarduzzi V., Lomio F., Huttunen H., Taibi D., Are SonarQube rules inducing bugs?, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 501-511, (2020); Rogers R.D., Monsell S., Costs of a predictible switch between simple cognitive tasks, J Exp Psychol, 124, 2, pp. 207-231, (1995); Data science and its relationship to big data and data-driven decision making, (2023); (2023); Alzubaidi L., Zhang J., Humaidi A.J., Al-Dujaili A., Duan Y., Al-Shamma O., Et al., Review of deep learning: concepts, CNN architectures, challenges, applications, future directions, J Big Data, 8, 1, (2021); Hellendoorn V.J., Sutton C., Singh R., Maniatis P., Bieber D., Global relational models of source code, presented at the International Conference on Learning Representations, (2019); Vasic M., Kanade A., Maniatis P., Bieber D., Singh R., Neural program repair by jointly learning to localize and repair, presented at the International Conference on Learning Representations, (2018); Jin M., Shahriar S., Tufano M., Shi X., Lu S., Sundaresan N., Et al., InferFix: end-to-end program repair with LLMs, (2023)","","Elsevier B.V.","","","","","","Article","Final","","Scopus","2-s2.0-85185720307"
"Guo Z.; Tan T.; Liu S.; Liu X.; Lai W.; Yang Y.; Li Y.; Chen L.; Dong W.; Zhou Y.","Guo, Zhaoqiang (57215669817); Tan, Tingting (57469859700); Liu, Shiran (57219357086); Liu, Xutong (57652393500); Lai, Wei (58479532700); Yang, Yibiao (55883652400); Li, Yanhui (55992301500); Chen, Lin (57189042207); Dong, Wei (57190581192); Zhou, Yuming (57022538800)","57215669817; 57469859700; 57219357086; 57652393500; 58479532700; 55883652400; 55992301500; 57189042207; 57190581192; 57022538800","Mitigating False Positive Static Analysis Warnings: Progress, Challenges, and Opportunities","2023","IEEE Transactions on Software Engineering","49","12","3329667","5154","5188","34","0","10.1109/TSE.2023.3329667","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180268008&doi=10.1109%2fTSE.2023.3329667&partnerID=40&md5=22e040c68f6b58bc55e501723f6740e8","Static analysis (SA) tools can generate useful static warnings to reveal the problematic code snippets in a software system without dynamically executing the corresponding source code. In the literature, static warnings are of paramount importance because they can easily indicate specific types of software defects in the early stage of a software development process, which accordingly reduces the maintenance costs by a substantial margin. Unfortunately, due to the conservative approximations of such SA tools, a large number of false positive (FP for short) warnings (i.e., they do not indicate real bugs) are generated, making these tools less effective. During the past two decades, therefore, many false positive mitigation (FPM for short) approaches have been proposed so that more accurate and critical warnings can be delivered to developers. This paper offers a detailed survey of research achievements on the topic of FPM. Given the collected 130 surveyed papers, we conduct a comprehensive investigation from five different perspectives. First, we reveal the research trends of this field. Second, we classify the existing FPM approaches into five different types and then present the concrete research progress. Third, we analyze the evaluation system applied to examine the performance of the proposed approaches in terms of studied SA tools, evaluation scenarios, performance indicators, and collected datasets, respectively. Fourth, we summarize the four types of empirical studies relating to SA warnings to exploit the insightful findings that are helpful to reduce FP warnings. Finally, we sum up 10 challenges unresolved in the literature from the aspects of systematicness, effectiveness, completeness, and practicability and outline possible research opportunities based on three emerging techniques in the future.  © 1976-2012 IEEE.","defects; false positives; software quality assurance; static analysis tools; Static warnings","Computer software selection and evaluation; Program debugging; Quality assurance; Quality control; Software design; Static analysis; Analysis tools; False positive; Maintenance cost; Software defects; Software development process; Software quality assurance; Software-systems; Source codes; Static analyse tool; Static warning; Defects","Kremenek T., Engler D.R., Z-Ranking: Using statistical analysis to counter the impact of static analysis approximations, Proc. 10th Int. Static Anal. Symp. (SAS), pp. 295-315, (2003); Kremenek T., Ashcraft K., Yang J., Engler D.R., Correlation exploitation in error ranking, Proc. 12th ACM SIGSOFT Int. Symp. Found. Softw. Eng. (FSE), pp. 83-93, (2004); Jung Y., Kim J., Shin J., Yi K., Taming false alarms from a domain-unaware C analyzer by a Bayesian statistical post analysis, Proc. 12th Int. Static Anal. Symp. (SAS), pp. 203-217, (2005); Rival X., Understanding the origin of alarms in Astree, Proc. 12th Int. Static Anal. Symp. (SAS), pp. 303-319, (2005); Rival X., Abstract dependences for alarm diagnosis, Proc. 3rd Asian Program. Lang. Syst. Symp. (APLAS), pp. 347-363, (2005); Aggarwal A., Jalote P., Integrating static and dynamic analysis for detecting vulnerabilities, Proc. 30th Annu. Int. Comput. Softw. Appl. Conf. (COMPSAC), pp. 343-350, (2006); Boogerd C., Moonen L., Prioritizing software inspection results using static profiling, Proc. 6th IEEE Int. Workshop Source Code Anal. Manipulation (SCAM), pp. 149-160, (2006); Cousot P., Et al., Combination of abstractions in the Astree static analyzer, Proc. 11th Asian Comput. Sci. Conf. (ASIAN), pp. 272-300, (2006); Ayewah N., Pugh W., Morgenthaler J.D., Penix J., Zhou Y., Evaluating static analysis defect warnings on production software, Proc. 7th ACM SIGPLAN-SIGSOFT Workshop Program Anal. Softw. Tools Eng. (PASTE), pp. 1-8, (2007); Heckman S.S., Adaptive probabilistic model for ranking code-based static analysis alerts, Proc. 29th Int. Conf. Softw. Eng. (ICSE Companion), pp. 89-90, (2007); Heckman S.S., Adaptively ranking alerts generated from automated static analysis, ACM Crossroads, 14, 1, pp. 1-11, (2007); Hovemeyer D., Pugh W.W., Finding more null pointer bugs, but not too many, Proc. 7th ACM SIGPLAN-SIGSOFT Workshop Program Anal. Softw. Tools Eng. (PASTE), pp. 9-14, (2007); Kim S., Ernst M.D., Which warnings should I fix first?, Proc. 6th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Int. Symp. Found. Softw. Eng. (FSE), pp. 45-54, (2007); Kim S., Ernst M.D., Prioritizing warning categories by analyzing software history, Proc. 4h Int. Workshop Mining Softw. Repositories (MSR), (2007); Kong D., Zheng Q., Chen C., Shuai J., Zhu M., ISA: A source code static vulnerability detection system based on data fusion, Proc. 2nf Int. Conf. Scalable Inf. Syst. (Infoscale), (2007); Layman L., Williams L.A., Amant R.S., Toward reducing fault fix time: Understanding developer behavior for the design of automated fault detection tools, Proc. 1st Int. Symp. Empirical Softw. Eng. Meas. (ESEM), pp. 176-185, (2007); Sherriff M., Heckman S.S., Lake J.M., Williams L.A., Using groupings of static analysis alerts to identify files likely to contain field failures, Proc. 6th Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Int. Symp. Found. Softw. Eng. (FSE), pp. 565-568, (2007); Delmas D., Souyris J., Astree: From research to industry, Proc. 14th Int. Static Anal. Symp. (SAS), pp. 437-451, (2007); Csallner C., Smaragdakis Y., Xie T., DSD-crasher: A hybrid analysis tool for bug finding, ACM Trans. Softw. Eng. Methodol., 17, 2, (2008); Emanuelsson P., Nilsson U., A comparative study of industrial static analysis tools, Electron. Notes Theor. Comput. Sci., 217, pp. 5-21, (2008); Smith Heckman S., Williams L.A., On establishing a benchmark for evaluating static analysis alert prioritization and classification techniques, Proc. 2nd Int. Symp. Empirical Softw. Eng. Meas. (ESEM), pp. 41-50, (2008); Post H., Sinz C., Kaiser A., Gorges T., Reducing false positives by combining abstract interpretation and bounded model checking, Proc. 23rd IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 188-197, (2008); Rungta N., Mercer E.G., A meta heuristic for effectively detecting concurrency errors, Proc. 4th Int. Haifa Verification Conf. (HVC), pp. 23-37, (2008); Ruthruff J.R., Penix J., Morgenthaler J.D., Elbaum S.G., Rothermel G., Predicting accurate and actionable static analysis warnings: An experimental approach, Proc. 30th Int. Conf. Softw. Eng. (ICSE), pp. 341-350, (2008); Ayewah N., Pugh W., Using checklists to review static analysis warnings, Proc. 2nd Int. Workshop Defects Large Softw. Syst. (DEFECTS), pp. 11-15, (2009); Livshits V.B., Nori A.V., Rajamani S.K., Banerjee A., Merlin: Specification inference for explicit information flow problems, Proc. ACM SIGPLAN Conf. Program. Lang. Des. Implementation (PLDI), pp. 75-86, (2009); Heckman S.S., Williams L.A., A model building process for identifying actionable static analysis alerts, Proc. 2nd Int. Conf. Softw. Testing Verification Validation (ICST), pp. 161-170, (2009); Wedyan F., Alrmuny D., Bieman J.M., The effectiveness of automated static analysis tools for fault detection and refactoring Prediction, Proc. 2nd Int. Conf. Softw. Testing Verification Validation (ICST), pp. 141-150, (2009); Baca D., Identifying security relevant warnings from static code analysis tools through code tainting, Proc. 5th Int. Conf. Availability, Rel. Secur. (ARES), pp. 386-390, (2010); Kim Y., Lee J., Han H., Choe K.-M., Filtering false alarms of buffer overflow analysis using SMT solvers, Inf. Softw. Technol., 52, 2, pp. 210-219, (2010); Liang G., Wu L., Wu Q., Wang Q., Xie T., Mei H., Automatic construction of an effective training set for prioritizing static analysis warnings, Proc. 25th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 93-102, (2010); Nanda M.G., Gupta M., Sinha S., Chandra S., Schmidt D., Balachandran P., Making defect-finding tools work for you, Proc. 32nd ACM/IEEE Int. Conf. Softw. Eng. (ICSE), 2, pp. 99-108, (2010); Li J.J., Palframan J.D., Landwehr J., SoftWare IMmunization (SWIM) - A combination of static analysis and automatic testing, Proc. 35th Annu. IEEE Int. Comput. Softw. Appl. Conf. (COMPSAC), pp. 656-661, (2011); Ge X., Taneja K., Xie T., Tillmann N., DyTa: Dynamic symbolic execution guided with static verification results, Proc. 33rd Int. Conf. Softw. Eng. (ICSE), pp. 992-994, (2011); Shen H., Fang J., Zhao J., EFindBugs: Effective error ranking for FindBugs, Proc. 4th IEEE Int. Conf. Softw. Testing, Verification Validation (ICST), pp. 299-308, (2011); Vetro A., Morisio M., Torchiano M., An empirical validation of FindBugs issues related to defects, Proc. 15th Annu. Conf. Eval. Assessment Softw. Eng. (EASE), pp. 144-153, (2011); Allier S., Anquetil N., Hora A.C., Ducasse S., A framework to compare alert ranking algorithms, Proc. 19th Work. Conf. Reverse Eng. (WCRE), pp. 277-285, (2012); Chebaro O., Kosmatov N., Giorgetti A., Julliand J., Program slicing enhances a verification technique combining static and dynamic analysis, Proc. ACM Symp. Appl. Comput. (SAC), pp. 1284-1291, (2012); Darke P., Khanzode M., Nair A., Shrotri U., Venkatesh R., Precise analysis of large industry code, Proc. 19th Asia-Pacific Softw. Eng. Conf. (APSEC), pp. 306-309, (2012); Joshi S., Lahiri S.K., Lal A., Underspecified harnesses and interleaved bugs, Proc. 39th ACM SIGPLAN-SIGACT Symp. Princ. Program. Lang. (POPL), pp. 19-30, (2012); Liang G., Wu Q., Wang Q., Mei H., An effective defect detection and warning prioritization approach for resource leaks, Proc. 36th Annu. IEEE Comput. Softw. Appl. Conf. (COMPSAC), pp. 119-128, (2012); Nadeem M., Williams B.J., Allen E.B., High false positive detection of security vulnerabilities: A case study, Proc. 50th Annu. Southeast Regional Conf. (SRC), pp. 359-360, (2012); Chen C., Lu K., Wang X., Zhou X., Fang L., Pruning false positives of static data-race detection via thread specialization, Proc. Adv. 10th Int. Symp. Parallel Process. Technol. (APPT), pp. 77-90, (2013); Fry Z.P., Weimer W., Clustering static analysis defect reports to reduce maintenance costs, Proc. 20th Work. Conf. Reverse Eng. (WCRE), pp. 282-291, (2013); Smith Heckman S., Williams L.A., A comparative evaluation of static analysis actionable alert identification techniques, Proc. 9th Int. Conf. Predictive Models Softw. Eng. (PROMISE), (2013); Johnson B., Song Y., Murphy-Hill E.R., Bowdidge R.W., Why don’t software developers use static analysis tools to find bugs?, Proc. 35th Int. Conf. Softw. Eng. (ICSE), pp. 672-681, (2013); Li M., Chen Y., Wang L., Xu G., Dynamically validating static memory leak warnings, Proc. Int. Symp. Softw. Testing Anal. (ISSTA), pp. 112-122, (2013); Muske T.B., Baid A., Sanas T., Review efforts reduction by partitioning of static analysis warnings, Proc. 13th IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), pp. 106-115, (2013); Muske T., Datar A., Khanzode M., Madhukar K., Efficient elimination of false positives using bounded model checking, Proc. 5th Int. Conf. Adv. Syst. Testing Validation Lifecycle (VALID), pp. 13-20, (2013); Yuksel U., Automated classification of static code analysis alerts: A case study, Proc. IEEE Int. Conf. Softw. Maintenance (ICSM), pp. 532-535, (2013); Zhang D., Jin D., Gong Y., Zhang H., Diagnosis-oriented alarm correlations, Proc. 20th Asia-Pacific Softw. Eng. Conf. (APSEC), pp. 172-179, (2013); Arai S., Sakamoto K., Washizaki H., Fukazawa Y., A gamified tool for motivating developers to remove warnings of bug pattern tools, Proc. 6th Int. Workshop Empirical Softw. Eng. Pract. (IWESEP), pp. 37-42, (2014); Hanam Q., Tan L., Holmes R., Lam P., Finding patterns in static analysis alerts: Improving actionable alert ranking, Proc. 11th Work. Conf. Mining Softw. Repositories (MSR), pp. 152-161, (2014); Medeiros I., Ferreira Neves N., Correia M., Automatic detection and correction of web application vulnerabilities using data mining to predict false positives, Proc. 23rd Int. World Wide Web Conf. (WWW), pp. 63-74, (2014); Muske T., Supporting reviewing of warnings in presence of shared variables: Need and effectiveness, Proc. 25th IEEE Int. Symp. Softw. Rel. Eng. Workshops (ISSRE Workshops), pp. 104-107, (2014); Muske T., Improving review of clustered-code analysis warnings, Proc. 30th IEEE Int. Conf. Softw. Maintenance Evol. (ICSME), pp. 569-572, (2014); Rahman F., Khatri S., Barr E.T., Devanbu P.T., Comparing static bug finders and statistical prediction, Proc. 36th Int. Conf. Softw. Eng. (ICSE), pp. 424-434, (2014); Tripp O., Guarnieri S., Pistoia M., Aravkin A.Y., ALETHEIA: Improving the usability of static security analysis, Proc. ACM SIGSAC Conf. Comput. Commun. Secur., pp. 762-774, (2014); Valdiviezo M., Cifuentes C., Krishnan P., A method for scalable and precise bug finding using program analysis and model checking, Proc. 12th Asian Symp. Program. Lang. Syst. (APLAS), pp. 196-215, (2014); Yoon J., Jin M., Jung Y., Reducing false alarms from an industrial-strength static analyzer by SVM, Proc. 21st Asia-Pacific Softw. Eng. Conf. (APSEC), pp. 3-6, (2014); Yuksel U., Sensoy M., Trust-based fusion of classifiers for static code analysis, Proc. 17th Int. Conf. Inf. Fusion (FUSION), pp. 1-6, (2014); Antonio de Araujo C., Delamaro M.E., Maldonado J.C., Vincenzi A.M.R., Investigating the correspondence between mutations and static warnings, Proc. 29th Brazilian Symp. Softw. Eng. (SBES), pp. 1-10, (2015); Chimdyalwar B., Darke P., Chavda A., Vaghani S., Chauhan A., Eliminating static analysis false positives using loop abstraction and bounded model checking, Proc. 20th Int. Symp. Formal Methods (FM), pp. 573-576, (2015); Mangal R., Zhang X., Nori A.V., Naik M., A user-guided approach to program analysis, Proc. 10th Joint Meeting Found. Softw. Eng. (FSE), pp. 462-473, (2015); Muske T., Khedker U.P., Efficient elimination of false positives using static analysis, Proc. 26th IEEE Int. Symp. Softw. Rel. Eng. (ISSRE), pp. 270-280, (2015); Panichella S., Arnaoudova V., Di Penta M., Antoniol G., Would static analysis tools help developers with code reviews?, Proc. 22nd IEEE Int. Conf. Softw. Anal., Evol., Reengineering (SANER), pp. 161-170, (2015); Salvi S., Ferdinand C., Bienm T., Exploiting synergies between static analysis and model-based testing, Proc. 11th Eur. Dependable Comput. Conf. (EDCC), pp. 13-24, (2015); Integrated static code analysis and runtime verification, Softw. Pract. Exp., 45, 10, pp. 1359-1373, (2015); Burhandenny A.E., Aman H., Kawahara M., Examination of coding violations focusing on their change patterns over releases, Proc. 23rd Asia-Pacific Softw. Eng. Conf. (APSEC), pp. 121-128, (2016); Dimastrogiovanni C., Laranjeiro N., Towards understanding the value of false positives in static code analysis, Proc. 7th Latin-Amer. Symp. Dependable Comput. (LADC), pp. 119-122, (2016); Muske T., Khedker U.P., Cause points analysis for effective handling of alarms, Proc. 27th IEEE Int. Symp. Softw. Rel. Eng. (ISSRE), pp. 173-184, (2016); Ostberg J.-P., Wagner S., At ease with your warnings: The principles of the salutogenesis model applied to automatic static analysis, Proc. IEEE 23rd Int. Conf. Softw. Anal., Evol., Reengineering (SANER), pp. 629-633, (2016); Park J., Lim I., Ryu S., Battles with false positives in static analysis of JavaScript web applications in the wild, Proc. 38th Int. Conf. Softw. Eng. (ICSE), pp. 61-70, (2016); Buckers T., Et al., UAV: Warnings from multiple automated static analysis tools at a glance, Proc. IEEE 24th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 472-476, (2017); Cheirdari F., Karabatis G., On the verification of software vulnerabilities during static code analysis using data mining techniques, Proc. On Move Meaningful Int. Syst. (OTM), pp. 99-106, (2017); Heo K., Oh H., Yi K., Machine-learning-guided selectively unsound static analysis, Proc. 39th Int. Conf. Softw. Eng. (ICSE), pp. 519-529, (2017); Lee W., Lee W., Kang D., Heo K., Oh H., Yi K., Sound non-statistical clustering of static analysis Alarms, ACM Trans. Program. Lang. Syst., 39, 4, (2017); Koc U., Saadatpanah P., Foster J.S., Porter A.A., Learning a classifier for false positive error reports emitted by static code analysis tools, Proc. 1st ACM SIGPLAN Int. Workshop Mach. Learn. Program. Lang. (MAPL@PLDI), pp. 35-42, (2017); Reynolds Z.P., Jayanth A.B., Koc U., Porter A.A., Raje R.R., Hill J.H., Identifying and documenting false positive patterns generated by static code analysis tools, Proc. 4th IEEE/ACM Int. Workshop Softw. Eng. Res. Ind. Pract. (SER&IP@ICSE), pp. 55-61, (2017); Wei L., Liu Y., Cheung S.-C., OASIS: Prioritizing static analysis warnings for Android apps based on app user reviews, Proc. 11th Joint Meeting Found. Softw. Eng. (FSE), pp. 672-682, (2017); Xypolytos A., Xu H., Vieira B., Ali-Eldin A.M.T., A framework for combining and ranking static analysis tool findings based on tool performance statistics, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur. Companion (QRS), pp. 595-596, (2017); Yan M., Zhang X., Xu L., Hu H., Sun S., Xia X., Revisiting the correlation between alerts and software defects: A case study on MyFaces, Camel, and CXF, Proc. 41st IEEE Annu. Computer Softw. Appl. Conf. (COMPSAC), pp. 103-108, (2017); Zampetti F., Scalabrino S., Oliveto R., Canfora G., Penta M.D., How open source projects use static code analysis tools in continuous integration pipelines, Proc. 14th Int. Conf. Mining Softw. Repositories (MSR), pp. 334-344, (2017); Alikhashashneh E.A., Raje R.R., Hill J.H., Using machine learning techniques to classify and predict static code analysis tool warnings, Proc. 15th IEEE/ACS Int. Conf. Comput. Syst. Appl. (AICCSA), pp. 1-8, (2018); Cheirdari F., Karabatis G., Analyzing false positive source code vulnerabilities using static analysis tools, Proc. IEEE Int. Conf. Big Data (BigData), pp. 4782-4788, (2018); Flynn L., Et al., Prioritizing alerts from multiple static analysis tools, using classification models, Proc. 1st Int. Workshop Softw. Qual. Dependencies (SQUADE@ICSE), pp. 13-20, (2018); Habib A., Pradel M., How many of all bugs do we find? A study of static bug detectors, Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng. (ASE), pp. 317-328, (2018); Muske T., Talluri R., Serebrenik A., Repositioning of static analysis alarms, Proc. 27th ACM SIGSOFT Int. Symp. Softw. Testing Anal. (ISSTA), pp. 187-197, (2018); Querel L.-P., Rigby P.C., WarningsGuru: Integrating statistical bug models with static analysis to provide timely and specific bug warnings, Proc. ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng. (FSE), pp. 892-895, (2018); Ribeiro A., Meirelles P., Lago N., Kon F., Ranking source code static analysis warnings for continuous monitoring of FLOSS repositories, Proc. 14th IFIP WG 2.13 Int. Conf. Open Source Syst., Enterprise Softw. Solutions (OSS), pp. 90-101, (2018); Sadowski C., Aftandilian E., Eagle A., Miller-Cushon L., Jaspan C., Lessons from building static analysis tools at Google, Commun. ACM, 61, 4, pp. 58-66, (2018); Vassallo C., Panichella S., Palomba F., Proksch S., Zaidman A., Gall H.C., Context is king: The developer perspective on the usage of static analysis tools, Proc. 25th Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 38-49, (2018); Wang J., Wang S., Wang Q., Is there a ‘golden’ feature set for static warning identification? An experimental evaluation, Proc. 12th ACM/IEEE Int. Symp. Empirical Softw. Eng. Meas. (ESEM), (2018); Wang H., Zhou M., Cheng X., Chen G., Gu M., Which defect should be fixed first? Semantic prioritization of static analysis report, Proc. 8th Int. Conf. Softw. Anal., Testing, Evol. (SATE), pp. 3-19, (2018); Aloraini B., Nagappan M., German D.M., Hayashi S., Higo Y., An empirical study of security warnings from static application security testing tools, J. Syst. Softw., 158, pp. 1-25, (2019); Giet J., Mauborgne L., Ferdinand C., Towards zero alarms in sound static analysis of finite state machines, Proc. 38th Int. Conf. Comput. Saf., Rel., Secur. (SAFECOMP), pp. 3-18, (2019); Imtiaz N., Rahman A., Farhana E., Williams L.A., Challenges with responding to static analysis tool alerts, Proc. 16th Int. Conf. Mining Softw. Repositories (MSR), pp. 245-249, (2019); Imtiaz N., Murphy B., Williams L.A., How do developers act on static analysis alerts? An empirical study of Coverity usage, Proc. 30th IEEE Int. Symp. Softw. Rel. Eng. (ISSRE), pp. 323-333, (2019); Imtiaz N., Williams L.A., A synopsis of static analysis alerts on open source software, Proc. 6th Annu. Symp. Hot Topics Sci. Secur. (HotSoS), (2019); Koc U., Wei S., Foster J.S., Carpuat M., Porter A.A., An empirical assessment of machine learning approaches for triaging reports of a Java static analysis tool, Proc. 12th IEEE Conf. Softw. Testing, Validation Verification (ICST), pp. 288-299, (2019); Lee S., Hong S., Yi J., Kim T., Kim C.-J., Yoo S., Classifying false positive static checker alarms in continuous integration using convolutional neural networks, Proc. 12th IEEE Conf. Softw. Testing, Validation Verification (ICST), pp. 391-401, (2019); Marcilio D., Bonifacio R., Monteiro E., Canedo E.D., Pinheiro Luz W., Pinto G., Are static analysis violations really fixed? A closer look at realistic usage of SonarQube, Proc. 27th Int. Conf. Program Comprehension (ICPC), pp. 209-219, (2019); Muske T., Talluri R., Serebrenik A., Reducing static analysis alarms based on non-impacting control dependencies, Proc. 17th Asian Symp. Program. Lang. Syst. (APLAS), pp. 115-135, (2019); Nguyen T.T., Maleehuan P., Aoki T., Tomita T., Yamada I., Reducing false positives of static analysis for SEI CERT C coding standard, Proc. Joint 7th Int. Workshop Conducting Empirical Stud. Ind. 6th Int. Workshop Softw. Eng. Res. Ind. Pract. (CESSERIP@ICSE), pp. 41-48, (2019); Pereira J.D., Campos J.R., Vieira M., An exploratory study on machine learning to combine security vulnerability alerts from static analysis tools, Proc. 9th Latin-Amer. Symp. Dependable Comput. (LADC), pp. 1-10, (2019); Ribeiro A., Meirelles P., Lago N., Kon F., Ranking warnings from multiple source code static analyzers via ensemble learning, Proc. 15th Int. Symp. Open Collaboration (OpenSym), (2019); Yang J., Tan L., Peyton J., Duer K.A., Towards better utilizing static application security testing, Proc. 41st Int. Conf. Softw. Eng., Softw. Eng. Pract. (ICSE-SEIP), pp. 51-60, (2019); Junior L.C., Belgamo A., Rafael Lobo de Mendonca V., Vincenzi A.M.R., WarningsFIX: A recommendation system for prioritizing warnings generated by automated static analyzers, Proc. 19th Brazilian Symp. Softw. Qual. (SBQS), 2020; Gao F., Wang Y., Wang L., Yang Z., Li X., Automatic buffer overflow warning validation, J. Comput. Sci. Technol., 35, 6, pp. 1406-1427, (2020); Muske T., Serebrenik A., Techniques for efficient automated elimination of false positives, Proc. 20th IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), 2020, pp. 259-263; Vassallo C., Panichella S., Palomba F., Proksch S., Gall H.C., Zaidman A., How developers engage with static analysis tools in different contexts, Empirical Softw. Eng., 25, 2, pp. 1419-1457, (2020); Zhang Y., Xing Y., Gong Y., Jin D., Li H., Liu F., A variable-level automated defect identification model based on machine learning, Soft Comput, 24, 2, pp. 1045-1061, (2020); Zhang Y., Jin D., Xing Y., Gong Y., Automated defect identification via path analysis-based features with transfer learning, J. Syst. Softw., 166; Flynn L., Snavely W., Kurtz Z., Test suites as a source of training data for static analysis alert classifiers, Proc. 2nd IEEE/ACM Int. Conf. Automat. Softw. Test (AST@ICSE), 2021, pp. 100-108; Liu K., Kim D., Bissyande T.F., Yoo S., Le Traon Y., Mining fix patterns for FindBugs violations, IEEE Trans. Softw. Eng., 47, 1, pp. 165-188, (2021); Siavvas M.G., Kalouptsoglou I., Tsoukalas D., Kehagias D.D., A self-adaptive approach for assessing the criticality of Security-related static analysis alerts, Proc. 21st Int. Conf. Comput. Sci. Appl. (ICCSA), 2021, pp. 289-305; Yang X., Yu Z., Wang J., Menzies T., Understanding static code warnings: An incremental AI approach, Expert Syst. Appl., 167; Yang X., Chen J., Yedida R., Yu Z., Menzies T., Learning to recognize actionable static code warnings (is intrinsically easy), Empirical Softw. Eng., 26, 3; Zheng Y., Et al., D2A: A dataset built for AI-based vulnerability detection methods using differential analysis, Proc. 43rd IEEE/ACM Int. Conf. Softw. Eng., Softw. Eng. Pract. (ICSE-SEIP), 2021, pp. 111-120; Heckman S.S., Williams L.A., A systematic literature review of actionable alert identification techniques for automated static code analysis, Inf. Softw. Technol., 53, 4, pp. 363-387, (2011); Muske T., Serebrenik A., Survey of approaches for handling static analysis alarms, Proc. 16th IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), pp. 157-166, (2016); TSE-survey-FPM, GitHub; Gu R., Et al., Towards efficient large-scale interprocedural program static analysis on distributed data-parallel computation, IEEE Trans. Parallel Distrib. Syst., 32, 4, pp. 867-883, (2021); Rutar N., Almazan C.B., Foster J.S., A comparison of bug finding tools for Java, Proc. 15th Int. Symp. Softw. Rel. Eng. (ISSRE), pp. 245-256, (2004); Nagappan N., Ball T., Static analysis tools as early indicators of pre-release defect density, Proc. 27th Int. Conf. Softw. Eng. (ICSE), pp. 580-586, (2005); Heckman S.E., Williams L., Automated adaptive ranking and filtering of static analysis alerts, Proc. 17th Int. Symp. Softw. Rel. Eng. (ISSRE), pp. 1-2, (2006); Cole B., Hakim D., Hovemeyer D., Lazarus R., Pugh W., Stephens K., Improving your software using static analysis to find bugs, Proc. Companion 21th Annu. ACM SIGPLAN Conf. Object-Oriented Program., Syst., Lang., Appl. (OOPSLA), pp. 673-674, (2006); Zheng J., Williams L.A., Nagappan N., Snipes W., Hudepohl J.P., Vouk M.A., On the value of static analysis for fault detection in software, IEEE Trans. Softw. Eng., 32, 4, pp. 240-253, (2006); Zuo Z., Et al., Grapple: A graph system for static finite-state property checking of large-scale systems code, Proc. 14th EuroSys Conf. (EuroSys), (2019); Zuo Z., Et al., Chianina: An evolving graph system for flow- and context-sensitive analyses of million lines of C code, Proc. 42nd ACM SIGPLAN Int. Conf. Program. Lang. Des. Implementation (PLDI), 2021, pp. 914-929; Gruber H., Hentschel A., Pomberger G., Schiffer S., On the relation between external software quality and static code analysis, Proc. 32nd Annu. IEEE Softw. Eng. Workshop (SEW), pp. 169-174, (2008); Ayewah N., Hovemeyer D., Morgenthaler J.D., Penix J., Pugh W., Using static analysis to find bugs, IEEE Softw, 25, 5, pp. 22-29, (2008); Bessey A., Et al., A few billion lines of code later: Using static analysis to find bugs in the real world, Commun. ACM, 53, 2, pp. 66-75, (2010); Ayewah N., Pugh W., The google FindBugs fixit, Proc. 19th Int. Symp. Softw. Testing Anal. (ISSTA), pp. 241-252, (2010); Kumar R., Nori A.V., The economics of static analysis tools, Proc. Joint Meeting Eur. Softw. Eng. Conf. ACM SIGSOFT Symp. Found. Softw. Eng. (FSE), pp. 707-710, (2010); Balachandran V., Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation, Proc. 35th Int. Conf. Softw. Eng. (ICSE), pp. 931-940, (2013); Wang K., Hussain A., Zuo Z., Xu G., Sani A.A., Graspan: A single-machine disk-based graph system for interprocedural static analyses of large-scale systems code, Proc. 22nd Int. Conf. Architectural Support Program. Lang. Oper. Syst. (ASPLOS), pp. 389-404, (2017); Watson C., Cooper N., Nader-Palacio D., Moran K., Poshyvanyk D., A systematic literature review on the use of deep learning in software engineering research; Beller M., Bholanath R., McIntosh S., Zaidman A., Analyzing the state of static analysis: A large-scale evaluation in open source software, Proc. IEEE 23rd Int. Conf. Softw. Anal., Evol., Reengineering (SANER), pp. 470-481, (2016); Zuo Z., Et al., BigSpa: An efficient interprocedural static analysis engine in the cloud, Proc. IEEE Int. Parallel Distrib. Process. Symp. (IPDPS), pp. 771-780, (2019); Nguyen L., Et al., Just-in-time static analysis, Proc. 26th ACM SIGSOFT Int. Symp. Softw. Testing Anal. (ISSTA), pp. 307-317, (2017); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang., 4; Liu K., Koyuncu A., Kim D., Bissyande T.F., AVATAR: Fixing semantic bugs with fix patterns of static analysis violations, Proc. 26th IEEE Int. Conf. Softw. Anal., Evol. Reengineering (SANER), pp. 456-467, (2019); Theeten B., Vandeputte F., Van Cutsem T., Import2vec learning embeddings for software libraries, Proc. 16th Int. Conf. Mining Softw. Repositories (MSR), pp. 18-28, (2019); Trautsch A., Herbold S., Grabowski J., A longitudinal study of static analysis warning evolution and the effects of PMD on software quality in Apache open-source projects, Empirical Softw. Eng., 25, 6, pp. 5137-5192, (2020); Trautsch A., Herbold S., Grabowski J., Static source code metrics and static analysis warnings for fine-grained just-in-time defect prediction, Proc. IEEE Int. Conf. Softw. Maintenance Evol. (ICSME), 2020, pp. 127-138; Marcilio D., Furia C.A., Bonifacio R., Pinto G., SpongeBugs: Automatically generating fix suggestions in response to static code analysis warnings, J. Syst. Softw., 168, pp. 1-20; Hoang T., Kang H.J., Lo D., Lawall J., CC2Vec: Distributed representations of code changes, Proc. 42nd Int. Conf. Softw. Eng. (ICSE), 2020, pp. 518-529; Wen M., Wu R., Cheung S.-C., How well do change sequences predict defects? Sequence learning from software changes, IEEE Trans. Softw. Eng., 46, 11, pp. 1155-1175; Wang J., Huang Y., Wang S., Wang Q., Find bugs in static bug finders, Proc. 30th Int. Conf. Program Comprehension (ICPC), 2021, pp. 516-527; Yang Y., Xia X., Lo D., Grundy J.C., A survey on deep learning for software engineering; Copeland P., Google’s innovation factory: Testing, culture, and infrastructure, Proc. 3rd Int. Conf. Softw. Testing, Verification Validation (ICST), pp. 11-14, (2010); Cabrera Lozoya R., Baumann A., Sabetta A., Bezzi M., Commit2Vec: Learning distributed representations of code changes, SN Comput. Sci., 2, 3; Ribeiro L.F.R., Saverese P.H.P., Figueiredo D.R., Struc2vec: Learning node representations from structural identity, Proc. KDD, pp. 385-394, (2017); Shi K., Lu Y., Chang J., Wei Z., PathPair2Vec: An AST path pair-based code representation method for defect prediction, J. Comput. Lang., 59, 2020; Amen B., Antoniou G., A theoretical study of anomaly detection in big data distributed static and stream analytics, Proc. 20th IEEE Int. Conf. High Perform. Comput. Commun., 16th IEEE Int. Conf. Smart City, 4th IEEE Int. Conf. Data Sci. Syst. (HPCC/SmartCity/ DSS), pp. 1177-1182, (2018); Zhu J., Li Q., Ying S., Failure analysis of static analysis software module based on big data tendency prediction, Complex, 2021, pp. 1-12; Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, (2019); Zekany S., Rings D., Harada N., Laurenzano M.A., Tang L., Mars J., CrystalBall: Statically analyzing runtime behavior via deep sequence learning, Proc. 49th Annu. IEEE/ACM Int. Symp. Microarchitecture (MICRO), (2016); Liu L., Wang B., Automatic malware detection using deep learning based on static analysis, Proc. 3rd Int. Conf. Pioneering Comput. Scientists, Eng. Educators (ICPCSEE), pp. 500-507, (2017); Darabian H., Et al., Detecting cryptomining malware: A deep learning approach for static and dynamic analysis, J. Grid Comput., 18, 2, pp. 293-303, (2020); Medeiros I., Neves N., Correia M., Statically detecting vulnerabilities by processing programming languages as natural languages, (2019); Zhou J., Zhang H., Lo D., Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports, Proc. 34th Int. Conf. Softw. Eng. (ICSE), pp. 14-24, (2012); Runeson P., Alexandersson M., Nyholm O., Detection of duplicate defect reports using natural language processing, Proc. 29th Int. Conf. Softw. Eng. (ICSE), pp. 499-510, (2007); Ren X., Xing Z., Xia X., Lo D., Wang X., Grundy J., Neural network-based detection of self-admitted technical debt: From performance to explainability, ACM Trans. Softw. Eng. Methodol., 28, 3, pp. 1-45, (2019); Muske T., Serebrenik A., Survey of approaches for postprocessing of static analysis alarms, ACM Comput. Surv., 55, 3; Hovemeyer D., Spacco J., Pugh W.W., Evaluating and tuning a static analysis to find null pointer bugs, Proc. ACM SIGPLAN-SIGSOFT Workshop Program Anal. Softw. Tools Eng. (PASTE), pp. 13-19, (2005); Luo Z.D., Hillis L., Das R., Qi Y., Effective static analysis to find concurrency bugs in Java, Proc. 10th IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), pp. 135-144, (2010); Delaitre A., Stivalet B., Fong E., Okun V., Evaluating bug finders - Test and measurement of static code analyzers, Proc. 1st IEEE/ACM Int. Workshop Complex Faults Failures Large Softw. Syst. (COUFLESS), pp. 14-20, (2015); Chappell T., Cifuentes C., Krishnan P., Geva S., Machine learning for finding bugs: An initial report, Proc. IEEE Workshop Mach. Learn. Techn. Softw. Qual. Eval. (MaLTeSQuE@SANER), pp. 21-26, (2017); Algaith A., Nunes P.J.C., Fonseca J., Gashi I., Vieira M., Finding SQL injection and cross site scripting vulnerabilities with diverse static analysis tools, Proc. 14th Eur. Dependable Comput. Conf. (EDCC), pp. 57-64, (2018); Ferenc R., Static code analysis alarms filtering reloaded: A new real-world dataset and its ML-based utilization, IEEE Access, 10, pp. 55090-55101; Kang H.J., Loong Aw K., Lo D., Detecting false alarms from automatic static analysis tools: How far are we?, Proc. 44th IEEE/ACM 44th Int. Conf. Softw. Eng. (ICSE), 2022, pp. 698-709; Kim H., Raghothaman M., Heo K., Learning probabilistic models for static analysis alarms, Proc. 44th IEEE/ACM 44th Int. Conf. Softw. Eng. (ICSE), 2022, pp. 1282-1293; Vu T.T., Vo H.D., Using multiple code representations to prioritize static analysis warnings, Proc. 14th Int. Conf. Knowl. Syst. Eng. (KSE), 2022, pp. 1-6; Muske T., Serebrenik A., Classification and ranking of delta static analysis alarms, Proc. 22nd IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), 2022, pp. 197-207; Mansoor N., Muske T., Serebrenik A., Sharif B., An empirical assessment on merging and repositioning of static analysis alarms, Proc. 22nd IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), 2022, pp. 219-229; Yedida R., Kang H.J., Tu H., Yang X., Lo D., Menzies T., How to find actionable static analysis warnings: A case study with FindBugs, IEEE Trans. Softw. Eng., 49, 4, pp. 2856-2872, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Article","Final","","Scopus","2-s2.0-85180268008"
"Zhout X.; Kim K.; Xu B.; Liu J.; Han D.; Lo D.","Zhout, Xin (55743318900); Kim, Kisub (57200368137); Xu, Bowen (57189036787); Liu, Jiakun (57218646274); Han, DongGyun (57424613700); Lo, David (35269388000)","55743318900; 57200368137; 57189036787; 57218646274; 57424613700; 35269388000","The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models","2023","Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023","","","","40","52","12","1","10.1109/ASE56229.2023.00157","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177075118&doi=10.1109%2fASE56229.2023.00157&partnerID=40&md5=95857aeb67197623f232af0136eb186e","Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0% and 254.0% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation.  © 2023 IEEE.","","Codes (symbols); Computational linguistics; Learning systems; Code distributions; Data distribution; Data properties; Data sample; Engineering tasks; Language model; Learning Based Models; Long-tailed distributions; Number of class; Property; Software engineering","LeCun Y., Bengio Y., Hinton G., Deep learning, nature, 521, 7553, pp. 436-444, (2015); Tan C., Sun F., Kong T., Zhang W., Yang C., Liu C., A survey on deep transfer learning, Artificial Neural Networks and Machine Learning-ICANN 2018: 27th International Conference on Artificial Neural Networks, pp. 270-279, (2018); Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P.T., On the naturalness of software, 34th International Conference on Software Engineering, ICSE 2012, pp. 837-847, (2012); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 1161-1173, (2021); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., Intellicode compose: Code generation using transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1433-1443, (2020); Tufano R., Masiero S., Mastropaolo A., Pascarella L., Poshyvanyk D., Bavota G., Using pre-trained models to boost code review automation, Proceedings of the 44th International Conference on Software Engineering, pp. 2291-2302, (2022); Irsan I.C., Zhang T., Thung F., Kim K., Lo D., Multi-modal api recommendation, 30th IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2023, (2023); Shirky C., Power laws, weblogs, and inequality, (2003); Brynjolfsson E., Hu Y., Smith M.D., Consumer surplus in the digital economy: Estimating the value of increased product variety at online booksellers, Management science, 49, 11, pp. 1580-1596, (2003); Liu Z., Miao Z., Zhan X., Wang J., Gong B., Yu S.X., Largescale long-tailed recognition in an open world, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2537-2546, (2019); Yang L., Jiang H., Song Q., Guo J., A survey on long-tailed visual recognition, International Journal of Computer Vision, 130, 7, pp. 1837-1872, (2022); Pan S., Bao L., Xia X., Lo D., Li S., Fine-grained commitlevel vulnerability type prediction by CWE tree structure, 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, pp. 957-969, (2023); CWE Top 25 Most Dangerous Software Weaknesses, (2022); Dowd M., McDonald J., Schuh J., The art of software security assessment: Identifying and preventing software vulnerabilities, (2006); Turner D., Fossi M., Johnson E., Mack T., Blackbird J., Entwisle S., Low M.K., McKinney D., Wueest C., Symantec global internet security threat report trends for, 12, pp. 1-36, (2008); Sharma T., Kechagia M., Georgiou S., Tiwari R., Vats I., Moazen H., Sarro F., A survey on machine learning techniques for source code analysis, (2021); Watson C., Cooper N., Palacio D.N., Moran K., Poshyvanyk D., A systematic literature review on the use of deep learning in software engineering research, ACM Transactions on Software Engineering and Methodology (TOSEM), 31, 2, pp. 1-58, (2022); Elahi G., Yu E., Zannone N., A vulnerability-centric requirements engineering framework: Analyzing security attacks, countermeasures, and requirements based on vulnerabilities, Requirements engineering, 15, pp. 41-62, (2010); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifieraware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Jiang W., Synovic N., Hyatt M., Schorlemmer T.R., Sethi R., Lu Y., Thiruvathukal G.K., Davis J.C., An empirical study of pre-trained model reuse in the hugging face deep learning model registry, 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, pp. 2463-2475, (2023); Niu C., Li C., Ng V., Chen D., Ge J., Luo B., An empirical comparison of pre-trained models of source code, 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, pp. 2136-2148, (2023); Zhou X., Han D., Lo D., Assessing generalizability of codebert, 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 425-436, (2021); Liu S., Wu B., Xie X., Meng G., Liu Y., Contrabert: Enhancing code pre-trained models via contrastive learning, 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, pp. 2476-2487, (2023); Yang Z., Shi J., He J., Lo D., Natural attack for pre-trained models of code, Proceedings of the 44th International Conference on Software Engineering, pp. 1482-1493, (2022); Lopez J.A.H., Weyssow M., Cuadrado J.S., Sahraoui H.A., Astprobe: Recovering abstract syntax trees from hidden representations of pre-trained language models, 37th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022, pp. 111-1111, (2022); Shi J., Yang Z., Xu B., Kang H.J., Lo D., Compressing pretrained models of code into 3 MB, 37th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022, pp. 241-2412, (2022); Croft R., Babar M.A., Kholoosi M.M., Data quality for software vulnerability datasets, 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023, pp. 121-133, (2023); Gini C., Variabilit e mutabilit, Reprinted in Memorie di metodologica statistica, (1912); Lin T.-Y., Goyal P., Girshick R., He K., Dollar P., Focal loss for dense object detection, Proceedings of the IEEE international conference on computer vision, pp. 2980-2988, (2017); Alshammari S., Wang Y.-X., Ramanan D., Kong S., Long-tailed recognition via weight balancing, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6897-6907, (2022); Anderson C., The long tail: Why the future of business is selling less of more, (2006); Lopes C.V., Ossher J., How scale affects structure in Java programs, Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2015, part of SPLASH 2015, pp. 675-694, (2015); Borges H., Hora A., Valente M.T., Understanding the factors that impact the popularity of github repositories, 2016 IEEE international conference on software maintenance and evolution (ICSME). IEEE, pp. 334-344, (2016); Fenton N.E., Ohlsson N., Quantitative analysis of faults and failures in a complex software system, IEEE Trans. Software Eng, 26, 8, pp. 797-814, (2000); Wang S., Yao X., Using class imbalance learning for software defect prediction, IEEE Trans. Reliab, 62, 2, pp. 434-443, (2013); Kamei Y., Fukushima T., McIntosh S., Yamashita K., Ubayashi N., Hassan A.E., Studying just-in-time defect prediction using crossproject models, Empir. Softw. Eng, 21, 5, pp. 2072-2106, (2016); Cabral G.G., Minku L.L., Shihab E., Mujahid S., Class imbalance evolution and verification latency in just-in-time software defect prediction, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 666-676, (2019); Ozturk M.M., Which type of metrics are useful to deal with class imbalance in software defect prediction, Inf. Softw. Technol, 92, pp. 17-29, (2017); Feng S., Keung J., Yu X., Xiao Y., Bennin K.E., Kabir M.A., Zhang M., COSTE: complexity-based oversampling technique to alleviate the class imbalance problem in software defect prediction, Inf. Softw. Technol, 129, (2021); Hoang T., Dam H.K., Kamei Y., Lo D., Ubayashi N., Deepjit: An end-to-end deep learning framework for just-in-time defect prediction, Proceedings of the 16th International Conference on Mining Software Repositories, MSR 2019, pp. 34-45, (2019); Tan M., Tan L., Dara S., Mayeux C., Online defect prediction for imbalanced data, 37th IEEE/ACM International Conference onSoftware Engineering, ICSE 2015, 2, pp. 99-108, (2015); Jiarpakdee J., Tantithamthavorn C., Treude C., The impact of automated feature selection techniques on the interpretation of defect models, Empir. Softw. Eng, 25, 5, pp. 3590-3638, (2020); Bennin K.E., Keung J., Phannachitta P., Monden A., Mensah S., MAHAKIL: diversity based oversampling approach to alleviate the class imbalance issue in software defect prediction, IEEE Trans. Software Eng, 44, 6, pp. 534-550, (2018); Van Horn G., Mac Aodha O., Song Y., Cui Y., Sun C., Shepard A., Adam H., Perona P., Belongie S., The inaturalist species classification and detection dataset, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8769-8778, (2018); Martins P., Achar R., Lopes C.V., 50k-c: A dataset of compilable, and compiled, Java projects, Proceedings of the 15th international conference on mining software repositories, pp. 1-5, (2018); Dabic O., Aghajani E., Bavota G., Sampling projects in github for msr studies, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, pp. 560-564, (2021); Ebert F., Castor F., Novielli N., Serebrenik A., Communicative intention in code review questions, 2018 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 519-523, (2018); Zhou J., Pacheco M., Wan Z., Xia X., Lo D., Wang Y., Hassan A.E., Finding a needle in a haystack: Automated mining of silent vulnerability fixes, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 705-716, (2021); Zhou Y., Siow J.K., Wang C., Liu S., Liu Y., Spi: Automated identification of security patches via commits, ACM Transactions on Software Engineering and Methodology (TOSEM), 31, 1, pp. 1-27, (2021); Chen Y., Santosa A.E., Yi A.M., Sharma A., Sharma A., Lo D., A machine learning approach for vulnerability curation, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 32-42, (2020); Gu X., Zhang H., Zhang D., Kim S., Deep api learning, Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering, pp. 631-642, (2016); Fowkes J., Sutton C., Parameter-free probabilistic api mining across github, Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering, pp. 254-265, (2016); Martin J., Guo J.L., Deep api learning revisited, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 321-330, (2022); Tufano R., Pascarella L., Tufano M., Poshyvanyk D., Bavota G., Towards automating code review activities, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 163-174, (2021); Thongtanunam P., Pornprasit C., Tantithamthavorn C., Autotransform: Automated code transformation to support modern code review process, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), (2022); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019); Nguyen V.-A., Nguyen D.Q., Nguyen V., Le T., Tran Q.H., Phung D., Regvd: Revisiting graph neural networks for vulnerability detection, Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings, pp. 178-182, (2022); Devlin J., Chang M., Lee K., Toutanova K., BERT: pre-training of deep bidirectional transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, 1, pp. 4171-4186, (2019); Clark K., Luong M., Le Q.V., Manning C.D., ELECTRA: pre-training text encoders as discriminators rather than generators, 8th International Conference on Learning Representations, ICLR 2020, (2020); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Stack Exchange Dumps, S. Overflow; Sutskever I., Vinyals O., Le Q.V., Sequence to sequence learning with neural networks, Advances in neural information processing systems, 27, (2014); Liu Z., Xia X., Yan M., Li S., Automating just-in-time comment updating, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, pp. 585-597, (2020); Shi E., Wang Y., Tao W., Du L., Zhang H., Han S., Zhang D., Sun H., Race: Retrieval-augmented commit message generation, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 5520-5530, (2022); difflib, a library to extract the token-level edits, (2023); Gupta A., Dollar P., Girshick R., Lvis: A dataset for large vocabulary instance segmentation, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 5356-5364, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Cui Y., Jia M., Lin T.-Y., Song Y., Belongie S., Class-balanced loss based on effective number of samples, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 9268-9277, (2019); Hanson S., Pratt L., Comparing biases for minimal network construction with back-propagation, Advances in neural information processing systems, 1, (1988); Huang C., Li Y., Loy C.C., Tang X., Deep imbalanced learning for face recognition and attribute prediction, IEEE transactions on pattern analysis and machine intelligence, 42, 11, pp. 2781-2794, (2019); Johnson B., Song Y., Murphy-Hill E., Bowdidge R., Why don't software developers use static analysis tools to find bugs, 2013 35th International Conference on Software Engineering (ICSE). IEEE, pp. 672-681, (2013); Kochhar P.S., Xia X., Lo D., Li S., Practitioners' expectations on automated fault localization, Proceedings of the 25th International Symposium on Software Testing and Analysis, pp. 165-176, (2016); Le X.-B.D., Thung F., Lo D., Goues C.L., Overfitting in semantics-based automated program repair, Proceedings of the 40th International Conference on Software Engineering, pp. 163-163, (2018); Zhu C., Byrd R.H., Lu P., Nocedal J., Algorithm 778: L-bfgsb: Fortran subroutines for large-scale bound-constrained optimization, ACM Transactions on mathematical software (TOMS), 23, 4, pp. 550-560, (1997); Hastie T., Tibshirani R., Friedman J.H., Friedman J.H., The elements of statistical learning: data mining, inference, and prediction, 2, (2009); Crammer K., Singer Y., On the algorithmic implementation of multiclass kernel-based vector machines, Journal of machine learning research, 2, pp. 265-292, (2001); Breiman L., Random forests, Machine learning, 45, pp. 5-32, (2001); Ko Y., A study of term weighting schemes using class information for text classification, Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pp. 1029-1030, (2012)","","Institute of Electrical and Electronics Engineers Inc.","","38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023","11 September 2023 through 15 September 2023","Echternach","194295","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85177075118"
"Zhong L.; Wang Z.","Zhong, Li (57226499433); Wang, Zilong (57221155226)","57226499433; 57221155226","Can LLM Replace Stack Overflow? A Study on Robustness and Reliability of Large Language Model Code Generation","2024","Proceedings of the AAAI Conference on Artificial Intelligence","38","19","","21841","21849","8","0","10.1609/aaai.v38i19.30185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189606835&doi=10.1609%2faaai.v38i19.30185&partnerID=40&md5=88178c44873682e1f7d8e113d932acce","Recently, large language models (LLMs) have shown an extraordinary ability to understand natural language and generate programming code. It has been a common practice for software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability, and robustness of the code generation from LLMs have not yet been thoroughly studied. The executable code is not equivalent to reliable and robust code, especially in the context of real-world software development. For example, the misuse of APIs in the generated code could lead to severe problems, such as resource leaks, program crashes, etc. Existing code evaluation benchmarks and datasets focus on crafting small tasks such as programming questions in coding interviews. However, this deviates from the problems developers typically consult LLMs about. To fill the missing piece, we propose a dataset ROBUSTAPI for evaluating the reliability and robustness of code generated by LLMs. We collect 1208 coding questions from Stack Overflow on 18 representative Java APIs. We summarize the common misuse patterns of these APIs and evaluate them on current popular LLMs. The evaluation results show that even GPT-4 has 62% of the generated code that contains API misuses. It would cause unexpected consequences if the code is introduced into real-world software. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Application programming interfaces (API); Artificial intelligence; Computational linguistics; Reliability; Software design; Codegeneration; Executable codes; Language model; Natural languages; Programming codes; Real-world; Reliability and robustness; Resource leaks; Stack overflow; Syntax errors; Semantics","Anil R., Dai A. M., Firat O., Johnson M., Lepikhin D., Passos A., Shakeri S., Taropa E., Bailey P., Chen Z., Et al., Palm 2 technical report, (2023); Austin J., Odena A., Nye M., Bosma M., Michalewski H., Dohan D., Jiang E., Cai C., Terry M., Le Q., Et al., Program synthesis with large language models, (2021); Chen M., Tworek J., Jun H., Yuan Q., Pinto H. P. d. O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, (2021); Chiang W.-L., Li Z., Lin Z., Sheng Y., Wu Z., Zhang H., Zheng L., Zhuang S., Zhuang Y., Gonzalez J. E., Stoica I., Xing E. P., Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality, (2023); Fischer F., Bottinger K., Xiao H., Stransky C., Acar Y., Backes M., Fahl S., Stack overflow considered harmful? the impact of copy&paste on android application security, 2017 IEEE Symposium on Security and Privacy (SP), pp. 121-136, (2017); Fischer G., Lusiardi J., Von Gudenberg J. W., Abstract syntax trees-and their role in model driven software development, International Conference on Software Engineering Advances (ICSEA 2007), pp. 38-38, (2007); Hendrycks D., Basart S., Kadavath S., Mazeika M., Arora A., Guo E., Burns C., Puranik S., He H., Song D., Et al., Measuring coding challenge competence with apps, (2021); Huang H., Shen B., Zhong L., Zhou Y., Protecting data integrity of web applications with database constraints inferred from application code, Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, 2, pp. 632-645, (2023); Jesse K., Ahmed T., Devanbu P. T., Morgan E., Large Language Models and Simple, Stupid Bugs, (2023); Jimenez C. E., Yang J., Wettig A., Yao S., Pei K., Press O., Narasimhan K., SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, (2023); Liu J., Xia C. S., Wang Y., Zhang L., Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation, (2023); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Luo Z., Xu C., Zhao P., Sun Q., Geng X., Hu W., Tao C., Ma J., Lin Q., Jiang D., WizardCoder: Empowering Code Large Language Models with Evol-Instruct, (2023); Nguyen H. A., Dyer R., Nguyen T. N., Rajan H., Mining preconditions of APIs in large-scale code corpus, Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 166-177, (2014); GPT-4 Technical Report; GPT-4 Technical Report; Patil S. G., Zhang T., Wang X., Gonzalez J. E., Gorilla: Large language model connected with massive apis, (2023); Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the keyboard? assessing the security of github copilot's code contributions, 2022 IEEE Symposium on Security and Privacy (SP), pp. 754-768, (2022); Perry N., Srivastava M., Kumar D., Boneh D., Do users write more insecure code with AI assistants?, (2022); Piplani T., Bamman D., DeepSeek: Content based image search & retrieval, (2018); Poesia G., Polozov O., Le V., Tiwari A., Soares G., Meek C., Gulwani S., Synchromesh: Reliable code generation from pre-trained language models, (2022); Sandoval G., Pearce H., Nys T., Karri R., Garg S., Dolan-Gavitt B., Lost at c: A user study on the security implications of large language model code assistants, (2023); Shen B., Zhang J., Chen T., Zan D., Geng B., Fu A., Zeng M., Yu A., Ji J., Zhao J., Et al., PanGuCoder2: Boosting Large Language Models for Code with Ranking Feedback, (2023); Shen X., Chen Z., Backes M., Zhang Y., chatgpt we trust? measuring and characterizing the reliability of chatgpt, (2023); Siddiq M. L., Majumder S. H., Mim M. R., Jajodia S., Santos J. C., An Empirical Study of Code Smells in Transformer-based Code Generation Techniques, 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM), pp. 71-82, (2022); Touvron H., Martin L., Stone K., Albert P., Almahairi A., Babaei Y., Bashlykov N., Batra S., Bhargava P., Bhosale S., Et al., Llama 2: Open foundation and fine-tuned chat models, (2023); Wang J., Dang Y., Zhang H., Chen K., Xie T., Zhang D., Mining succinct and high-coverage API usage patterns from source code, 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 319-328, (2013); Xu F. F., Alon U., Neubig G., Hellendoorn V. J., A systematic evaluation of large language models of code, Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, pp. 1-10, (2022); Yang D., Hussain A., Lopes C. V., From query to usable code: an analysis of stack overflow code snippets, Proceedings of the 13th International Conference on Mining Software Repositories, pp. 391-402, (2016); Ye J., Chen X., Xu N., Zu C., Shao Z., Liu S., Cui Y., Zhou Z., Gong C., Shen Y., Et al., A comprehensive capability analysis of gpt-3 and gpt-3.5 series models, (2023); Yetistiren B., Ozsoy I., Tuzun E., Assessing the quality of GitHub copilot's code generation, Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 62-71, (2022); Yin P., Deng B., Chen E., Vasilescu B., Neubig G., Learning to mine aligned code and natural language pairs from stack overflow, Proceedings of the 15th international conference on mining software repositories, pp. 476-486, (2018); Zhang T., Upadhyaya G., Reinhardt A., Rajan H., Kim M., Are code examples on an online Q&A forum reliable?: a study of API misuse on stack overflow, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 886-896, (2018); Zhou J., Walker R. J., API deprecation: a retrospective analysis and detection method for code examples on the web, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 266-277, (2016)","Wooldridge M.; Dy J.; Natarajan S.","Association for the Advancement of Artificial Intelligence","Association for the Advancement of Artificial Intelligence","38th AAAI Conference on Artificial Intelligence, AAAI 2024","20 February 2024 through 27 February 2024","Vancouver","198370","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189606835"
"Sharma T.; Kechagia M.; Georgiou S.; Tiwari R.; Vats I.; Moazen H.; Sarro F.","Sharma, Tushar (25224153100); Kechagia, Maria (36634273100); Georgiou, Stefanos (56988937100); Tiwari, Rohit (56583482300); Vats, Indira (57928881700); Moazen, Hadi (54951876300); Sarro, Federica (36631133800)","25224153100; 36634273100; 56988937100; 56583482300; 57928881700; 54951876300; 36631133800","A survey on machine learning techniques applied to source code","2024","Journal of Systems and Software","209","","111934","","","","0","10.1016/j.jss.2023.111934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181046174&doi=10.1016%2fj.jss.2023.111934&partnerID=40&md5=878c3604b3353452697955130c6a6a77","The advancements in machine learning techniques have encouraged researchers to apply these techniques to a myriad of software engineering tasks that use source code analysis, such as testing and vulnerability detection. Such a large number of studies hinders the community from understanding the current research landscape. This paper aims to summarize the current knowledge in applied machine learning for source code analysis. We review studies belonging to twelve categories of software engineering tasks and corresponding machine learning techniques, tools, and datasets that have been applied to solve them. To do so, we conducted an extensive literature search and identified 494 studies. We summarize our observations and findings with the help of the identified studies. Our findings suggest that the use of machine learning techniques for source code analysis tasks is consistently increasing. We synthesize commonly used steps and the overall workflow for each task and summarize machine learning techniques employed. We identify a comprehensive list of available datasets and tools useable in this context. Finally, the paper discusses perceived challenges in this area, including the availability of standard datasets, reproducibility and replicability, and hardware resources. Editor's note: Open Science material was validated by the Journal of Systems and Software Open Science Board. © 2023 The Authors","Datasets; Deep learning; Machine learning for software engineering; Source code analysis; Tools","Codes (symbols); Computer programming languages; Learning algorithms; Learning systems; Software testing; 'current; Dataset; Deep learning; Engineering tasks; Machine learning for software engineering; Machine learning techniques; Machine-learning; On-machines; Open science; Source code analysis; Deep learning","Abbas R., Albalooshi F.A., Hammad M., Software change proneness prediction using machine learning, 2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT), pp. 1-7, (2020); Abdalkareem R., Mujahid S., Shihab E., A machine learning approach to improve the detection of ci skip commits, IEEE Trans. Softw. Eng., (2020); Abdeljaber O., Avci O., Kiranyaz S., Gabbouj M., Inman D.J., Real-time vibration-based structural damage detection using one-dimensional convolutional neural networks, J. Sound Vib., 388, pp. 154-170, (2017); Abuhamad M., AbuHmed T., Mohaisen A., Nyang D., Large-scale and language-oblivious code authorship identification, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, pp. 101-114, (2018); Abunadi I., Alenezi M., Towards cross project vulnerability prediction in open source web applications, Proceedings of the the International Conference on Engineering & MIS 2015, ICEMIS ’15, (2015); Aggarwal S., Software code analysis using ensemble learning techniques, Proceedings of the International Conference on Advanced Information Science and System, AISS ’19, (2019); Agnihotri M., Chug A., Application of machine learning algorithms for code smell prediction using object-oriented software metrics, J. Stat. Manag. Syst., 23, 7, pp. 1159-1171, (2020); Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4998-5007, (2020); Ahmed U.Z., Kumar P., Karkare A., Kar P., Gulwani S., Compilation error repair: For the student programs, from the student programs, Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training, ICSE-SEET ’18, pp. 78-87, (2018); Al-Jamimi H.A., Ahmed M., Machine learning-based software quality prediction models: State of the art, 2013 International Conference on Information Science and Applications (ICISA), pp. 1-4, (2013); Al Qasem O., Akour M., Alenezi M., The influence of deep learning algorithms factors in software fault prediction, IEEE Access, 8, pp. 63945-63960, (2020); AL-Shaaby A., Aljamaan H.I., Alshayeb M., Bad smell detection using machine learning techniques: A systematic literature review, Arab. J. Sci. Eng., 45, pp. 2341-2369, (2020); Alazba A., Aljamaan H., Code smell detection using feature selection and stacking ensemble: An empirical investigation, Inf. Softw. Technol., 138, (2021); Aleem S., Capretz L.F., Ahmed F., Et al., Comparative performance analysis of machine learning techniques for software bug detection, Proceedings of the 4th International Conference on Software Engineering and Applications, number 1, pp. 71-79, (2015); Aleti A., Martinez M., E-APR: mapping the effectiveness of automated program repair techniques, Empir. Softw. Eng., 26, 5, pp. 1-30, (2021); Alhusain S., Coupland S., John R., Kavanagh M., Towards machine learning based design pattern recognition, 2013 13th UK Workshop on Computational Intelligence (UKCI), pp. 244-251, (2013); Ali N., Sharafi Z., Gueheneuc Y.-G., Antoniol G., An empirical study on the importance of source code entities for requirements traceability, Empir. Softw. Eng., 20, 2, pp. 442-478, (2015); Ali Alatwi H., Oh T., Fokoue E., Stackpole B., Android malware detection using category-based machine learning classifiers, Proceedings of the 17th Annual Conference on Information Technology Education, SIGITE ’16, pp. 54-59, (2016); Alikhashashneh E.A., Raje R.R., Hill J.H., Using machine learning techniques to classify and predict static code analysis tool warnings, 2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA), pp. 1-8, (2018); Aljamaan H., Alazba A., Software defect prediction using tree-based ensembles, Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 1-10, (2020); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 38-49, (2015); Allamanis M., Barr E.T., Devanbu P., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surv., 51, 4, (2018); Allamanis M., Brockschmidt M., Khademi M., Learning to represent programs with graphs, International Conference on Learning Representations, (2018); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, (2016); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 207-216, (2013); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, 10th Working Conference on Mining Software Repositories (MSR), pp. 207-216, (2013); Allamanis M., Tarlow D., Gordon A.D., Wei Y., Bimodal modelling of source code and natural language, Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, ICML ’15, pp. 2123-2132, (2015); Allix K., Bissyande T.F., Klein J., Le Traon Y., AndroZoo: Collecting millions of android apps for the research community, Proceedings of the 13th International Conference on Mining Software Repositories, MSR ’16, pp. 468-471, (2016); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, SIGPLAN Not., 53, 4, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, POPL, (2019); Alrajeh D., Kramer J., Russo A., Uchitel S., Automated support for diagnosis and repair, Commun. ACM, 58, 2, pp. 65-72, (2015); Alsolai H., Roper M., A systematic literature review of machine learning techniques for software maintainability prediction, Inf. Softw. Technol., 119, (2020); Altarawy D., Shahin H., Mohammed A., Meng N., Lascad: Language-agnostic software categorization and similar application detection, J. Syst. Softw., 142, pp. 21-34, (2018); Alves H., Fonseca B., Antunes N., Experimenting machine learning techniques to predict vulnerabilities, 2016 Seventh Latin-American Symposium on Dependable Computing (LADC), pp. 151-156, (2016); Amal B., Kessentini M., Bechikh S., Dea J., Said L.B., On the use of machine learning and search-based software engineering for ill-defined fitness function: A case study on software refactoring, Search-Based Software Engineering, pp. 31-45, (2014); Amorim L., Costa E., Antunes N., Fonseca B., Ribeiro M., Experience report: Evaluating the effectiveness of decision trees for detecting code smells, 2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE), pp. 261-269, (2015); Amorim L.A., Freitas M.F., Dantas A., de Souza E.F., Camilo-Junior C.G., Martins W.S., A new word embedding approach to evaluate potential fixes for automated program repair, 2018 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2018); Aniche M., Maziero E., Durelli R., Durelli V., The effectiveness of supervised machine learning algorithms in predicting software refactoring, IEEE Trans. Softw. Eng., (2020); Arar .F., Ayan K., Software defect prediction using cost-sensitive neural network, Appl. Soft Comput., 33, pp. 263-277, (2015); Arcelli Fontana F., Zanoni M., Code smell severity classification using machine learning techniques, Knowl.-Based Syst., 128, pp. 43-58, (2017); Aribandi V.K., Kumar L., Bhanu Murthy Neti L., Krishna A., Prediction of refactoring-prone classes using ensemble learning, Neural Information Processing, pp. 242-250, (2019); Azcona D., Arora P., Hsiao I.-H., Smeaton A., User2code2vec: Embeddings for profiling students based on distributional representations of source code, Proceedings of the 9th International Conference on Learning Analytics & Knowledge, LAK19, pp. 86-95, (2019); Azeem M.I., Palomba F., Shi L., Wang Q., Machine learning techniques for code smell detection: A systematic literature review and meta-analysis, Inf. Softw. Technol., 108, pp. 115-138, (2019); Bader J., Scott A., Pradel M., Chandra S., Getafix: Learning to fix bugs automatically, Proc. ACM Program. Lang., 3, OOPSLA, (2019); Balog M., Gaunt A.L., Brockschmidt M., Nowozin S., Tarlow D., DeepCoder: Learning to write programs, (2016); Ban X., Liu S., Chen C., Chua C., A performance evaluation of deep-learnt features for software vulnerability detection, Concurr. Comput.: Pract. Exper., 31, 19, (2019); Bandara U., Wijayarathna G., A machine learning based tool for source code plagiarism detection, Int. J. Mach. Learn. Comput., pp. 337-343, (2011); Banna V., Chinnakotla A., Yan Z., Vegesana A., Vivek N., Krishnappa K., Jiang W., Lu Y.-H., Thiruvathukal G.K., Davis J.C., An experience report on machine learning reproducibility: Guidance for practitioners and TensorFlow model garden contributors, (2021); Bansal A., Haque S., McMillan C., Project-level encoding for neural source code summarization of subroutines, 2021 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC) (ICPC), pp. 253-264, (2021); Barbez A., Khomh F., Gueheneuc Y.-G., A machine-learning based ensemble method for anti-patterns detection, J. Syst. Softw., 161, (2020); Barone A.V.M., Sennrich R., A parallel corpus of python functions and documentation strings for automated code documentation and code generation, (2017); Batur Sahin C., Abualigah L., A novel deep learning-based feature selection model for improving the static analysis of vulnerability detection, Neural Comput. Appl., 33, 20, pp. 14049-14067, (2021); Bavota G., Gethers M., Oliveto R., Poshyvanyk D., Lucia A.D., Improving software modularization via automated analysis of latent topics and dependencies, ACM Trans. Softw. Eng. Methodol. (TOSEM), 23, 1, pp. 1-33, (2014); Bavota G., Oliveto R., Gethers M., Poshyvanyk D., De Lucia A., Methodbook: Recommending move method refactorings via relational topic models, IEEE Trans. Softw. Eng., 40, 7, pp. 671-694, (2013); Ben-Nun T., Jakobovits A.S., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS ’18, pp. 3589-3601, (2018); Bhandari G.P., Gupta R., Machine learning based software fault prediction utilizing source code metrics, 2018 IEEE 3rd International Conference on Computing, Communication and Security (ICCCS), pp. 40-45, (2018); Bhatia S., Kohli P., Singh R., Neuro-symbolic program corrector for introductory programming assignments, Proceedings of the 40th International Conference on Software Engineering, ICSE ’18, pp. 60-70, (2018); Bielik P., Raychev V., Vechev M.T., Program synthesis for character level language modeling, ICLR, (2017); Bilgin Z., Ersoy M.A., Soykan E.U., Tomur E., Comak P., Karacay L., Vulnerability prediction from source code using machine learning, IEEE Access, 8, pp. 150672-150684, (2020); Black P.E., Software assurance with SAMATE reference dataset, tool standards, and studies, (2007); Boland F., Black P., The Juliet 1.1 C/C++ and Java test suite, (2012); Bowes D., Hall T., Harman M., Jia Y., Sarro F., Wu F., Mutation-aware fault prediction, Proceedings of the 25th International Symposium on Software Testing and Analysis, ISSTA 2016, pp. 330-341, (2016); Braga R., Neto P.S., Rabelo R., Santiago J., Souza M., A machine learning approach to generate test oracles, Proceedings of the XXXII Brazilian Symposium on Software Engineering, SBES ’18, pp. 142-151, (2018); Brauckmann A., Goens A., Ertel S., Castrillon J., Compiler-based graph representations for deep learning models of code, Proceedings of the 29th International Conference on Compiler Construction, CC 2020, pp. 201-211, (2020); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative code modeling with graphs, International Conference on Learning Representations, (2019); Brown T.B., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D.M., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language models are few-shot learners, (2020); Bruch M., Monperrus M., Mezini M., Learning from examples to improve code completion systems, Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE ’09, pp. 213-222, (2009); Brun Y., Meliou A., Software fairness, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2018, pp. 754-759, (2018); Bui N.D.Q., Jiang L., Yu Y., Cross-language learning for program classification using bilateral tree-based convolutional neural networks, AAAI Workshops, (2018); Bui N.D.Q., Yu Y., Jiang L., Bilateral dependency neural networks for cross-language algorithm classification, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 422-433, (2019); Butgereit L., Using machine learning to prioritize automated testing in an agile environment, 2019 Conference on Information Communications Technology and Society (ICTAS), pp. 1-6, (2019); Cai J., Shin R., Song D., Making neural programming architectures generalize via recursion, (2017); Cai C.-H., Sun J., Dobbie G., Automatic B-model repair using model checking and machine learning, Autom. Softw. Eng., 26, 3, (2019); Cambronero J.P., Rinard M.C., AL: autogenerating supervised learning programs, Proc. ACM Program. Lang., 3, OOPSLA, pp. 1-28, (2019); Caram F.L., Rodrigues B.R.D.O., Campanelli A.S., Parreiras F.S., Machine learning techniques for code smells detection: a systematic mapping study, Int. J. Softw. Eng. Knowl. Eng., 29, 2, pp. 285-316, (2019); Caram F.L., Rodrigues B.R.D.O., Campanelli A.S., Parreiras F.S., Machine learning techniques for code smells detection: A systematic mapping study, Int. J. Softw. Eng. Knowl. Eng., 29, 2, pp. 285-316, (2019); Cesare S., Xiang Y., Zhang J., Clonewise – detecting package-level clones using machine learning, Security and Privacy in Communication Networks, pp. 197-215, (2013); Cetiner M., Sahingoz O.K., A comparative analysis for machine learning based software defect prediction systems, 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT), pp. 1-7, (2020); Ceylan E., Kutlubay F.O., Bener A.B., Software defect identification using machine learning techniques, 32nd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO’06), pp. 240-247, (2006); Chakraborty S., Ding Y., Allamanis M., Ray B., CODIT: Code editing with tree-based neural models, IEEE Trans. Softw. Eng., (2020); Chakraborty S., Ding Y., Allamanis M., Ray B., CODIT: Code editing with tree-based neural models, IEEE Trans. Softw. Eng., 48, 4, pp. 1385-1399, (2022); Chakraborty S., Ray B., On multi-modal learning of editing source code, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 443-455, (2021); Challagulla V.U.B., Bastani F.B., Yen I.-L., Paul R.A., Empirical assessment of machine learning based software defect prediction techniques, Int. J. Artif. Intell. Tools, 17, 2, pp. 389-400, (2008); Chappelly T., Cifuentes C., Krishnan P., Gevay S., Machine learning for finding bugs: An initial report, 2017 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE), pp. 21-26, (2017); Chaturvedi S., Chaturvedi A., Tiwari A., Agarwal S., Design pattern detection using machine learning techniques, 2018 7th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)(ICRITO), pp. 1-6, (2018); Chen D., Chen X., Li H., Xie J., Mu Y., Deepcpdp: Deep learning based cross-project defect prediction, IEEE Access, 7, pp. 184832-184848, (2019); Chen Q., Hu H., Liu Z., Code summarization with abstract syntax tree, Neural Information Processing, pp. 652-660, (2019); Chen J., Hu K., Yu Y., Chen Z., Xuan Q., Liu Y., Filkov V., Software visualization and deep transfer learning for effective software defect prediction, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, ICSE ’20, pp. 578-589, (2020); Chen F., Kim M., Choo J., Novel natural language summarization of program code via leveraging multiple input representations, Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 2510-2520, (2021); Chen Z., Kommrusch S.J., Tufano M., Pouchet L., Poshyvanyk D., Monperrus M., SEQUENCER: Sequence-to-sequence learning for end-to-end program repair, IEEE Trans. Softw. Eng., (2019); Chen X., Liu C., Shin R., Song D., Chen M., Latent attention for if-then program synthesis, Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS ’16, pp. 4581-4589, (2016); Chen X., Liu C., Song D., Towards synthesizing complex programs from input-output examples, (2018); Chen X., Liu C., Song D., Execution-guided neural program synthesis, International Conference on Learning Representations, (2019); Chen Y., Santosa A.E., Yi A.M., Sharma A., Sharma A., Lo D., A machine learning approach for vulnerability curation, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 32-42, (2020); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, (2021); Chen M., Wan X., Neural comment generation for source code with auxiliary code classification task, 2019 26th Asia-Pacific Software Engineering Conference (APSEC), pp. 522-529, (2019); Chen Q., Xia X., Hu H., Lo D., Li S., Why my code summarization model does not work: Code comment improvement with category prediction, ACM Trans. Softw. Eng. Methodol. (TOSEM), 30, 2, pp. 1-29, (2021); Chen L., Ye W., Zhang S., Capturing source code semantics via tree-based convolution over API-enhanced AST, Proceedings of the 16th ACM International Conference on Computing Frontiers, CF ’19, pp. 174-182, (2019); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 826-831, (2018); Chernis B., Verma R., Machine learning methods for software vulnerability detection, Proceedings of the Fourth ACM International Workshop on Security and Privacy Analytics, IWSPA ’18, pp. 31-39, (2018); Chidamber S.R., Kemerer C.F., A metrics suite for object oriented design, IEEE Trans. Softw. Eng., 20, 6, pp. 476-493, (1994); Choi Y., Kim S., Lee J., Source code summarization using attention-based keyword memory networks, 2020 IEEE International Conference on Big Data and Smart Computing (BigComp), pp. 564-570, (2020); Choudhary G.R., Kumar S., Kumar K., Mishra A., Catal C., Empirical analysis of change metrics for software fault prediction, Comput. Electr. Eng., 67, pp. 15-24, (2018); Chug A., Dhall S., Software defect prediction using supervised learning algorithm and unsupervised learning algorithm, Confluence 2013: The Next Generation Information Technology Summit (4th International Conference), pp. 173-179, (2013); Clemente C.J., Jaafar F., Malik Y., Is predicting software security bugs using deep learning better than the traditional machine learning algorithms?, 2018 IEEE International Conference on Software Quality, Reliability and Security (QRS), pp. 95-102, (2018); Compton R., Frank E., Patros P., Koay A., Embedding java classes with code2vec: Improvements from variable obfuscation, Proceedings of the 17th International Conference on Mining Software Repositories, MSR ’20, pp. 243-253, (2020); Cortes-Coy L.F., Vasquez M., Aponte J., Poshyvanyk D., On automatically generating commit messages via summarization of source code changes, 2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation, pp. 275-284, (2014); Cruz D., Santana A., Figueiredo E., Detecting bad smells with machine learning algorithms: an empirical study, Proceedings of the 3rd International Conference on Technical Debt, pp. 31-40, (2020); Cruz D., Santana A., Figueiredo E., Detecting bad smells with machine learning algorithms: An empirical study, Proceedings of the 3rd International Conference on Technical Debt, TechDebt ’20, pp. 31-40, (2020); Cui J., Wang L., Zhao X., Zhang H., Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications, Comput. Commun., 155, pp. 125-131, (2020); Cummins C., Petoumenos P., Wang Z., Leather H., Synthesizing benchmarks for predictive modeling, 2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), pp. 86-99, (2017); Cunha W.S., Armijo G.A., de Camargo V.V., Investigating non-usually employed features in the identification of architectural smells: A machine learning-based approach, Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse, pp. 21-30, (2020); Cvitkovic M., Singh B., Anandkumar A., Open vocabulary learning on source code with a graph-structured cache, Proceedings of Machine Learning Research, 97, pp. 1475-1485, (2019); Dam H.K., Pham T., Ng S.W., Tran T., Grundy J., Ghose A., Kim T., Kim C.-J., Lessons learned from using a deep tree-based model for software defect prediction in practice, Proceedings of the 16th International Conference on Mining Software Repositories, MSR ’19, pp. 46-57, (2019); D'Ambros M., Lanza M., Robbes R., Evaluating defect prediction approaches: A benchmark and an extensive comparison, Empir. Softw. Eng., 17, 4-5, pp. 531-577, (2012); Dantas A., de Souza E.F., Souza J., Camilo-Junior C.G., Code naturalness to assist search space exploration in search-based program repair methods, Search-Based Software Engineering, pp. 164-170, (2019); De Lucia A., Di Penta M., Oliveto R., Panichella A., Panichella S., Labeling source code with information retrieval methods: an empirical study, Empir. Softw. Eng., 19, 5, pp. 1383-1420, (2014); Dejaeger K., Verbraken T., Baesens B., Toward comprehensible software fault prediction models using bayesian network classifiers, IEEE Trans. Softw. Eng., 39, 2, pp. 237-257, (2012); Devlin J., Bunel R., Singh R., Hausknecht M., Kohli P., Neural program meta-induction, Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPS ’17, pp. 2077-2085, (2017); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Devlin J., Uesato J., Bhupatiraju S., Singh R., Mohamed A.-R., Kohli P., RobustFill: Neural program learning under noisy I/O, Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML ’17, pp. 990-998, (2017); Dewangan S., Rao R.S., Mishra A., Gupta M., A novel approach for code smell detection: An empirical study, IEEE Access, 9, pp. 162869-162883, (2021); Dhamayanthi N., Lavanya B., Improvement in software defect prediction outcome using principal component analysis and ensemble machine learning algorithms, International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018, pp. 397-406, (2019); Di Martino S., Ferrucci F., Gravino C., Sarro F., A genetic algorithm to configure support vector machines for predicting fault-prone components, Product-Focused Software Process Improvement, pp. 247-261, (2011); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 612-621, (2018); Dong L., Lapata M., Language to logical form with neural attention, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 33-43, (2016); Dos Santos G.E., Figueiredo E., Veloso A., Viggiato M., Ziviani N., Understanding machine learning software defect predictions, Autom. Softw. Eng., 27, pp. 369-392, (2020); Du X., Chen B., Li Y., Guo J., Zhou Y., Liu Y., Jiang Y., LEOPARD: Identifying vulnerable code for vulnerability assessment through program metrics, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 60-71, (2019); Du Y., Wang X., Wang J., A static android malicious code detection method based on multi-source fusion, Secur. Commun. Netw., 8, 17, pp. 3238-3246, (2015); Durelli V.H.S., Durelli R.S., Borges S.S., Endo A.T., Eler M.M., Dias D.R.C., Guimaraes M.P., Machine learning applied to software testing: A systematic mapping study, IEEE Trans. Reliab., 68, 3, pp. 1189-1212, (2019); Dwivedi A.K., Tirkey A., Ray R.B., Rath S.K., Software design pattern recognition using machine learning techniques, 2016 Ieee Region 10 Conference (Tencon), pp. 222-227, (2016); Efstathiou V., Spinellis D., Semantic source code models using identifier embeddings, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), pp. 29-33, (2019); Elovici Y., Shabtai A., Moskovitch R., Tahan G., Glezer C., Applying machine learning techniques for detection of malicious code in network traffic, KI 2007: Advances in Artificial Intelligence, pp. 44-50, (2007); Eniser H.F., Gerasimou S., Sen A., DeepFault: Fault localization for deep neural networks, Fundamental Approaches to Software Engineering, pp. 171-191, (2019); Erturk E., Sezer E.A., A comparison of some soft computing methods for software fault prediction, Expert Syst. Appl., 42, 4, pp. 1872-1879, (2015); Etemadi K., Monperrus M., On the relevance of cross-project learning with nearest neighbours for commit message generation, Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops, pp. 470-475, (2020); Fakhoury S., Arnaoudova V., Noiseux C., Khomh F., Antoniol G., Keep it simple: Is deep learning good for linguistic smell detection?, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 602-611, (2018); Falleri J.-R., Morandat F., Blanc X., Martinez M., Monperrus M., Fine-grained and accurate source code differencing, Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering, ASE ’14, pp. 313-324, (2014); Fan G., Diao X., Yu H., Yang K., Chen L., Deep semantic feature learning with embedded static metrics for software defect prediction, 2019 26th Asia-Pacific Software Engineering Conference (APSEC), pp. 244-251, (2019); Fang Y., Liu Y., Huang C., Liu L., FastEmbed: Predicting vulnerability exploitation possibility based on ensemble machine learning algorithm, PLoS ONE, 15, (2020); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2020, pp. 516-527, (2020); Felix E.A., Lee S.P., Integrated approach to software defect prediction, IEEE Access, 5, pp. 21524-21547, (2017); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Ferenc R., Hegedundefineds P., Gyimesi P., Antal G., Ban D., Gyimothy T., Challenging machine learning algorithms in predicting vulnerable JavaScript functions, Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering, RAISE ’19, pp. 8-14, (2019); Ferreira F., Silva L.L., Valente M.T., Software engineering meets deep learning: A mapping study, Proceedings of the 36th Annual ACM Symposium on Applied Computing, SAC ’21, pp. 1542-1549, (2021); Fontana F., Mantyla M., Zanoni M., Marino A., Comparing and experimenting machine learning techniques for code smell detection, Empir. Softw. Eng., 21, pp. 1143-1191, (2015); Fontana F.A., Zanoni M., Marino A., Mantyla M.V., Code smell detection: Towards a machine learning-based approach, 2013 IEEE International Conference on Software Maintenance, pp. 396-399, (2013); Gamma E., Helm R., Johnson R., Vlissides J., Design Patterns: Elements of Reusable Object-Oriented Software, (1994); Gao Z., Xia X., Grundy J., Lo D., Li Y.-F., Generating question titles for stack overflow from mined code snippets, ACM Trans. Softw. Eng. Methodol., 29, 4, (2020); Ghadhab L., Jenhani I., Mkaouer M.W., Messaoud M.B., Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model, Inf. Softw. Technol., 135, (2021); Ghaffarian S.M., Shahriari H.R., Software vulnerability analysis and discovery using machine-learning and data-mining techniques: A survey, ACM Comput. Surv., 50, 4, (2017); Gharbi S., Mkaouer M.W., Jenhani I., Messaoud M.B., On the classification of software change messages using multi-label active learning, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, pp. 1760-1767, (2019); Giray G., A software engineering perspective on engineering machine learning systems: State of the art and challenges, J. Syst. Softw., 180, (2021); GitHub archive, (2020); Godefroid P., Peleg H., Singh R., Learn fuzz: Machine learning for input fuzzing, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 50-59, (2017); Gondra I., Applying machine learning to software fault-proneness prediction, J. Syst. Softw., 81, 2, pp. 186-195, (2008); Gopalakrishnan R., Sharma P., Mirakhorli M., Galster M., Can latent topics in source code predict missing architectural tactics?, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), pp. 15-26, (2017); Gopalakrishnan R., Sharma P., Mirakhorli M., Galster M., Can latent topics in source code predict missing architectural tactics?, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), pp. 15-26, (2017); Gopinath D., Khurshid S., Saha D., Chandra S., Data-guided repair of selection statements, Proceedings of the 36th International Conference on Software Engineering, ICSE 2014, pp. 243-253, (2014); Gopinath D., Wang K., Hua J., Khurshid S., Repairing intricate faults in code using machine learning and path exploration, 2016 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 453-457, (2016); Goues C.L., Pradel M., Roychoudhury A., Automated program repair, Commun. ACM, 62, 12, pp. 56-65, (2019); Gousios G., The GHTorrent dataset and tool suite, Proceedings of the 10th Working Conference on Mining Software Repositories, MSR ’13, pp. 233-236, (2013); Grano G., Titov T.V., Panichella S., Gall H.C., How high will it be? Using machine learning models to predict branch coverage in automated testing, 2018 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE), pp. 19-24, (2018); Graves A., Jaitly N., Mohamed A.-R., Hybrid speech recognition with deep bidirectional LSTM, Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, pp. 273-278, (2013); Greff K., Srivastava R.K., Koutnik J., Steunebrink B.R., Schmidhuber J., LSTM: A search space odyssey, IEEE Trans. Neural Netw. Learn. Syst., 28, 10, pp. 2222-2232, (2017); Grodzicka H., Ziobrowski A., Lakomiak Z., Kawa M., Madeyski L., Code smell prediction employing machine learning meets emerging java language constructs, Data-Centric Business and Applications: Towards Software Development (Volume 4), pp. 137-167, (2020); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Guggulothu T., Moiz S.A., Code smell detection using multi-label classification approach, Softw. Qual. J., pp. 1-24, (2020); Gulwani S., Harris W.R., Singh R., Spreadsheet data manipulation using examples, Commun. ACM, 55, 8, pp. 97-105, (2012)","","Elsevier Inc.","","","","","","Article","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85181046174"
"Ding H.; Kumar V.; Tian Y.; Wang Z.; Kwiatkowski R.; Li X.; Ramanathan M.K.; Ray B.; Bhatia P.; Sengupta S.; Roth D.; Xiang B.","Ding, Hantian (57955134000); Kumar, Varun (57220974632); Tian, Yuchen (57954916400); Wang, Zijian (57566888400); Kwiatkowski, Rob (58713840500); Li, Xiaopeng (57221401597); Ramanathan, Murali Krishna (58828757600); Ray, Baishakhi (24492560400); Bhatia, Parminder (57209095435); Sengupta, Sudipta (57225741939); Roth, Dan (7401669040); Xiang, Bing (7005065960)","57955134000; 57220974632; 57954916400; 57566888400; 58713840500; 57221401597; 58828757600; 24492560400; 57209095435; 57225741939; 7401669040; 7005065960","A Static Evaluation of Code Completion by Large Language Models","2023","Proceedings of the Annual Meeting of the Association for Computational Linguistics","5","","","347","360","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174223789&partnerID=40&md5=908d498fe60c8e2f24187b9e72d9faec","Large language models trained on code have shown great potential to increase productivity of software developers. Several execution-based benchmarks have been proposed to evaluate functional correctness of model-generated code on simple programming problems. Nevertheless, it is expensive to perform the same evaluation on complex real-world projects considering the execution cost. On the contrary, static analysis tools such as linters, which can detect errors without running the program, haven't been well explored for evaluating code generation models. In this work, we propose a static evaluation framework to quantify static errors in Python code completions, by leveraging Abstract Syntax Trees. Compared with execution-based evaluation, our method is not only more effcient, but also applicable to code in the wild. For experiments, we collect code context from open source repos to generate one million function bodies using public models. Our static analysis reveals that Undefned Name and Unused Variable are the most common errors among others made by language models. Through extensive studies, we also show the impact of sampling temperature, model size, and context on static errors in code completions. © ACL 2023.All rights reserved.","","Computational linguistics; Errors; Functional programming; Open source software; Open systems; Syntactics; Trees (mathematics); Code completions; Execution costs; Functional correctness; Language model; Programming problem; Real world projects; Simple++; Software developer; Static error; Static evaluation; Static analysis","Ahmad Wasi, Chakraborty Saikat, Ray Baishakhi, Chang Kai-Wei, Unifed pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Aho Alfred V, Sethi Ravi, Ullman Jeffrey D, Compilers: principles, techniques, and tools, 2, (2007); Athiwaratkun Ben, Gouda Sanjay Krishna, Wang Zijian, Li Xiaopeng, Tian Yuchen, Tan Ming, Ahmad Wasi Uddin, Wang Shiqi, Sun Qing, Shang Mingyue, Gonugondla Su-jan Kumar, Ding Hantian, Kumar Varun, Fulton Nathan, Farahani Arash, Jain Siddhartha, Giaquinto Robert, Qian Haifeng, Ra-manathan Murali Krishna, Nallapati Ramesh, Ray Baishakhi, -der Bhatia Parmin, Sengupta Sudipta, Roth Dan, Xiang Bing, Multi-lingual evaluation of code generation models, CoRR, (2022); Austin Jacob, Odena Augustus, Nye Maxwell I., Bosma Maarten, Michalewski Henryk, Dohan David, Jiang Ellen, Cai Carrie J., Terry Michael, Le Quoc V., Sutton Charles, Program synthesis with large language models, CoRR, (2021); Ayewah Nathaniel, Pugh William, Hovemeyer David, David Morgenthaler J, Penix John, Using static analysis to fnd bugs, IEEE software, 25, 5, pp. 22-29, (2008); Chen Mark, Tworek Jerry, Jun Heewoo, Yuan Qiming, de Oliveira Pinto Henrique Ponde, Kaplan Jared, Edwards Harrison, Burda Yuri, Joseph Nicholas, Brockman Greg, Ray Alex, Puri Raul, Krueger Gretchen, Petrov Michael, Khlaaf Heidy, Sas-try Girish, Mishkin Pamela, Chan Brooke, Gray Scott, Ryder Nick, Pavlov Mikhail, Power Alethea, Kaiser Lukasz, Bavarian Mohammad, Winter Clemens, Tillet Philippe, Such Felipe Petroski, Cum-mings Dave, Plappert Matthias, Chantzis Fotios, Barnes Elizabeth, Herbert-Voss Ariel, Guss William Hebgen, Nichol Alex, Paino Alex, Tezak Nikolas, Tang Jie, Babuschkin Igor, Balaji Suchir, Jain Shantanu, Saunders William, Hesse Christopher, Carr Andrew N., Leike Jan, Achiam Joshua, Misra Vedant, Morikawa Evan, Radford Alec, Knight Matthew, Brundage Miles, Murati Mira, Mayer Katie, Welinder Peter, McGrew Bob, Amodei Dario, McCandlish Sam, Sutskever Ilya, Zaremba Wojciech, Evaluating large language models trained on code, CoRR, (2021); Chess Brian, McGraw Gary, Static analysis for security, IEEE security & privacy, 2, 6, pp. 76-79, (2004); Chess Brian, West Jacob, Secure programming with static analysis, (2007); Emanuelsson Par, Nilsson Ulf, A comparative study of industrial static analysis tools, Electronic notes in theoretical computer science, 217, pp. 5-21, (2008); Feng Zhangyin, Guo Daya, Tang Duyu, Duan Nan, Feng Xi-aocheng, Gong Ming, Shou Linjun, Qin Bing, Liu Ting, Jiang Daxin, Zhou Ming, Code-BERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Fried Daniel, Aghajanyan Armen, Lin Jessy, Wang Sida, Wallace Eric, Shi Freda, Zhong Ruiqi, Yih Wen-tau, Zettlemoyer Luke, Lewis Mike, Incoder: A generative model for code inflling and synthesis, CoRR, (2022); Guo Daya, Lu Shuai, Duan Nan, Wang Yanlin, Zhou Ming, Yin Jian, UniXcoder: Unifed cross-modal pre-training for code representation, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 7212-7225, (2022); Iyer Srinivasan, Konstas Ioannis, Cheung Alvin, Zettlemoyer Luke, Mapping language to code in programmatic context, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1643-1652, (2018); Lai Yuhang, Li Chengxi, Wang Yiming, Zhang Tianyi, Zhong Ruiqi, Zettlemoyer Luke, Wen-tau Yih Scott, Fried Daniel, Wang Sida I., Yu Tao, DS-1000: A natural and reliable benchmark for data science code generation, CoRR, (2022); Li Yujia, Choi David H., Chung Junyoung, Kush-man Nate, Schrittwieser Julian, Leblond Remi, Ec-cles Tom, Keeling James, Gimeno Felix, Dal Lago Agustin, Hubert Thomas, Choy Peter, de Mas-son d'Autume Cyprien, Babuschkin Igor, Chen Xinyun, Huang Po-Sen, Welbl Johannes, Gowal Sven, Cherepanov Alexey, Molloy James, Mankowitz Daniel J., Robson Esme Sutherland, Kohli Pushmeet, de Freitas Nando, Kavukcuoglu Koray, Vinyals Oriol, Competition-level code generation with alpha-code, CoRR, (2022); Lu Shuai, Guo Daya, Ren Shuo, Huang Junjie, Svyatkovskiy Alexey, Blanco Ambrosio, Clement Colin B., Drain Dawn, Jiang Daxin, Tang Duyu, Li Ge, Zhou Li-dong, Shou Linjun, Zhou Long, Tu-fano Michele, Gong Ming, Zhou Ming, Duan Nan, Sun-daresan Neel, Deng Shao Kun, Fu Shengyu, Liu Shujie, Codexglue: A machine learning benchmark dataset for code understanding and generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, (2021); Nijkamp Erik, Pang Bo, Hayashi Hiroaki, Tu Lifu, Wang Huan, Zhou Yingbo, Savarese Silvio, Xiong Caiming, Codegen: An open large language model for code with multi-turn program synthesis, (2022); Svyatkovskiy Alexey, Zhao Ying, Fu Shengyu, Sundaresan Neel, Pythia: Ai-assisted code completion system, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2019, pp. 2727-2735, (2019); Tufano Michele, Watson Cody, Bavota Gabriele, Di Penta Massi-miliano, White Martin, Poshy-vanyk Denys, An empirical study on learning bug-fxing patches in the wild via neural machine translation, ACM Trans. Softw. Eng. Methodol, 28, 4, (2019); Vaithilingam Priyan, Zhang Tianyi, Glass-man Elena L., Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models, Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems, CHI EA '22, (2022); Van Oort Bart, Cruz Luis, Aniche Mauricio, Van Deursen Arie, The prevalence of code smells in machine learning projects, 2021 IEEE/ACM 1st Workshop on AI Engineering-Software Engineering for AI (WAIN), pp. 1-8, (2021); Wang Yue, Wang Weishi, Joty Shafq, Hoi Steven C.H., CodeT5: Identifer-aware unifed pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, (2021); Zheng Jiang, Williams Laurie, Nagappan Nachiappan, Snipes Will, Hudepohl John P, Vouk Mladen A, On the value of static analysis for fault detection in software, IEEE transactions on software engineering, 32, 4, pp. 240-253, (2006); Ziegler Albert, Kalliamvakou Eirini, Simister Shawn, Sittampalam Ganesh, Li Alice, Rice Andrew, Rifkin Devon, Aftandilian Edward, Productivity assessment of neural code completion, (2022)","","Association for Computational Linguistics (ACL)","","61st Annual Meeting of the Association for Computational Linguistics, ACL 2023","10 July 2023 through 12 July 2023","Toronto","192160","Conference paper","Final","","Scopus","2-s2.0-85174223789"
"Zhang F.; Liu J.; Wan Y.; Yu X.; Liu X.; Keung J.","Zhang, Fengji (57290701700); Liu, Jin (55978402400); Wan, Yao (57089582400); Yu, Xiao (58258194200); Liu, Xiao (52365658400); Keung, Jacky (6603066702)","57290701700; 55978402400; 57089582400; 58258194200; 52365658400; 6603066702","Diverse title generation for Stack Overflow posts with multiple-sampling-enhanced transforme","2023","Journal of Systems and Software","200","","111672","","","","2","10.1016/j.jss.2023.111672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149984186&doi=10.1016%2fj.jss.2023.111672&partnerID=40&md5=f7049fcb22cb46aac461317e37e8ba95","Stack Overflow is one of the most popular programming communities where developers can seek help for their encountered problems. Nevertheless, if inexperienced developers fail to describe their problems clearly, it is hard for them to attract sufficient attention and get the anticipated answers. To address such a problem, we propose M3NSCT5, a novel approach to automatically generate multiple post titles from the given code snippets. Developers may take advantage of the generated titles to find closely related posts and complete their problem descriptions. M3NSCT5 employs the CodeT5 backbone, which is a pre-trained Transformer model with an excellent language understanding and generation ability. To alleviate the ambiguity issue that the same code snippets could be aligned with different titles under varying contexts, we propose the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from. We build a large-scale dataset with 890,000 question posts covering eight programming languages to validate the effectiveness of M3NSCT5. The automatic evaluation results on the BLEU and ROUGE metrics demonstrate the superiority of M3NSCT5 over six state-of-the-art baseline models. Moreover, a human evaluation with trustworthy results also demonstrates the great potential of our approach for real-world applications. © 2023 Elsevier Inc.","CodeT5; Maximal marginal ranking; Nucleus sampling; Stack Overflow; Title generation","Codes (symbols); Software engineering; Codet5; Language generation; Maximal marginal ranking; Multiple sampling; Nucleus sampling; Problem description; Programming community; Stack overflow; Title generation; Transformer modeling; Large dataset","Ahmad W., Chakraborty S., Ray B., pp. 4998-5007, (2020); Ahmad W., Chakraborty S., Ray B., pp. 2655-2668, (2021); Baltes S., Dumani L., Treude C., Diehl S., pp. 319-330, (2018); Chatterjee P., Automatic identification of informative code in stack overflow posts, (2022); Chatterjee P., Kong M., Pollock L., Finding help with programming errors: An exploratory study of novice software engineers’ focus in stack overflow posts, J. Syst. Softw., 159, (2020); Chen Y., Dai H., Yu X., Hu W., Xie Z., Tan C., Improving ponzi scheme contract detection using multi-channel textCNN and transformer, Sensors, 21, 19, (2021); Chen Y., Lu X., Deep category-level and regularized hashing with global semantic similarity learning, IEEE Trans. Cybern., 51, 12, pp. 6240-6252, (2020); Chen Y., Lu X., Li X., Supervised deep hashing with a joint deep network, Pattern Recognit., 105, (2020); Chen Y., Lu X., Wang S., Deep cross-modal image–voice retrieval in remote sensing, IEEE Trans. Geosci. Remote Sens., 58, 10, pp. 7049-7061, (2020); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, (2021); Chen Y., Xiong S., Mou L., Zhu X.X., Deep quadruple-based hashing for remote sensing image-sound retrieval, IEEE Trans. Geosci. Remote Sens., 60, pp. 1-14, (2022); Cheng W., Hu P., Wei S., Mo R., Keyword-guided abstractive code summarization via incorporating structural and contextual information, Inf. Softw. Technol., 150, (2022); Chengran Y., Xu B., Thung F., Shi Y., Zhang T., Yang Z., Zhou X., Shi J., He J., Han D., Et al., Answer summarization for technical queries: Benchmark and new approach, (2022); Cobbe K., Kosaraju V., Bavarian M., Hilton J., Nakano R., Hesse C., Schulman J., Training verifiers to solve math word problems, (2021); Cohen J., A coefficient of agreement for nominal scales, Educ. Psychol. Meas., 20, 1, pp. 37-46, (1960); Devine P., Blincoe K., Unsupervised extreme multi label classification of stack overflow posts, 2022 IEEE/ACM 1st International Workshop on Natural Language-Based Software Engineering (NLBSE), pp. 1-8, (2022); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Feng S., Keung J., Yu X., Xiao Y., Zhang M., Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction, Inf. Softw. Technol., 139, (2021); Fried D., Aghajanyan A., Lin J., Wang S., Wallace E., Shi F., Zhong R., Yih W.-T., Zettlemoyer L., Lewis M., Incoder: A generative model for code infilling and synthesis, (2022); Gage P., A new algorithm for data compression, C Users Journal, 12, 2, pp. 23-38, (1994); Gao Z., Xia X., Grundy J., Lo D., Li Y.-F., Generating question titles for stack overflow from mined code snippets, ACM Trans. Softw. Eng. Methodol. (TOSEM), 29, 4, pp. 1-37, (2020); Gao Z., Xia X., Lo D., Grundy J.C., Zhang X., Xing Z., I know what you are searching for: Code snippet recommendation from stack overflow posts, ACM Trans. Softw. Eng. Methodol., (2022); Guo J., Liu J., Wan Y., Li L., Zhou P., pp. 486-500; Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Unified cross-modal pre-training for code representation, (2022); He C., Wu J., Zhang Q., Research leadership flow determinants and the role of proximity in research collaborations, J. Assoc. Inf. Sci. Technol., 71, 11, pp. 1341-1356, (2020); He C., Wu J., Zhang Q., Characterizing research leadership on geographically weighted collaboration network, Scientometrics, 126, 5, pp. 4005-4037, (2021); He C., Wu J., Zhang Q., Proximity-aware research leadership recommendation in research collaboration via deep neural networks, J. Assoc. Inf. Sci. Technol., 73, 1, pp. 70-89, (2022); He J., Xu B., Yang Z., Han D., Yang C., Lo D., pp. 1-11; Hendrycks D., Basart S., Kadavath S., Mazeika M., Arora A., Guo E., Burns C., Puranik S., He H., Song D., Et al., Measuring coding challenge competence with apps, (2021); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Holtzman A., Buys J., Du L., Forbes M., Choi Y., The curious case of neural text degeneration, (2019); Inala J.P., Wang C., Yang M., Codas A., Encarnacion M., Lahiri S.K., Musuvathi M., Gao J., Fault-aware neural code rankers, (2022); Kenton J.D.M.-W.C., Toutanova L.K.B., pp. 4171-4186, (2019); Khandelwal U., He H., Qi P., Jurafsky D., pp. 284-294, (2018); Kincaid J.P., Fishburne R.P., Rogers R.L., Chissom B.S., Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel: Technical Report, (1975); Kou B., Di Y., Chen M., Zhang T., pp. 247-251, (2022); Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L.B., pp. 7871-7880, (2020); Li Y., Choi D., Chung J., Kushman N., Schrittwieser J., Leblond R., Eccles T., Keeling J., Gimeno F., Lago A.D., Et al., Competition-level code generation with alphacode, (2022); Li Z., Wu Y., Peng B., Chen X., Sun Z., Liu Y., Yu D., Secnn: A semantic CNN parser for code comment generation, J. Syst. Softw., 181, (2021); Lin C.-Y., ROUGE: A package for automatic evaluation of summaries, Text Summarization Branches Out, pp. 74-81, (2004); Lin C.-Y., pp. 501-507, (2004); Liu K., Yang G., Chen X., Yu C., Sotitle: A transformer-based post title generation approach for stack overflow, (2022); Liu K., Yang G., Chen X., Zhou Y., pp. 147-155; Liu J., Zhou P., Yang Z., Liu X., Grundy J.C., FastTagRec: fast tag recommendation for software information sites, Autom. Softw. Eng., 25, pp. 675-701, (2018); Loshchilov I., Hutter F., Decoupled weight decay regularization, (2017); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Ma X., Keung J., Yang Z., Yu X., Li Y., Zhang H., CASMS: Combining clustering with attention semantic model for identifying security bug reports, Inf. Softw. Technol., 147, (2022); Mashhadi E., Hemmati H., Applying codebert for automated program repair of java simple bugs, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories, MSR, pp. 505-509, (2021); Mondal S., Saifullah C.K., Bhattacharjee A., Rahman M.M., pp. 1-11, (2021); Nadi S., Treude C., Essential sentences for navigating stack overflow answers, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 229-239, (2020); Nijkamp E., Pang B., Hayashi H., Tu L., Wang H., Zhou Y., Savarese S., Xiong C., A conversational paradigm for program synthesis, arXiv e-prints, pp. arXiv-2203, (2022); Papineni K., Roukos S., Ward T., pp. 311-318, (2002); Radford A., Narasimhan K., Salimans T., Sutskever I.; Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, J. Mach. Learn. Res., 21, pp. 1-67, (2020); Robertson S., Zaragoza H., The probabilistic relevance framework: BM25 and beyond, Inf. Retr., 3, 4, pp. 333-389, (2009); Rubei R., Sipio C.D., Nguyen P.T., Rocco J.D., Ruscio D.D., PostFinder: Mining stack overflow posts to support software developers, Inf. Softw. Technol., 127, (2020); See A., Liu P.J., pp. 1073-1083, (2017); Senter R., Smith E.A., Automated Readability Index: Technical Report, (1967); Shi F., Fried D., Ghazvininejad M., Zettlemoyer L., Wang S.I., Natural language to code translation with execution, (2022); Shi E., Wang Y., Du L., Zhang H., Han S., Zhang D., Sun H., Cast: Enhancing code summarization with hierarchical splitting and reconstruction of abstract syntax trees, (2021); Tang Z., Li C., Ge J., Shen X., Zhu Z., Luo B., AST-transformer: Encoding abstract syntax trees efficiently for code summarization, 2021 36th IEEE/ACM International Conference on Automated Software Engineering, pp. 1193-1195, (2021); Tang Z., Shen X., Li C., Ge J., Huang L., Zhu Z., Luo B., pp. 150-162, (2022); Tu Z., Lu Z., Liu Y., Liu X., Li H., Modeling coverage for neural machine translation, (2016); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Adv. Neural Inf. Process. Syst., 30, (2017); Wan Y., Zhao Z., Yang M., Xu G., Ying H., Wu J., pp. 397-407, (2018); Wang S., Lo D., Vasilescu B., Serebrenik A., EnTagRec++: An enhanced tag recommendation system for software information sites, Empir. Softw. Eng., 23, pp. 800-832, (2014); Wang Y., Wang W., Joty S., Hoi S.C., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Wang X., Wei J., Schuurmans D., Le Q., Chi E., Zhou D., Self-consistency improves chain of thought reasoning in language models, (2022); Wang X., Xia X., Lo D., TagCombine: Recommending tags to contents in software information sites, J. Comput. Sci. Tech., 30, pp. 1017-1035, (2015); Xia X., Lo D., Wang X., Zhou B., pp. 287-296, (2013); Xu F.F., Alon U., Neubig G., pp. 1-10, (2022); Xu B., Hoang T., Sharma A., Yang C., Xia X., Lo D., Post2Vec: Learning distributed representations of stack overflow posts, IEEE Trans. Softw. Eng., (2021); Xu B., Xing Z., Xia X., Lo D., AnswerBot: Automated generation of answer summary to developers’ technical questions, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering, ASE, pp. 706-716, (2017); Yang Z., Keung J., Kabir M.A., Yu X., Tang Y., Zhang M., Feng S., Acomnn: Attention enhanced compound neural network for financial time-series forecasting with cross-regional features, Appl. Soft Comput., 111, (2021); Yang Z., Keung J., Yu X., Gu X., Wei Z., Ma X., Zhang M., A multi-modal transformer-based code summarization approach for smart contracts, 2021 IEEE/ACM 29th International Conference on Program Comprehension, ICPC, pp. 1-12, (2021); Yu X., Bennin K.E., Liu J., Keung J.W., Yin X., Xu Z., An empirical study of learning to rank techniques for effort-aware defect prediction, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering, SANER, pp. 298-309, (2019); Yu X., Keung J., Xiao Y., Feng S., Li F., Dai H., Predicting the precise number of software defects: Are we there yet?, Inf. Softw. Technol., 146, (2022); Yu X., Liu J., Keung J.W., Li Q., Bennin K.E., Xu Z., Wang J., Cui X., Improving ranking-oriented defect prediction using a cost-sensitive ranking SVM, IEEE Trans. Reliab., 69, 1, pp. 139-153, (2019); Yu X., Liu J., Yang Z., Liu X., The Bayesian network based program dependence graph and its application to fault localization, J. Syst. Softw., 134, pp. 44-53, (2017); Yu X., Wu M., Jian Y., Bennin K.E., Fu M., Ma C., Cross-company defect prediction via semi-supervised clustering-based data filtering and MSTrA-based transfer learning, Soft Comput., 22, 10, pp. 3461-3472, (2018); Zhang A., Fang L., Ge C., Li P., Liu Z., Efficient transformer with code token learner for code clone detection, J. Syst. Softw., (2022); Zhang F., Keung J., Yu X., Xie Z., Yang Z., Ma C., Zhang Z., Improving stack overflow question title generation with copying enhanced codeBERT model and bi-modal information, Inf. Softw. Technol., (2022); Zhao K., Liu J., Xu Z., Liu X., Xue L., Xie Z., Zhou Y., Wang X., Graph4Web: A relation-aware graph attention network for web service classification, J. Syst. Softw., 190, (2022); Zhao K., Xu Z., Yan M., Zhang T., Xue L., Fan M., Keung J., The impact of class imbalance techniques on crashing fault residence prediction models, Empirical Software Engineering, 28, 2, (2023); Zhen Y., KEUNG J.W., Xiao Y., Yan X., Zhi J., ZHANG J., On the significance of category prediction for code-comment synchronization, ACM Trans. Softw. Eng. Methodol., (2022); Zhou P., Liu J., Liu X., Yang Z., Grundy J., Is deep learning better than traditional approaches in tag recommendation for software information sites?, Inf. Softw. Technol., 109, pp. 1-13, (2019); Zhou P., Liu J., Yang Z., Zhou G., pp. 272-282, (2017); Zhou Y., Shen J., Zhang X., Yang W., Han T., Chen T., Automatic source code summarization with graph attention networks, J. Syst. Softw., 188, (2022); Zhou Z., Yu H., Fan G., Huang Z., Yang X., Summarizing source code with hierarchical code representation, Inf. Softw. Technol., 143, (2022)","","Elsevier Inc.","","","","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85149984186"
"Jesse K.; Kuhmuench C.; Sawant A.","Jesse, Kevin (57217632287); Kuhmuench, Christoph (6506868713); Sawant, Anand (57095585000)","57217632287; 6506868713; 57095585000","RefactorScore: Evaluating Refactor Prone Code","2023","IEEE Transactions on Software Engineering","49","11","","5008","5026","18","0","10.1109/TSE.2023.3324613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174818770&doi=10.1109%2fTSE.2023.3324613&partnerID=40&md5=768e7fe0e9301d92afb5a2c477fab149","We propose RefactorScore, an automatic evaluation metric for code. RefactorScore computes the number of refactor prone locations on each token in a candidate file and maps the occurrences into a quantile to produce a score. RefactorScore is evaluated across 61,735 commits and uses a model called RefactorBERT trained to predict refactors on 1,111,246 commits. Finally, we validate RefactorScore on a set of industry leading projects providing each with a RefactorScore. We calibrate RefactorScore's detection of low quality code with human developers through a human subject study. RefactorBERT, the model driving the scoring mechanism, is capable of predicting defects and refactors predicted by RefDiff 2.0. To our knowledge, our approach, coupled with the use of large scale data for training and validated with human developers, is the first code quality scoring metric of its kind.  © 1976-2012 IEEE.","automatic evaluation; machine learning; Refactor; software repositories","C++ (programming language); Codes (symbols); Java programming language; Learning systems; Automatic evaluation; C language; Code; Computational modelling; Evaluation metrics; Java; Machine-learning; Predictive models; Refactor; Software repositories; Unified Modeling Language","Fowler M., Refactoring: Improving the Design of Existing Code, (2018); Kannangara S., Wijayanayake W., An empirical evaluation of impact of refactoring on internal and external measures of code quality, (2015); Leitch R., Stroulia E., Assessing the maintainability benefits of design restructuring using dependency analysis, Proc. 5th Int. Workshop Enterprise Netw. Comput. Healthcare Industry (IEEE Cat. No. 03EX717), pp. 309-322, (2004); Murphy-Hill E., Parnin C., Black A.P., How we refactor, and how we know it, IEEE Trans. Softw. Eng., 38, 1, pp. 5-18, (2012); Tsantalis N., Guana V., Stroulia E., Hindle A., A multidimensional empirical study on refactoring activity, Proc. Conf. Center Adv. Stud. Collaborative Res. (CASCON), pp. 132-146, (2013); Kim M., Zimmermann T., Nagappan N., A field study of refactoring challenges and benefits, Proc. ACM SIGSOFT 20th Int. Symp. Found. Softw. Eng., pp. 1-11, (2012); Silva D., Tsantalis N., Valente M.T., Why we refactor? Confessions of github contributors, Proc. 24th ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 858-870, (2016); Chaparro O., Bavota G., Marcus A., Di Penta M., On the impact of refactoring operations on code quality metrics, Proc. IEEE Int. Conf. Softw. Maintenance Evolution, pp. 456-460, (2014); Nagappan N., Ball T., Zeller A., Mining metrics to predict component failures, Proc. 28th Int. Conf. Softw. Eng., pp. 452-461, (2006); Nagappan N., Ball T., Use of relative code churn measures to predict system defect density, Proc. 27th Int. Conf. Softw. Eng., pp. 284-292, (2005); Tsantalis N., Ketkar A., Dig D., RefactoringMiner 2.0, IEEE Trans. Softw. Eng., 48, 3, pp. 930-950, (2020); Silva D., Valente M.T., RefDiff: Detecting refactorings in version histories, Proc. IEEE/ACM 14th Int. Conf. Mining Softw. Repositories (MSR), pp. 269-279, (2017); Silva D., Da Silva J.P., Santos G., Terra R., Valente M.T., RefDiff 2.0: A multi-language refactoring detection tool, IEEE Trans. Softw. Eng., 47, 12, pp. 2786-2802, (2021); Mariani T., Vergilio S.R., A systematic review on search-based refactoring, Inf. Softw. Technol., 83, pp. 14-34, (2017); O'Keeffe M., Cinneide M.O., Search-based refactoring: An empirical study, J. Softw. Maintenance Evolution, Res. Pract., 20, 5, pp. 345-364, (2008); Bavota G., De Lucia A., Di Penta M., Oliveto R., Palomba F., An experimental investigation on the innate relationship between quality and refactoring, J. Syst. Softw., 107, pp. 1-4, (2015); Aniche M., Maziero E., Durelli R., Durelli V., The effectiveness of supervised machine learning algorithms in predicting software refactoring, IEEE Trans. Softw. Eng., 48, 4, pp. 1432-1450, (2022); Kim M., Gee M., Loh A., Rachatasumrit N., Ref-Finder: A refactoring reconstruction tool based on logic query templates, Proc. 18th ACM SIGSOFT Int. Symp. Found. Softw. Eng., pp. 371-372, (2010); Dig D., Comertoglu C., Marinov D., Johnson R., Automatic detection of refactorings for libraries and frameworks, Proc. Workshop Object Oriented Reengineering (WOOR), (2005); Xing Z., Stroulia E., The JDEvAn tool suite in support of objectoriented evolutionary development, Proc. Companion 30th Int. Conf. Softw. Eng., pp. 951-952, (2008); Xing Z., Stroulia E., UMLDiff: An algorithm for object-oriented design differencing, Proc. 20th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 54-65, (2005); Karampatsis R.-M., Babii H., Robbes R., Sutton C., Janes A., Big code!= big vocabulary: Open-vocabulary models for source code, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng. (ICSE), pp. 1073-1085, (2020); Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages, (2020); Guo D., Et al., GraphCodeBERT: Pre-training code representations with data flow, (2020); Wang Y., Wang W., Joty S., Hoi S.C., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Chen M., Et al., Evaluating large language models trained on code, (2021); Xu F.F., Alon U., Neubig G., Hellendoorn V.J., A systematic evaluation of large language models of code, Proc. 6th ACM SIGPLAN Int. Symp. Mach. Program., pp. 1-10, (2022); Sennrich R., Haddow B., Birch A., Neural machine translation of rare words with subword units, (2015); Kudo T., Richardson J., Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing, (2018); Lu S., Et al., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, (2021); Peruma A., Mkaouer M.W., Decker M.J., Newman C.D., Contextualizing rename decisions using refactorings, commit messages, and data types, J. Syst. Softw., 169, (2020); Brown N., Et al., Managing technical debt in software-reliant systems, Proc. FSE/SDP Workshop Future Softw. Eng. Res., pp. 47-52, (2010); Fontana F.A., Ferme V., Spinelli S., Investigating the impact of code smells debt on quality code evaluation, Proc. 3rd Int. Workshop Manag. Tech. Debt (MTD), pp. 15-22, (2012); Azeem M.I., Palomba F., Shi L., Wang Q., Machine learning techniques for code smell detection: A systematic literature review and meta-analysis, Inf. Softw. Technol., 108, pp. 115-138, (2019); Mens T., Tourwe T., A survey of software refactoring, IEEE Trans. Softw. Eng., 30, 2, pp. 126-139, (2004); Baqais A.A.B., Alshayeb M., Automatic software refactoring: A systematic literature review, Softw. Qual. J., 28, 2, pp. 459-502, (2020); Moghadam I.H., Cinneide M.O., Code-Imp: A tool for automated search-based refactoring, Proc. 4th Workshop Refactoring Tools, pp. 41-44, (2011); Mohan M., Greer D., A survey of search-based refactoring for software maintenance, J. Softw. Eng. Res. Develop., 6, 1, pp. 1-52, (2018); Pecorelli F., Palomba F., Di Nucci D., De Lucia A., Comparing heuristic and machine learning approaches for metric-based code smell detection, Proc. IEEE/ACM 27th Int. Conf. Program Comprehension (ICPC), pp. 93-104, (2019); Fontana F.A., Zanoni M., Code smell severity classification using machine learning techniques, Knowl.-Based Syst., 128, pp. 43-58, (2017); Arcelli Fontana F., Mantyla M.V., Zanoni M., Marino A., Comparing and experimenting machine learning techniques for code smell detection, Empirical Softw. Eng., 21, 3, pp. 1143-1191, (2016); Fontana F.A., Zanoni M., Marino A., Mantyla M.V., Code smell detection: Towards a machine learning-based approach, Proc. IEEE Int.Conf. Softw. Maintenance, Piscataway, NJ, USA: IEEE Press, pp. 396-399, (2013); Pritam N., Et al., Assessment of code smell for predicting class change proneness using machine learning, IEEE Access, 7, pp. 37414-37425, (2019); Pecorelli F., Di Nucci D., De Roover C., De Lucia A., A large empirical assessment of the role of data balancing in machinelearning-based code smell detection, J. Syst. Softw., 169, (2020); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, Proc. IEEE 25th Int. Conf. Softw. Anal., Evolution Reengineering (SANER), pp. 612-621, (2018); Demeyer S., Ducasse S., Nierstrasz O., Finding refactorings via change metrics, ACM SIGPLAN Notices, 35, 10, pp. 166-177, (2000); Antoniol G., Di Penta M., Merlo E., An automatic approach to identify class evolution discontinuities, Proc. 7th Int. Workshop Princ. Softw. Evolution, pp. 31-40, (2004); Weissgerber P., Diehl S., Identifying refactorings from source-code changes, Proc. 21st IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 231-240, (2006); Dig D., Comertoglu C., Marinov D., Johnson R., Automated detection of refactorings in evolving components, Proc. Eur. Conf. Object-Oriented Program., pp. 404-428, (2006); Tsantalis N., Mansouri M., Eshkevari L., Mazinanian D., Dig D., Accurate and efficient refactoring detection in commit history, Proc. IEEE/ACM 40th Int. Conf. Softw. Eng. (ICSE), pp. 483-494, (2018); Prete K., Rachatasumrit N., Sudan N., Kim M., Template-based reconstruction of complex refactorings, Proc. IEEE Int. Conf. Softw. Maintenance, pp. 1-10, (2010); De Moor O., Et al., Keynote address:.QL for source code analysis, Proc. 7th IEEE Int. Work. Conf. Source Code Anal. Manipulation (SCAM), pp. 3-16, (2007); Lenarduzzi V., Lomio F., Huttunen H., Taibi D., Are sonarQube rules inducing bugs?, Proc. IEEE 27th Int. Conf. Softw. Anal., Evolution Reengineering (SANER), pp. 501-511, (2020); Marcilio D., Bonifacio R., Monteiro E., Canedo E., Luz W., Pinto G., Are static analysis violations really fixed? A closer look at realistic usage of sonarqube, Proc. IEEE/ACM 27th Int. Conf. Program Comprehension (ICPC), pp. 209-219, (2019); Moreno L., Bavota G., Di Penta M., Oliveto R., Marcus A., Canfora G., ARENA: An approach for the automated generation of release notes, IEEE Trans. Softw. Eng., 43, 2, pp. 106-127, (2017); Ratzinger J., Sigmund T., Gall H.C., On the relation of refactorings and software defect prediction, Proc. Int. Work. Conf. Mining Softw. Repositories, pp. 35-38, (2008); Soares G., Gheyi R., Murphy-Hill E., Johnson B., Comparing approaches to analyze refactoring activity on software repositories, J. Syst. Softw., 86, 4, pp. 1006-1022, (2013); Kadar I., Hegedus P., Ferenc R., Gyimothy T., A manually validated code refactoring dataset and its assessment regarding software maintainability, Proc. 12th Int. Conf. Predictive Models Data Analytics Softw. Eng., pp. 1-4, (2016); Vaswani A., Et al., Attention is all you need, Proc. 31st Int. Conf. Adv. Neural Inf. Process. Syst. (NIPS), 30, pp. 6000-6010, (2017); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Cho K., Van Merrienboer B., Bahdanau D., Bengio Y., On the properties of neural machine translation: Encoder-decoder approaches, (2014); Spadini D., Aniche M., Bacchelli A., PyDriller: Python framework for mining software repositories, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 908-911, (2018); Phan L., Et al., CoTexT: Multi-task learning with code-text transformer, (2021); Buratti L., Et al., Exploring software naturalness through neural language models, (2020); Hanif H., Maffeis S., VulBERTa: Simplified source code pretraining for vulnerability detection, (2022); Ahmad W.U., Chakraborty S., Ray B., Chang K.-W., Unified pre-training for program understanding and generation, (2021); Coimbra D., Reis S., Abreu R., Pasareanu C., Erdogmus H., On using distributed representations of source code for the detection of C security vulnerabilities, (2021); Liu Y., Et al., RoBERTa: A robustly optimized BERT pretraining approach, (2019); Herzig K., Just S., Zeller A., The impact of tangled code changes on defect prediction models, Empirical Softw. Eng., 21, 2, pp. 303-336, (2016); Dias M., Bacchelli A., Gousios G., Cassou D., Ducasse S., Untangling fine-grained code changes, Proc. IEEE 22nd Int. Conf. Softw. Anal., Evolution, Reengineering (SANER), pp. 341-350, (2015); Kirinuki H., Higo Y., Hotta K., Kusumoto S., Hey! Are you committing tangled changes?, Proc. 22nd Int. Conf. Program Comprehension, pp. 262-265, (2014); Bagheri A., Hegedus P., Is refactoring always a good egg? Exploring the interconnection between bugs and refactorings, Proc. IEEE/ACM 19th Int. Conf. Mining Softw. Repositories (MSR), pp. 117-121, (2022); D'Ambros M., Lanza M., Robbes R., An extensive comparison of bug prediction approaches, Proc. 7th IEEE Work. Conf. Mining Softw. Repositories (MSR), pp. 31-41, (2010); Kim S., Zimmermann T., Whitehead E.J., Zeller A., Predicting faults from cached history, Proc. 29th Int. Conf. Softw. Eng. (ICSE), pp. 489-498, (2007); Ostrand T.J., Weyuker E.J., Bell R.M., Predicting the location and number of faults in large software systems, IEEE Trans. Softw. Eng., 31, 4, pp. 340-355, (2005); Hassan A.E., Holt R.C., The top ten list: Dynamic fault prediction, Proc. 21st IEEE Int. Conf. Softw. Maintenance (ICSM), pp. 263-272, (2005)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Article","Final","","Scopus","2-s2.0-85174818770"
"Deshpande N.; Mkaouer M.W.; Ouni A.; Sharma N.","Deshpande, Niranjana (57219160269); Mkaouer, Mohamed Wiem (55904259300); Ouni, Ali (50761492200); Sharma, Naveen (57213712442)","57219160269; 55904259300; 50761492200; 57213712442","Third-party software library migration at the method-level using multi-objective evolutionary search","2024","Swarm and Evolutionary Computation","84","","101444","","","","0","10.1016/j.swevo.2023.101444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185886250&doi=10.1016%2fj.swevo.2023.101444&partnerID=40&md5=399afb8edcf69cf2c0ed1a9b55c203ce","Software developers commonly use third-party software libraries to reduce implementation efforts and mitigate errors in their source code while building high-quality and reliable software. To support software evolution, newer libraries are released periodically with added features, improvements in performance as well as critical updates such as bug fixes. Hence, older, existing (source) libraries need to be replaced with their newer, updated (target) counterparts, in a process known as library migration. Typically, library migration is a time-consuming, manual, and error-prone process that requires developers to analyze the source and target library code and its documentation. Specifically, developers examine Application Programming Interface (API) implementations and documentation to replace each source API with a target API without modifying the underlying software functionality. While recent works have used various techniques to recommend suitable target library replacements, these approaches do not generalize well, e.g., when a source library method needs to be replaced by one or more target library APIs or methods. To address this limitation, we propose the use of multi-objective evolutionary algorithms to identify suitable method replacements during library migration. In particular, we formulate library migration at the method-level as a multi-objective combinatorial optimization problem and examine the performance of 7 multi-objective evolutionary algorithms: UNSGAIII, RNSGAII, AGEMOEA, SMSEMOA, NSGAII, IBEA and MOEAD. We use method signature and documentation similarity, and co-occurrence probability to accurately recommend one or more target library methods. We evaluate our approach by conducting an empirical study on 9 popular Java library migrations mined from 57,447 open-source projects on GitHub. Our results demonstrate that UNSGAIII, RNSGAII, AGEMOEA, SMSEMOA, NSGAII, IBEA and MOEAD achieve 90%, 89%, 94%, 90%, 91%, 94%, and 71% precision on average, and 83%, 23%, 58%, 63%, 58%, 60% and 17% average recall respectively. In the interest of reproducibility, we make all code and results publicly available at: http://bit.ly/MOO-api-migration. © 2023","API migration; Library migration; Multi-objective search; NSGAII; Search-based software engineering","Application programming interfaces (API); Application programs; Evolutionary algorithms; Libraries; Open source software; Application programming interface migration; Applications programming interfaces; Interface migration; Library migration; Multi objective; Multi-objective search; NSGA-II; Search-based; Search-based software engineering; Third party software; Combinatorial optimization","Bloch J., How to design a good API and why it matters, Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications, pp. 506-507, (2006); Derr E., Bugiel S., Fahl S., Acar Y., Backes M., Keep me updated: An empirical study of third-party library updatability on Android, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 2187-2200, (2017); Teyton C., Falleri J.-R., Blanc X., Mining library migration graphs, 19th Working Conference on Reverse Engineering, (2012); Teyton C., Falleri J.-R., Palyart M., Blanc X., A study of library migrations in java, J. Softw. Evol. Process, 26, 11, pp. 1030-1052, (2014); Alrubaye H., Mkaouer M.W., Automating the detection of third-party Java library migration at the function level, CASCON, pp. 60-71, (2018); Alrubaye H., Mkaouer M.W., Peruma A., Variability in library evolution: An exploratory study on open-source Java libraries, Software Engineering for Variability Intensive Systems, pp. 295-320, (2019); Alrubaye H., Mkaouer M.W., Khokhlov I., Reznik L., Ouni A., Mcgoff J., Learning to recommend third-party library migration opportunities at the API level, Appl. Soft Comput., 90, (2020); Chen C., Similarapi: mining analogical APIs for library migration, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings, pp. 37-40, (2020); Rubei R., Di Ruscio D., Di Sipio C., Di Rocco J., Nguyen P.T., Providing upgrade plans for third-party libraries: A recommender system using migration graphs, (2022); He H., Xu Y., Ma Y., Xu Y., Liang G., Zhou M., A multi-metric ranking approach for library migration recommendations, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 72-83, (2021); Xie W., Peng X., Liu M., Treude C., Xing Z., Zhang X., Zhao W., API method recommendation via explicit matching of functionality verb phrases, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1015-1026, (2020); Alrubaye H., Mkaouer M.W., Ouni A., On the Use of Information Retrieval to Automate the Detection of Third-Party Java Library Migration at the Method Level; Kula R.G., German D.M., Ouni A., Ishio T., Inoue K., Do developers update their library dependencies?, Empir. Softw. Eng., (2018); Deshpande N., Mkaouer M.W., Ouni A., Sharma N., Search-based third-party library migration at the method-level, Applications of Evolutionary Computation, pp. 173-190, (2022); Chen J., Luo F., Li G., Wang Z., Batch Bayesian optimization with adaptive batch acquisition functions via multi-objective optimization, Swarm Evol. Comput., 79, (2023); Jin Y., Wang H., Chugh T., Guo D., Miettinen K., Data-driven evolutionary optimization: An overview and case studies, IEEE Trans. Evol. Comput., 23, 3, pp. 442-458, (2019); Houssein E.H., Gad A.G., Wazery Y.M., Suganthan P.N., Task scheduling in cloud computing based on meta-heuristics: Review, taxonomy, open challenges, and future trends, Swarm Evol. Comput., 62, (2021); Dulebenets M.A., A Diffused Memetic Optimizer for reactive berth allocation and scheduling at marine container terminals in response to disruptions, Swarm Evol. Comput., 80, (2023); Mara S.T.W., Sarker R., Essam D., Elsayed S., Solving electric vehicle–drone routing problem using memetic algorithm, Swarm Evol. Comput., 79, (2023); Singh P.P., Das S., Wen F., Palu I., Singh A.K., Thakur P., Multi-objective planning of electric vehicles charging in distribution system considering priority-based vehicle-to-grid scheduling, Swarm Evol. Comput., 77, (2023); Zang X., Jiang L., Liang C., Dong J., Lu W., Mladenovic N., Optimization approaches for the urban delivery problem with trucks and drones, Swarm Evol. Comput., 75, (2022); Chesalin D.D., Kulikov E.A., Yaroshevich I.A., Maksimov E.G., Selishcheva A.A., Pishchalnikov R.Y., Differential evolution reveals the effect of polar and nonpolar solvents on carotenoids: A case study of astaxanthin optical response modeling, Swarm Evol. Comput., 75, (2022); Ma Z., Wu G., Suganthan P.N., Song A., Luo Q., Performance assessment and exhaustive listing of 500+ nature-inspired metaheuristic algorithms, Swarm Evol. Comput., 77, (2023); Bui N., Towards zero knowledge learning for cross language API mappings, International Conference on Software Engineering: Companion Proceedings, (2019); Phan H.D., Nguyen A.T., Nguyen T.D., Nguyen T.N., Statistical migration of API usages, International Conference on Software Engineering Companion (ICSE-C), (2017); Nguyen T.D., Nguyen A.T., Phan H.D., Nguyen T.N., Exploring API embedding for API usages and applications, International Conference on Software Engineering, (2017); Panichella A., An adaptive evolutionary algorithm based on non-euclidean geometry for many-objective optimization, Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, pp. 595-603, (2019); Deb K., Sundar J., Reference point based multi-objective optimization using evolutionary algorithms, Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation, GECCO ’06, pp. 635-642, (2006); Beume N., Naujoks B., Emmerich M., SMS-EMOA: Multiobjective selection based on dominated hypervolume, European J. Oper. Res., 181, 3, pp. 1653-1669, (2007); Deb K., Pratap A., Agarwal S., Meyarivan T., A fast and elitist multiobjective genetic algorithm: NSGA-II, IEEE Trans. Evol. Comput., 6, 2, pp. 182-197, (2002); Zitzler E., Kunzli S., Indicator-based selection in multiobjective search, Parallel Problem Solving from Nature - PPSN VIII, pp. 832-842, (2004); Zhang Q., Li H., MOEA/D: A multiobjective evolutionary algorithm based on decomposition, IEEE Trans. Evol. Comput., 11, 6, pp. 712-731, (2007); Harman M., The current state and future of search based software engineering, Future of Software Engineering (FOSE ’07), pp. 342-357, (2007); Malhotra R., Khanna M., Raje R.R., On the application of search-based techniques for software engineering predictive modeling: A systematic review and future directions, Swarm Evol. Comput., 32, pp. 85-109, (2017); Mao C., Xiao L., Yu X., Chen J., Adapting ant colony optimization to generate test data for software structural testing, Swarm Evol. Comput., 20, pp. 23-36, (2015); Cai X., Geng S., Wu D., Chen J., Unified integration of many-objective optimization algorithm based on temporary offspring for software defects prediction, Swarm Evol. Comput., 63, (2021); Ludwig S.A., Memetic algorithms applied to the optimization of workflow compositions, Swarm Evol. Comput., 10, pp. 31-40, (2013); Ouni A., Kula R.G., Kessentini M., Ishio T., German D.M., Inoue K., Search-based software library recommendation using multi-objective optimization, Inf. Softw. Technol., (2017); He H., Xu Y., Cheng X., Liang G., Zhou M., MigrationAdvisor: Recommending library migrations from large-scale open-source data, 2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), pp. 9-12, (2021); He H., Xu Y., Ma Y., Xu Y., Liang G., Zhou M., A multi-metric ranking approach for library migration recommendations, 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 72-83, (2021); Alexandre R., Ouni A., Saied M.A., Bouktif S., Mkaouer M.W., On the identification of third-party library usage patterns for android applications, pp. 255-259, (2022); Nadi S., Sakr N., Selecting third-party libraries: The data scientist's perspective, Empir. Softw. Eng., 28, 1, (2023); Golubev Y., Bogomolov E., Bulychev E., Bryksin T., So much in so little: Creating lightweight embeddings of python libraries, (2022); Nafi K.W., Asaduzzaman M., Roy B., Roy C.K., Schneider K.A., Mining software information sites to recommend cross-language analogical libraries, 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 913-924, (2022); Xu S., Dong Z., Meng N., Meditor: Inference and application of API migration edits, International Conference on Program Comprehension, (2019); Xing Z., Stroulia E., API-evolution support with diff-catchup, IEEE Trans. Softw. Eng., 33, (2007); Wu W., Gueheneuc Y.-G., Antoniol G., Kim M., AURA: a hybrid approach to identify framework evolution; Nguyen P.T., Di Rocco J., Rubei R., Di Sipio C., Di Ruscio D., DeepLib: Machine translation techniques to recommend upgrades for third-party libraries, Expert Syst. Appl., 202, (2022); Pandita R., Jetley R.P., Sudarsan S.D., Williams L., Discovering likely mappings between APIs using text mining, 2015 International Working Conference on Source Code Analysis and Manipulation, (2015); Islam M., Jha A.K., Nadi S., PyMigBench and PyMigTax: A benchmark and taxonomy for Python library migration, (2022); Ossendrijver R., Schroevers S., Grelck C., Towards automated library migrations with error prone and refaster, Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing, SAC ’22, pp. 1598-1606, (2022); Nam D., Myers B., Vasilescu B., Hellendoorn V., Improving API knowledge discovery with ML: A case study of comparable API methods, 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE), pp. 1890-1906, (2023); Schmiedmayer P., Bauer A., Bruegge B., Reducing the impact of breaking changes to web service clients during web API evolution, 2023 IEEE/ACM 10th International Conference on Mobile Software Engineering and Systems (MOBILESoft), pp. 1-11, (2023); Galappaththi A., Nadi S., A data set of generalizable python code change patterns, (2023); Ramos D., Mitchell H., Lynce I., Manquinho V., Martins R., Goues C.L., MELT: Mining effective lightweight transformations from pull requests, (2023); Nadi S., Sakr N., Selecting third-party libraries: the data scientist's perspective, Empir. Softw. Eng., 28, 1, (2023); Liu M., Yang Y., Lou Y., Peng X., Zhou Z., Du X., Yang T., Recommending analogical APIs via knowledge graph embedding, (2023); Alshahwan N., Harman M., Marginean A., Software testing research challenges: An industrial perspective, 2023 IEEE Conference on Software Testing, Verification and Validation (ICST), pp. 1-10, (2023); Collie B., Ginsbach P., Woodruff J., Rajan A., O'Boyle M.F., M3: Semantic API migrations, International Conference on Automated Software Engineering (ASE), (2020); Chen C., SimilarAPI: Mining analogical APIs for library migration, 2020 IEEE/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), pp. 37-40, (2020); Bairi R., Sonwane A., Kanade A., C V.D., Iyer A., Parthasarathy S., Rajamani S., Ashok B., Shet S., CodePlan: Repository-level coding using LLMs and planning, (2023); Zhou B., Wang X., Xu S., Yao Y., Pan M., Xu F., Ma X., Hybrid API migration: A marriage of small API mapping models and large language models, Proceedings of the 14th Asia-Pacific Symposium on Internetware, Internetware ’23, pp. 12-21, (2023); Nguyen P.T., Rubei R., Rocco J.D., Sipio C.D., Ruscio D.D., Penta M.D., Dealing with popularity bias in recommender systems for third-party libraries: How far are we?, (2023); Osaba E., Villar-Rodriguez E., Del Ser J., Nebro A.J., Molina D., LaTorre A., Suganthan P.N., Coello Coello C.A., Herrera F., A tutorial on the design, experimentation and application of metaheuristic algorithms to real-world optimization problems, Swarm Evol. Comput., 64, (2021); Ali S., Arcaini P., Pradhan D., Safdar S.A., Yue T., Quality indicators in search-based software engineering: An empirical evaluation, ACM Trans. Softw. Eng. Methodol., 29, 2, (2020); Li M., Yao X., Quality evaluation of solution sets in multiobjective optimisation: A survey, ACM Comput. Surv., 52, 2, (2019); Li M., Chen T., Yao X., A critical review of: ”a practical guide to select quality indicators for assessing Pareto-based search algorithms in search-based software engineering”: Essay on quality indicator selection for SBSE, Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results, ICSE-NIER ’18, pp. 17-20, (2018); Li M., Chen T., Yao X., How to evaluate solutions in Pareto-based search-based software engineering? A critical review and methodological guidance, IEEE Trans. Softw. Eng., (2020); Cormen T.H., Leiserson C.E., Rivest R.L., Stein C., Introduction to Algorithms, Third Edition, (2009); Alshoaibi D., Mkaouer M.W., Ouni A., Wahaishi A., Desell T., Soui M., Search-based detection of code changes introducing performance regression, Swarm Evol. Comput., 73, (2022); Kumar A., Wu G., Ali M.Z., Luo Q., Mallipeddi R., Suganthan P.N., Das S., A Benchmark-Suite of real-World constrained multi-objective optimization problems and some baseline results, Swarm Evol. Comput., 67, (2021); Qi Y., Li X., Yu J., Miao Q., User-preference based decomposition in MOEA/D without using an ideal point, Swarm Evol. Comput., 44, pp. 597-611, (2019); Nguyen H.A., Nguyen T.T., Wilson G., Nguyen A.T., Kim M., Nguyen T.N., A graph-based approach to API usage adaptation, International Conference on Object Oriented Programming Systems Languages and Applications, (2010); Cer D., Yang Y., yi Kong S., Hua N., Limtiaco N., John R.S., Constant N., Guajardo-Cespedes M., Yuan S., Tar C., Sung Y.-H., Strope B., Kurzweil R., Universal sentence encoder, (2018); Li B., Li J., Tang K., Yao X., Many-objective evolutionary algorithms: A survey, ACM Comput. Surv., 48, 1, (2015); Emmerich M.T.M., Deutz A.H., A tutorial on multiobjective optimization: fundamentals and evolutionary methods, Nat. Comput., 17, 3, pp. 585-609, (2018); Brockhoff D., GECCO 2018 tutorial on evolutionary multiobjective optimization, Proceedings of the Genetic and Evolutionary Computation Conference Companion, GECCO ’18, pp. 349-372, (2018); Zhou A., Qu B.-Y., Li H., Zhao S.-Z., Suganthan P.N., Zhang Q., Multiobjective evolutionary algorithms: A survey of the state of the art, Swarm Evol. Comput., 1, 1, pp. 32-49, (2011); Seada H., Deb K., A unified evolutionary optimization procedure for single, multiple, and many objectives, IEEE Trans. Evol. Comput., 20, 3, pp. 358-369, (2016); Arcuri A., Briand L., A practical guide for using statistical tests to assess randomized algorithms in software engineering, Proceedings of the 33rd International Conference on Software Engineering, ICSE ’11, pp. 1-10, (2011); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, (2020)","","Elsevier B.V.","","","","","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85185886250"
"Yang Y.; Hu X.; Gao Z.; Chen J.; Ni C.; Xia X.; Lo D.","Yang, Yanming (57219792540); Hu, Xing (57191413796); Gao, Zhipeng (57215134215); Chen, Jinfu (58852603200); Ni, Chao (57189892547); Xia, Xin (58275220100); Lo, David (35269388000)","57219792540; 57191413796; 57215134215; 58852603200; 57189892547; 58275220100; 35269388000","Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction","2024","IEEE Transactions on Software Engineering","50","2","","296","321","25","0","10.1109/TSE.2023.3347898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181563468&doi=10.1109%2fTSE.2023.3347898&partnerID=40&md5=76b2f45aeed762b6805217b752e8fed4","In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers' ability to gain insights into industry developers' concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions. © 1976-2012 IEEE.","code clone detection; defect prediction; Federated learning; parameter aggregation strategy; skewed data distribution","Benchmarking; Cloning; Codes (symbols); Data privacy; Deep learning; Defects; Job analysis; Mapping; Research laboratories; Aggregation strategy; Benchmark testing; Code; Code clone detection; Data distribution; Defect prediction; Federated learning; Parameter aggregation strategy; Parameter aggregations; Skewed data; Skewed data distribution; Task analysis; Forecasting","Bjerge K., Mann H.M., Hoye T.T., Real-time insect tracking and monitoring with computer vision and deep learning, Remote Sens. Ecology Conservation, 8, 3, pp. 315-327, (2022); Subramanian A.S., Weng C., Watanabe S., Yu M., Yu D., Deep learning based multi-source localization with source splitting and its effectiveness in multi-talker speech recognition, Comput. Speech Lang., 75, (2022); Lauriola I., Lavelli A., Aiolli F., An introduction to deep learning in natural language processing: Models, techniques, and tools, Neurocomputing, 470, pp. 443-456, (2022); Jiang L., Misherghi G., Su Z., Glondu S., DECKARD: Scalable and accurate tree-based detection of code clones, Proc. 29th Int. Conf. Softw. Eng. (ICSE), pp. 96-105, (2007); Wu Y., Et al., SCDetector: Software functional clone detection based on semantic tokens analysis, Proc. 35th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 821-833, (2020); Zhang F., Zheng Q., Zou Y., Hassan A.E., Cross-project defect prediction using a connectivity-based unsupervised classifier, Proc. IEEE/ACM 38th Int. Conf. Softw. Eng. (ICSE), pp. 309-320, (2016); Koch B., Denton E., Hanna A., Foster J.G., Reduced, reused and recycled: The life of a dataset in machine learning research, (2021); Munappy A.R., Bosch J., Olsson H.H., Arpteg A., Brinne B., Data management for production quality deep learning models: Challenges and solutions, J. Syst. Softw., (2022); Herrera Y.M., Kapur D., Improving data quality: Actors, incentives, and capabilities, Political Anal., 15, 4, pp. 365-386, (2007); Li Q., Diao Y., Chen Q., He B., Federated learning on non-IID data silos: An experimental study, Proc. IEEE 38th Int. Conf. Data Eng. (ICDE), pp. 965-978, (2022); Rahman W., Et al., Clone detection on large Scala codebases, Proc. IEEE 14th Int. Workshop Softw. Clones (IWSC), pp. 38-44, (2020); (2023); Cordy J.R., Roy C.K., The nicad clone detector, Proc. IEEE 19th Int. Conf. Program Comprehension, pp. 219-220, (2011); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proc. 38th Int. Conf. Softw. Eng., pp. 1157-1168, (2016); Kapser C.J., Godfrey M.W., Cloning considered harmful considered harmful: Patterns of cloning in software, Empirical Softw. Eng., 13, 6, pp. 645-692, (2008); Islam M.R., Zibran M.F., Nagpal A., Security vulnerabilities in categories of clones and non-cloned code: An empirical study, Proc. ACM/IEEE Int. Symp. Empirical Softw. Eng. Meas. (ESEM), pp. 20-29, (2017); Learning F., Collaborative machine learning without centralized training data, (2017); Liang P.P., Et al., Think locally, act globally: Federated learning with local and global representations, (2020); Li T., Sahu A.K., Talwalkar A., Smith V., Federated learning: Challenges, methods, and future directions, IEEE Signal Process. Mag., 37, 3, pp. 50-60, (2020); Lo S.K., Lu Q., Wang C., Paik H.-Y., Zhu L., A systematic literature review on federated machine learning: From a software engineering perspective, ACM Comput. Surv. (CSUR), 54, 5, pp. 1-39, (2021); Zhuo H.H., Feng W., Lin Y., Xu Q., Yang Q., Federated deep reinforcement learning, (2019); Yu H., Et al., A fairness-aware incentive scheme for federated learning, Proc. AAAI/ACM Conf. AI, Ethics, Soc., pp. 393-399, (2020); Truex S., Et al., A hybrid approach to privacy-preserving federated learning, Proc. 12th ACM Workshop Artif. Intell. Secur., pp. 1-11, (2019); Suzen A.A., Simsek M.A., A novel approach to machine learning application to protection privacy data in healthcare: Federated learning, Namik Kemal Tip Dergisi, 8, 1, pp. 22-30, (2020); McMahan B., Moore E., Ramage D., Hampson S., Arcas B.A.Y., Communication-efficient learning of deep networks from decentralized data, Proc. 20th Int. Conf. Artif. Intell. Statist., PMLR, pp. 1273-1282, (2017); Kairouz P., Et al., Advances and open problems in federated learning, Found. Trends Mach. Learn., 14, 1-2, pp. 1-210, (2021); (2023); (2016); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 87-98, (2016); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proc. 26th Int. Joint Conf. Artif. Intell. (IJCA), pp. 3034-3040, (2017); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proc. IEEE/ACM 15th Int. Conf. Mining Softw. Repositories (MSR), pp. 542-553, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Proc. Adv. Neural Inf. Process. Syst., pp. 10197-10207, (2019); Ni C., Xia X., Lo D., Yang X., Hassan A.E., Just-in-time defect prediction on JavaScript projects: A replication study, ACM Trans. Softw. Eng. Method., 31, 4, pp. 1-38, (2022); Feng Z., Et al., CodeBERT: A pre-trained model for programming and natural languages, (2020); Guo D., Et al., GraphCodeBERT: Pre-training code representations with data flow, (2020); Harer J.A., Et al., Automated software vulnerability detection with machine learning, (2018); Lu S., Et al., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, (2021); Alhija H.A., Azzeh M., Almasalha F., Software defect prediction using support vector machine, (2022); Jadon S., Code clones detection using machine learning technique: Support vector machine, Proc. Int. Conf. Comput., Commun. Automat. (ICCCA), pp. 399-403, (2016); (2020); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, Proc. IEEE Int. Conf. Softw. Maintenance Evolution, pp. 476-480, (2014); (2022); Zhao G., Huang J., DeepSim: Deep learning code functional similarity, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 141-151, (2018); Li X., Huang K., Yang W., Wang S., Zhang Z., On the convergence of FEDAVG on non-IID data, (2019); Arammongkolvichai V., Koschke R., Ragkhitwetsagul C., Choetkiertikul M., Sunetnanta T., Improving clone detection precision using machine learning techniques, Proc. 10th Int. Workshop Empirical Softw. Eng. Pract. (IWESEP), pp. 31-315, (2019); Zhou J., Et al., Finding a needle in a haystack: Automated mining of silent vulnerability fixes, Proc. 36th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 705-716, (2021); Carka J., Esposito M., Falessi D., On effort-aware metrics for defect prediction, Empirical Softw. Eng., 27, 6, (2022); Yan M., Xia X., Shihab E., Lo D., Yin J., Yang X., Automating change-level self-admitted technical debt determination, IEEE Trans. Softw. Eng., 45, 12, pp. 1211-1229, (2019); MacBeth G., Razumiejczyk E., Ledesma R.D., Cliff's Delta Calculator: A non-parametric effect size program for two groups of observations, 10, 2, pp. 545-555, (2011); Luque A., Carrasco A., Martin A., De Las H.A., The impact of class imbalance in classification performance metrics based on the binary confusion matrix, Pattern Recognit., 91, pp. 216-231, (2019); Malhotra R., Budhiraja A., Singh A.K., Ghoshal I., Meena S., Multiple feature selection frameworks based on evolutionary computing and ensemble learning for software defect prediction, Proc. 5th Int. Conf. Comput. Intell. Netw. (CINE), pp. 1-6, (2022); Moussa R., Sarro F., On the use of evaluation measures for defect prediction studies, Proc. 31st ACM SIGSOFT Int. Symp. Softw. Testing Anal., pp. 101-113, (2022); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. IEEE 27th Int. Conf. Softw. Anal., Evolution Reeng. (SANER), pp. 261-271, (2020); Raychev V., Bielik P., Vechev M., Probabilistic model for code with decision trees, ACM SIGPLAN Notices, 51, 10, pp. 731-747, (2016); Yang Q., Liu Y., Chen T., Tong Y., Federated machine learning: Concept and applications, ACM Trans. Intell. Syst. Technol. (TIST), 10, 2, pp. 1-19, (2019); Brisimi T.S., Chen R., Mela T., Olshevsky A., Paschalidis I.C., Shi W., Federated learning of predictive models from federated electronic health records, Int. J. Med. Informatics, 112, pp. 59-67, (2018); Xu J., Glicksberg B.S., Su C., Walker P., Bian J., Wang F., Federated learning for healthcare informatics, J. Healthcare Inform. Res., 5, 1, pp. 1-19, (2021); Yang W., Zhang Y., Ye K., Li L., Xu C.-Z., FFD: A federated learning based method for credit card fraud detection, Proc. Int. Conf. Big Data, pp. 18-32, (2019); Long G., Tan Y., Jiang J., Zhang C., Federated learning for open banking, Federated Learning., pp. 240-254, (2020); Khan L.U., Saad W., Han Z., Hossain E., Hong C.S., Federated learning for Internet of things: Recent advances, taxonomy, and open challenges, IEEE Commun. Surveys Tuts., 23, 3, pp. 1759-1799, (2021); Nguyen D.C., Ding M., Pathirana P.N., Seneviratne A., Li J., Poor H.V., Federated learning for Internet of things: A comprehensive survey, IEEE Commun. Surveys Tuts., 23, 3, pp. 1622-1658, (2021); Abyane A.E., Zhu D., De Souza R.M., Ma L., Hemmati H., Towards understanding quality challenges of the federated learning: A first look from the lens of robustness, (2022); Verma D.C., White G., De Mel G., Federated AI for the enterprise: A web services based implementation, Proc. IEEE Int. Conf. Web Services (ICWS), pp. 20-27, (2019); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: A qualitative approach, Sci. Comput. Program., 74, 7, pp. 470-495, (2009); Rattan D., Bhatia R.K., Singh M., Software clone detection: A systematic review, Inf. Softw. Technol., 55, 7, pp. 1165-1199, (2013); Lee S., Jeong I., SDD: High performance code clone detection system for large scale source code, Proc. Companion 20th Annu. ACM SIGPLAN Conf. Object-Oriented Program., Syst., Lang., Appl. (OOPSLA), pp. 140-141, (2005); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Trans. Softw. Eng., 28, 7, pp. 654-670, (2002); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., SourcererCC: Scaling code clone detection to big-code, Proc. 38th Int. Conf. Softw. Eng. (ICSE), pp. 1157-1168, (2016); Roy C.K., Cordy J.R., NICAD: Accurate detection of near-miss intentional clones using flexible pretty-printing and code normalization, Proc. 16th IEEE Int. Conf. Program Comprehension (ICPC), pp. 172-181, (2008); Krinke J., Identifying similar code with program dependence graphs, Proc. 8th Work. Conf. Reverse Eng. (WCRE), pp. 301-309, (2001); Liu C., Chen C., Han J., Yu P.S., GPLAG: Detection of software plagiarism by program dependence graph analysis, Proc. 12th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 872-881, (2006); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proc. ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., (ESEC/SIGSOFT FSE), pp. 354-365, (2018); Lanubile F., Mallardo T., Finding function clones in web applications, Proc. 7th Eur. Conf. Softw. Maintenance Reeng. (CSMR), (2003); Liu C., Lin Z., Lou J.-G., Wen L., Zhang D., Can neural clone detection generalize to unseen functionalities f, Proc. 36th IEEE/ACM Int. Conf. Automated Softw. Eng. (ASE), pp. 617-629, (2021); Mockus A., Weiss D.M., Predicting risk of software changes, Bell Labs Tech. J., 5, 2, pp. 169-180, (2000); Kamei Y., Et al., A large-scale empirical study of just-in-time quality assurance, IEEE Trans. Softw. Eng., 39, 6, pp. 757-773, (2013); Kamei Y., Fukushima T., McIntosh S., Yamashita K., Ubayashi N., Hassan A.E., Studying just-in-time defect prediction using crossproject models, Empirical Softw. Eng., 21, 5, pp. 2072-2106, (2016); Kamei Y., Shihab E., Defect prediction: Accomplishments and future challenges, Proc. IEEE 23rd Conf. Softw. Anal., Evolution, Reeng. (SANER), 5, pp. 33-45, (2016); Xia X., Lo D., Pan S.J., Nagappan N., Wang X., HYDRA: Massively compositional model for cross-project defect prediction, IEEE Trans. Softw. Eng., 42, 10, pp. 977-998, (2016); Ibrahim D.R., Ghnemat R., Hudaib A., Software defect prediction using feature selection and random forest algorithm, Proc. Int. Conf. New Trends Comput. Sci. (ICTCS), pp. 252-257, (2017); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur. (QRS), pp. 318-328, (2017)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Article","Final","","Scopus","2-s2.0-85181563468"
"Palit I.; Shetty G.; Arif H.; Sharma T.","Palit, Indranil (35318523500); Shetty, Gautam (58795770600); Arif, Hera (58795464700); Sharma, Tushar (25224153100)","35318523500; 58795770600; 58795464700; 25224153100","Automatic Refactoring Candidate Identification Leveraging Effective Code Representation","2023","Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023","","","","369","374","5","0","10.1109/ICSME58846.2023.00047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181542748&doi=10.1109%2fICSME58846.2023.00047&partnerID=40&md5=a697ac6a2ba88e62abd3f16f1f68af95","The use of machine learning to automate the detection of refactoring candidates is a rapidly evolving research area. The majority of work in this direction uses source code metrics and commit messages to predict refactoring candidates and do not exploit the rich semantics of source code. This paper proposes a new approach for extract method refactoring candidates identification. First, we propose a novel mechanism to identify negative samples for the refactoring candidate identification task. We then employ a self-supervised autoencoder to acquire a compact representation of source code generated by a pre-trained large language model. Subsequently, we train a binary classifier to predict extract method refactoring candidates. Experiments show that our new approach outperforms the state of the art by 30% in terms of F1 score. The proposed work has implications for researchers and practitioners. Software developers may use the proposed automated approach to predict refactoring candidates better. This study will facilitate the development of improved refactoring candidate identification methods that the researchers in the field could use and extend. © 2023 IEEE.","code representation; deep learning; extract method refactoring","Codes (symbols); Deep learning; Forecasting; Automatic refactoring; Candidate identifications; Code representation; Deep learning; Extract method refactoring; Machine-learning; New approaches; Refactorings; Research areas; Source codes; Semantics","Opdyke W.F., Refactoring: A Program Restructuring Aid in Designing Object-oriented Application Frameworks, (1992); Fowler M., Becker P., Beck K., Brant J., Opdyke W., Roberts D., Refactoring: Improving the Design of Existing Code, (1999); Mens T., Tourwe T., A survey of software refactoring, IEEE Transactions on Software Engineering, 30, 2, pp. 126-139, (2004); Sharma T., Spinellis D., A survey on software smells, Journal of Systems and Software, 138, pp. 158-173, (2018); Aniche M.F., Maziero E.G., Durelli R.S., Durelli V.H.S., The effectiveness of supervised machine learning algorithms in predicting software refactoring, IEEE Transactions on Software Engineering, 48, pp. 1432-1450, (2020); Karakati C.B., Thirumaaran S., Software code refactoring based on deep neural network-based fitness function, Concurrency and Computation: Practice and Experience, 35, 4; Kurbatova Z., Veselov I., Golubev Y., Bryksin T., Recommendation of move method refactoring using path-based representation of code, Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops, (2020); Xu S., Sivaraman A., Khoo S.-C., Xu J., Gems: An extract method refactoring recommender, 2017 IEEE 28th International Symposium on Software Reliability Engineering (ISSRE, pp. 24-34, (2017); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc ACM Program. Lang, 3, pp. 401-4029, (2019); Karmakar A., Robbes R., What do pre-Trained code models know about code?"" in, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE, pp. 1332-1336, (2021); Tsantalis N., Mansouri M., Eshkevari L.M., Mazinanian D., Dig D., Accurate and efficient refactoring detection in commit history, Proceedings of the 40th International Conference on Software Engineering ACM, pp. 483-494, (2018); Tsantalis N., Ketkar A., Dig D., Refactoringminer 2.0, IEEE Transactions on Software Engineering, 48, 3, pp. 930-950, (2022); Trautsch A., Erbel J., Herbold S., Grabowski J., What really changes when developers intend to improve their source code: A commitlevel study of static metric value and static analysis warning changes, Empirical Software Engineering, 28, 2, (2023); Sharma T., Efstathiou V., Louridas P., Spinellis D., Code smell detection by deep direct-learning and transfer-learning, Journal of Systems and Software, 176, (2021); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?"" in, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER, pp. 612-621, (2018); Murphy-Hill E., Parnin C., Black A.P., How we refactor, and how we know it, IEEE Transactions on Software Engineering, 38, 1, pp. 5-18, (2012); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-Training Code Representations with Data Flow, (2020); Liou C.-Y., Cheng W.-C., Liou J.-W., Liou D.-R., Autoencoder for words, Neurocomputing, 139, pp. 84-96, (2014); Palit I., Shetty G., Arif H., Sharma T., Extract Method Identification; Palit I., Shetty G., Arif H., Sharma T., Dataset for Automatic Refactoring Candidate Identification Leveraging Effective Code Representation; Spadini D., Aniche M., Bacchelli A., PyDriller: Python framework for mining software repositories, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering-ESEC/FSE 2018, pp. 908-911, (2018); Yamanaka J., Hayase Y., Amagasa T., Recommending Extract Method Refactoring Based on Confidence of Predicted Method Name, (2021); Delphine Immaculate S., Farida Begam M., Floramary M., Software bug prediction using supervised machine learning algorithms, 2019 International Conference on Data Science and Communication (IconDSC, pp. 1-7, (2019); Van Leij Der D., Binda J., Van Dalen R., Vallen P., Luo Y., Aniche M., Data-driven extract method recommendations: A study at ing, Association for Computing Machinery, pp. 1337-1347, (2021); Van Maaten Der L., Hinton G., Visualizing data using t-sne, Journal of Machine Learning Research, 9, 11, (2008); Al Dallal J., Identifying refactoring opportunities in object-oriented code: A systematic literature review, Information and Software Technology, 58, pp. 231-249, (2015); Du Bois B., Demeyer S., Verelst J., Refactoring-improving coupling and cohesion of existing code, 11th Working Conference on Reverse Engineering, pp. 144-151, (2004); Kataoka Y., Ernst M.D., Griswold W.G., Notkin D., Automated support for program refactoring using invariants, Proceedings IEEE International Conference on Software Maintenance. ICSM, 2001, pp. 736-743, (2001); Czibula I.G., Czibula G., Hierarchical clustering based automatic refactorings detection, WSEAS Transactions on Electronics, 5, 7, pp. 291-302, (2008); Serban G., Czibula I.-G., Restructuring software systems using clustering, 2007 22nd International Symposium on Computer and Information Sciences, pp. 1-6, (2007); Bavota G., De Lucia A., Oliveto R., Identifying extract class refactoring opportunities using structural and semantic cohesion measures, Journal of Systems and Software, 84, 3, pp. 397-414, (2011); Tsantalis N., Chatzigeorgiou A., Identification of extract method refactoring opportunities, 2009 13th European Conference on Software Maintenance and Reengineering, pp. 119-128, (2009); Gerling J., Machine Learning for Software Refactoring: A Large-scale Empirical Study, (2020); Kumar L., Satapathy S.M., Murthy L.B., Method level refactoring prediction on five open source java projects using machine learning techniques, Proceedings of the 12th Innovations on Software Engineering Conference, (2019); Sagar P.S., Al Omar E.A., Mkaouer M.W., Ouni A., Newman C.D., Comparing commit messages and source code metrics for the prediction refactoring activities, Algorithms, 14, 10, (2021)","","Institute of Electrical and Electronics Engineers Inc.","Fundacion GCF Aprendi Libre; IEEE Computer Society; IEEE Computer Society Technical Community on Software Engineering (TCSE); Universidad de Los Andes","39th IEEE International Conference on Software Maintenance and Evolution, ICSME 2023","1 October 2023 through 6 October 2023","Bogota","195314","Conference paper","Final","","Scopus","2-s2.0-85181542748"
"Khan B.; Shah Z.A.; Usman M.; Khan I.; Niazi B.","Khan, Bilal (57216127356); Shah, Zohaib Ali (58662712000); Usman, Muhammad (56844860100); Khan, Inayat (57189853778); Niazi, Badam (57189027746)","57216127356; 58662712000; 56844860100; 57189853778; 57189027746","Exploring the Landscape of Automatic Text Summarization: A Comprehensive Survey","2023","IEEE Access","11","","","109819","109840","21","1","10.1109/ACCESS.2023.3322188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174836747&doi=10.1109%2fACCESS.2023.3322188&partnerID=40&md5=d8fbfbfd971856c5a368e8a1769cb8f6","The discipline of Automatic Text Summarization (ATS), which is expanding quickly, intends to automatically create summaries of enormous amounts of text so that readers can save time and effort. ATS is a rapidly growing field that aims to save readers time and effort by automatically generating summaries of large volumes of text. In recent years, significant advancements have been witnessed in this area, accompanied by challenges that have spurred extensive research. The proliferation of textual data has sparked substantial interest in ATS, which is thoroughly examined in this survey study. Researchers have been refining ATS techniques since the 1950s, primarily categorized as extractive, abstractive, or hybrid approaches. In the extractive approach, key sentences are extracted from the source document(s) and combined to form the summary, while the abstractive approach employs an intermediary representation of the input document(s) to generate a summary that may differ from the original text. Hybrid approaches combine elements of both extractive and abstractive methods. Despite various recommended methodologies, the generated summaries still exhibit noticeable differences compared to those created by humans. This research survey offers an inclusive exploration of ATS, covering its challenges, types, classifications, approaches, applications, methods, implementations, processing and preprocessing techniques, linguistic analysis, datasets, and evaluation measures, catering to the needs of researchers in the field. © 2013 IEEE.","Automatic text summarization; text summarization challenges; text summarization datasets; text summarization evaluation measures; text summarization methods","Classification (of information); Feature extraction; Linguistics; Natural language processing systems; Automatic text summarization; Evaluation measures; Features extraction; Language processing; Natural language processing; Natural languages; Text categorization; Text Summarisation; Text summarization challenge; Text summarization dataset; Text summarization evaluation measure; Text summarization method; Text-processing; Time-frequency Analysis; Transformer; Text processing","Alami N., Meknassi M., En-Nahnahi N., El Adlouni Y., Ammor O., Unsupervised neural networks for automatic Arabic text summarization using document clustering and topic modeling, Expert Syst. Appl, 172, (2021); Kumar G.K., Rani D.M., Paragraph summarization based on word frequency using NLP techniques, AIP Conf. Proc, 2317, (2021); Sanders A.C., White R.C., Severson L.S., Ma R., McQueen R., Paulo H.C.A., Zhang Y., Erickson J.S., Bennett K.P., Unmasking the conversation on masks: Natural language processing for topical sentiment analysis of COVID-19 Twitter discourse, AMIA J. Summits Transl. Sci. Proc, 2021, pp. 555-564, (2021); Luhn H.P., The automatic creation of literature abstracts, IBM J. Res. Develop, 2, 2, pp. 159-165, (1958); Hovy E., Lin C.-Y., Automated text summarization and the SUMMARIST system, Proc. Tipster Text Program Phase III, pp. 197-214, (1996); Allahyari M., Pouriyeh S., Assefi M., Safaei S., Trippe E.D., Gutierrez J.B., Kochut K., Text summarization techniques: A brief survey, (2017); Gambhir M., Gupta V., Recent automatic text summarization techniques: A survey, Artif. Intell. Rev, 47, 1, pp. 1-66, (2017); Syed A.A., Gaol F.L., Matsuo T., A survey of the state-of-the-art models in neural abstractive text summarization, IEEE Access, 9, pp. 13248-13265, (2021); El-Kassas W.S., Salama C.R., Rafea A.A., Mohamed H.K., Automatic text summarization: A comprehensive survey, Expert Syst. Appl, 165, (2021); Goldstein J., Mittal V., Carbonell J., Kantrowitzt M., Multidocument summarization by sentence extraction, Proc. ANLP/NAACL Workshop Autom. Summarization, pp. 40-48, (1998); Verma P., Om H., MCRMR: Maximum coverage and relevancy with minimal redundancy based multi-document summarization, Expert Syst. Appl, 120, pp. 43-56, (2019); Tomer M., Kumar M., Multi-document extractive text summarization based on firefly algorithm, J. King Saud Univ. Comput. Inf. Sci, 34, 8, pp. 6057-6065, (2022); Rautray R., Balabantaray R.C., An evolutionary framework for multi document summarization using cuckoo search approach: MDSCSA, Appl. Comput. Informat, 14, 2, pp. 134-144, (2018); Jezek K., Steinberger J., Automatic text summarization: (The state of the art 2007 and new challenges), Proc. Znalosti, pp. 1-12, (2008); Mishra P., Problems with Existing Abstractive Text Summarization Models-Even SOTA; Shelton A., Lemons C.J., Wexler J., Supporting main idea identification and text summarization in middle school co-taught classes, Intervent School Clinic, 56, 4, pp. 217-223, (2021); Steinberger J., Je K., Text summarization: An old challenge and new approaches, Foundations of Computational, Intelligence, 6, pp. 127-149, (2009); Erkan G., Radev D.R., LexRank: Graph-based lexical centrality as salience in text summarization, J. Artif. Intell. Res, 22, pp. 457-479, (2004); Mihalcea R., Graph-based ranking algorithms for sentence extraction, applied to text summarization, Proc. ACL Interact. Poster Demonstration Sessions, pp. 170-173, (2004); Radev D.R., Blair-Goldensohn S., Zhang Z., Experiments in single and multi-document summarization using MEAD, Proc. 1st Document Understand. Conf, pp. 1-8, (2001); Moratanch N., Chitrakala S., A survey on extractive text summarization, Proc. Int. Conf. Comput., Commun. Signal Process. (ICCCSP), pp. 1-6, (2017); Gupta V., Lehal G.S., A survey of text summarization extractive techniques, J. Emerg. Technol. Web Intell, 2, 3, pp. 258-268, (2010); Ma C., Emma Zhang W., Guo M., Wang H., Sheng Q.Z., Multidocument summarization via deep learning techniques: A survey, (2020); Mohan M.J., Sunitha C., Ganesh A., Jaya A., A study on ontology based abstractive summarization, Proc. Comput. Sci, 87, pp. 32-37, (2016); Bhat I.K., Mohd M., Hashmy R., SumItUp: A hybrid singledocument text summarizer, Soft Computing: Theories and Applications (Advances in Intelligent Systems and Computing), 583, pp. 619-634, (2018); Mohammed S., Introducing the new JETWI associate editor-in-chief, J. Emerg. Technol. Web Intell, 5, 1, (2013); Joshi M., Wang H., McClean S., Dense semantic graph and its application in single document summarisation, Emerging Ideas on Information Filtering and Retrieval, pp. 55-67, (2018); Gupta V.K., Siddiqui T.J., Multi-document summarization using sentence clustering, Proc. 4th Int. Conf. Intell. Human Comput. Interact. (IHCI), pp. 1-5, (2012); Yogan J.K., Goh O.S., Halizah B., Ngo H.C., Puspalata C., A review on automatic text summarization approaches, J. Comput. Sci, 12, 4, pp. 178-190, (2016); Sahoo D., Balabantaray R., Phukon M., Saikia S., Aspect based multi-document summarization, Proc. Int. Conf. Comput., Commun. Autom. (ICCCA), pp. 873-877, (2016); Mohd M., Jan R., Shah M., Text document summarization using word embedding, Expert Syst. Appl, 143, (2020); Takeuchi K., A study on operations used in text summarization, (2002); Dernoncourt F., Ghassemi M., Chang W., A repository of corpora for summarization, Proc. 11th Int. Conf. Lang. Resour. Eval. (LREC), pp. 3221-3227, (2019); Woodsend K., Lapata M., Automatic generation of story highlights, Proc. 48th Annu. Meeting Assoc. Comput. Linguistics, pp. 565-574, (2010); Khan A., Salim N., Farman H., Khan M., Jan B., Ahmad A., Ahmed I., Paul A., Abstractive text summarization based on improved semantic graph approach, Int. J. Parallel Program, 46, 5, pp. 992-1016, (2018); Kouris P., Alexandridis G., Stafylopatis A., Abstractive text summarization: Enhancing sequence-to-sequence models using word sense disambiguation and semantic content generalization, Comput. Linguistics, 47, 4, pp. 813-859, (2021); Supreetha D., Rajeshwari S.B., Kallimani J.S., Abstractive text summarization, J. Xidian Univ, 14, 6, pp. 26884-26888, (2020); Sharma G., Sharma D., Automatic text summarization methods: A comprehensive review, Social Netw. Comput. Sci, 4, 1, (2023); Gupta S., Gupta S.K., Abstractive summarization: An overview of the state of the art, Expert Syst. Appl, 121, pp. 49-65, (2019); Moratanch N., Chitrakala S., Anaphora resolved abstractive text summarization (AR-ATS) system, Multimedia Tools Appl, 82, 3, pp. 4569-4597, (2023); Khan A., Salim N., A review on abstractive summarization methods, J. Theor. Appl. Inf. Technol, 59, 1, pp. 64-72, (2014); Madhuri J.N., Ganesh Kumar R., Extractive text summarization using sentence ranking, Proc. Int. Conf. Data Sci. Commun. (IconDSC), pp. 1-3, (2019); Jain A., Bhatia D., Thakur M.K., Extractive text summarization using word vector embedding, Proc. Int. Conf. Mach. Learn. Data Sci. (MLDS), pp. 51-55, (2017); Alshaina S., John A., Nath A.G., Multi-document abstractive summarization based on predicate argument structure, Proc. IEEE Int. Conf. Signal Process., Informat., Commun. Energy Syst. (SPICES), pp. 1-6, (2017); Nallapati R., Zhou B., Dos Santos C.N., Gulcehre C., Xiang B., Abstractive text summarization using sequence-to-sequence RNNs and beyond, (2016); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, (2017); Ma S., Sun X., Lin J., Ren X., A hierarchical end-to-end model for jointly improving text summarization and sentiment classification, (2018); Yadav A.K., Singh A., Dhiman M., Vineet, Kaundal R., Verma A., Yadav D., Extractive text summarization using deep learning approach, Int. J. Inf. Technol, 14, 5, pp. 2407-2415, (2022); Elsaid A., Mohammed A., Ibrahim L.F., Sakre M.M., A comprehensive review of Arabic text summarization, IEEE Access, 10, pp. 38012-38030, (2022); Agarwal P., Mehta S., Empirical analysis of five nature-inspired algorithms on real parameter optimization problems, Artif. Intell. Rev, 50, 3, pp. 383-439, (2018); Nenkova A., McKeown K., A survey of text summarization techniques, Mining Text Data, pp. 43-76, (2012); Mehta P., Majumder P., Effective aggregation of various summarization techniques, Inf. Process. Manage, 54, 2, pp. 145-158, (2018); Nazari N., Mahdavi M., A survey on automatic text summarization, J. AI Data Mining, 7, 1, pp. 121-135, (2019); Wang S., Zhao X., Li B., Ge B., Tang D., Integrating extractive and abstractive models for long text summarization, Proc. IEEE Int. Congr. Big Data (BigData Congress), pp. 305-312, (2017); Al-Sabahi K., Zhang Z., Long J., Alwesabi K., An enhanced latent semantic analysis approach for Arabic document summarization, Arabian J. Sci. Eng, 43, 12, pp. 8079-8094, (2018); Mohamed M., Oussalah M., SRL-ESA-TextSum: A text summarization approach based on semantic role labeling and explicit semantic analysis, Inf. Process. Manage, 56, 4, pp. 1356-1372, (2019); Kobayashi H., Noguchi M., Yatsuka T., Summarization based on embedding distributions, Proc. Conf. Empirical Methods Natural Lang. Process, pp. 1984-1989, (2015); Chen L., Nguyen M.L., Sentence selective neural extractive summarization with reinforcement learning, Proc. 11th Int. Conf. Knowl. Syst. Eng. (KSE), pp. 1-5, (2019); Sanchez-Gomez J.M., Vega-Rodriguez M.A., Perez C.J., Experimental analysis of multiple criteria for extractive multidocument text summarization, Expert Syst. Appl, 140, (2020); Sharaff A., Khaire A.S., Sharma D., Analysing fuzzy based approach for extractive text summarization, Proc. Int. Conf. Intell. Comput. Control Syst. (ICCS), pp. 906-910, (2019); Bhat I.K., Mohd M., Hashmy R., SumItUp: A hybrid singledocument text summarizer, Proc. Soft Comput., Theories Appl. (SoCTA), 1, pp. 619-634, (2018); Lloret E., Roma-Ferri M.T., Palomar M., COMPENDIUM: A text summarization system for generating abstracts of research papers, Data Knowl. Eng, 88, pp. 164-175, (2013); Patil A.P., Dalmia S., Ansari S.A.A., Aul T., Bhatnagar V., Automatic text summarizer, Proc. Int. Conf. Adv. Comput., Commun. Informat. (ICACCI), pp. 1530-1534, (2014); Wang H., Qin K., Zakari R.Y., Lu G., Yin J., Deep neural networkbased relation extraction: An overview, Neural Comput. Appl, 34, 6, pp. 4781-4801, (2022); Gupta H., Patel M., Method of text summarization using LSA and sentence based topic modelling with bert, Proc. Int. Conf. Artif. Intell. Smart Syst. (ICAIS), pp. 511-517, (2021); Das A.K., Thumu B., Sarkar A., Vimal S., Das A.K., Graph-based text summarization and its application on COVID-19 Twitter data, Int. J. Uncertainty, Fuzziness Knowl.-Based Syst, 30, 3, pp. 513-540, (2022); Lund B.D., Wang T., Chatting about ChatGPT: How may AI and GPT impact academia and libraries?, Library Hi Tech News, 40, 3, pp. 26-29, (2023); Huang Z., Xie Z., A patent keywords extraction method using TextRank model with prior public knowledge, Complex Intell. Syst, 8, 1, pp. 1-12, (2022); Gupta H., Patel M., Study of extractive text summarizer using the Elmo embedding, Proc. 4th Int. Conf. I-SMAC (IoT Social, Mobile, Analytics Cloud) (I-SMAC), pp. 829-834, (2020); Wang M., He J., Hahn P.R., Local Gaussian process extrapolation for BART models with applications to causal inference, (2022); Zheng O., Abdel-Aty M., Wang D., Wang Z., Ding S., ChatGPT is on the Horizon: Could a large language model be all we need for intelligent transportation?, (2023); Jiwani N., Gupta K., Whig P., Analysis of the potential impact of omicron crises using NLTK (natural language toolkit), Proc. 3rd Doctoral Symp. Comput. Intell. (DoSCI), pp. 445-454, (2022); Serere H.N., Resch B., Havas C.R., Enhanced geocoding precision for location inference of tweet text using spaCy, nominatim and Google Maps. A comparative analysis of the influence of data selection, PLoS ONE, 18, 3, (2023); Sufi F.K., Khalil I., Automated disaster monitoring from social media posts using AI-based location intelligence and sentiment analysis, IEEE Trans. Computat. Social Syst., (2022); Jiang W., Synovic N., Hyatt M., Schorlemmer T.R., Sethi R., Lu Y.-H., Thiruvathukal G.K., Davis J.C., An empirical study of pre-trained model reuse in the hugging face deep learning model registry, (2023); Esuli A., Sebastiani F., Training data cleaning for text classification, Proc. Conf. Theory Inf. Retr, pp. 29-41, (2009); Pak I., Teh P.L., Text segmentation techniques: A critical review, Innovative Computing, Optimization and Its Applications: Modeling and Simulations, pp. 167-181, (2018); Kaur J., Buttar P.K., A systematic review on stopword removal algorithms, Int. J. Future Revolution Comput. Sci. Commun. Eng, 4, 4, pp. 207-210, (2018); Pramana R., Debora, Subroto J.J., Gunawan A.A.S., Anderies, Systematic literature review of stemming and lemmatization performance for sentence similarity, Proc. IEEE 7th Int. Conf. Inf. Technol. Digit. Appl. (ICITDA), pp. 1-6, (2022); Budi I., Suryono R.R., Application of named entity recognition method for Indonesian datasets: A review, Bull. Electr. Eng. Informat, 12, 2, pp. 969-978, (2023); Kanakaraddi S.G., Nandyal S.S., Survey on parts of speech tagger techniques, Proc. Int. Conf. Current Trends Towards Converging Technol. (ICCTCT), pp. 1-6, (2018); Kaur H., Mangat V., Nidhi, A survey of sentiment analysis techniques, Proc. Int. Conf. I-SMAC (IoT Social, Mobile, Analytics Cloud) (I-SMAC), pp. 921-925, (2017); Sukthanker R., Poria S., Cambria E., Thirunavukarasu R., Anaphora and coreference resolution: A review, Inf. Fusion, 59, pp. 139-162, (2020); Awasthi I., Gupta K., Bhogal P.S., Anand S.S., Soni P.K., Natural Language Processing (NLP) based text summarization-A survey, Proc. 6th Int. Conf. Inventive Comput. Technol. (ICICT), pp. 1310-1317, (2021); Boros T., Dumitrescu S.D., Burtica R., NLP-Cube: End-to-end raw text processing with neural networks, Proc. CoNLL Shared Task, Multilingual Parsing Raw Text Universal Dependencies, pp. 171-179, (2018); Martins A.F.T., Smith N.A., Summarization with a joint model for sentence extraction and compression, Proc. Workshop Integer Linear Program. Natural Langauge Process. (ILP), pp. 1-9, (2009); Gupta T., Keyword extraction: A review, Int. J. Eng. Appl. Sci. Technol, 2, 4, pp. 215-220, (2017); Li Y., Fei T., Zhang F., A regionalization method for clustering and partitioning based on trajectories from NLP perspective, Int. J. Geographical Inf. Sci, 33, 12, pp. 2385-2405, (2019); Zhang Y., Lin H., Yang Z., Wang J., Sun Y., Xu B., Zhao Z., Neural network-based approaches for biomedical relation classification: A review, J. Biomed. Informat, 99, (2019); Ma C., Zhang W.E., Guo M., Wang H., Sheng Q.Z., Multidocument summarization via deep learning techniques: A survey, ACM Comput. Surv, 55, 5, pp. 1-37, (2023); Magdum P.G., Rathi S., A survey on deep learning-based automatic text summarization models, Proc. Adv. Artif. Intell. Data Eng. (AIDE), pp. 377-392, (2021); Jaiswal A., Babu A.R., Zadeh M.Z., Banerjee D., Makedon F., A survey on contrastive self-supervised learning, Technologies, 9, 1, (2020); Jung N., Lee G., Automated classification of building information modeling (BIM) case studies by BIM use based on natural language processing (NLP) and unsupervised learning, Adv. Eng. Informat, 41, (2019); Wang W.Y., Li J., He X., Deep reinforcement learning for NLP, Proc. 56th Annu. Meeting Assoc. Comput. Linguistics, Tutorial Abstr, pp. 19-21, (2018); Strubell E., Ganesh A., McCallum A., Energy and policy considerations for deep learning in NLP, (2019); Chiche A., Yitagesu B., Part of speech tagging: A systematic review of deep learning and machine learning approaches, J. Big Data, 9, 1, pp. 1-25, (2022); Shelar H., Kaur G., Heda N., Agrawal P., Named entity recognition approaches and their comparison for custom NER model, Sci. Technol. Libraries, 39, 3, pp. 324-337, (2020); Doitch A., Yazdi R., Hazan T., Reichart R., Perturbation based learning for structured NLP tasks with application to dependency parsing, Trans. Assoc. Comput. Linguistics, 7, pp. 643-659, (2019); Hasan M.R., Maliha M., Arifuzzaman M., Sentiment analysis with NLP on Twitter data, Proc. Int. Conf. Comput., Commun., Chem., Mater. Electron. Eng. (IC4ME2), pp. 1-4, (2019); Clarke N., Foltz P., Garrard P., How to do things with (thousands of) words: Computational approaches to discourse analysis in Alzheimer's disease, Cortex, 129, pp. 446-463, (2020); Gillick D., Favre B., Hakkani-Tur D., The ICSI summarization system at TAC 2008, (2008); Long C., Huang M., Zhu X., Tsinghua University at TAC 2009: Summarizing multi-documents by information distance, (2009); Ji H., Grishman R., Dang H.T., Griffitt K., Ellis J., Overview of the TAC 2010 knowledge base population track, Proc. 3rd Text Anal. Conf. (TAC), 3, 2, (2010); Oufaida H., Nouali O., Blache P., Minimum redundancy and maximum relevance for single and multi-document Arabic text summarization, J. King Saud Univ. Comput. Inf. Sci, 26, 4, pp. 450-461, (2014); Gallina Y., Boudin F., Daille B., KPTimes: A large-scale dataset for keyphrase generation on news documents, (2019); Zhang Y., Meng J.E., Pratama M., Extractive document summarization based on convolutional neural networks, Proc. 42nd Annu. Conf. IEEE Ind. Electron. Soc. (IECON), pp. 918-922, (2016); Passonneau R., Evaluating an evaluation method: The pyramid method applied to 2003 document understanding conference (DUC) data, (2006); Seki Y., Eguchi K., Kando N., Aono M., Opinion-focused summarization and its analysis at DUC 2006, Proc. Document Understand. Conf. (DUC), pp. 122-130, (2006); Eide S.R., Tahmasebi N., Borin L., The Swedish culturomics gigaword corpus: A one billion word Swedish reference dataset for NLP, Proc. From Digitization Knowl. Workshop, pp. 8-12, (2016); Grusky M., Naaman M., Artzi Y., Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies, (2018); Gupta V., Bharti P., Nokhiz P., Karnick H., SumPubMed: Summarization dataset of PubMed scientific articles, Proc. 59th Annu. Meeting Assoc. Comput. Linguistics 11th Int. Joint Conf. Natural Lang. Process., Student Res. Workshop, pp. 292-303, (2021); Khotimah N., Girsang A.S., Indonesian news articles summarization using genetic algorithm, Eng. Lett, 30, 1, pp. 1-9, (2022); Suleiman D., Awajan A.A., Deep learning based extractive text summarization: Approaches, datasets and evaluation measures, Proc. 6th Int. Conf. Social Netw. Anal., Manage. Secur. (SNAMS), pp. 204-210, (2019); Zhang H., Wang J., An unsupervised semantic sentence ranking scheme for text documents, Integr. Comput.-Aided Eng, 28, 1, pp. 17-33, (2020); Belwal R.C., Rai S., Gupta A., Text summarization using topicbased vector space model and semantic measure, Inf. Process. Manage, 58, 3, (2021); Hu B., Chen Q., Zhu F., LCSTS: A large scale Chinese short text summarization dataset, (2015); Dalton J., Xiong C., Kumar V., Callan J., CAsT-19: A dataset for conversational information seeking, Proc. 43rd Int. ACM SIGIR Conf. Res. Develop. Inf. Retr, pp. 1985-1988, (2020); Naseem R., Khan B., Shah M.A., Wakil K., Khan A., Alosaimi W., Uddin M.I., Alouffi B., Performance assessment of classification algorithms on early detection of liver syndrome, J. Healthcare Eng, 2020, (2020); Naseem R., Khan B., Ahmad A., Almogren A., Jabeen S., Hayat B., Shah M.A., Investigating tree family machine learning techniques for a predictive system to unveil software defects, Complexity, 2020, (2020); Khan B., Naseem R., Muhammad F., Abbas G., Kim S., An empirical evaluation of machine learning techniques for chronic kidney disease prophecy, IEEE Access, 8, pp. 55012-55022, (2020); Ouni S., Fkih F., Omri M.N., Toward a new approach to author profiling based on the extraction of statistical features, Social Netw. Anal. Mining, 11, 1, pp. 1-16, (2021); Hayashi Y., Fukunaga K., Accuracy of rule extraction using a recursive-rule extraction algorithm with continuous attributes combined with a sampling selection technique for the diagnosis of liver disease, Informat. Med. Unlocked, 5, pp. 26-38, (2016); Tanwar S., Bhatia Q., Patel P., Kumari A., Singh P.K., Hong W.-C., Machine learning adoption in blockchain-based smart applications: The challenges, and a way forward, IEEE Access, 8, pp. 474-488, (2020)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85174836747"
"Petersen K.","Petersen, Kai (22635718800)","22635718800","Case study identification with GPT-4 and implications for mapping studies","2024","Information and Software Technology","171","","107452","","","","0","10.1016/j.infsof.2024.107452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189468248&doi=10.1016%2fj.infsof.2024.107452&partnerID=40&md5=6d17d23e05280c433f45e3ff6dc68f5a","Context: Rainer and Wohlin showed that case studies are not well understood by reviewers and authors and thus they say that a given research is a case study when it is not. Objective: Rainer and Wohlin proposed a smell indicator (inspired by code smells) to identify case studies based on the frequency of occurrences of words, which performed better than human classifiers. With the emergence of ChatGPT, we evaluate ChatGPT to assess its performance in accurately identifying case studies. We also reflect on the results’ implications for mapping studies, specifically data extraction. Method: We used ChatGPT with the model GPT-4 to identify case studies and compared the result with the smell indicator for precision, recall, and accuracy. Results: GPT-4 and the smell indicator perform similarly, with GPT-4 performing slightly better in some instances and the smell indicator (SI) in others. The advantage of GPT-4 is that it is based on the definition of case studies and provides traceability on how it reaches its conclusions. Conclusion: As GPT-4 performed well on the task and provides traceability, we should use and, with that, evaluate it on data extraction tasks, supporting us as authors. © 2024 The Author(s)","Case study; Data extraction; GPT-4; Systematic mapping studies","Data mining; Extraction; Case-studies; Code smell; Data extraction; GPT-4; Mapping studies; Performance; Systematic mapping studies; Mapping","pp. 1-10, (2008); Rainer A., Wohlin C., Case study identification: A trivial indicator outperforms human classifiers, Inf. Softw. Technol., (2023); Yin R.K., Case Study Research: Design and Methods, vol. 5, (2009); Runeson P., Host M., Guidelines for conducting and reporting case study research in software engineering, Empir. Softw. Eng., 14, pp. 131-164, (2009); Wohlin C., Case study research in software engineering—It is a case, and it is a study, but is it a case study?, Inf. Softw. Technol., 133, (2021)","","Elsevier B.V.","","","","","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85189468248"
"Grishina A.; Hort M.; Moonen L.","Grishina, Anastasiia (57205678390); Hort, Max (57218601709); Moonen, Leon (7003285889)","57205678390; 57218601709; 7003285889","The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification","2023","ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering","","","","895","907","12","0","10.1145/3611643.3616304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180550065&doi=10.1145%2f3611643.3616304&partnerID=40&md5=5665a1be8826c3b483b76f2bd6d44734","The use of modern Natural Language Processing (NLP) techniques has shown to be beneficial for software engineering tasks, such as vulnerability detection and type inference. However, training deep NLP models requires significant computational resources. This paper explores techniques that aim at achieving the best usage of resources and available information in these models. We propose a generic approach, EarlyBIRD, to build composite representations of code from the early layers of a pre-trained transformer model. We empirically investigate the viability of this approach on the CodeBERT model by comparing the performance of 12 strategies for creating composite representations with the standard practice of only using the last encoder layer. Our evaluation on four datasets shows that several early layer combinations yield better performance on defect detection, and some combinations improve multi-class classification. More specifically, we obtain a +2 average improvement of detection accuracy on Devign with only 3 out of 12 layers of CodeBERT and a 3.3x speed-up of fine-tuning. These findings show that early layers can be used to obtain better results using the same resources, as well as to reduce resource usage during fine-tuning and inference. © 2023 Owner/Author.","AI4Code; AI4SE; code classification; ML4SE; model optimization; sustainability; transformer; vulnerability detection","Classification (of information); Learning algorithms; Natural language processing systems; Signal encoding; Ai4code; AI4SE; Code classification; Composite representations; ML4SE; Model optimization; Natural languages; Performance; Transformer; Vulnerability detection; Software engineering","Ahmad W., Chakraborty S., Ray B., Chang K., Unified Pre-training for Program Understanding and Generation, Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655-2668, (2021); Ahmed T., Devanbu P., Multilingual Training for Software Engineering, Proceedings of the 44th International Conference on Software Engineering. ACM, Pittsburgh Pennsylvania, pp. 1443-1455, (2022); Allamanis M., Barr E.T., Devanbu P., Sutton C., A Survey of Machine Learning for Big Code and Naturalness, Comput. Surveys, 51, 4, pp. 811-8137, (2018); Berabi B., He J., Raychev V., Vechev M., TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer, International Conference on Machine Learning, 139, pp. 780-791, (2021); Bhandari G., Naseer A., Moonen L., CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software, International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE). ACM, pp. 30-39, (2021); Blevins T., Levy O., Zettlemoyer L., Deep RNNs Encode Soft Hierarchical Syntax, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 14-19, (2018); Chakraborty S., Krishna R., Ding Y., Ray B., Deep Learning Based Vulnerability Detection: Are We There Yet, IEEE Transactions on Software Engineering, 48, 9, pp. 3280-3296, (2022); Chen M., Tworek J., Jun H., Yuan Q., De Oliveira H.P.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F.P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W.H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Chen Z., Kommrusch S.J., Tufano M., Pouchet L., Poshyvanyk D., Monperrus M., SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair, IEEE Transactions on Software Engineering, 47, 9, pp. 1943-1959, (2019); Clement C., Drain D., Timcheck J., Svyatkovskiy A., Sundaresan N., PyMT5: Multi-Mode Translation of Natural Language and Python Code with Transformers, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 9052-9065, (2020); Devanbu P., New Initiative: The Naturalness of Software, Proceedings-International Conference on Software Engineering, 2, pp. 543-546, (2015); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL, Vol 1), pp. 4171-4186, (2019); Fan A., Grave E., Joulin A., Reducing Transformer Depth on Demand with Structured Dropout, (2019); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics: EMNLP 2020. Online, pp. 1536-1547, (2020); Fu M., Tantithamthavorn C., Le T., Van N., Phung D., VulRepair: A T5-based Automated Software Vulnerability Repair, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022), pp. 935-947, (2022); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training Code Representations with Data Flow, International Conference on Learning Representations, ICLR 2021. Virtual Event, Austria, pp. 1-18, (2021); Hellendoorn V.J., Bird C., Barr E.T., Allamanis M., Deep Learning Type Inference, Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), pp. 152-162, (2018); Lopez J.A.H., Weyssow M., Cuadrado J.S., Sahraoui H., AST-Probe: Recovering Abstract Syntax Trees from Hidden Representations of Pre-Trained Language Models, Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering (ASE '22), pp. 1-11, (2023); Howard J., Ruder S., Universal Language Model Finetuning for Text Classification, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 328-339, (2018); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and Evaluating Contextual Embedding of Source Code, Proceedings of the 37th International Conference on Machine Learning. PMLR, pp. 5110-5121, (2020); Karmakar A., Robbes R., What Do Pre-Trained Code Models Know about Code, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1332-1336, (2021); Lan Z., Chen M., Goodman S., Gimpel K., Sharma P., Soricut R., ALBERT: A Lite BERT for Self-supervised Learning of Language Representations, (2020); Li R., Allal L.B., Zi Y., Muennighoff N., Kocetkov D., Mou C., Marone M., Akiki C., Li J., Chim J., Liu Q., Zheltonozhskii E., Zhuo T.Y., Wang T., Dehaene O., Davaadorj M., Lamy-Poirier J., Monteiro J., Shliazhko O., Gontier N., Meade N., Zebaze A., Yee M., Umapathi L.K., Zhu J., Lipkin B., Oblokulov M., Wang Z., Murthy R., Stillerman J., Patel S.S., Abulkhanov D., Zocca M., Dey M., Zhang Z., Fahmy N., Bhattacharyya U., Yu W., Singh S., Luccioni S., Villegas P., Kunakov M., Zhdanov F., Romero M., Lee T., Timor N., Ding J., Schlesinger C., Schoelkopf H., Ebert J., Dao T., Mishra M., Gu A., Robinson J., Anderson C.J., Dolan-Gavitt B., Contractor D., Reddy S., Fried D., Bahdanau D., Jernite Y., Ferrandis C.M., Hughes S., Wolf T., Guha A., Von Werra L., De Vries H., Star-Coder: May the Source Be with You!, (2023); Liu N.F., Gardner M., Belinkov Y., Peters M.E., Smith N.A., Linguistic Knowledge and Transferability of Contextual Representations, (2019); Liu S., Wu B., Xie X., Meng G., Liu Y., ContraBERT: Enhancing Code Pre-Trained Models via Contrastive Learning, Proceedings of the 45th International Conference on Software Engineering (ICSE '23), pp. 2476-2487, (2023); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A Robustly Optimized BERT Pretraining Approach, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S.K., Fu S., Liu S., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks, pp. 1-16, (2021); Niu C., Li C., Luo B., Ng V., Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code, (2022); Paltenghi M., Pradel M., Thinking Like a Developer Comparing the Attention of Humans with Neural Models of Code, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 867-879, (2021); Pan C., Lu M., Xu B., An Empirical Study on Software Defect Prediction Using CodeBERT Model, Applied Sciences, 11, 11, (2021); Peer D., Stabinger S., Engl S., Rodriguez-Sanchez A., Greedy-Layer Pruning: Speeding up Transformer Models for Natural Language Processing, Pattern Recognition Letters, 157, pp. 76-82, (2022); Peters M., Neumann M., Zettlemoyer L., Yih W., Dissecting Contextual Word Embeddings: Architecture and Representation, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1499-1509, (2018); Peters M.E., Ruder S., Smith N.A., To Tune or Not to Tune Adapting Pretrained Representations to Diverse Tasks, Proceedings of the 4thWorkshop on Representation Learning for NLP (RepL4NLP-2019), pp. 7-14, (2019); Phan L., Tran H., Le D., Nguyen H., Annibal J., Peltekian A., Ye Y., CoTexT: Multi-task Learning with Code-Text Transformer, Workshop on Natural Language Processing for Programming (NLP4Prog 2021), pp. 40-47, (2021); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated Vulnerability Detection in Source Code Using Deep Representation Learning, International Conference on Machine Learning and Applications (ICMLA). IEEE, Orlando, FL, pp. 757-762, (2018); Sajjad H., Dalvi F., Durrani N., Nakov P., On the Effect of Dropping Layers of Pre-trained Transformer Models, Computer Speech & Language, 77, (2023); Sharma R., Chen F., Fard F., Lo D., An Exploratory Study on Code Attention in BERT, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension (ICPC '22), pp. 437-448, (2022); Sharma T., Kechagia M., Georgiou S., Tiwari R., Sarro F., A Survey on Machine Learning Techniques for Source Code Analysis, (2021); Sun C., Qiu X., Xu Y., Huang X., How to Fine-Tune BERT for Text Classification, Chinese Computational Linguistics (Lecture Notes in Computer Science), pp. 194-206, (2019); Sun C., Qiu X., Xu Y., Huang X., How to Fine-Tune BERT for Text Classification, (2020); Vargha A., Delaney H.D., A Critique and Improvement of the CL Common Language Effect Size Statistics of McGraw and Wong, Journal of Educational and Behavioral Statistics, 25, 2, pp. 101-132, (2000); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser U., Polosukhin I., Attention Is All You Need, International Conference on Neural Information Processing Systems (NeurIPS), pp. 5998-6008, (2017); Wang Y., Wang W., Joty S., Hoi S.C.H., CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation, Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, (2021); Wei H., Lin G., Li L., Jia H., A Context-Aware Neural Embedding for Function-Level Vulnerability Detection, Algorithms, 14, 11, (2021); Wilcoxon F., Individual Comparisons by Ranking Methods, Breakthroughs in Statistics: Methodology and Distribution, pp. 196-202, (1992); Yang Z., Dai Z., Yang Y., Carbonell J., Salakhutdinov R., Le Q.V., XLNet: Generalized Autoregressive Pretraining for Language Understanding, (2020); Yasunaga M., Liang P., Break-It-Fix-It: Unsupervised Learning for Program Repair, International Conference on Machine Learning. PMLR, 12, (2021); Ye H., Martinez M., Monperrus M., Neural Program Repair with Execution-Based Backpropagation, Proceedings of the 44th International Conference on Software Engineering (ICSE '22), pp. 1506-1518, (2022); Zhang T., Wu F., Katiyar A., Weinberger K.Q., Artzi Y., Revisiting Few-sample BERT Fine-tuning, NeurIPS 2021, pp. 1-22, (2021); Zhao G., Huang J., DeepSim: Deep Learning Code Functional Similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks, International Conference on Neural Information Processing Systems (NeurIPS), 11, (2019)","Chandra S.; Blincoe K.; Tonella P.","Association for Computing Machinery, Inc","ACM SIGSOFT; Ant Group; et al.; Google; JetBrains; Meta","31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023","3 December 2023 through 9 December 2023","San Francisco","195093","Conference paper","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85180550065"
"Bertolotti F.; Cazzola W.","Bertolotti, Francesco (57914120400); Cazzola, Walter (6602449966)","57914120400; 6602449966","Fold2Vec: Towards a Statement-Based Representation of Code for Code Comprehension","2023","ACM Transactions on Software Engineering and Methodology","32","1","3514232","","","","3","10.1145/3514232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152605859&doi=10.1145%2f3514232&partnerID=40&md5=784ed33b7e8feda931e42a777267bfca","We introduce a novel approach to source code representation to be used in combination with neural networks. Such a representation is designed to permit the production of a continuous vector for each code statement. In particular, we present how the representation is produced in the case of Java source code. We test our representation for three tasks: code summarization, statement separation, and code search. We compare with the state-of-the-art non-autoregressive and end-to-end models for these tasks. We conclude that all tasks benefit from the proposed representation to boost their performance in terms of F1-score, accuracy, and mean reciprocal rank, respectively. Moreover, we show how models trained on code summarization and models trained on statement separation can be combined to address methods with tangled responsibilities, meaning that these models can be used to detect code misconduct.  © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Big code; intent identification; learning representations; method name suggestion","Big code; Code comprehension; Code search; Intent identification; Java source codes; Learning representation; Method name suggestion; Neural-networks; Source code representations; State of the art","Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 10th Joint Meeting of the European Software Engineering Conference and the ACMSIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE'15), pp. 38-49, (2015); Allamanis M., Brockschmmmidt M., Khademi M., Learning to represent programs with graphs, Proceedings of the 6th International Conference on Learning Representations (ICLR'18), (2018); Allamanis M., Peng H., Sutton C.A., A convolutional attention network for extreme summarization of source code, Proceedings of the 33rd International Conference on Machine Learning (ICML'16), pp. 2091-2100, (2016); Allamanis M., Sutton C., Mining source code repositories at massive scale using language modeling, Proceedings of the 10th Working Conference on Mining Software Repositories (MSR'13), pp. 207-216, (2013); Alon U., Brody S., Levy O., Yahav E., code2seq: Generating sequences from structured representations of code, Proceedings of the 7th International Conference on Learning Representations (ICLR'19), (2019); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, Proceedings of the 39th ACM Conference on Programming Language Design and Implementation (PLDI'18), pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the 46th Annual Symposium on Principles of Programming Languages (POPL'19), (2019); Amodio M., Chaudhuri S., Reps T., Neural attribute machines for programming generation, (2017); Lei Ba J., Ryan Kiros J., Hilton G.E., Layer normalization, (2016); Balntas V., Riba E., Ponsa D., Mikolajczyk K., Learning local feature descriptors with triplets and shallow convolutional neural networks, Proceedings of the British Machine Vision Conference (BMVC'16), (2016); Ben-Nun T., Shashana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Proceedings of the 32nd International Conference on Neural Information Processing Systems (NIPS'18), pp. 3589-3601, (2018); Bengio Y., Simard P., Frasconi P., Learning long-term dependencies with gradient descent is difficult, IEEE Transaction on Neural Networks, 5, 2, pp. 157-166, (1994); Breu S., Krinke J., Aspect mining using event traces, Proceedings of the 19th IEEE/ACMInternational Conference on Automated Software Engineering (ASE'04), pp. 310-315, (2004); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative code modeling with graphs, Proceedings of the 7th International Conference on Learning Representations (ICLR'19, poster session), (2019); Butler S., Wermelinger M., Yu Y., Sharp H., Improving the tokenisation of identifier names, ECOOP 2011-Object-Oriented Programming. Lecture Notes in Computer Science, 6813, pp. 130-154, (2011); Celik A., Sreepathi P., Khurshid S., Gligoric M., Bounded exhaustive test-input generation on GPUs, Proceedings of the 32nd Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA'17), (2017); Chen M., Tworek J., Jun H., Yuan Q., De Oliveira Pinto H.P., Kaplan J., Edwards H., Et al., Evaluating large language models trained on code, (2021); Chen Q., Zhou M., A neural framework for retrieval and summarization of source code, Proceedings of the 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE'18), pp. 826-831, (2018); Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS'18), pp. 2552-2562, (2018); Cox D.R., The regression analysis of binary sequences, Journal of the Royal Statistical Society, 20, 2, pp. 215-232, (1958); Cudill M., Neural networks primer, part I, AI Expert, 2, 12, pp. 46-52, (1987); Khanh Dam H., Pham T., Wee Ng S., Tran T., Grundy J., Ghose A., Taeksu K., Kim C.-J., Lessons learned from using a deep tree-based model for software defect prediction in practice, Proceedings of the 16th International Conference on Mining Software Repositories (MSR'19), pp. 46-57, (2019); Donaldson A., Evrard H., Lascu A., Thomson P., Bounded exhaustive test-input generation on GPUs, Proceedings of the 32nd Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA'17), (2017); Prakash Dwivedi V., Shrivastava M., Beyond Word2Vec: Embedding words and phrases in same vector space, Proceedings of the 14th International Conference on Natural Language Processing (ICON'17), pp. 205-211, (2017); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Et al., CodeBERT: A pre-trained model for programming and natural languages, Proceedings of the Empirical Methods in Natural Language Processing (EMNLP'20), pp. 1536-1547, (2020); Gers F.A., Schmidhuber J.A., Cummins F.A., Learning to forget: Continual prediction with LSTM, Neural Computation, 12, 10, pp. 451-2471, (2000); Gu X., Zhang H., Kim S., Deep code search, Proceedings of the 40th International Conference on Software Engineering (ICSE'18), pp. 933-944, (2018); Haiduc S., Aponte J., Marcus A., Supporting program comprehension with source code summarization, Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering (ICSE'10), pp. 223-226, (2010); Halevy A., Norvig P., Pereira F., The unreasonable effectiveness of data, IEEE Intelligent Systems, 24, pp. 8-12, (2009); Hellendoorn V.J., Devanbu P., Are deep neural network the best choice formodeling source code?, Proceedings of the 11th Joint Meeting of the European Software Engineering Conference and the Symposium on the Foundations of Software Engineering (ESEC/FSE'17), pp. 763-773, (2017); Hill E., Binkley D., Lawrie D., Pollock L., Vujay-Shanker K., An empirical study of identifier splitting techniques, Empirical Software Engineering, 19, 6, pp. 1754-1780, (2014); Hoang T., Jin Kang H., Lo D., Lawall J., CC2Vec: Distributed representations of code changes, Proceedings of the 42nd ACM/IEEE International Conference on Software Engineering (ICSE'20), pp. 518-529, (2020); Hu H., Chen Q., Liu Z., Code generation from supervised code embeddings, Proceedings of the 26th International Conference on Neural Information Processing (ICONIP'19). Communications in Computer and Information Science, 1142, pp. 388-396, (2019); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, Proceedings of the 26th Conference on Program Comprehension (ICPC'18), pp. 200-210, (2018); Hucka M., Spiral: Splitters for identifiers in source code files, Journal of Open Source Software, 3, 24, (2018); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., CodeSearchNet Challenge: Evaluating the state of semantic code search, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL'16), pp. 2073-2083, (2016); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we?, Proceedings of the 34th International Conference on Automated Software Engineering (ASE'19), pp. 602-614, (2019); Jiang N., Lutellier T., Tan L., CURE: Code-aware neural machine translation for automatic program repair, Proceedings of the 43rd ACM/IEEE International Conference on Software Engineering (ICSE'21), pp. 1161-1173, (2021); Jiang S., Armaly A., McMillan C., Automatically generating commitmessages from diffs using neural machine translation, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE'17), pp. 135-146, (2017); Jin Kang H., Bissyande T.F., Lo D., Assessing the generalizability of code2vec token embeddings, Proceedings of the 34th International Conference on Automated Software Engineering (ASE'19), pp. 1-12, (2019); Kastner C., Dreiling A., Ostermann K., Variability mining: Consistent semi-automatic detection of product-line features, IEEE Transactions on Software Engineering, 40, 1, pp. 67-82, (2014); Keim J., Kaplan A., Koziolek A., Mirakhorli M., Does BERT understand code?-An exploratory study on the detection of architectural tactics in code, Software Architecture. Lecture Notes in Computer Science, 12292, pp. 220-228, (2020); Kingma D.P., Ba J., Adam: A method for stochastic optimization, Proceedings of the International Conference on Learning Representations (ICLR'15), (2015); Kiros R., Zhu Y., Salakhutdinov R., Zemel R.S., Torralba A., Urtasun R., Fidler S., Skip-thought vectors, Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS'15), pp. 3294-3302, (2015); Lu Y., Chaudhuri S., Jermaine C., Melski D., Data-driven program completion, (2017); Luong M.-T., Pham H., Manning C.D., Effective approaches to attention-based neural machine translation, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP'15), pp. 1412-1421, (2015); Maddison C., Tarlow D., Structured generative models of natural source code, Proceedings of the 31st International Conference on Machine Learning (ICML'14), pp. 649-657, (2014); Martin R.C., Newkirk J.W., Koss R.S., Agile Software Development: Principles, Patterns and Practices, (2003); Martinez J., Ziadi T., Bissyande T.F., Klein J., Le Traon Y., Automating the extraction of model-based software product lines from model variants, Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering (ASE'15), pp. 396-406, (2015); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proceedings of the 26th International Conference on Neural Information Processing Systems (NIPS'13), pp. 3111-3119, (2013); Mishne A., Shoham S., Yahav E., Typestate-based semantic code search over partial programs, Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications (OOPSLA'12), pp. 997-1016, (2012); Sofia Moldovan G., Erban G., Aspect mining using a vector-space model based clustering approach, Proceedings of the 2nd Workshop on Linking Aspect Technology and Evolution (LATE'06), pp. 36-40, (2006); Movshovitz-Attias D., Cohen W.W., Natural language models for predicting programming comments, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL'13), pp. 35-40, (2013); Murali V., Qi L., Chaudhuri S., Jermain C., Neural sketch learning for conditional program generation, Proceedings of the 6th International Conference on Learning Representations (ICLR'18), (2018); Niu N., Savolainen J., Bhowmik T., Mahmoud A., Reddivari S., A framework for examining topical locality in object-oriented software, Proceedings of the 36th International Conference on Computer Software and Applications (COMPSAC'12), pp. 219-224, (2012); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., Learning to generate pseudo-code from source code using statistical machine translation, Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering (ASE'15), pp. 574-584, (2015); Omote Y., Tamura A., Ninomiya T., Dependency-based relative positional encoding for transformer NMT, Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANPL'19), pp. 854-861, (2019); Pascanu R., Mikolov T., Bengio Y., On the difficulty of training recurrent neural networks, Proceedings of the 30th International Conference on Machine Learning (ICML'13), pp. III1310-III1318, (2013); Pennington J., Socher R., Manning C., GloVe: Global vectors for word representation, Proceedings of the Empirical Methods in Natural Language Processing (EMNLP'14), pp. 1532-1543, (2014); Piech C., Huang J., Nguyen A., Phulsuksombati M., Sahami M., Guibas L., Learning program embeddings to propagate feedback on student code, Proceedings of the 32nd International Conference on Machine Learning (ICML'15), pp. 1093-1102, (2015); Qu L., Liu D., Extending dynamic aspect mining using formal concept analysis, Proceedings of the 4th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD'07), pp. 564-567, (2007); Islam Rabin R., Bui Q.N.D., Wang K., Yu Y., Jiang L., Amin Alipour M., On the generalizability of neural program models with respect to semantic-preserving program transformations, Information and Software Technology, 135, (2021); Islam Rabin R., Mukherjee A., Gnawali O., Amin Alipour M., Towards demystifying dimensions of source code embeddings, Proceedings of the 1st International Workshop on Representation Learning for Software Engineering and Program Languages (RL+SE&PL'20), pp. 29-38, (2020); Raychev V., Vechev M., Krause A., Predicting program properties from 'big code, Proceedings of the 42nd Annual Symposium on Principles of Programming Languages (POPL'15), pp. 111-124, (2015); Raychev V., Vechev M., Yahav E., Code completion with statistical language models, Proceedings of the 35th ACM Conference on Programming Language Design and Implementation (PLDI'14), pp. 419-428, (2014); Shi H., Zhou H., Chen J., Li L., On tree-based neural sentence modeling, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP'18), pp. 4631-4641, (2018); Shi K., Lu Y., Chang J., Weu Z., PathPair2Vec: An AST path pair-based code representation method for defect prediction, Journal of Computer Languages, 59, (2020); Sheng Tai K., Socher R., Manning C.D., Improved semantic representations from treestructured long short-term memory networks, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL/IJCNLP'15), pp. 1556-1566, (2015); Tonella P., Ceccato M., Aspect mining through the formal concept analysis of execution traces, Proceedings of the 11th Working Conference on Reverse Engineering (WCRE'04), pp. 112-121, (2004); Tullio Valente M., Borges V., Passos L., A semi-automatic approach for extracting software product-lines, IEEE Transactions on Software Engineering, 38, 4, pp. 737-754, (2012); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.M., Kaiser U., Polosukhin I., Attention is all you need, Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS'17), pp. 6000-6010, (2017); Wang K., Sing R., Su Z., Dynamic neural program embedding for program repair, Proceedings of the 6th International Conference on Learning Representations (ICLR'18), (2018); Wang S., Li B.Z., Khabsa M., Fang H., Ma H., Linformer: Self-attention with linear complexity, (2017); Wang W., Zhang Y., Sui Y., Wan Y., Zhao Z., Yu J., Yu P., Xy G., Reinforcement-learning-guided source code summarization via hierarchical attention, IEEE Transactions on Software Engineering, 48, 1, pp. 102-119, (2022); Wang Y., Wang K., Gao F., Wang L., Learning semantic program embeddings with graph interval neural network, Proceedings of the 35th Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA'20), pp. 1-27, (2020)","","Association for Computing Machinery","","","","","","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85152605859"
"Szabó Z.; Bilicki V.","Szabó, Zoltán (58829305800); Bilicki, Vilmos (6503856058)","58829305800; 6503856058","A New Approach to Web Application Security: Utilizing GPT Language Models for Source Code Inspection","2023","Future Internet","15","10","326","","","","1","10.3390/fi15100326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175167540&doi=10.3390%2ffi15100326&partnerID=40&md5=9ac66518c4c1cba38d84b4eeca804afc","Due to the proliferation of large language models (LLMs) and their widespread use in applications such as ChatGPT, there has been a significant increase in interest in AI over the past year. Multiple researchers have raised the question: how will AI be applied and in what areas? Programming, including the generation, interpretation, analysis, and documentation of static program code based on promptsis one of the most promising fields. With the GPT API, we have explored a new aspect of this: static analysis of the source code of front-end applications at the endpoints of the data path. Our focus was the detection of the CWE-653 vulnerability—inadequately isolated sensitive code segments that could lead to unauthorized access or data leakage. This type of vulnerability detection consists of the detection of code segments dealing with sensitive data and the categorization of the isolation and protection levels of those segments that were previously not feasible without human intervention. However, we believed that the interpretive capabilities of GPT models could be explored to create a set of prompts to detect these cases on a file-by-file basis for the applications under study, and the efficiency of the method could pave the way for additional analysis tasks that were previously unavailable for automation. In the introduction to our paper, we characterize in detail the problem space of vulnerability and weakness detection, the challenges of the domain, and the advances that have been achieved in similarly complex areas using GPT or other LLMs. Then, we present our methodology, which includes our classification of sensitive data and protection levels. This is followed by the process of preprocessing, analyzing, and evaluating static code. This was achieved through a series of GPT prompts containing parts of static source code, utilizing few-shot examples and chain-of-thought techniques that detected sensitive code segments and mapped the complex code base into manageable JSON structures.Finally, we present our findings and evaluation of the open source project analysis, comparing the results of the GPT-based pipelines with manual evaluations, highlighting that the field yields a high research value. The results show a vulnerability detection rate for this particular type of model of 88.76%, among others. © 2023 by the authors.","Angular; CWE-653; GPT; large language models; sensitive data; static code analysis; vulnerability detection","Chemical detection; Computational linguistics; Computer programming languages; Open systems; Project management; Sensitive data; Static analysis; Angular; Code segments; CWE-653; GPT; Language model; Large language model; Sensitive datas; Source codes; Static code analysis; Vulnerability detection; Open source software","Sanderson K., GPT-4 is here: What scientists think, Nature, 615, (2023); Deng J., Lin Y., The Benefits and Challenges of ChatGPT: An Overview, Front. Comput. Intell. Syst, 2, pp. 81-83, (2023); Janki Z.R., Bilicki V., Rule-Based Architectural Design Pattern Recognition with GPT Models, Electronics, 12, (2023); Hourani H., Hammad A., Lafi M., The Impact of Artificial Intelligence on Software Testing, Proceedings of the 2019 IEEE Jordan International Joint Conference on Electrical Engineering and Information Technology (JEEIT); Heydon A., Maimone M., Tygar J., Wing J., Zaremski A., Miro: Visual specification of security, IEEE Trans. Softw. Eng, 16, pp. 1185-1197, (1990); Giordano M., Polese G., Visual Computer-Managed Security: A Framework for Developing Access Control in Enterprise Applications, IEEE Softw, 30, pp. 62-69, (2013); Hossain Misu M.R., Sakib K., FANTASIA: A Tool for Automatically Identifying Inconsistency in AngularJS MVC Applications, Proceedings of the Twelfth International Conference on Software Engineering Advances; Szabo Z., Bilicki V., Access Control of EHR Records in a Heterogeneous Cloud Infrastructure, Acta Cybern, 25, pp. 485-516, (2021); Martin B., Brown M., Paller A., Kirby D., Christey S., CWE, SANS Top, 25, (2011); Rainey S., McGillivray K., Akintoye S., Fothergill T., Bublitz C., Stahl B., Is the European Data Protection Regulation sufficient to deal with emerging data concerns relating to neurotechnology?, J. Law Biosci, 7, (2020); Cheng S., Zhang J., Dong Y., How to Understand Data Sensitivity? A Systematic Review by Comparing Four Domains, Proceedings of the 2022 4th International Conference on Big Data Engineering; Belen Saglam R., Nurse J.R., Hodges D., Personal information: Perceptions, types and evolution, J. Inf. Secur. Appl, 66, (2022); Lang C., Woo C., Sinclair J., Quantifying data sensitivity, Proceedings of the Tenth International Conference on Learning Analytics & Knowledge; Chua H.N., Ooi J.S., Herbland A., The effects of different personal data categories on information privacy concern and disclosure, Comput. Secur, 110, (2021); Rumbold J.M., Pierscionek B.K., What Are Data? A Categorization of the Data Sensitivity Spectrum, Big Data Res, 12, pp. 49-59, (2018); Botti-Cebria V., del Val E., Garcia-Fornes A., Automatic Detection of Sensitive Information in Educative Social Networks, Proceedings of the 13th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2020), pp. 184-194; Jiang L., Liu H., Jiang H., Machine Learning Based Recommendation of Method Names: How Far are We, Proceedings of the 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE); Momeni P., Wang Y., Samavi R., Machine Learning Model for Smart Contracts Security Analysis, Proceedings of the 2019 17th International Conference on Privacy, Security and Trust (PST); Mhawish M.Y., Gupta M., Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics, J. Comput. Sci. Technol, 35, pp. 1428-1445, (2020); Cui J., Wang L., Zhao X., Zhang H., Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications, Comput. Commun, 155, pp. 125-131, (2020); Park S., Choi J.Y., Malware Detection in Self-Driving Vehicles Using Machine Learning Algorithms, J. Adv. Transp, 2020, (2020); Jiang N., Lutellier T., Tan L., CURE: Code-Aware Neural Machine Translation for Automatic Program Repair, Proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), (2021); Sharma T., Kechagia M., Georgiou S., Tiwari R., Vats I., Moazen H., Sarro F., A Survey on Machine Learning Techniques for Source Code Analysis, arXiv, (2022); Sarkar A., Gordon A.D., Negreanu C., Poelitz C., Ragavan S.S., Zorn B., What is it like to program with artificial intelligence?, arXiv, (2022); Wei J., Tay Y., Bommasani R., Raffel C., Zoph B., Borgeaud S., Yogatama D., Bosma M., Zhou D., Metzler D., Et al., Emergent Abilities of Large Language Models, arXiv, (2022); Liu Y., Han T., Ma S., Zhang J., Yang Y., Tian J., He H., Li A., He M., Liu Z., Et al., Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models, arXiv, (2023); Surameery N.M.S., Shakor M.Y., Use Chat GPT to Solve Programming Bugs, Int. J. Inf. Technol. Comput. Eng, 3, pp. 17-22, (2023); Borji A., Mohammadian M., Battle of the Wordsmiths: Comparing ChatGPT, GPT-4, Claude, and Bard, SSRN Electron. J, (2023); Wu J., Literature review on vulnerability detection using NLP technology, arXiv, (2021); Thapa C., Jang S.I., Ahmed M.E., Camtepe S., Pieprzyk J., Nepal S., Transformer-based language models for software vulnerability detection, Proceedings of the 38th Annual Computer Security Applications Conference, pp. 481-496; Omar M., Detecting software vulnerabilities using Language Models, arXiv, (2023); Sun Y., Wu D., Xue Y., Liu H., Wang H., Xu Z., Xie X., Liu Y., When GPT Meets Program Analysis: Towards Intelligent Detection of Smart Contract Logic Vulnerabilities in GPTScan, arXiv, (2023); Cheshkov A., Zadorozhny P., Levichev R., Evaluation of ChatGPT Model for Vulnerability Detection, arXiv, (2023); Feng S., Chen C., Prompting Is All You Need: Automated Android Bug Replay with Large Language Models, arXiv, (2023); Ferraiolo D., Cugini J., Kuhn D.R., Role-based access control (RBAC): Features and motivations, Proceedings of the 11th Annual Computer Security Application Conference, pp. 241-248; Yuan E., Tong J., Attributed based access control (ABAC) for Web services, Proceedings of the IEEE International Conference on Web Services (ICWS’05); (2023); Qiu R., Editorial: GPT revolutionizing AI applications: Empowering future digital transformation, Digit. Transform. Soc, 2, pp. 101-103, (2023); Shoeybi M., Patwary M., Puri R., LeGresley P., Casper J., Catanzaro B., Megatron-lm: Training multi-billion parameter language models using model parallelism, arXiv, (2019); Ji Z., Lee N., Frieske R., Yu T., Su D., Xu Y., Ishii E., Bang Y.J., Madotto A., Fung P., Survey of Hallucination in Natural Language Generation, ACM Comput. Surv, 55, (2023); Moghaddam S.R., Honey C.J., Boosting Theory-of-Mind Performance in Large Language Models via Prompting, arXiv, (2023); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., Language models are few-shot learners, Adv. Neural Inf. Process. Syst, 33, pp. 1877-1901, (2020); Wang X., Wei J., Schuurmans D., Le Q., Chi E., Narang S., Chowdhery A., Zhou D., Self-Consistency Improves Chain of Thought Reasoning in Language Models, arXiv, (2023); Martin R.C., Getting a SOLID Start. Robert C Martin-objectmentor.com, (2013); Kokrehel G., Bilicki V., The impact of the software architecture on the developer productivity, Pollack Period, 17, pp. 7-11, (2022)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85175167540"
"Choi Y.-H.; Liu P.; Shang Z.; Wang H.; Wang Z.; Zhang L.; Zhou J.; Zou Q.","Choi, Yoon-Ho (56532761600); Liu, Peng (36727836300); Shang, Zitong (57218584145); Wang, Haizhou (57212307447); Wang, Zhilong (57218582446); Zhang, Lan (57221585349); Zhou, Junwei (37022014400); Zou, Qingtian (57216038963)","56532761600; 36727836300; 57218584145; 57212307447; 57218582446; 57221585349; 37022014400; 57216038963","Using deep learning to solve computer security challenges: a survey","2020","Cybersecurity","3","1","15","","","","22","10.1186/s42400-020-00055-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089676959&doi=10.1186%2fs42400-020-00055-5&partnerID=40&md5=cbbd4df84cfbb51fabcfe9fb18f947f5","Although using machine learning techniques to solve computer security challenges is not a new idea, the rapidly emerging Deep Learning technology has recently triggered a substantial amount of interests in the computer security community. This paper seeks to provide a dedicated review of the very recent research works on using Deep Learning techniques to solve computer security challenges. In particular, the review covers eight computer security problems being solved by applications of Deep Learning: security-oriented program analysis, defending return-oriented programming (ROP) attacks, achieving control-flow integrity (CFI), defending network attacks, malware classification, system-event-based anomaly detection, memory forensics, and fuzzing for software security. © 2020, The Author(s).","Control-flow integrity; Deep learning; Fuzzing for software security; Malware classification; Memory forensics; Network attacks; Return-oriented programming attacks; Security-oriented program analysis; System-event-based anomaly detection","Anomaly detection; Application programs; Computer control systems; Computer systems programming; Learning systems; Malware; Security systems; Computer security problems; Control-flow integrities; Learning techniques; Learning technology; Machine learning techniques; Malware classifications; Return-oriented programming; Security challenges; Deep learning","Abadi M., Budiu M., Erlingsson U., Ligatti J., Control-Flow Integrity Principles, Implementations, and Applications, ACM Trans Inf Syst Secur (TISSEC), 13, 1, (2009); Bao T., Burket J., Woo M., Turner R., Brumley D., BYTEWEIGHT: Learning to Recognize Functions in Binary Code, 23rd USENIX Security Symposium (USENIX Security 14), pp. 845-860, (2014); Bekrar S., Bekrar C., Groz R., Mounier L., A Taint Based Approach for Smart Fuzzing, In: 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation. IEEE, (2012); Bengio Y., Courville A., Vincent P., Representation Learning: A Review and New Perspectives, IEEE Trans Pattern Anal Mach Intell, 35, 8, pp. 1798-1828, (2013); Bertero C., Roy M., Sauvanaud C., Tredan G., Experience Report: Log Mining Using Natural Language Processing and Application to Anomaly Detection, In: 2017 IEEE 28Th International Symposium on Software Reliability Engineering (ISSRE). IEEE., (2017); Brown A., Tuor A., Hutchinson B., Nichols N., Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection, Proceedings of the First Workshop on Machine Learning for Computing Systems, MLCS’18, pp. 1:1-1:8, (2018); Bottinger K., Godefroid P., Singh R., ) Deep Reinforcement Fuzzing, In: 2018 IEEE Security and Privacy Workshops (SPW), pp. 116-122, (2018); Chen L., Sultana S., Sahita R., Henet: A Deep Learning Approach on Intel Ⓡ Processor Trace for Effective Exploit Detection, In: 2018 IEEE Security and Privacy Workshops (SPW). IEEE, (2018); Chua Z.L., Shen S., Saxena P., Liang Z., Neural Nets Can Learn Function Type Signatures from Binaries, In: 26Th USENIX Security Symposium (USENIX Security 17), pp. 99-116, (2017); Cui Z., Xue F., Cai X., Cao Y., Wang G.G., Chen J., Detection of Malicious Code Variants Based on Deep Learning, IEEE Trans Ind Inform, 14, 7, pp. 3187-3196, (2018); Dahl G.E., Stokes J.W., Deng L., Yu D., Large-scale Malware Classification using Random Projections and Neural Networks, In: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE., (2013); Dai Y., Li H., Qian Y., Lu X., A Malware Classification Method Based on Memory Dump Grayscale Image, Digit Investig, 27, pp. 30-37, (2018); Das A., Mueller F., Siegel C., Vishnu A., Desh: Deep Learning for System Health Prediction of Lead Times to Failure in HPC, Proceedings of the 27th International Symposium on High-Performance Parallel and Distributed Computing, HPDC ’18, pp. 40-51, (2018); David O.E., Netanyahu N.S., DeepSign: Deep Learning for Automatic Malware Signature Generation and Classification, In: 2015 International Joint Conference on Neural Networks (IJCNN). IEEE., (2015); de La Rosa L., Kilgallon S., Vanderbruggen T., Cavazos J., Efficient Characterization and Classification of Malware Using Deep Learning, In: 2018 Resilience Week (RWS). IEEE, (2018); Du M., Li F., Spell: Streaming Parsing of System Event Logs, In: 2016 IEEE 16Th International Conference on Data Mining (ICDM). IEEE., (2016); Du M., Li F., Zheng G., Srikumar V., DeepLog: Anomaly Detection and Diagnosis from System Logs Through Deep Learning, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS ’17, pp. 1285-1298, (2017); Faker O., Dogdu E., Intrusion Detection Using Big Data and Deep Learning Techniques, Proceedings of the 2019 ACM Southeast Conference on ZZZ - ACM SE ’19, pp. 86-93, (2019); Ghosh A.K., Wanken J., Charron F., Detecting Anomalous and Unknown Intrusions against Programs, Proceedings 14th annual computer security applications conference (Cat. No. 98Ex217), pp. 259-267, (1998); Godefroid P., Peleg H., Singh R., Learn&Fuzz: Machine Learning for Input Fuzzing, 2017 32Nd IEEE/ACM International Conference on Automated Software Engineering (ASE)., (2017); Embeddings, (2016); Guo W., Mu D., Xu J., Su P., Wang G., Xing X., Lemna: Explaining deep learning based security applications, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, pp. 364-379, (2018); Guo W., Mu D., Xing X., Du M., Song D., {DEEPVSA}: Facilitating Value-set Analysis with Deep Learning for Postmortem Program Analysis, 28th USENIX Security Symposium (USENIX Security 19), pp. 1787-1804, (2019); Heller K.A., Svore K.M., Keromytis A.D., Stolfo S.J., One Class Support Vector Machines for Detecting Anomalous Windows Registry Accesses, Proceedings of the Workshop on Data Mining for Computer Security, (2003); Horwitz S., Precise Flow-insensitive May-alias Analysis is NP-hard, ACM Trans Program Lang Syst, 19, 1, pp. 1-6, (1997); Hu W., Liao Y., Vemuri V.R., Robust Anomaly Detection using Support Vector Machines, Proceedings of the international conference on machine learning, pp. 282-289, (2003); Datasets (2019), (2017); Kalash M., Rochan M., Mohammed N., Bruce N.D.B., Wang Y., Iqbal F., Malware Classification with Deep Convolutional Neural Networks, 2018 9Th IFIP International Conference on New Technologies, Mobility and Security (NTMS), pp. 1-5, (2018); Kiriansky V., Bruening D., Amarasinghe S.P., Et al., Secure Execution via Program Shepherding, USENIX Security Symposium, volume 92, page 84, (2002); Kolosnjaji B., Eraisha G., Webster G., Zarras A., Eckert C., Empowering Convolutional Networks for Malware Classification and Analysis, Proc Int Jt Conf Neural Netw, 2017-May, pp. 3838-3845, (2017); Krizhevsky A., Nair V., Hinton G., CIFAR-10 (Canadian Institute for Advanced Research), (2010); Lecun Y., Cortes C., MNIST Handwritten Digit Database, (2010); Li J., Zhao B., Zhang C., Fuzzing: A Survey, Cybersecurity, 1, 1, (2018); Li X., Hu Z., Fu Y., Chen P., Zhu M., Liu P., ROPNN: Detection of ROP Payloads Using Deep Neural Networks, (2018); McLaughlin N., Martinez Del Rincon J., Kang B.J., Yerima S., Miller P., Sezer S., Safaei Y., Trickel E., Zhao Z., Doupe A., Ahn G.J., Deep Android Malware Detection, Proceedings of the 7Th ACM Conference on Data and Application Security and Privacy, pp. 301-308, (2017); Meng W., Liu Y., Zhu Y., Zhang S., Pei D., Liu Y., Chen Y., Zhang R., Tao S., Sun P., Zhou R., Loganomaly: Unsupervised Detection of Sequential and Quantitative Anomalies in Unstructured Logs, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence. International Joint Conferences on Artificial Intelligence Organization, (2019); Michalas A., Murray R., MemTri: A Memory Forensics Triage Tool Using Bayesian Network and Volatility, Proceedings of the 2017 International Workshop on Managing Insider Security Threats, MIST ’17, pages 57–66, (2017); Millar K., Cheng A., Chew H.G., Lim C.-C., Deep Learning for Classifying Malicious Network Traffic, Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 156-161, (2018); Moustafa N., Slay J., UNSW-NB15: A Comprehensive Data Set for Network Intrusion Detection Systems (UNSW-NB15 Network Data Set), 2015 Military Communications and Information Systems Conference (Milcis)., (2015); Nguyen M.H., Nguyen D.L., Nguyen X.M., Quan T.T., Auto-Detection of Sophisticated Malware using Lazy-Binding Control Flow Graph and Deep Learning, Comput Secur, 76, pp. 128-155, (2018); Nix R., Zhang J., Classification of Android Apps and Malware using Deep Neural Networks, Proc Int Jt Conf Neural Netw, 2017-May, pp. 1871-1878, (2017); Intern Report for Congress, (2019); Petrik R., Arik B., Smith J.M., Towards Architecture and OS-Independent Malware Detection via Memory Forensics, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, pages 2267–2269, (2018); Phan A.V., Nguyen M.L., Bui L.T., Convolutional Neural Networks over Control Flow Graphs for Software defect prediction, 2017 IEEE 29Th International Conference on Tools with Artificial Intelligence (ICTAI), pp. 45-52, (2017); Rajpal M., Blum W., Singh R., Not All Bytes are Equal: Neural Byte Sieve for Fuzzing, (2017); Rosenberg I., Shabtai A., Rokach L., Elovici Y., Generic Black-box End-to-End Attack against State of the Art API Call based Malware Classifiers, Research in Attacks, Intrusions, and Defenses, pp. 490-510, (2018); Salwant J., Ropgadget, (2015); Saxe J., Berlin K., Deep Neural Network based Malware Detection using Two Dimensional Binary Program Features, In: 2015 10Th International Conference on Malicious and Unwanted Software (MALWARE). IEEE., (2015); Shacham H., Et al., The Geometry of Innocent Flesh on the Bone: Return-into-libc without Function Calls (on the x86), ACM Conference on Computer and Communications Security, pp. 552-561, (2007); Shi D., Pei K., NEUZZ: Efficient Fuzzing with Neural Program Smoothing, IEEE Secur Priv., (2019); Shin E.C.R., Song D., Moazzezi R., Recognizing Functions in Binaries with Neural Networks, In: 24Th USENIX Security Symposium (USENIX Security 15). USENIX Association, (2015); Sommer R., Paxson V., Outside the Closed World: On Using Machine Learning For Network Intrusion Detection, 2010 IEEE Symposium on Security and Privacy (S&P)., (2010); Song W., Yin H., Liu C., Song D., DeepMem: Learning Graph Neural Network Models for Fast and Robust Memory Forensic Analysis, Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, pp. 606-618, (2018); Stephens N., Grosen J., Salls C., Dutcher A., Wang R., Corbetta J., Shoshitaishvili Y., Kruegel C., Vigna G., Driller: Augmenting Fuzzing Through Selective Symbolic Execution, Proceedings 2016 Network and Distributed System Security Symposium. Internet Society, (2016); Tan G., Jaeger T., CFG Construction Soundness in Control-Flow Integrity, Proceedings of the 2017 Workshop on Programming Languages and Analysis for Security - PLAS ’17, (2017); Tobiyama S., Yamaguchi Y., Shimada H., Ikuse T., Yagi T., Malware Detection with Deep Neural Network Using Process Behavior, Proc Int Comput Softw Appl Conf, 2, pp. 577-582, (2016); Unicorn-The Ultimate CPU Emulator, (2015); Ustebay S., Turgut Z., Aydin M.A., Cyber Attack Detection by Using Neural Network Approaches: Shallow Neural Network, Deep Neural Network and Autoencoder In: Computer Networks, pp. 144-155, (2019); Varenne R., Delorme J.M., Plebani E., Pau D., Tomaselli V., Intelligent Recognition of TCP Intrusions for Embedded Micro-Controllers In: International Conference on Image Analysis and Processing, pp. 361-373, (2019); Wang Z., Liu P., GPT Conjecture: Understanding the Trade-Offs between Granularity, Performance and Timeliness in Control-Flow Integrity., (2019); Wang Y., Wu Z., Wei Q., Wang Q., NeuFuzz: Efficient Fuzzing with Deep Neural Network, IEEE Access, 7, pp. 36340-36352, (2019); Xu W., Huang L., Fox A., Patterson D., Jordan M.I., Detecting Large-Scale System Problems by Mining Console Logs, Proceedings of the ACM SIGOPS 22Nd Symposium on Operating Systems Principles SOSP ’09, pp. 117-132, (2009); Xu X., Liu C., Feng Q., Yin H., Song L., Song D., Neural Network-Based Graph Embedding for Cross-Platform Binary Code Similarity Detection, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pp. 363-376, (2017); Xu L., Zhang D., Jayasena N., Cavazos J., HADM: Hybrid Analysis for Detection of Malware, 16, pp. 702-724, (2018); Xu X., Ghaffarinia M., Wang W., Hamlen K.W., Lin Z., CONFIRM: Evaluating Compatibility and Relevance of Control-flow Integrity Protections for Modern Software, 28th USENIX Security Symposium (USENIX Security 19), pages 1805–1821, (2019); Yagemann C., Sultana S., Chen L., Lee W., Barnum: Detecting Document Malware via Control Flow Anomalies in Hardware Traces, Lecture Notes in Computer Science, pp. 341-359, (2019); Yin C., Zhu Y., Fei J., He X., A Deep Learning Approach for Intrusion Detection using Recurrent Neural Networks, IEEE Access, 5, pp. 21954-21961, (2017); Yuan X., Li C., Li X., DeepDefense: Identifying DDoS Attack via Deep Learning, 2017 IEEE International Conference on Smart Computing (SMARTCOMP)., (2017); Yun I., Lee S., Xu M., Jang Y., Kim T., QSYM: A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing, 27th USENIX Security Symposium (USENIX Security 18), pages 745–761, (2018); Zhang S., Meng W., Bu J., Yang S., Liu Y., Pei D., Xu J., Chen Y., Dong H., Qu X., Song L., Syslog Processing for Switch Failure Diagnosis and Prediction in Datacenter Networks, In: 2017 IEEE/ACM 25Th International Symposium on Quality of Service (Iwqos). IEEE, (2017); Zhang J., Chen W., Niu Y., Deepcheck: A Non-Intrusive Control-Flow Integrity Checking Based on Deep Learning, (2019); Zhang X., Xu Y., Lin Q., Qiao B., Zhang H., Dang Y., Xie C., Yang X., Cheng Q., Li Z., Chen J., He X., Yao R., Lou J.-G., Chintalapati M., Shen F., Zhang D., Robust Log-based Anomaly Detection on Unstable Log Data, Proceedings of the 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019, pages 807–817, (2019); Zhang Y., Chen X., Guo D., Song M., Teng Y., Wang X., PCCN: Parallel Cross Convolutional Neural Network for Abnormal Network Traffic Flows Detection in Multi-Class Imbalanced Network Traffic Flows, IEEE Access, 7, pp. 119904-119916, (2019)","","Springer Science and Business Media B.V.","","","","","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85089676959"
"Billion Polak P.; Prusa J.D.; Khoshgoftaar T.M.","Billion Polak, Preston (58791336200); Prusa, Joseph D. (57117743400); Khoshgoftaar, Taghi M. (7006211475)","58791336200; 57117743400; 7006211475","Low-shot learning and class imbalance: a survey","2024","Journal of Big Data","11","1","1","","","","0","10.1186/s40537-023-00851-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181239822&doi=10.1186%2fs40537-023-00851-z&partnerID=40&md5=58f10918846f69e6f1b0be2b83dc67d6","The tasks of few-shot, one-shot, and zero-shot learning—or collectively “low-shot learning” (LSL)—at first glance are quite similar to the long-standing task of class imbalanced learning; specifically, they aim to learn classes for which there is little labeled data available. Motivated by this similarity, we conduct a survey to review the recent literature for works which combine these fields in one of two ways, either addressing the obstacle of class imbalance within a LSL setting, or utilizing LSL techniques or frameworks in order to combat class imbalance within other settings. In our survey of over 60 papers in a wide range of applications from January 2020 to July 2023 (inclusive), we examine and report methodologies and experimental results, find that most works report performance at or above their respective state-of-the-art, and highlight current research gaps which hold potential for future work, especially those involving the use of LSL techniques in imbalanced tasks. To this end, we emphasize the lack of works utilizing LSL approaches based on large language models or semantic data, and works using LSL for big-data imbalanced tasks. © 2023, The Author(s).","Class imbalance; Class-imbalanced learning; Few-shot learning; Low-shot learning; Machine learning; Zero-shot learning","Learning systems; Semantics; Class imbalance; Class-imbalanced learning; Few-shot learning; Imbalanced Learning; Labeled data; Learn+; Learning techniques; Low-shot learning; Machine-learning; Standing tasks; Zero-shot learning","Leevy J.L., Khoshgoftaar T.M., Bauder R.A., Seliya N., A survey on addressing high-class imbalance in big data, J Big Data, 5, 1, (2018); Johnson J.M., Khoshgoftaar T.M., Survey on deep learning with class imbalance, J Big Data, 6, 1, (2019); Snell J., Swersky K., Zemel R., Prototypical networks for few-shot learning. In: Advances in neural information processing systems, vol. 30. Curran Associates, Inc.; 2017. https://proceedings.neurips.cc/paper_files/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html. Accessed 30 June 2023.; Finn C., Abbeel P., Levine S., Model-agnostic meta-learning for fast adaptation of deep networks, Proceedings of the 34Th International Conference on Machine Learning. PMLR; 2017. ISSN: 2640-3498. P., pp. 1126-1135, (2023); Xian Y., Schiele B., Akata Z., Zero-shot learning—the good, the bad and the ugly; 2017. P. 4582–91. https://openaccess.thecvf.com/content_cvpr_2017/html/Xian_Zero-Shot_Learning_-_CVPR_2017_paper.html. Accessed 23 Oct 2023.; Chen Z., Huang Y., Chen J., Geng Y., Zhang W., Fang Y., Pan J.Z., Chen H.D.U.E.T., Cross-modal semantic grounding for contrastive zero-shot learning. In: Proceedings of the AAAI conference on artificial intelligence. 2023;37(1):405–13. https://doi.org/10.1609/aaai.v37i1.25114. Number: 1. Accessed 24 Aug 2023.; Sussman G.J., Yip K., Sparse representations for fast, one-shot learning, AI Memos, (1997); Triantafillou E., Zemel R., Urtasun R., Few-shot learning through an information retrieval lens. In: Advances in neural information processing systems, vol. 30. Curran Associates, Inc.; 2017.; Parnami A., Lee M., Learning from Few Examples: A Summary of Approaches to Few-Shot Learning, 2022, (2023); Bromley J., Guyon I., Lecun Y., Sackinger E., Shah R., Signature Verification using a “Siamese” time delay neural network, Advances in Neural Information Processing Systems, 6, (1993); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language models are few-shot learners, Adv Neural Inf Process Syst, 33, pp. 1877-1901, (2020); Tax D.M.J., One-Class Classification: Concept Learning in the Absence of Counter-Examples, (2002); Zhai X., Wang X., Mustafa B., Steiner A., Keysers D., Kolesnikov A., Beyer L., Lit: Zero-Shot Transfer with Locked-Image Text Tuning; 2022, pp. 18123-18133, (2023); van Hulse J., Khoshgoftaar T.M., Napolitano A., Experimental perspectives on learning from imbalanced data, Proceedings of the 24Th International Conference on Machine Learning. ICML ’07, pp. 935-942, (2007); He H., Garcia E.A., Learning from imbalanced data, IEEE Trans Knowl Data Eng., 21, 9, pp. 1263-1284, (2009); Ochal M., Patacchiola M., Vazquez J., Storkey A., Wang S., Few-shot learning with class imbalance, IEEE Trans Artif Intell, (2023); Zhou J., Li B., Wang P., Li P., Gan W., Wu W., Yan J.W., Real-time visual object tracking via few-shot learning; 2021; Zhang Z., Zhoa J., Liang X., Zero-shot learning based on semantic embedding for ship detection, 3Rd International Conference on Unmanned Systems (ICUS). IEEE; 2020. P, pp. 1152-1156, (2020); Rahman S., Khan S., Barnes N., Improved visual-semantic alignment for zero-shot object detection, In: Proceedings of the AAAI Conference on Artificial Intelligence, 34, pp. 11932-11939, (2020); Gao Y., Hou R., Gao Q., Hou Y., A fast and accurate few-shot detector for objects with fewer pixels in drone image, Electronics, 10, 7, (2021); Wolters P., Daw C., Hutchinson B., Phillips L., Proposal-Based Few-Shot Sound Event Detection for Speech and Environmental Sounds with Perceivers; Huang K., Geng J., Jiang W., Deng X., Xu Z., Pseudo-loss confidence metric for semi-supervised few-shot learning, Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 8671-8680, (2021); Yang H., Cai S., Sheng H., Deng B., Huang J., Hua X.-S., Tang Y., Zhang Y., Balanced and hierarchical relation learning for one-shot object detection, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 7591-7600; Liu T., Yang Y., Fan W., Wu C., Few-shot learning for cardiac arrhythmia detection based on electrocardiogram data from wearable devices, Dig Signal Process, 116, (2021); Olah J., Baruah S., Bose D., Narayanan S. Cross Domain Emotion Recognition Using Few Shot Knowledge Transfer; 2021. Arxiv Preprint Arxiv; Zhang L., Zhou S., Guan J., Zhang J.; Ma S., Li X., Tang J., Guo F., A zero-shot method for 3d medical image segmentation, IEEE International Conference on Multimedia and Expo (ICME). IEEE, 202, pp. 1-6, (2021); Masihullah S., Garg R., Mukherjee P., Ray A., Attention based coupled framework for road and pothole segmentation, 2020 25Th International Conference on Pattern Recognition (ICPR). IEEE, pp. 5812-5819, (2021); Hua Y., Yi D., Synthetic to realistic imbalanced domain adaption for urban scene perception, IEEE Trans Ind Inform, 18, 5, pp. 3248-3255, (2021); Yuan Y., Chen W., Chen T., Yang Y., Ren Z., Wang Z., Hua G., Calibrated domain-invariant learning for highly generalizable large scale re-identification, In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2020, pp. 3589-3598; Zhang L., Zhang C., Quan S., Xiao H., Kuang G., Liu L., A class imbalance loss for imbalanced object recognition, IEEE J Select Top Appl Earth Obs Remote Sens, 13, pp. 2778-2792, (2020); Li Q., Zhang Y., Sun S., Zhao X., Li K., Tan M., Rethinking semantic-visual alignment in zero-shot object detection via a softplus margin focal loss, Neurocomputing, 449, pp. 117-135, (2021); Olson A.W., Cucu A., Bock T. Multi-Class Zero-Shot Learning for Artistic Material Recognition; 2020. Arxiv Preprint Arxiv, (2010); Wu C., Wang B., Liu S., Liu X., Wu P., TD-sampler: Learning a training difficulty based sampling strategy for few-shot object detection, 7Th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA). IEEE; 2022. P, pp. 275-279, (2022); Chen R., Chen T., Hui X., Wu H., Li G., Lin L., Knowledge graph transfer network for few-shot recognition. In: Proceedings of the AAAI conference on artificial intelligence, vol. 34; 2020. p. 10575–82.; Malik V., Kumar A., Veppa J. Exploring the Limits of Natural Language Inference Based Setup for Few-Shot Intent Detection; 2021. Arxiv Preprint Arxiv; Li G., Zhai Y., Chen Q., Gao X., Zhang J., Zhang Y., Continual few-shot intent detection, Proceedings of the 29Th International Conference on Computational Linguistics, 2022, pp. 333-343; Veilleux O., Boudiaf M., Piantanida P., Ben Ayed I., Realistic evaluation of transductive few-shot learning, Adv Neural Inf Process Syst, 34, pp. 9290-9302, (2021); Hess S., Ditzler G., A Maximum Log-Likelihood Method for Imbalanced Few-Shot Learning Tasks, 2022; Tao R., Chen H., Savvides M., Towards Class-Balanced Transductive Few-Shot Learning, 2022; Wertheimer D., Tang L., Baijal D., Mittal P., Talwar A., Hariharan B., Few-Shot Learning in Long-Tailed Settings; Wang Y., Yu Z., Wang J., Heng Q., Chen H., Ye W., Xie R., Xie X., Zhang S., Exploring vision-language models for imbalanced learning, (2023); Deng L., He C., Xu G., Zhu H., Wang H., PcGAN: a noise robust conditional generative adversarial network for one shot learning, IEEE Trans Intell Transp Syst, 23, 12, pp. 25249-25258, (2022); He C., Wang R., Chen X., A tale of two CILs: The connections between class incremental learning and class imbalanced learning, and beyond, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3559-3569, (2021); Smith L.N., Conovaloff A., Building one-shot semi-supervised (BOSS) learning up to fully supervised performance, Front Artif Intell, 5, (2022); Arfeen A., Dutta T., Biswas S., Handling Class-Imbalance for Improved Zero-Shot Domain Generalization. BMVC, (2022); Ji Z., Yu X., Yu Y., Pang Y., Zhang Z., Semantic-guided class-imbalance learning model for zero-shot image classification, IEEE Trans Cybernetics, 52, 7, pp. 6543-6554, (2021); Ye C., Barnes N., Petersson L., Tsuchida R., Efficient Gaussian process model on class-imbalanced datasets for generalized zero-shot learning, 26Th International Conference on Pattern Recognition (ICPR). IEEE; 2022. P, pp. 2078-2085, (2022); Majee A., Agrawal K., Subramanian A., Few-shot learning for road object detection, AAAI Workshop on Meta-Learning and Metadl Challenge. PMLR; 2021, pp. 115-126; Agarwal A., Majee A., Subramanian A., Arora C., Attention guided cosine margin for overcoming class-imbalance in few-shot road object detection, (2022); Huang X., He B., Tong M., Wang D., He C., Few-shot object detection on remote sensing images via shared attention module and balanced fine-tuning strategy, Remote Sens, 13, 19, (2021); Wang Y., Xu C., Liu C., Li Z., Context information refinement for few-shot object detection in remote sensing images, Remote Sens, 14, 14, (2022); Ouyang C., Biffi C., Chen C., Kart T., Qiu H., Rueckert D., Self-supervision with superpixels: Training few-shot medical image segmentation without annotation. In: Computer vision-ECCV 2020: 16th European conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXIX 16. Springer; 2020. p. 762–80.; Dutta T., Singh A., Biswas S., Adaptive margin diversity regularizer for handling data imbalance in zero-shot sbir. In: Proceedings, Part V 16, computer vision-ECCV 2020: 16th European conference, Glasgow, UK, August 23–28. Springer; 2020. p. 349–64.; Wu G., Gong S., Generalising without forgetting for lifelong person re-identification, Proceedings of the AAAI conference on artificial intelligence, 35, pp. 2889-2897, (2021); Chen Z., Ma W., Xu N., Ji C., Zhang Y., SiameseCCR: a novel method for one-shot and few-shot Chinese CAPTCHA recognition using deep Siamese network, IET Image Process, 14, 12, pp. 2855-2859, (2020); Wang Y., Wei Y., Zhang Y., Jin C., Xin G., Wang B., Few-shot learning in realistic settings for text CAPTCHA recognition, Neural Comput Appl, 35, 15, pp. 10751-10764, (2023); Lei W., Su Q., Jiang T., Gu R., Wang N., Liu X., Wang G., Zhang X., Zhang S., One-shot weakly-supervised segmentation in 3D medical images, IEEE Trans Med Imaging, (2023); Cui H., Wei D., Ma K., Gu S., Zheng Y., A unified framework for generalized low-shot medical image segmentation with scarce data, IEEE Trans Med Imaging, 40, 10, pp. 2656-2671, (2020); Bragg J., Cohan A., Lo K., Beltagy I., Flex: unifying evaluation for few-shot nlp, Adv Neural Inf Process Syst, 34, pp. 15787-15800, (2021); Kim M., Yang Y., Ryu J.H., Kim T., Meta-learning with adaptive weighted loss for imbalanced cold-start recommendation, (2023); Yu T., Guo H., Zhu Y., Center loss guided prototypical networks for unbalance few-shot industrial fault diagnosis. Mobile information systems, (2022); Li K., Shang C., Ye H., Reweighted regularized prototypical network for few-shot fault diagnosis, IEEE Trans Neural Netw Learn Syst, (2022); Vinyals O., Blundell C., Lillicrap T., Kavukcuoglu K W.D., Matching networks for one shot learning, Advances in Neural Information Processing Systems, 29, (2016); Wah C., Branson S., Welinder P., Perona P., Belongie S., The Caltech-Ucsd Birds-200-2011 Dataset; Chen W.-Y., Liu Y.-C., Kira Z., Wang Y.-C., Huang J.-B., A Closer Look at Few-Shot Classification, (2018); Hu Y., Gripon V., Pateux S., Leveraging the feature distribution in transfer-based few-shot learning; 2021. ArXiv. arXiv:2006.03806 [cs, stat]. http://arxiv.org/abs/2006.03806. Accessed 10 May 2023.; Boudiaf M., Masud Z.I., Rony J., Dolz J., Piantanida P., Ayed I.B., Transductive information maximization for few-shot learning; 2020. ArXiv. arXiv:2008.11297 [cs, stat]. http://arxiv.org/abs/2008.11297. Accessed 10 May 2023.; Ren M., Triantafillou E., Ravi S., Snell J., Swersky K., Tenenbaum J.B., Larochelle H., Zemel R.S., Meta-Learning for Semi-Supervised Few-Shot Classification, (2018); Ziko I., Dolz J., Granger E., Ayed I.B., Laplacian regularized few-shot learning, International Conference on Machine Learning. PMLR; 2020, pp. 11660-11670; Triantafillou E., Zhu T., Dumoulin V., Lamblin P., Evci U., Xu K., Goroshin R., Gelada C., Swersky K., Manzagol P.-A., Larochelle H., Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples, (2019); Wertheimer D., Hariharan B., Few-shot learning with localization in realistic settings. In: 2019 IEEE/CVF conference on computer vision and pattern recognition (CVPR); 2019. p. 6551–60. https://doi.org/10.1109/CVPR.2019.00672. ISSN: 2575-7075.; van Horn G., Mac Aodha O., Song Y., Cui Y., Sun C., Shepard A., Adam H., Perona P., Belongie S., The Inaturalist Species Classification and Detection Dataset, pp. 8769-8778, (2018); Radford A., Kim J.W., Hallacy C., Ramesh A., Goh G., Agarwal S., Sastry G., Askell A., Mishkin P., Clark J., Krueger G., Sutskever I., Learning transferable visual models from natural language supervision; 2021. ArXiv. arXiv:2103.00020 [cs]. https://doi.org/10.48550/arXiv.2103.00020. http://arxiv.org/abs/2103.00020. Accessed 04 Sept 2023.; Zhang S., Li Z., Yan S., He X., Sun J., Distribution Alignment: A Unified Framework for Long-Tail Visual Recognition, pp. 2361-2370, (2021); Liu Z., Miao Z., Zhan X., Wang J., Gong B., Yu S.X., Large-Scale Long-Tailed Recognition in an Open World, pp. 2537-2546, (2019); Krizhevsky A., Learning Multiple Layers of Features from Tiny Images, (2009); Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L., ImageNet: A large-scale hierarchical image database. In: 2009 IEEE conference on computer vision and pattern recognition; 2009. p. 248–55. https://doi.org/10.1109/CVPR.2009.5206848. ISSN: 1063-6919.; Netzer Y., Wang T., Coates A., Bissacco A., Wu B., Ng A.Y., Reading digits in natural images with unsupervised feature learning, NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011, (2011); Peng X., Bai Q., Xia X., Huang Z., Saenko K., Wang B., Moment matching for multi-source domain adaptation; 2019. P. 1406–15. https://openaccess.thecvf.com/content_ICCV_2019/html/Peng_Moment_Matching_for_Multi-Source:Domain_Adaptation_ICCV_2019_paper.html. Accessed 19 July 2023.; Xiao J., Hays J., Ehinger K.A., Oliva A., Torralba A. SUN database: large-scale scene recognition from abbey to zoo. In: 2010 IEEE computer society conference on computer vision and pattern recognition; 2010. p. 3485–92.; Xian Y., Lampert C.H., Schiele B., Akata Z., Zero-shot learning-a comprehensive evaluation of the good, the bad and the ugly, IEEE Trans Pattern Anal Mach Intell, 41, 9, pp. 2251-2265, (2019); Skorokhodov I., Elhoseiny M., Class normalization for (Continual)? Generalized zero-shot learning; 2021. arXiv. arXiv:2006.11328 [cs, stat].; Varma G., Subramanian A., Namboodiri A., Chandraker M., Jawahar C.V.I.D.D., A dataset for exploring problems of autonomous navigation in unconstrained environments. In: 2019 IEEE winter conference on applications of computer vision (WACV); 2019. p. 1743–51; Wang X., Huang T.E., Darrell T., Gonzalez J.E., Yu F. Frustratingly simple few-shot object detection; 2020. arXiv. arXiv:2003.06957 [cs].; Everingham M., Van Gool L., Williams C.K.I., Winn J., Zisserman A., The pascal visual object classes (VOC) challenge, Int J Comput Vis, 88, 2, pp. 303-338, (2010); Cheng G., Han J., Zhou P., Guo L., Multi-class geospatial object detection and geographic image classification based on collection of part detectors, ISPRS J Photogrammetry Remote Sens, 98, pp. 119-132, (2014); Li K., Wan G., Cheng G., Meng L., Han J., Object detection in optical remote sensing images: A survey and a new benchmark, ISPRS J Photogrammetry Remote Sens, 159, pp. 296-307, (2020); Wang K., Liew J.H., Zou Y., Zhou D., Feng J., PANet: Few-shot image semantic segmentation with prototype alignment. In: 2019 IEEE/CVF international conference on computer vision (ICCV); 2019. p. 9196–205; Shrivastava A., Gupta A., Girshick R., Training Region-Based Object Detectors with Online Hard Example Mining, pp. 761-769, (2016); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Medical Image Computing and Computer-Assisted intervention—MICCAI 2015. Lecture Notes in Computer Science, pp. 234-241, (2015); Khashabi D., Min S., Khot T., Sabharwal A., Tafjord O., Clark P., Hajishirzi H.U.N.I.F.I.E.D.Q.A., Crossing format boundaries with a single qa system. In: findings of the association for computational linguistics: EMNLP. Association for Computational Linguistics, Online 2020; 2020. p. 1896–907. https://doi.org/10.18653/v1/2020.findings-emnlp.171.; Duan R., Li D., Tong Q., Yang T., Liu X., Liu X., A survey of few-shot learning: an effective method for intrusion detection. Security and communication networks, (2021); Bansal A., Goldblum M., Cherepanova V., Schwarzschild A., Bruss C.B., Goldstein T. Metabalance: High-Performance Neural Networks for Class-Imbalanced Data; 2021. Arxiv Preprint Arxiv; Zhu L., Yang Y., Inflated episodic memory with region self-attention for long-tailed visual recognition, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4344-4353, (2020); Samuel D., Atzmon Y., Chechik G., From generalized zero-shot learning to long-tail with class descriptors, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 286-295, (2021); Patra A., Noble J.A., Hierarchical class incremental learning of anatomical structures in fetal echocardiography videos, IEEE J Biomed Health Inform, 24, 4, pp. 1046-1058, (2020); Guan J., Liu J., Sun J., Feng P., Shuai T., Wang W., Meta metric learning for highly imbalanced aerial scene classification. In: ICASSP 2020-2020 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE; 2020. p. 4047–51; Weng W.-H., Deaton J., Natarajan V., Elsayed G.F., Liu Y., Addressing the real-world class imbalance problem in dermatology, Machine learning for health, pp. 415-429, (2020); Dong N., Kampffmeyer M., Voiculescu I., Learning underrepresented classes from decentralized partially labeled medical images, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, pp. 67-76, (2022); Pei Z., Jiang H., Li X., Zhang J., Liu S., Data augmentation for rolling bearing fault diagnosis using an enhanced few-shot Wasserstein auto-encoder with meta-learning, Meas Sci Technol, 32, 8, (2021); Liu X., Gao W., Li R., Xiong Y., Tang X., Chen S., One shot ancient character recognition with siamese similarity network, Sci Rep, 12, 1, (2022); Cui Z., Wang Q., Guo J., Lu N., Few-shot classification of façade defects based on extensible classifier and contrastive learning, Autom Constr, 141, (2022); Sumer O., Hellmann F., Hustinx A., Hsieh T.-C., Andre E., Krawitz P., Few-shot meta-learning for recognizing facial phenotypes of genetic disorders, Stud Health Technol Inform, 302, pp. 932-936, (2023); Zhan Z., Zhou J., Xu B., Fabric defect classification using prototypical network of few-shot learning algorithm, Comput Ind, 138, (2022); Tambwekar A., Agrawal K., Majee A., Subramanian A., Few-shot batch incremental road object detection via detector fusion, Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 3070-3077, (2021); Tian Y., Maicas G., Pu L.Z.C.T., Singh R., Verjans J.W., Carneiro G., Few-shot anomaly detection for polyp frames from colonoscopy. In: Medical image computing and computer assisted intervention-MICCAI 2020:, Lima, Peru, October 4-8, 2020, Proceedings, Part VI 23. Springer; 2020. p. 274–84.; Ji Z., Liu X., Pang Y., Ouyang W., Li X., Few-shot human-object interaction recognition with Semantic-guided attentive prototypes network, IEEE Trans Image Process Publ IEEE Signal Process Soc, 30, pp. 1648-1661, (2021); Sharma R., Sharma G., Pattanaik M., A few shot learning based approach for hardware trojan detection using deep siamese cnn, 34Th International Conference on VLSI Design and 2021 20Th International Conference on Embedded Systems (VLSID). IEEE; 2021. P, pp. 163-168, (2021); Hu X., Jiang Y., Tang K., Chen J., Miao C., Zhang H., Learning to segment the tail, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 14045-14054, (2020); Chen X., Zheng X., Sun K., Liu W., Zhang Y., Self-supervised vision transformer-based few-shot learning for facial expression recognition, Inf Sci, 634, pp. 206-226, (2023); He C., Zhang J., Yao J., Zhuo L., Tian Q., Meta-Learning Paradigm and CosAttn for Streamer Action Recognition in Live Video, IEEE Signal Process Lett, 29, pp. 1097-1101, (2022); Romanov S., Song H., Valstar M., Sharkey D., Henry C., Triguero I., Torres M.T., Few-shot learning for postnatal gestational age estimation, International Joint Conference on Neural Networks (IJCNN). IEEE, 202, pp. 1-8, (2021); Shi Y., Li J., Li Y., Du Q., Sensor-independent hyperspectral target detection with semisupervised domain adaptive few-shot learning, IEEE Trans Geosci Remote Sens, 59, 8, pp. 6894-6906, (2020); Bedi P., Gupta N., Jindal V., I-SiamIDS: an improved Siam-IDS for handling class imbalance in network-based intrusion detection systems, Appl Intell, 51, pp. 1133-1151, (2021); Huang S., Liu Y., Fung C., An W., He R., Zhao Y., Yang H., Luan Z. A gated few-shot learning model for anomaly detection. In: 2020 international conference on information networking (ICOIN); 2020. p. 505–9; Gesi J., Li J., Ahmed I., An empirical examination of the impact of bias on just-in-time defect prediction, Proceedings of the 15Th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM); 2021, pp. 1-12; Wu X., Wang N., Detecting errors with zero-shot learning, Entropy (Basel, Switzerland), 24, 7, (2022); Li M., Zhang Y., Han D., Zhou M., Meta-IP: An imbalanced processing model based on meta-learning for IT project extension forecasts, Mathematical Problems in Engineering, (2022); Chen X., Zhang C., Lin G., Han J., Compositional prototype network with multi-view comparision for few-shot point cloud semantic segmentation; 2020. ArXiv preprint arXiv:2012.14255; Gao A., Mei F., Zheng J., Sha H., Guo M., Xie Y., Electricity theft detection based on contrastive learning and non-intrusive load monitoring, IEEE Trans Smart Grid, (2023); Gupta P., Bhaskarpandit S., Gupta M., Similarity Learning based few shot learning for ECG time series classification, Digital Image Computing: Techniques and Applications (DICTA). IEEE, 202, pp. 1-8, (2021); Bhosale S., Tiwari U., Chakraborty R., Kopparapu S.K., Contrastive learning of cough descriptors for automatic COVID-19 preliminary diagnosis, Interspeech, (2021); Renteria S., Vallejo E.E., Taylor C.E., Birdsong phrase verification and classification using siamese neural networks. BioRxiv, Cold Spring Harbor Laboratory, pp. 2021-2103, (2021); Sunder V., Fosler-Lussier E. Handling class imbalance in low-resource dialogue systems by combining few-shot classification and interpolation. In: ICASSP 2021-2021 IEEE international conference on acoustics, speech and signal processing (ICASSP), IEEE, 2021, pp. 7633-7637; Fernandez-Llaneza D., Ulander S., Gogishvili D., Nittinger E., Zhao H., Tyrchan C., Siamese Recurrent neural network with a self-attention mechanism for bioactivity prediction, ACS Omega, 6, 16, pp. 11086-11094, (2021); Wenjuan G., Zhang Y., Wang W., Cheng P., Sabate J.G., Meta-MMFNet: Meta-learning based multi-model fusion network for micro-expression recognition. ACM transactions on multimedia computing, communications and applications, Association for Computing Machinery (ACM), (2022); Patil S., Ravindran B., Predicting software defect type using concept-based classification, Empir Softw Eng, 25, 2, pp. 1341-1378, (2020); Tolstikhin I., Bousquet O., Gelly S., Schoelkopf B., Wasserstein auto-encoders; 2019. ArXiv. arXiv:1711.01558 [cs, stat].; Nichol A., Achiam J., Schulman J., On first-order meta-learning algorithms; 2018. ArXiv. arXiv:1803.02999 [cs].; Deng J., Guo J., Xue N., Zafeiriou S., Arcface: Additive Angular Margin Loss for Deep Face Recognition, pp. 4690-4699, (2019); Fan Q., Zhuo W., Tang C.-K., Tai Y.-W., Few-shot object detection with attention-rpn and multi-relation detector; 2020. ArXiv. arXiv:1908.01998 [cs]. https://doi.org/10.48550/arXiv.1908.01998.; Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards real-time object detection with region proposal networks; 2016. arXiv. arXiv:1506.01497 [cs]. https://doi.org/10.48550/arXiv.1506.01497. http://arxiv.org/abs/1506.01497. Accessed 18 June 2023.; Lin T.-Y., Maire M., Belongie S., Hays J., Perona P., Ramanan D., Dollar P., Zitnick C.L., Microsoft COCO: common objects in context, Computer vision–ECCV 2014 Lecture notes in computer science, pp. 740-755, (2014); Gupta A., Dollar P., Girshick R., LVIS: A Dataset for Large Vocabulary Instance Segmentation, pp. 5356-5364, (2019); Liu Z., Luo P., Wang X., Tang X., Deep learning face attributes in the wild, Proceedings of International Conference on Computer Vision (ICCV), (2015); Bedi P., Gupta N., Jindal V., Siam-IDS: handling class imbalance problem in intrusion detection systems using siamese neural network, Procedia Comput Sci, 171, pp. 780-789, (2020); Tavallaee M., Bagheri E., Lu W., Ghorbani AA. A detailed analysis of the KDD CUP 99 data set. In: 2009 IEEE symposium on computational intelligence for security and defense applications; 2009. p. 1–6. https://doi.org/10.1109/CISDA.2009.5356528. ISSN: 2329-6275; Hoang T., Khanh Dam H., Kamei Y., Lo D., Ubayashi N., DeepJIT: An end-to-end deep learning framework for just-in-time defect prediction. In: 2019 IEEE/ACM 16th international conference on mining software repositories (MSR); 2019. p. 34–45. https://doi.org/10.1109/MSR.2019.00016. ISSN: 2574-3864.; Heidari A., McGrath J., Ilyas I.F., Rekatsinas T., HoloDetect: Few-shot learning for error detection, Proceedings of the 2019 International Conference on Management of Data. SIGMOD ’19, pp. 829-846, (2019); Seliya N., Abdollah Zadeh A., Khoshgoftaar T.M., A literature review on one-class classification and its potential applications in big data, J Big Data, 8, 1, (2021); Navigli R., Word sense disambiguation: a survey, ACM Comput Surv, 41, 2, pp. 10-11069, (2009)","","Springer Nature","","","","","","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85181239822"
"Li H.; Gao Q.; Zhang S.","Li, Haiyang (58725782000); Gao, Qing (57020563800); Zhang, Shikun (7409376421)","58725782000; 57020563800; 7409376421","Assessing and Improving Dataset and Evaluation Methodology in Deep Learning for Code Clone Detection","2023","Proceedings - International Symposium on Software Reliability Engineering, ISSRE","","","","497","508","11","0","10.1109/ISSRE59848.2023.00044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178051285&doi=10.1109%2fISSRE59848.2023.00044&partnerID=40&md5=8845f6b555a7b3bda49d5f08cd988824","Code clone detection is a task that identifies whether two code snippets are semantically identical. In recent years, deep learning models have shown high performance in detecting Type-3 and Type-4 code clones, and received increasing attention from the research community. However, compared with the attention given to the model design by the researchers, there is little research work on the quality of the datasets and the evaluation methodology (the way of dividing the dataset into training set and test set), which poses a challenge to the credibility of deep learning models.In this paper, we conduct experiments to evaluate the performance of the existing state-of-the-art models in multi-perspectives. At the same time, we release two new datasets for code clone detection, namely ConBigCloneBench and Google-CodeJam2 based on the existing datasets BigCloneBench and GoogleCodeJam, respectively. Our experiments show that the performance of the same model decreases up to 0.5 F1 score (from 0.9 to 0.4) on different evaluation perspectives and datasets, and the performance of some models is only similar to the simple MLP model. We analyze reasons for the performance decline further, and provide suggestions for future research to improve the performance of deep learning models from multi-perspectives.  © 2023 IEEE.","code clone detection; datasets; evaluation method; neural networks","Cloning; Codes (symbols); Learning systems; Network coding; Quality control; Statistical tests; Code clone; Code clone detection; Dataset; Evaluation methodologies; Evaluation methods; Learning models; Multi-perspective; Neural-networks; Performance; Research communities; Deep learning","Roy C.K., Cordy J.R., A mutation/injection-based automatic framework for evaluating code clone detection tools, 2009 International Conference on Software Testing, Verification, and Validation Workshops, pp. 157-166, (2009); Mondal M., Rahman M.S., Roy C.K., Schneider K.A., Is cloned code really stable, Empirical Software Engineering, 23, 2, pp. 693-770, (2018); Mondal M., Roy C.K., Schneider K.A., Does cloned code increase maintenance effort, 2017 IEEE 11th International Workshop on Software Clones (IWSC), pp. 1-7, (2017); Bettenburg N., Shang W., Ibrahim W., Adams B., Zou Y., Hassan A.E., An empirical study on inconsistent changes to code clones at release level, 2009 16th Working Conference on Reverse Engineering, pp. 85-94, (2009); Roy C., Cordy J., A survey on software clone detection research, School of Computing TR 2007-541, 01, (2007); Wang P., Svajlenko J., Wu Y., Xu Y., Roy C.K., Ccaligner: A token based large-gap clone detector, Proceedings of the 40th International Conference on Software Engineering, pp. 1066-1077, (2018); Kamiya T., Kusumoto S., Inoue K., Ccfinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pp. 1157-1168, (2016); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)., pp. 783-794, (2019); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. Melbourne, Australia: International Joint Conferences on Artificial Intelligence Organization, pp. 3034-3040, (2017); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 261-271, (2020); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC), pp. 70-80, (2019); Lei M., Li H., Li J., Aundhkar N., Kim D.-K., Deep learning application on code clone detection: A review of current knowledge, Journal of Systems and Software, 184, (2022); Yu H., Hu X., Li G., Li Y., Wang Q., Xie T., Assessing and improving an evaluation dataset for detecting semantic code clones via deep learning, ACM Transactions on Software Engineering and Methodology, 31, 4, pp. 621-6225, (2022); Krinke J., Ragkhitwetsagul C., Bigclonebench considered harmful for machine learning, 2022 IEEE 16th International Workshop on Software Clones (IWSC), pp. 1-7, (2022); LeClair A., McMillan C., Recommendations for datasets for source code summarization, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)., pp. 3931-3937, (2019); Nie P., Zhang J., Li J.J., Mooney R., Gligoric M., Impact of evaluation methodologies on code summarization, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)., pp. 4936-4960, (2022); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Transactions on Software Engineering, 46, 12, pp. 1267-1293, (2020); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M.M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution., pp. 476-480, (2014); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI conference on artificial intelligence, (2016); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2020); Svajlenko J., Roy C.K., Evaluating clone detection tools with bigclonebench, 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME), pp. 131-140, (2015); Ijadataset 2. 0, (2013); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data flow, (2021); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., Unixcoder: Unified cross-modal pre-training for code representation, (2022); Li G., Wu Y., Roy C.K., Sun J., Peng X., Zhan N., Hu B., Ma J., Saga: Efficient and large-scale detection of near-miss clones with GPU acceleration, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 272-283, (2020); Koschke R., Falke R., Frenzel P., Clone detection using abstract syntax suffix trees, pp. 253-262, (2006); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, 2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 87-98, (2016); Buch L., Andrzejak A., Learning-based recursive aggregation of abstract syntax trees for code clone detection, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)., pp. 95-104, (2019); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: detection of clones in the twilight zone, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 354-365, (2018); Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., Clcdsa: Cross language code clone detection using syntactical features and api documentation, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)., pp. 1026-1037, (2019); Fang C., Liu Z., Shi Y., Huang J., Shi Q., Functional code clone detection with syntax and semantics fusion learning, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2020., pp. 516-527, (2020); Zhao G., Huang J., Deepsim: deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering., pp. 141-151, (2018); Liu J., Zeng J., Wang X., Liang Z., Learning graph-based code representations for source-level functional similarity detection; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020., pp. 1536-1547, (2020); Zeng Z., Tan H., Zhang H., Li J., Zhang Y., Zhang L., An extensive study on pre-trained models for program understanding and generation, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis., pp. 39-51, (2022); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F.P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W.H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating large language models trained on code, (2021); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S.K., Fu S., Liu S., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Siow J.K., Liu S., Xie X., Meng G., Liu Y., Learning program semantics with code representations: An empirical study, (2022); Bender E.M., Gebru T., McMillan-Major A., Shmitchell S., On the dangers of stochastic parrots: Can language models be too big, Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, ser. FAccT '21, pp. 610-623, (2021)","","IEEE Computer Society","IEEE; IEEE Computer Society; IEEE Computer Society Technical Committee on Software Engineering (TCSE); IEEE Reliability Society; RESTART","34th IEEE International Symposium on Software Reliability Engineering, ISSRE 2023","9 October 2023 through 12 October 2023","Florence","194273","Conference paper","Final","","Scopus","2-s2.0-85178051285"
"Wang T.; Chen Z.","Wang, Tianyu (58886423200); Chen, Zhixiong (57219151682)","58886423200; 57219151682","Analyzing Code Text Strings for Code Evaluation","2023","Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023","","","","5619","5628","9","0","10.1109/BigData59044.2023.10386406","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184979868&doi=10.1109%2fBigData59044.2023.10386406&partnerID=40&md5=18ec288f1a4e9e14ba692573a491005b","This paper presents a comprehensive investigation into the collection and organization of the LeetCode 70K human-submitted dataset, aimed at providing a valuable resource for assessing code quality, encompassing correctness and performance considerations. We introduce methods for effective code evaluation and annotation, resulting in a labeled dataset. We compare the performance of two widely used deep learning models, Long Short-Term Memory (LSTM) and Bidirectional Encoder Representations from Transformers (BERT), for classification. The BERT model demonstrates exceptional performance, positioning it as a reliable classifier for code quality assessment. Beyond classification, our research advances by constructing and evaluating the dataset using regression models to establish a code quality score, a comprehensive metric for intrinsic code assessment. This score offers insights into code quality and efficiency, informing coding practices without even executing code. Importantly, the implications of the code quality score extend beyond code evaluation, identifying and addressing code security issues. Leveraging the code quality score enhances vulnerability detection, fortifying software against cyber threats. The amalgamation of AI-driven code assessment and cybersecurity marks a pivotal advancement, shaping robust and secure software development practices. Our research underscores the pivotal role of AI-human cooperation in software development's future and cybersecurity landscape.  © 2023 IEEE.","code annotation; code assessment; code security; deep learning; nature language processing; software assurance","","Chen M., Et al., Evaluating large language models trained on code, (2021); Austin J., Et al., Program synthesis with large language models, (2021); Wei J., Et al., Chain-of-thought prompting elicits reasoning in large language models, Advances in Neural Information Processing Systems, 35, pp. 24824-24837, (2022); Sel B., Al-Tawaha A., Khattar V., Wang L., Jia R., Jin M., Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models, (2023); Tufano M., Et al., When and why your code starts to smell bad, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 403-414, (2015); Li Y., Et al., Competition-level code generation with alphacode, Science, 378, 6624, pp. 1092-1097, (2022); Hendrycks D., Et al., Measuring coding challenge competence with apps, (2021); Ren S., Et al., Codebleu: A method for automatic evaluation of code synthesis, (2020); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., De Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, 2018 ieee 25th international conference on software analysis, evolution and reengineering (saner), pp. 612-621, (2018); Hanif H., Nasir M.H.N.M., Ab Razak M.F., Firdaus A., Anuar N.B., The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches, Journal of Network and Computer Applications, 179, (2021); Ucci D., Aniello L., Baldoni R., Survey of machine learning techniques for malware analysis, Computers & Security, 81, pp. 123-147, (2019); Jie G., Xiao-Hui K., Qiang L., Survey on software vulnerability analysis method based on machine learning, 2016 IEEE first international conference on data science in cyberspace (DSC), pp. 642-647, (2016); Sharma T., Kechagia M., Georgiou S., Tiwari R., Sarro F., A survey on machine learning techniques for source code analysis, (2021); Heo K., Oh H., Yi K., Machine-learning-guided selectively unsound static analysis, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), pp. 519-529, (2017); Ribeiro A., Meirelles P., Lago N., Kon F., Ranking warnings from multiple source code static analyzers via ensemble learning, Proceedings of the 15th International Symposium on Open Collaboration, pp. 1-10, (2019); Alikhashashneh E.A., Raje R.R., Hill J.H., Using machine learning techniques to classify and predict static code analysis tool warnings, 2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA), pp. 1-8, (2018); Reddivari S., Raman J., Software quality prediction: An investigation based on machine learning, 2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI), pp. 115-122, (2019); Malhotra R., Chug A., Software maintainability prediction using machine learning algorithms, Software engineering: An international Journal (SeiJ), 2, 2, (2012); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR), pp. 542-553, (2018); Peng H., Mou L., Li G., Liu Y., Zhang L., Jin Z., Building program vector representations for deep learning, International conference on knowledge science, engineering and management, pp. 547-553, (2015); Alon U., Zilberstein M., Levy O., Yahav E., A general path-based representation for predicting program properties, ACM SIGPLAN Notices, 53, 4, pp. 404-419, (2018); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, POPL, pp. 1-29, (2019); Le Q., Mikolov T., Distributed representations of sentences and documents, International conference on machine learning, pp. 1188-1196, (2014); Wang T., Chen L.-C., Genc Y., A dictionary-based method for detecting machine-generated domains, Information Security Journal: A Global Perspective, (2020); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Gonzalez-Carvajal S., Garrido-Merchan E.C., Comparing BERT against traditional machine learning text classification, (2020); Ciniselli M., Cooper N., Pascarella L., Poshyvanyk D., Di Penta M., Bavota G., An empirical study on the usage of bert models for code completion, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 108-119, (2021); Touvron H., Et al., Llama: Open and efficient foundation language models, (2023)","He J.; Palpanas T.; Hu X.; Cuzzocrea A.; Dou D.; Slezak D.; Wang W.; Gruca A.; Lin J.C.-W.; Agrawal R.","Institute of Electrical and Electronics Engineers Inc.","Ankura; IEEE Dataport","2023 IEEE International Conference on Big Data, BigData 2023","15 December 2023 through 18 December 2023","Sorrento","196820","Conference paper","Final","","Scopus","2-s2.0-85184979868"
"Alazba A.; Aljamaan H.; Alshayeb M.","Alazba, Amal (57202938469); Aljamaan, Hamoud (57220207494); Alshayeb, Mohammad (6506030177)","57202938469; 57220207494; 6506030177","CoRT: Transformer-based code representations with self-supervision by predicting reserved words for code smell detection","2024","Empirical Software Engineering","29","3","59","","","","1","10.1007/s10664-024-10445-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188448314&doi=10.1007%2fs10664-024-10445-9&partnerID=40&md5=180b68245490c5e236e4b75831b8513a","Context: Code smell detection is the process of identifying poorly designed and implemented code pieces. Machine learning-based approaches require enormous amounts of manually labeled data, which are costly and difficult to scale. Unsupervised semantic feature learning, or learning without manual annotation, is vital for effectively harvesting an enormous amount of available data. Objective: The objective of this study is to propose a new code smell detection approach that utilizes self-supervised learning to learn intermediate representations without the need for labels and then fine-tune these representations on multiple tasks. Method: We propose a Code Representation with Transformers (CoRT) to learn the semantic and structural features of the source code by training transformers to recognize masked reserved words that are applied to the code given as input. We empirically demonstrated that the defined proxy task provides a powerful method for learning semantic and structural features. We exhaustively evaluated our approach on four downstream tasks: detection of the Data Class, God Class, Feature Envy, and Long Method code smells. Moreover, we compare our results with those of two paradigms: supervised learning and a feature-based approach. Finally, we conducted a cross-project experiment to evaluate the generalizability of our method to unseen labeled data. Results: The results indicate that the proposed method has a high detection performance for code smells. For instance, the detection performance of CoRT on Data Class achieved a score of F1 between 88.08–99.4, Area Under Curve (AUC) between 89.62–99.88, and Matthews Correlation Coefficient (MCC) between 75.28–98.8, while God Class achieved a value of F1 ranges from 86.32–99.03, AUC of 92.1–99.85, and MCC of 76.15–98.09. Compared with the baseline model and feature-based approach, CoRT achieved better detection performance and had a high capability to detect code smells in unseen datasets. Conclusions: The proposed method has been shown to be effective in detecting class-level, and method-level code smells. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Bad smell detection; Deep learning; Self-supervised learning","Codes (symbols); Deep learning; Feature extraction; Odors; Semantics; Bad smell detection; Bad smells; Code representation; Code smell; Deep learning; Detection performance; Labeled data; Self-supervised learning; Semantic features; Structural feature; Supervised learning","Abdou A., Darwish N., Severity classification of software code smells using machine learning techniques: A comparative study, J Softw Evol Process, (2022); AbuHassan A., Alshayeb M., Ghouti L., Software smell detection techniques: A systematic literature review, J Softw Evol Process, 33, (2021); Akiba T., Sano S., Yanase T., Ohta T., Koyama M., (2019) Optuna: A next-generation hyperparameter optimization framework, Proceedings of the 25Th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. Association for Computing Machinery, pp. 2623-2631; Alazba A., Aljamaan H., Code smell detection using feature selection and stacking ensemble: An empirical investigation, Inf Softw Technol, 138, (2021); Alazba A., Aljamaan H., Alshayeb M., Deep learning approaches for bad smell detection: a systematic literature review, Empir Softw Eng, 28, (2023); Alkhaeir T., Walter B., The Effect of Code Smells on the Relationship Between Design Patterns and Defects, IEEE Access, 9, pp. 3360-3373, (2021); Alkharabsheh K., Crespo Y., Manso E., Taboada J.A., Software Design Smell Detection: a systematic mapping study, Softw Qual J, 27, pp. 1069-1148, (2019); Al-Shaaby A., Aljamaan H., Alshayeb M., Bad Smell Detection Using Machine Learning Techniques: A Systematic Literature Review, Arab J Sci Eng, (2020); Amorim L., Antunes N., Fonseca B., Ribeiro M., Experience report: evaluating the effectiveness of decision trees for detecting code smells, 2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE), pp. 261-269, (2015); Arcelli Fontana F., Zanoni M., Code smell severity classification using machine learning techniques, Knowl-Based Syst, 128, pp. 43-58, (2017); Arcelli Fontana F., Mantyla M.V., Zanoni M., Marino A., Comparing and experimenting machine learning techniques for code smell detection, Empir Softw Eng, 21, pp. 1143-1191, (2016); Banker R.D., Datar S.M., Kemerer C.F., Zweig D., Software complexity and maintenance costs, Commun ACM, 36, pp. 81-94, (1993); Barbez A., Khomh F., Gueheneuc Y.-G., A machine-learning based ensemble method for anti-patterns detection, J Syst Softw, 161, (2019); Barbez A., Khomh F., Gueheneuc Y.-G., Deep Learning anti-patterns from Code metrics history, In: 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)., pp. 114-124, (2019); Bryton S., Brito E Abreu F., Monteiro M., Reducing subjectivity in code smells detection: Experimenting with the long method, 2010 Seventh International Conference on the Quality of Information and Communications Technology, pp. 337-342, (2010); Charalampidou S., Ampatzoglou A., Avgeriou P., Size and cohesion metrics as indicators of the long method bad smell: An empirical study, Proceedings of the 11Th International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 1-10, (2015); Chen Z., Chen L., Ma W., Et al., Understanding metric-based detectable smells in Python software: A comparative study, Inf Softw Technol, 94, pp. 14-29, (2018); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, In: Proceedings of Naacl-Hlt, 1, (2019); Dewangan S., Rao R.S., Mishra A., Gupta M., A Novel Approach for Code Smell Detection: An Empirical Study, IEEE Access, 9, pp. 162869-162883, (2021); Di Nucci D., Palomba F., Tamburri D.A., Serebrenik A., de Lucia A., Detecting code smells using machine learning techniques: Are we there yet?, 2018 IEEE 25Th Int Conf Softw Anal Evol Reengineering SANER 612–621., (2018); dos Reis J.P., Abreu F.B., e CarneiroGdeF, Crowdsmelling: A preliminary study on using collective knowledge in code smells detection, Empir Softw Eng, 27, (2022); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, In Findings of the Association for Computational Linguistics: EMNLP 2020, Online, pp. 1536-1547, (2020); Fontana F.A., Zanoni M., Marino A., Mantyla M.V., Code smell detection: Towards a machine learning-based approach, : Proceedings of the 2013 IEEE International Conference on Software Maintenance., pp. 396-399, (2013); Fowler M., Beck K., Brant J., Et al., Refactoring: Improving the Design of Existing Code, (1999); Gidaris S., Singh P., Komodakis N., Unsupervised representation learning by predicting image rotations, (2018); Guggulothu T., Moiz S.A., Code smell detection using multi-label classification approach, Softw Qual J, 28, pp. 1063-1086, (2020); Guo X., Shi C., Jiang H., Deep semantic-based feature envy identification, Proceedings of the 11Th Asia-Pacific Symposium on Internetware. Association for Computing Machinery, pp. 1-6, (2019); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Yin J., Jiang D., Zhou M., GraphCodeBERT: Pre-training Code Representations with Data Flow, Arxiv, (2020); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., UniXcoder: Unified cross-modal pre-training for code representation, Annual Meeting of the Association for Computational Linguistics, (2022); Hadj-Kacem M.N., A hybrid approach to detect code smells using deep learning, In: Proceedings of the 13Th International Conference on Evaluation of Novel Approaches to Software Engineering., pp. 137-146, (2018); Hadj-Kacem M., Bouassida N., Deep representation learning for code smells detection using variational auto-encoder, 2019 International Joint Conference on Neural Networks (IJCNN), pp. 1-8, (2019); Hadj-Kacem M., Bouassida N., Improving the identification of code smells by combining structural and semantic information, Neural Information Processing, pp. 296-304, (2019); Hassaine S., Khomh F., Gueheneuc Y.-G., Hamel S., IDS: An immune-inspired approach for the detection of software design smells, In: 2010 Seventh International Conference on the Quality of Information and Communications Technology, pp. 343-348, (2010); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Hua W., Sui Y., Wan Y., Et al., FCCA: Hybrid Code Representation for Functional Clone Detection Using Attention Networks, IEEE Trans Reliab, 70, pp. 304-318, (2021); Ioffe S., Szegedy C., Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, International Conference on Machine Learning, pp. 448-456, (2015); Jaiswal A., Babu A.R., Zadeh M.Z., Et al., A Survey on Contrastive Self-Supervised Learning, Technologies, 9, (2021); Kaur A., Jain S., Goel S., A support vector machine based approach for code smell detection, 2017 international conference on machine learning and data science (MLDS), pp. 9-14, (2017); Khleel N.A.A., Nehez K., Deep convolutional neural network model for bad code smells detection based on oversampling method, Indones J Electr Eng Comput Sci, 26, pp. 1725-1735, (2022); Khomh F., Vaucher S., Gueheneuc Y.-G., Sahraoui H., A Bayesian approach for the detection of code and design smells, 2009 Ninth International Conference on Quality Software, pp. 305-314, (2009); Khomh F., Vaucher S., Gueheneuc Y.-G., Sahraoui H., BDTEX: A GQM-based Bayesian approach for the detection of antipatterns, J Syst Softw, 84, pp. 559-572, (2011); Kim D.K., Finding bad code smells with neural network models, Int J Electr Comput Eng IJECE, 7, pp. 3613-3621, (2017); Kotsiantis S.B., (, . In: Proceedings of the 2007 Conference on Emerging Artificial Intelligence Applications in Computer Engineering: Real Word AI Systems with Applications in Ehealth, pp. 3-24, (2007); Lacerda G., Petrillo F., Pimenta M., Gueheneuc Y.G., Code smells and refactoring: A tertiary systematic review of challenges and observations, J Syst Softw, 167, (2020); Le H., Wang Y., Gotmare A.D., Savarese S., Hoi S.C., Coderl: Mastering code generation through pretrained models and deep reinforcement learning, Adv Neural Inf Process Syst, 35, pp. 21314-21328, (2022); Lim T.-S., Loh W.-Y., Shih Y.-S., A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty-Three Old and New Classification Algorithms, Mach Learn, 40, pp. 203-228, (2000); Liu H., Xu Z., Zou Y., Deep learning based feature envy detection, Proceedings of the 33Rd ACM/IEEE International Conference on Automated Software Engineering., pp. 385-396, (2018); Liu H., Jin J., Xu Z., Zou Y., Bu Y., Zhang L., Deep learning based code smell detection, IEEE Trans Softw Eng, 47, 9, pp. 1811-1837, (2019); Liu X., Zhang F., Hou Z., Mian L., Wang Z., Zhang J., Tang J., Self-supervised Learning: Generative or Contrastive, IEEE Trans Knowl Data Eng, 35, 1, pp. 857-876, (2021); Liu S., Wu B., Xie X., Meng G., Liu Y., Contrabert: Enhancing Code Pre-Trained Models via Contrastive Learning. Arxiv Preprint Arxiv, 2301, (2023); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Li G., Codexglue: A Machine Learning Benchmark Dataset for Code Understanding and Generation. Arxiv Preprint Arxiv, 2102, (2021); Maiga A., Ali N., Bhattacharya N., Sabane A., Gueheneuc Y.G., Aimeur E., SMURF: A SVM-based incremental anti-pattern detection approach, 2012 19Th Working Conference on Reverse Engineering, pp. 466-475, (2012); Maiga A., Ali N., Bhattacharya N., Sabane A., Gueheneuc Y.G., Antoniol G., Aimeur E., Support vector machines for anti-pattern detection, 2012 Proceedings of the 27Th IEEE/ACM International Conference on Automated Software Engineering, pp. 278-281, (2012); Mayvan B.B., Rasoolzadegan A., Jafari A.J., Bad smell detection using quality metrics and refactoring opportunities, J Softw Evol Process, 32, (2020); Moha N., Gueheneuc Y.-G., Duchien L., Le Meur A.-F., DECOR: A Method for the Specification and Detection of Code and Design Smells, IEEE Trans Softw Eng, 36, pp. 20-36, (2010); Myung I.J., The Importance of Complexity in Model Selection, J Math Psychol, 44, pp. 190-204, (2000); Nafi K.W., Kar T.S., Roy B., Roy C.K., Schneider K.A., CLCDSA: Cross language code clone detection using syntactical features and api documentation, 2019 34Th IEEE/ACM International Conference on Automated Software Engineering (ASE, pp. 1026-1037, (2019); Olbrich S.M., Cruzes D.S., Sjoberg D.I.K., Are all code smells harmful? A study of God Classes and Brain Classes in the evolution of three open source systems, 2010 IEEE International Conference on Software Maintenance, pp. 1-10, (2010); Parr T., The Definitive ANTLR 4 Reference. the Definitive ANTLR 4 Reference, pp. 1-326, (2013); Ren S., Shi C., Zhao S., Exploiting multi-aspect interactions for god class detection with dataset fine-tuning, In: 2021 IEEE 45Th Annual Computers, Software, and Applications Conference (COMPSAC)., pp. 864-873, (2021); Roy G.G., Veraart V.E., Software engineering education: From an engineering perspective, Proceedings 1996 International Conference Software Engineering: Education and Practice, pp. 256-262, (1996); Sandouka R., Aljamaan H., Python code smells detection using conventional machine learning models, PeerJ Comput Sci, 9, (2023); Sharma T., Efstathiou V., Louridas P., Spinellis D., Code smell detection by deep direct-learning and transfer-learning, J Syst Softw, 176, (2021); Sotto-Mayor B., Elmishali A., Kalech M., Abreu R., Exploring Design smells for smell-based defect prediction, Eng Appl Artif Intell, 115, (2022); Tantithamthavorn C., McIntosh S., Hassan A.E., Matsumoto K., The Impact of Automated Parameter Optimization on Defect Prediction Models, IEEE Trans Softw Eng, 45, pp. 683-711, (2019); Tempero E., Anslow C., Dietrich J., Han T., Li J., Lumpe M., Melton H., Noble J., The qualitas corpus: A curated collection of java code for empirical studies, . In: 2010 Asia Pacific Software Engineering Conference, pp. 336-345, (2010); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention Is All You Need, Adv Neural Inf Process Syst, 30, (2017); Wang X., Dang Y., Zhang L., Zhang D., Lan E., Mei H., Can I clone this piece of code here?, 2012 Proceedings of the 27Th IEEE/ACM International Conference on Automated Software Engineering, pp. 170-179, (2012); Wang H., Liu J., Kang J., Yin W., Sun H.H., Feature envy detection based on Bi-LSTM with self-attention mechanism, In: 2020 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking, pp. 448-457, (2020); Wang Y., Wang W., Joty S., Hoi S.C.H., CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Arxiv Preprint Arxiv, 2109, (2021); Wang Y., Le H., Gotmare A.D., Bui N.D., Li J., Hoi S.C., CodeT5+: Open code large language models for code understanding and generation, Arxiv Preprint Arxiv, 2305, (2023); Watanabe S., Hutter F., C-TPE: Generalizing tree-structured parzen estimator with inequality constraints for continuous and categorical hyperparameter optimization, (2022); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, In: 2016 31St IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 87-98, (2016); Xu W., Zhang X., Multi-granularity code smell detection using deep learning method based on abstract syntax tree, Proceeding 33Rd Int. Conf. Software Engineering and Knowledge Engineering, pp. 503-509, (2021); Yin X., Shi C., Zhao S., Local and global feature based explainable feature envy detection, In: 2021 IEEE 45Th Annual Computers, Software, and Applications Conference (COMPSAC)., pp. 942-951, (2021)","","Springer","","","","","","Article","Final","","Scopus","2-s2.0-85188448314"
"Kedziora D.J.; Musial K.; Gabrys B.","Kedziora, David Jacob (25421572300); Musial, Katarzyna (14626743000); Gabrys, Bogdan (7006540228)","25421572300; 14626743000; 7006540228","AutonoML: Towards an Integrated Framework for Autonomous Machine Learning","2024","Foundations and Trends in Machine Learning","17","4","","590","766","176","0","10.1561/2200000093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189861293&doi=10.1561%2f2200000093&partnerID=40&md5=fd0f0592ca03e30888ef6a6a6c0f3acb","Over the last decade, the long-running endeavour to automate high-level processes in machine learning (ML) has risen to mainstream prominence, stimulated by advances in optimisation techniques and their impact on selecting ML models/algorithms. Central to this drive is the appeal of engineering a computational system that both discovers and deploys high-performance solutions to arbitrary ML problems with minimal human interaction. Beyond this, an even loftier goal is the pursuit of autonomy, which describes the capability of the system to independently adjust an ML solution over a lifetime of changing contexts. However, these ambitions are unlikely to be achieved in a robust manner without the broader synthesis of various mechanisms and theoretical frameworks, which, at the present time, remain scattered across numerous research threads. Accordingly, this review seeks to motivate a more expansive perspective on what constitutes an automated/autonomous ML system, alongside consideration of how best to consolidate those elements. In doing so, we survey developments in the following research areas: hyperparameter optimisation, multi-component models, neural architecture search, automated feature engineering, meta-learning, multi-level ensembling, dynamic adaptation, multi-objective evaluation, resource constraints, flexible user involvement, and the principles of generalisation. We also develop a conceptual framework throughout the review, augmented by each topic, to illustrate one possible way of fusing high-level mechanisms into an autonomous ML system. Ultimately, we conclude that the notion of architectural integration deserves more discussion, without which the field of automated ML risks stifling both its technical advantages and general uptake. ©2024 D. J. Kedziora et al.","","Automation; Autonomous machines; Computational system; Integrated frameworks; Level process; Machine learning models; Machine learning systems; Machine-learning; Model algorithms; Optimization techniques; Performance; Machine learning","Vanschoren J., Brazdil P., Kietz J.-U., 5th Planning to Learn Workshop WS28 at ECAI 2012, (2012); Aalst W.M.P.V.D., The Application of Petri Nets to Workflow Management, Journal of Circuits, Systems and Computers, 8, 1, pp. 21-66, (1998); Abdulrahman S., Improving Algorithm Selection Methods using Meta-Learning by Considering Accuracy and Run Time, (2017); Abdulrahman S.M., Adamu A., Ibrahim Y.A., Muhammad A.R., An Overview of the Algorithm Selection Problem, International Journal of Computer (IJC), 26, 1, pp. 71-98, (2017); Agasiev T., Karpenko A., The Program System for Automated Parameter Tuning of Optimization Algorithms, Procedia Computer Science, 103, pp. 347-354, (2017); Aha D.W., Generalizing from Case Studies: A Case Study, Machine Learning Proceedings 1992, pp. 1-10, (1992); Ahn L.V., Maurer B., McMillen C., Abraham D., Blum M., reCAPTCHA: Human-Based Character Recognition via Web Security Measures, Science, 321, 5895, pp. 1465-1468, (2008); Alanne K., Sierla S., An overview of machine learning applications for smart buildings, Sustainable Cities and Society, 76, (2022); Alexandre F., Beyond Machine Learning: Autonomous Learning, Proceedings of the 8th International Joint Conference on Computational Intelligence, (2016); Ali A.R., Budka M., Gabrys B., A Review of Meta-level Learning in the Context of Multi-component, Multi-level Evolving Prediction Systems, (2015); Ali A.R., Budka M., Gabrys B., Towards Meta-learning of Deep Architectures for Efficient Domain Adaptation, PRI-CAI 2019: Trends in Artificial Intelligence, pp. 66-79, (2019); Ali A.R., Gabrys B., Budka M., Cross-domain Metalearning for Time-series Forecasting, Procedia Computer Science, 126, pp. 9-18, (2018); Ali S., Smith-Miles K.A., A meta-learning approach to automatic kernel selection for support vector machines, Neurocomputing, 70, 1-3, pp. 173-186, (2006); Ali Y., Awwad E., Al-Razgan M., Maarouf A., Hyperparameter Search for Machine Learning Algorithms for Optimizing the Computational Complexity, Processes, 11, 2, (2023); Alletto S., Huang S., Francois-Lavet V., Nakata Y., Rabusseau G., RandomNet: Towards Fully Automatic Neural Architecture Design for Multimodal Learning, ArXiv, (2020); Almeida E., Ferreira C., Gama J., Adaptive Model Rules from Data Streams, Advanced Information Systems Engineering, pp. 480-492, (2013); Alsharef A., Aggarwal K., Sonia M.K., Mishra A., Review of ML and AutoML Solutions to Forecast Time-Series Data, Archives of Computational Methods in Engineering, 29, 7, pp. 5297-5311, (2022); Anderson A., Dubois S., Cuesta-Infante A., Veeramachaneni K., Sample, Estimate, Tune: Scaling Bayesian Auto-Tuning of Data Science Pipelines, 2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA), (2017); Anderson A.W., Deep Mining: scaling Bayesian auto-tuning of data science pipelines, (2017); Anderson M.R., Antenucci D., Cafarella M.J., Run-time Support for Human-in-the-Loop Feature Engineering Systems, IEEE Data Eng. Bull., 39, pp. 62-84, (2016); Andrychowicz M., Denil M., Gomez S., Hoffman M.W., Pfau D., Schaul T., Shillingford B., de Freitas N., Learning to learn by gradient descent by gradient descent, Advances in Neural Information Processing Systems, 29, pp. 3981-3989, (2016); Angelov P., Kasabov N., Evolving computational intelligence systems, Proceedings of the 1st international workshop on genetic fuzzy systems, pp. 76-82, (2005); Kaggle vs. Auto-WEKA, (2013); Bach S.H., Maloof M.A., Paired Learners for Concept Drift, 2008 Eighth IEEE International Conference on Data Mining, (2008); Baena-Garcia M., del Campo-Avila J., Fidalgo R., Bifet A., Gavalda R., Morales-Bueno R., Early drift detection method, Fourth international workshop on knowledge discovery from data streams, 6, pp. 77-86, (2006); Bagnall A., Cawley G.C., On the Use of Default Parameter Settings in the Empirical Evaluation of Classification Algorithms, ArXiv, (2017); Bahri M., Salutari F., Putina A., Sozio M., AutoML: state of the art with a focus on anomaly detection, challenges, and research directions, International Journal of Data Science and Analytics, 14, 2, pp. 113-126, (2022); Baker B., Gupta O., Naik N., Raskar R., Designing Neural Network Architectures using Reinforcement Learning, 5th International Conference on Learning Representations, ICLR 2017, (2017); Bakirov R., Gabrys B., Fay D., On sequences of different adaptive mechanisms in non-stationary regression problems, 2015 International Joint Conference on Neural Networks (IJCNN), (2015); Bakirov R., Gabrys B., Fay D., Multiple adaptive mechanisms for data-driven soft sensors, Computers & Chemical Engineering, 96, pp. 42-54, (2017); Bakirov R., Gabrys B., Fay D., Generic adaptation strategies for automated machine learning, ArXiv, (2018); Balaji A., Allen A., Benchmarking Automatic Machine Learning Frameworks, ArXiv, (2018); Bardenet R., Brendel M., Kegl B., Sebag M., Collaborative hyperparameter tuning, International conference on machine learning, pp. 199-207, (2013); Barreiro E., Munteanu C.R., Cruz-Monteagudo M., Pazos A., Gonzalez-Diaz H., Net-Net Auto Machine Learning (AutoML) Prediction of Complex Ecosystems, Scientific Reports, 8, 1, (2018); Bengio Y., Gradient-Based Optimization of Hyperparameters, Neural Computation, 12, 8, pp. 1889-1900, (2000); Bennett K.P., Kunapuli G., Hu J., Pang J.-S., Bilevel Optimization and Machine Learning, IEEE World Congress on Computational Intelligence, pp. 25-47, (2008); Bensusan H., God doesn’t always shave with Occam’s razor — Learning when and how to prune, Machine Learning: ECML-98, pp. 119-124, (1998); Bergstra J., Bengio Y., Random search for hyper-parameter optimization, Journal of machine learning research, 13, pp. 281-305, (2012); Bergstra J., Komer B., Eliasmith C., Warde-Farley D., Preliminary evaluation of hyperopt algorithms on HPOLib, ICML workshop on AutoML, (2014); Bergstra J., Yamins D., Cox D., Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms, Proceedings of the 12th Python in Science Conference, (2013); Bergstra J.S., Bardenet R., Bengio Y., Kegl B., Algorithms for hyper-parameter optimization, Advances in neural information processing systems, pp. 2546-2554, (2011); Bermudez-Chacon R., Gonnet G.H., Smith K., Automatic problem-specific hyperparameter optimization and model selection for supervised machine learning, (2015); Biamonte J., Wittek P., Pancotti N., Rebentrost P., Wiebe N., Lloyd S., Quantum machine learning, Nature, 549, 7671, pp. 195-202, (2017); Bifet A., Holmes G., Kirkby R., Pfahringer B., MOA: Massive online analysis, Journal of Machine Learning Research, 11, pp. 1601-1604, (2010); Bilalli B., Learning the impact of data pre-processing in data analysis, (2018); Bilalli B., Abello A., Aluja-Banet T., Munir R.F., Wrembel R., PRESISTANT: Data Pre-processing Assistant, International Conference on Advanced Information Systems Engineering, pp. 57-65, (2018); Bischl B., Casalicchio G., Feurer M., Hutter F., Lang M., Mantovani R.G., van Rijn J.N., Vanschoren J., OpenML Benchmarking Suites, ArXiv, (2017); Bischl B., Richter J., Bossek J., Horn D., Thomas J., Lang M., mlrMBO: A Modular Framework for Model-Based Optimization of Expensive Black-Box Functions, ArXiv, (2017); Blum A.L., Langley P., Selection of relevant features and examples in machine learning, Artificial Intelligence, 97, 1-2, pp. 245-271, (1997); Bond R., Koene A., Dix A., Boger J., Mulvenna M.D., Galushka M., Bradley B.W., Browne F., Wang H., Wong A., Democratisation of Usable Machine Learning in Computer Vision, ArXiv, (2019); Bosch S.V.D., Automatic feature generation and selection in predictive analytics solutions, (2017); Bouchachia A., Gabrys B., Sahel Z., Overview of Some Incremental Learning Algorithms, 2007 IEEE International Fuzzy Systems Conference, (2007); Brazdil P., Giraud-Carrier C., Metalearning and Algorithm Selection: progress, state of the art and introduction to the 2018 Special Issue, Machine Learning, 107, 1, pp. 1-14, (2017); Brazdil P.B., Soares C., da Costa J.P., Ranking Learning Algorithms: Using IBL and Meta-Learning on Accuracy and Time Results, Machine Learning, 50, 3, pp. 251-277, (2003); Brazdil P., Data transformation and model selection by experimentation and meta-learning, Proceedings of the ECML-98 Workshop on Upgrading Learning to Meta-Level: Model Selection and Data Transformation, pp. 11-17, (1998); Breiman L., Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author), Statistical Science, 16, 3, pp. 199-231, (2001); Brochu E., Cora V.M., de Freitas N., A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning, ArXiv, (2010); Brown A.L., Kane M.J., Preschool children can learn to transfer: Learning to learn and learning from example, Cognitive Psychology, 20, 4, pp. 493-523, (1988); Budka M., Gabrys B., Density-Preserving Sampling: Robust and Efficient Alternative to Cross-Validation for Error Estimation, IEEE Transactions on Neural Networks and Learning Systems, 24, 1, pp. 22-34, (2013); Budka M., Gabrys B., Correntropy-based density-preserving data sampling as an alternative to standard cross-validation, The 2010 International Joint Conference on Neural Networks (IJCNN), (2010); Budka M., Gabrys B., Musial K., On Accuracy of PDF Divergence Estimators and Their Applicability to Representative Data Sampling, Entropy, 13, 7, pp. 1229-1266, (2011); Cachada M., Abdulrahman S., Brazdil P., Combining Feature and Algorithm Hyperparameter Selection using some Metalearning Methods, AutoML@PKDD/ECML, (2017); Cacoveanu S., Vidrighin C., Potolea R., Evolutional meta-learning framework for automatic classifier selection, 2009 IEEE 5th International Conference on Intelligent Computer Communication and Processing, pp. 27-30, (2009); Cai H., Zhu L., Han S., ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware, 7th International Conference on Learning Representations, ICLR 2019, (2019); Camilleri M., Neri F., Papoutsidakis M., An algorithmic approach to parameter selection in machine learning using meta-optimization techniques, WSEAS Transactions on systems, 13, pp. 202-213, (2014); Caruana R., Niculescu-Mizil A., Crew G., Ksikes A., Ensemble selection from libraries of models, Twenty-first international conference on Machine learning - ICML’04, (2004); Celik B., Singh P., Vanschoren J., Online AutoML: an adaptive AutoML framework for online learning, Machine Learning, 112, 6, pp. 1897-1921, (2022); Celik B., Vanschoren J., Adaptation Strategies for Automated Machine Learning on Evolving Data, IEEE Transactions on Pattern Analysis and Machine Intelligence, (2021); Chan P.K., Stolfo S.J., Experiments on multistrategy learning by meta-learning, Proceedings of the second international conference on Information and knowledge management - CIKM’93, (1993); Chan S., Treleaven P., Capra L., Continuous hyperparameter optimization for large-scale recommender systems, 2013 IEEE International Conference on Big Data, (2013); Chandola V., Banerjee A., Kumar V., Anomaly detection: A survey, ACM Computing Surveys, 41, 3, pp. 1-58, (2009); Chapman P., Clinton J., Kerber R., Khabaza T., Reinartz T., Shearer C., Wirth R., CRISP-DM 1.0: Step-by-step data mining guide, (2000); Charnes A., Cooper W., Rhodes E., Measuring the efficiency of decision making units, European Journal of Operational Research, 2, 6, pp. 429-444, (1978); Chekina L., Rokach L., Shapira B., Meta-learning for Selecting a Multi-label Classification Algorithm, 2011 IEEE 11th International Conference on Data Mining Workshops, (2011); Chen B., Wu H., Mo W., Chattopadhyay I., Lipson H., Autostacker: A compositional evolutionary learning system, Proceedings of the Genetic and Evolutionary Computation Conference - GECCO’18, (2018); Cheng J., Bernstein M.S., Flock: Hybrid Crowd-Machine Learning Classifiers, Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing - CSCW’15, (2015); Cheng W., Kasneci G., Graepel T., Stern D., Herbrich R., Automated feature generation from structured knowledge, Proceedings of the 20th ACM international conference on Information and knowledge management - CIKM’11, (2011); Chowdhary M., Lilienthal D., Saha S.S., Palle K.C., AutoML for On-Sensor Tiny Machine Learning, IEEE Sensors Letters, 7, 11, pp. 1-4, (2023); Cios K.J., Kurgan L.A., Trends in Data Mining and Knowledge Discovery, Advanced Information and Knowledge Processing, pp. 1-26, (2005); Claesen M., De Moor B., Hyperparameter search in machine learning, eng, pp. 1-5, (2015); Clemen R.T., Combining forecasts: A review and annotated bibliography, International Journal of Forecasting, 5, 4, pp. 559-583, (1989); Cochran D., Roe M., Goudar C., Martyn B., Das M., Uppuluri P., Lennon S., Panda B., King S., Dolan L., Et al., A methodology for automated feature engineering in training of shallow neural networks for prediction of multi-linear growth failures (“Nova Algorithm”), Technical Disclosure Commons, (2018); Whitepaper: Multi-Stage Ensemble and Feature Engineering, (2016); Cowen-Rivers A.I., Lyu W., Tutunov R., Wang Z., Grosnit A., Griffiths R.R., Maraval A.M., Jianye H., Wang J., Peters J., Bou-Ammar H., HEBO: An Empirical Study of Assumptions in Bayesian Optimisation, Journal of Artificial Intelligence Research, 74, pp. 1269-1349, (2022); Crankshaw D., Sela G.-E., Zumar C., Mo X., Gonzalez J.E., Stoica I., Tumanov A., InferLine: ML Inference Pipeline Composition Framework, ArXiv, (2018); Cui C., Hu M., Weir J.D., Wu T., A recommendation system for meta-modeling: A meta-learning based approach, Expert Systems with Applications, 46, pp. 33-44, (2016); Cui H., Ganger G.R., Gibbons P.B., MLtuner: System Support for Automatic Machine Learning Tuning, ArXiv, (2018); Culotta A., Kristjansson T., McCallum A., Viola P., Corrective feedback and persistent learning for information extraction, Artificial Intelligence, 170, 14-15, pp. 1101-1122, (2006); Deb K., Pratap A., Agarwal S., Meyarivan T., A fast and elitist multiobjective genetic algorithm: NSGA-II, IEEE Transactions on Evolutionary Computation, 6, 2, pp. 182-197, (2002); Dewancker I., McCourt M., Clark S., Hayes P., Johnson A., Ke G., A strategy for ranking optimization methods using multiple criteria, Workshop on Automatic Machine Learning, pp. 11-20, (2016); Dey N., Hassanien A.E., Bhatt C., Ashour A.S., Satapathy S.C., Internet of Things and Big Data Analytics Toward Next-Generation Intelligence, (2018); Diveev A., Konstantinov S., Sofronova E., A Comparison of Evolutionary Algorithms and Gradient-based Methods for the Optimal Control Problem, 2018 5th International Conference on Control, Decision and Information Technologies (CoDIT), (2018); Domhan T., Springenberg J.T., Hutter F., Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves, Twenty-Fourth International Joint Conference on Artificial Intelligence, (2015); Dong X., Kedziora D.J., Musial K., Gabrys B., Automated Deep Learning: Neural Architecture Search Is Not the End, ArXiv, (2021); Dong X., Liu L., Musial K., Gabrys B., NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size, IEEE Transactions on Pattern Analysis and Machine Intelligence, (2020); Dong X., Tan M., Yu A.W., Peng D., Gabrys B., Le Q.V., AutoHAS: Efficient Hyperparameter and Architecture Search, ArXiv, (2020); Dong X., Yang Y., Searching for a Robust Neural Architecture in Four GPU Hours, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), (2019); Dor O., Reich Y., Strengthening learning algorithms by feature discovery, Information Sciences, 189, pp. 176-190, (2012); Drori I., Krishnamurthy Y., Rampin R., Lourenco R., One J., Cho K., Silva C., Freire J., AlphaD3M: Machine learning pipeline synthesis, AutoML Workshop at ICML, (2018); Drozdal J., Weisz J., Wang D., Dass G., Yao B., Zhao C., Muller M., Ju L., Su H., Trust in AutoML: exploring information needs for establishing trust in automated machine learning systems, Proceedings of the 25th International Conference on Intelligent User Interfaces, pp. 297-307, (2020); Dubois S., Deep mining: Copula-based hyper-parameter optimization for machine learning pipelines, (2015); Dunner C., Parnell T., Atasu K., Sifalakis M., Pozidis H., Understanding and optimizing the performance of distributed machine learning applications on apache spark, 2017 IEEE International Conference on Big Data (Big Data), (2017); Dura-Bernal S., Suter B.A., Gleeson P., Cantarelli M., Quintana A., Rodriguez F., Kedziora D.J., Chadderdon G.L., Kerr C.C., Neymotin S.A., McDougal R.A., Hines M., Shepherd G.M., Lytton W.W., NetPyNE, a tool for data-driven multiscale modeling of brain circuits, eLife, 8, (2019); Eastwood M., Gabrys B., The Dynamics of Negative Correlation Learning, The Journal of VLSI Signal Processing Systems for Signal, Image, and Video Technology, 49, 2, pp. 251-263, (2007); Eastwood M., Gabrys B., Model level combination of tree ensemble hyperboxes via GFMM, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD), (2011); Eastwood M., Gabrys B., Generalised bottom-up pruning: A model level combination of decision trees, Expert Systems with Applications, 39, 10, pp. 9150-9158, (2012); Efimova V., Filchenkov A., Shalyto A., Reinforcement-Based Simultaneous Algorithm and Its Hyperparameters Selection, Communications in Computer and Information Science, pp. 15-27, (2019); Eggensperger K., Feurer M., Hutter F., Bergstra J., Snoek J., Hoos H., Leyton-Brown K., Towards an empirical foundation for assessing bayesian optimization of hyperparameters, NIPS workshop on Bayesian Optimization in Theory and Practice, 10, 3, (2013); Eggensperger K., Hutter F., Hoos H., Leyton-Brown K., Efficient benchmarking of hyperparameter optimizers via surrogates, Twenty-Ninth AAAI Conference on Artificial Intelligence, (2015); Elsken T., Metzen J.H., Hutter F., Neural Architecture Search: A Survey, Journal of Machine Learning Research, 20, 55, pp. 1-21, (2019); Erickson N., Mueller J., Shirkov A., Zhang H., Larroy P., Li M., Smola A., AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data, ArXiv, (2020); Escalante H.J., Montes M., Sucar L.E., Particle Swarm Model Selection, J. Mach. Learn. Res., 10, pp. 405-440, (2009); Fakoor R., Mueller J., Erickson N., Chaudhari P., Smola A.J., Fast, Accurate, and Simple Models for Tabular Data via Augmented Distillation, Advances in Neural Information Processing Systems, 33, (2020); Falkner S., Klein A., Hutter F., Combining hyperband and bayesian optimization, Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS), Bayesian Optimization Workshop, (2017); Fang M., Li Y., Cohn T., Learning how to Active Learn: A Deep Reinforcement Learning Approach, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, (2017); Farmer J., Packard N.H., Perelson A.S., The immune system, adaptation, and machine learning, Physica D: Nonlinear Phenomena, 22, 1-3, pp. 187-204, (1986); Fayyad U., Piatetsky-Shapiro G., Smyth P., The KDD process for extracting useful knowledge from volumes of data, Communications of the ACM, 39, 11, pp. 27-34, (1996); Fernandez S., de la Rosa T., Fernandez F., Suarez R., Ortiz J., Borrajo D., Manzano D., Using automated planning for improving data mining processes, The Knowledge Engineering Review, 28, 2, pp. 157-173, (2013); Feurer M., Eggensperger K., Falkner S., Lindauer M., Hutter F., Auto-Sklearn 2.0: Hands-Free AutoML via Meta-Learning, J. Mach. Learn. Res., 23, 1, (2022); Feurer M., Klein A., Eggensperger K., Springenberg J., Blum M., Hutter F., Efficient and Robust Automated Machine Learning, Advances in Neural Information Processing Systems, 28, pp. 2962-2970, (2015); Feurer M., Klein A., Eggensperger K., Springenberg J.T., Blum M., Hutter F., Auto-sklearn: Efficient and Robust Automated Machine Learning, Automated Machine Learning, pp. 113-134, (2019); Feurer M., Springenberg J.T., Hutter F., Initializing bayesian hyperparameter optimization via meta-learning, Twenty-Ninth AAAI Conference on Artificial Intelligence, (2015); Finn C., Abbeel P., Levine S., Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks, Proceedings of the 34th International Conference on Machine Learning - Volume 70. ICML’17, pp. 1126-1135, (2017); Finn C., Yu T., Zhang T., Abbeel P., Levine S., One-Shot Visual Imitation Learning via Meta-Learning, Proceedings of the 1st Annual Conference on Robot Learning, 78, pp. 357-368, (2017); Fonseca P., Mendoza J., Wainer J., Ferrer J., Pinto J., Guerrero J., Castaneda B., Automatic breast density classification using a convolutional neural network architecture search procedure, Medical Imaging 2015: Computer-Aided Diagnosis, (2015); Fowers J., Ovtcharov K., Papamichael M., Massengill T., Liu M., Lo D., Alkalay S., Haselman M., Adams L., Ghandi M., Heil S., Patel P., Sapek A., Weisz G., Woods L., Lanka S., Reinhardt S.K., Caulfield A.M., Chung E.S., Burger D., A Configurable Cloud-Scale DNN Processor for Real-Time AI, 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA), (2018); Fu Y., Chen W., Wang H., Li H., Lin Y., Wang Z., AutoGAN-Distiller: Searching to Compress Generative Adversarial Networks, Proceedings of the 37th International Conference on Machine Learning, 119, pp. 3292-3303, (2020); Fulcher B.D., Jones N.S., Highly Comparative Feature-Based Time-Series Classification, IEEE Transactions on Knowledge and Data Engineering, 26, 12, pp. 3026-3037, (2014); Furnkranz J., Petrak J., An evaluation of landmarking variants, Working Notes of the ECML/PKDD 2000 Workshop on Integrating Aspects of Data Mining, Decision Support and Meta-Learning, pp. 57-68, (2001); Gabrys B., Combining neuro-fuzzy classifiers for improved generalisation and reliability, Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN’02 (Cat. No.02CH37290), (2002); Gabrys B., Learning hybrid neuro-fuzzy classifier models from data: to combine or not to combine?, Fuzzy Sets and Systems, 147, 1, pp. 39-56, (2004); Gabrys B., Bargiela A., Neural Networks Based Decision Support in Presence of Uncertainties, Journal of Water Resources Planning and Management, 125, 5, pp. 272-280, (1999); Gabrys B., Leiviska K., Strackeljan J., Do Smart Adaptive Systems Exist?, (2005); Gabrys B., Ruta D., Genetic algorithms in classifier fusion, Applied Soft Computing, 6, 4, pp. 337-347, (2006); Gama J., Medas P., Castillo G., Rodrigues P., Learning with Drift Detection, Advances in Artificial Intelligence – SBIA 2004, pp. 286-295, (2004); Gama J., Zliobaite I., Bifet A., Pechenizkiy M., Bouchachia A., A survey on concept drift adaptation, ACM Computing Surveys, 46, 4, pp. 1-37, (2014); Ganin Y., Lempitsky V., Unsupervised Domain Adaptation by Backpropagation, Proceedings of the 32nd International Conference on Machine Learning, 37, pp. 1180-1189, (2015); Garciarena U., Mendiburu A., Santana R., Towards a more efficient representation of imputation operators in TPOT, ArXiv, (2018); Garciarena U., Santana R., Mendiburu A., Evolving imputation strategies for missing data in classification problems with TPOT, ArXiv, (2017); Garciarena U., Santana R., Mendiburu A., Analysis of the Complexity of the Automatic Pipeline Generation Problem, 2018 IEEE Congress on Evolutionary Computation (CEC), (2018); Garouani M., Ahmad A., Bouneffa M., Hamlich M., Bourguin G., Lewandowski A., Towards big industrial data mining through explainable automated machine learning, The International Journal of Advanced Manufacturing Technology, 120, 1-2, pp. 1169-1188, (2022); Gashler M., Giraud-Carrier C., Martinez T., Decision Tree Ensemble: Small Heterogeneous Is Better Than Large Homogeneous, 2008 Seventh International Conference on Machine Learning and Applications, (2008); Gelernter D., Mirror worlds: or the day software puts the universe in a shoebox—how it will happen and what it will mean, (1991); Geman S., Bienenstock E., Doursat R., Neural Networks and the Bias/Variance Dilemma, Neural Computation, 4, 1, pp. 1-58, (1992); Gemert T.V., On the influence of dataset characteristics on classifier performance, (2017); Gemp I., Theocharous G., Ghavamzadeh M., Automated data cleansing through meta-learning, Twenty-Ninth IAAI Conference, (2017); Gencoglu O., van Gils M., Guldogan E., Morikawa C., Suzen M., Gruber M., Leinonen J., Huttunen H., HARK Side of Deep Learning – From Grad Student Descent to Automated Machine Learning, ArXiv, (2019); Gennatas E.D., Friedman J.H., Ungar L.H., Pirracchio R., Eaton E., Reichmann L.G., Interian Y., Luna J.M., Simone C.B., Auerbach A., Delgado E., van der Laan M.J., Solberg T.D., Valdes G., Expert-augmented machine learning, Proceedings of the National Academy of Sciences, 117, 9, pp. 4571-4577, (2020); Gerdes M., Galar D., Scholz D., Automated parameter optimization for feature extraction for condition monitoring, 14th IMEKO TC10 Workshop on Technical Diagnostics 2016: New Perspectives in Measurements, Tools and Techniques for Systems Reliability, Maintainability and Safety, pp. 452-457, (2016); Gijsbers P., LeDell E., Thomas J., Poirier S., Bischl B., Vanschoren J., An Open Source AutoML Benchmark, ArXiv, (2019); Gijsbers P., Vanschoren J., GAMA: Genetic Automated Machine learning Assistant, Journal of Open Source Software, 4, 33, (2019); Gil Y., Honaker J., Gupta S., Ma Y., D'Orazio V., Garijo D., Gadewar S., Yang Q., Jahanshad N., Towards human-guided machine learning, Proceedings of the 24th International Conference on Intelligent User Interfaces, (2019); Glazer A., Markovitch S., Resource-Bounded Selection of Learning Algorithms, (2013); Gomes T.A., Prudencio R.B., Soares C., Rossi A.L., Carvalho A., Combining meta-learning and search techniques to select parameters for support vector machines, Neurocomputing, 75, 1, pp. 3-13, (2012); Gong X., Chang S., Jiang Y., Wang Z., AutoGAN: Neural Architecture Search for Generative Adversarial Networks, 2019 IEEE/CVF International Conference on Computer Vision (ICCV), (2019); Grabczewski K., Jankowski N., Versatile and Efficient Meta-Learning Architecture: Knowledge Representation and Management in Computational Intelligence, 2007 IEEE Symposium on Computational Intelligence and Data Mining, (2007); Grabczewski K., Meta-Learning in Decision Tree Induction, (2014); Guyon I., Chaabane I., Escalante H.J., Escalera S., Jajetic D., Lloyd J.R., Macia N., Ray B., Romaszko L., Sebag M., Statnikov A., Treguer S., Viegas E., A brief review of the ChaLearn AutoML challenge: any-time any-dataset learning without human intervention, Workshop on Automatic Machine Learning, pp. 21-30, (2016); Guyon I., Saffari A., Dror G., Cawley G., Model selection: Beyond the bayesian/frequentist divide, Journal of Machine Learning Research, 11, pp. 61-87, (2010); Guyon I., Saffari A., Dror G., Cawley G., Challenges in Data Representation, Model Selection, and Performance Prediction, Hands-On Pattern Recognition Challenges in Machine Learning, 1, (2011); H2O AutoML, (2017); Hajian S., Bonchi F., Castillo C., Algorithmic Bias: From Discrimination Discovery to Fairness-aware Data Mining, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, (2016); Hall P.M., Marshall D., Martin R.R., Incremental Eigenanalysis for Classification, Proceedings of the British Machine Vision Conference 1998, (1998); Hansing T., Krell M.M., Kirchner F., hyperSPACE: Automated Optimization of Complex Processing Pipelines for pySPACE, NIPS Workshop on Bayesian Optimization. NIPS Workshop on Bayesian Optimization (BayesOPT2016), (2016); Hanussek M., Blohm M., Kintz M., Can AutoML outperform humans? An evaluation on popular OpenML datasets using AutoML Benchmark, ArXiv, (2020); Harlap A., Narayanan D., Phanishayee A., Seshadri V., Devanur N., Ganger G., Gibbons P., PipeDream: Fast and Efficient Pipeline Parallel DNN Training, ArXiv, (2018); He C., Annavaram M., Avestimehr S., FedNAS: Federated Deep Learning via Neural Architecture Search, ArXiv, (2020); He K., Zhang X., Ren S., Sun J., Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, Computer Vision – ECCV 2014, pp. 346-361, (2014); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2016); He X., Zhao K., Chu X., AutoML: A survey of the state-of-the-art, Knowledge-Based Systems, 212, (2019); Heaton J.T., Automated Feature Engineering for Deep Neural Networks with Genetic Programming, (2017); Hennig P., Schuler C.J., Entropy Search for Information-Efficient Global Optimization, J. Mach. Learn. Res., 13, pp. 1809-1837, (2012); Hertel L., Collado J., Sadowski P.J., Baldi P., Sherpa: Hyperparameter Optimization for Machine Learning Models, 32nd Conference on Neural Information Processing Systems (NIPS 2018), (2018); Ho T.K., Basu M., Complexity measures of supervised classification problems, IEEE Transactions on Pattern Analysis and Machine Intelligence, 24, 3, pp. 289-300, (2002); Hoffman M., Shahriari B., Freitas N., On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning, Artificial Intelligence and Statistics, pp. 365-374, (2014); Hofmann M., Klinkenberg R., RapidMiner: Data mining use cases and business analytics applications, (2016); Hollmann N., Muller S., Hutter F., Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering, ArXiv, (2023); Hoos H.H., Neumann F., Trautmann H., Automated Algorithm Selection and Configuration (Dagstuhl Seminar 16412), Dagstuhl Reports, 6, 10, pp. 33-74, (2017); Horn D., Wagner T., Biermann D., Weihs C., Bischl B., Model-Based Multi-objective Optimization: Taxonomy, Multi-Point Proposal, Toolbox and Benchmark, Lecture Notes in Computer Science, pp. 64-78, (2015); Hoste V., Hendrickx I., Daelemans W., van den Bosch A., Parameter optimization for machine-learning of word sense disambiguation, Natural Language Engineering, 8, 4, pp. 311-325, (2002); Hu H., Langford J., Caruana R., Horvitz E., Dey D., Macro Neural Architecture Search Revisited, 2nd Workshop on Meta-Learning at NeurIPS, (2018); Hu Y.-J., Huang S.-W., Challenges of automated machine learning on causal impact analytics for policy evaluation, 2017 2nd International Conference on Telecommunication and Networks (TEL-NET), (2017); Hutter F., Hoos H.H., Leyton-Brown K., Stuetzle T., ParamILS: An Automatic Algorithm Configuration Framework, Journal of Artificial Intelligence Research, 36, pp. 267-306, (2009); Hutter F., Bartz-Beielstein T., Hoos H.H., Leyton-Brown K., Murphy K.P., Sequential Model-Based Parameter Optimization: an Experimental Investigation of Automated and Interactive Approaches, Experimental Methods for the Analysis of Optimization Algorithms, pp. 363-414, (2010); Hutter F., Hoos H., Leyton-Brown K., An Efficient Approach for Assessing Hyperparameter Importance, Proceedings of the 31st International Conference on Machine Learning, 32, 1, pp. 754-762, (2014); Hutter F., Hoos H.H., Leyton-Brown K., Sequential Model-Based Optimization for General Algorithm Configuration, International conference on learning and intelligent optimization, pp. 507-523, (2011); Hutter F., Hoos H.H., Leyton-Brown K., Murphy K.P., An experimental investigation of model-based parameter optimisation: SPO and beyond, Proceedings of the 11th Annual conference on Genetic and evolutionary computation - GECCO’09, (2009); Hutter F., Kotthoff L., Vanschoren J., Automated Machine Learning: Methods, Systems, Challenges, (2019); Hutter F., Lucke J., Schmidt-Thieme L., Beyond Manual Tuning of Hyperparameters, KI - Künstliche Intelligenz, 29, 4, pp. 329-337, (2015); Hutter F., Xu L., Hoos H.H., Leyton-Brown K., Algorithm runtime prediction: Methods & evaluation, Artificial Intelligence, 206, pp. 79-111, (2014); Imbrea A., An empirical comparison of automated machine learning techniques for data streams, (2020); Jamieson K., Talwalkar A., Non-stochastic Best Arm Identification and Hyperparameter Optimization, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, 51, pp. 240-248, (2016); Jankowski N., Duch W., Grabczewski K., Meta-learning in computational intelligence, 358, (2011)","","Now Publishers Inc","","","","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85189861293"
"Jin M.; Shahriar S.; Tufano M.; Shi X.; Lu S.; Sundaresan N.; Svyatkovskiy A.","Jin, Matthew (57566373500); Shahriar, Syed (58151241600); Tufano, Michele (57651427900); Shi, Xin (57565396400); Lu, Shuai (57204470965); Sundaresan, Neel (7005588783); Svyatkovskiy, Alexey (36640625700)","57566373500; 58151241600; 57651427900; 57565396400; 57204470965; 7005588783; 36640625700","InferFix: End-to-End Program Repair with LLMs","2023","ESEC/FSE 2023 - Proceedings of the 31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering","","","","1646","1656","10","0","10.1145/3611643.3613892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180554634&doi=10.1145%2f3611643.3613892&partnerID=40&md5=528a86559e550f7c698f3e2b189da3db","Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs. combines a Retriever - transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator - an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow. © 2023 ACM.","finetuning; Program repair; prompt augmentation; static analyses","Java programming language; Learning systems; Life cycle; Program debugging; Repair; Software design; End to end; Finetuning; Language model; Program repair; Prompt augmentation; Software defects; Software development costs; Software development life-cycle; Static analyze; Static analyzers; Static analysis","acs-aem-common, (2023); Allamanis M., Jackson-Flux H., Brockschmidt M., Self-Supervised Bug Detection and Repair, Advances in Neural Information Processing Systems, 34, pp. 27865-27876, (2021); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language Models are Few-Shot Learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language Models are Few-Shot Learners, Advances in Neural Information Processing Systems, 33, pp. 1877-1901, (2020); Chakraborty S., Ding Y., Allamanis M., Ray B., Codit: Code editing with tree-based neural models, IEEE Transactions on Software Engineering, (2020); Chen M., Tworek J., Jun H., Yuan Q., De Oliveira Pinto H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Petroski Such F., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Hebgen Guss W., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Chen Z., Kommrusch S., Tufano M., Pouchet L., Poshyvanyk D., Martin M., SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair, IEEE Transactions on Software Engineering, 47, pp. 1943-1959, (2021); Chowdhery A., Narang S., Devlin J., Bosma M., Mishra G., Roberts A., Barham P., Won Chung H., Sutton C., Gehrmann S., Schuh P., Shi K., Tsvyashchenko S., Maynez J., Rao A., Barnes P., Tay Y., Shazeer N., Prabhakaran V., Reif E., Du N., Hutchinson B., Pope R., Bradbury J., Austin J., Isard M., Gur-Ari G., Yin P., Duke T., Levskaya A., Ghemawat S., Dev S., Michalewski H., Garcia X., Misra V., Robinson K., Fedus L., Zhou D., Ippolito D., Luan D., Lim H., Zoph B., Spiridonov A., Sepassi R., Dohan D., Agrawal S., Omernick M., Dai A.M., Sankaranarayana Pillai T., Pellat M., Lewkowycz A., Moreira E., Child R., Polozov O., Lee K., Zhou Z., Wang X., Saeta B., Diaz M., Firat O., Catasta M., Wei J., Meier-Hellstern K., Eck D., Dean J., Petrov S., Fiedel N., PaLM: Scaling Language Modeling with Pathways, (2022); Clement C., Lu S., Liu X., Tufano M., Drain D., Duan N., Sundaresan N., Svyatkovskiy A., Long-Range Modeling of Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 4713-4722, (2021); Cui L., Wu Y., Liu J., Yang S., Zhang Y., Template-Based Named Entity Recognition Using BART, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pp. 1835-1845, (2021); Devlin J., Chang M., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 4171-4186, (2019); Drain D., Wu C., Svyatkovskiy A., Sundaresan N., Generating Bug-Fixes Using Pretrained Transformers, Proceedings of the 5th ACM SIGPLAN International Symposium on Machine Programming (Virtual, Canada) (MAPS 2021), pp. 1-8, (2021); Ferenc R., Toth Z., Ladanyi G., Siket I., Gyimothy T., A public unified bug dataset for Java, Proceedings of the 14th international conference on predictive models and data analytics in software engineering, pp. 12-21, (2018); Fried D., Aghajanyan A., Lin J., Wang S., Wallace E., Shi F., Zhong R., Yih W., Zettlemoyer L., Lewis M., InCoder: A Generative Model for Code Infilling and Synthesis, (2022); Jiang J., Xiong Y., Zhang H., Gao Q., Chen X., Shaping program repair space with existing patches and similar code, Proceedings of the 27th ACM SIGSOFT international symposium on software testing and analysis, pp. 298-309, (2018); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 1161-1173, (2021); Joshi H., Cambronero J., Gulwani S., Le V., Radicek I., Verbruggen G., Repair Is Nearly Generation: Multilingual Program Repair with LLMs, (2022); Just R., Jalali D., Ernst M.D., Defects4J: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 international symposium on software testing and analysis, pp. 437-440, (2014); Karampatsis R., Sutton C., How often do singlestatement bugs occur? The manysstubs4j dataset, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 573-577, (2020); Karpukhin V., Oguz B., Min S., Lewis P., Wu L., Edunov S., Chen D., Yih W., Dense Passage Retrieval for Open-Domain Question Answering, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6769-6781, (2020); Li Y., Wang S., Nguyen T.N., Dlfix: Context-based code transformation learning for automated program repair, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 602-614, (2020); Lin D., Koppel J., Chen A., Solar-Lezama A., QuixBugs: A multi-lingual program repair benchmark set based on the Quixey Challenge, Proceedings Companion of the 2017 ACM SIGPLAN international conference on systems, programming, languages, and applications: Software for humanity, pp. 55-56, (2017); Liu P., Yuan W., Fu J., Jiang Z., Hayashi H., Neubig G., Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing, ACM Comput. Surv. (sep 2022), (2022); Liu P., Yuan W., Fu J., Jiang Z., Hayashi H., Neubig G., Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing, ACM Comput. Surv., 55, 9, (2023); Lu S., Duan N., Han H., Guo D., Hwang S.-W., Svyatkovskiy A., ReACC: A Retrieval-Augmented Code Completion Framework, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (volume 1: Long Papers), pp. 6227-6240, (2022); Lutellier T., Viet Pham H., Pang L., Li Y., Wei M., Tan L., Coconut: Combining context-aware neural translation models using ensemble for program repair, Proceedings of the 29th ACM SIGSOFT international symposium on software testing and analysis, pp. 101-114, (2020); Scaling Static Analyses at Facebook, (2023); InferSharp, (2023); Monperrus M., Automatic Software Repair: A Bibliography, ACM Comput. Surv., 51, 1, (2018); Panthaplackel S., Allamanis M., Brockschmidt M., Copy that! Editing Sequences by Copying Spans, AAAI, (2021); Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the Keyboard? Assessing the Security of GitHub Copilot's Code Contributions, (2021); Petroni F., Rocktaschel T., Riedel S., Lewis P., Bakhtin A., Wu Y., Miller A., Language Models as Knowledge Bases?, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 2463-2473, (2019); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); Ruder S., Peters M.E., Swayamdipta S., Wolf T., Transfer Learning in Natural Language Processing, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, pp. 15-18, (2019); Bener Shirin Akbarinasaji A., Caglayan B., Predicting bug-fixing time: A replication study using an open source software project, Journal of Systems and Software, pp. 173-186, (2018); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation, ACM Trans. Softw. Eng. Methodol., 28, 4, (2019); Van Den Oord A., Li Y., Vinyals O., Representation Learning with Contrastive Predictive Coding, (2018); Wei J., Wang X., Schuurmans D., Bosma M., Ichter B., Xia F., Chi E., Le Q., Zhou D., Chain of Thought Prompting Elicits Reasoning in Large Language Models, (2022); Wu Z., Xiong Y., Yu S.X., Lin D., Unsupervised Feature Learning via Non-parametric Instance Discrimination, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3733-3742, (2018); Zhu Q., Sun Z., Xiao Y., Zhang W., Yuan K., Xiong Y., Zhang L., A syntax-guided edit decoder for neural program repair, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 341-353, (2021)","Chandra S.; Blincoe K.; Tonella P.","Association for Computing Machinery, Inc","ACM SIGSOFT; Ant Group; et al.; Google; JetBrains; Meta","31st ACM Joint Meeting European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2023","3 December 2023 through 9 December 2023","San Francisco","195093","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85180554634"
"Asaad J.; Avksentieva E.","Asaad, Jameleh (58744629900); Avksentieva, Elena (57204910364)","58744629900; 57204910364","Review of ways to apply machine learning methods in software engineering","2023","E3S Web of Conferences","449","","07018","","","","0","10.1051/e3sconf/202344907018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178611846&doi=10.1051%2fe3sconf%2f202344907018&partnerID=40&md5=3860ddd6411e090ca8f071b063df3e81","This article reviews the integration of machine learning (ML) techniques into Software Engineering (SE) across various phases of the software development life cycle (SDLC). The purpose is to investigate the applications of ML in SE, analyze its methodologies, present findings, and draw conclusions regarding its impact. The study categorized ML applications in SE and assessed the performance of various ML algorithms. Authors identified ML applications in SDLC phases, including requirements analysis, design, implementation, testing, and maintenance. ML algorithms, such as supervised and unsupervised learning, are employed for tasks like software requirement identification, design pattern recognition, code generation, and automated testing. In summary, we find that ML-based techniques are experiencing a substantial surge in adoption within the field of software engineering. Nevertheless, it is evident that substantial endeavors are needed to establish thorough comparisons and synergies among these approaches, perform meaningful evaluations grounded in detailed real-world implementations that are applicable to industrial software development. Therefore, our key takeaway is the necessity for a shift in focus towards reproducible research, prioritizing this over isolated novel concepts. Failure to do so may result in the limited practical implementation of these promising applications. © 2023 EDP Sciences. All rights reserved.","","","Lwakatare L.E., Raj A., Bosch J., Olsson H.H., Crnkovic I., Kruchten P., Fraser S., Coallier F., Agile Processes in Software Engineering and Extreme Programming. XP 2019. Lecture Notes in Business Information Processing, 355, pp. 227-243, (2019); Shehab M., Abualigah L., Jarrah M.I., Alomari O.A., Daoud M.S., Artificial intelligence in software engineering and inverse, International Journal of Computer Integrated Manufacturing, 33, 1011, pp. 1129-1144, (2020); Durelli V.H., Durelli R.S., Borges S.S., Endo A.T., Eler M.M., Dias D.R., Guimaraes M.P., Machine learning applied to software testing: A systematic mapping study, IEEE Transactions on Reliability, 68, 3, pp. 1189-1212, (2019); Khomh F., Adams B., Cheng J., Fokaefs M., Antoniol G., Software engineering for machine-learning applications: The road ahead, IEEE Software, 35, 5, pp. 81-84, (2018); Maneerat N., Muenchaisri P., Bad-smell Prediction from Software Design Model Using Machine Learning Techniques, pp. 331-336, (2011); Talele P., Phalnikar R., Joshi A., Khosravy M., Gupta N., Machine Learning for Predictive Analysis. Lecture Notes in Networks and Systems, 141, pp. 257-267, (2021); Zou J., Xu L., Guo W., Yan M., Yang D., Zhang X., Which Non-functional Requirements Do Developers Focuson? An Empirical Study on Stack Overflow Using Topic Analysis, pp. 446-449, (2015); Ahmad A., Li K., Feng C., Sun T., An empirical study on how iOS developers report quality Aspects on stack overflow, International Journal of Machine Learning and Computing, 8, 5, pp. 501-506, (2018); Treude C., Barzilay O., Storey M.A., How Do Programmers Ask and Answer Questions on the Web? Nier Track, pp. 804-807, (2011); Zou J., Xu L., Yang M., Zhang X., Yang D., Towards comprehending the non-functional requirements through developers'eyes: An exploration of stack overflow using topic analysis, Information and Software Technology, 84, pp. 19-32, (2017); Ahmad A., Feng C., Li K., Asim S.M., Sun T., Toward empirically investigating nonfunctional requirements of iOS developers on stack overflow, IEEE Access, 7, pp. 61145-61169, (2019); Yin H., Pfahl D., A Preliminary Study on the Suitability of Stack Overflow for Open Innovation in Requirements Engineering, pp. 45-49, (2017); Bajaj K., Pattabiraman K., Mesbah A., Mining Questions Asked by Web Developers, pp. 112-121, (2014); Pinto G., Castor F., Liu Y.D., Mining Questions about Software Energy Consumption, pp. 22-31, (2014); Xiao M., Yin G., Wang T., Yang C., Chen M., Liu L., Aoyama M., Requirements Engineering in the Big Data Era. Communications in Computer and Information Science, 558, pp. 64-74, (2015); Rosen C., Shihab E., What are mobile developers asking about? A large-scale study using stack overflow, Empirical Software Engineering, 21, 3, pp. 1192-1223, (2016); Abad Z.S.H., Shymka A., Pant S., Currie A., Ruhe G., 2016 IEEE 24th International Requirements Engineering Conference Workshops (REW), pp. 334-343, (2016); Pinto G.H., Kamei F., What Do Programmers Say about Refactoring Tools? An Empirical Investigation of Stack Overflow, pp. 33-36, (2013); Jivani A.G., A comparative study of stemming algorithms, International Journal of Computer Applications in Technology, 2, 6, pp. 1930-1938, (2011); Khan A., Baharudin B., Lee L.H., Khan K., A review of machine learning algorithms for text-documents classification, Journal of Advances in Information Technology, 1, 1, pp. 4-20, (2010); Fernandes E., Oliveira J., Vale G., Paiva T., Figueiredo E., A Review-based Comparative Study of Bad Smell Detection Tools, pp. 1-12, (2016); Ferenc R., Beszedes A., Fulop L., Lele J., Design Pattern Mining Enhanced by Machine Learning, pp. 295-304, (2005); Zanoni M., Fontana F.A., Stella F., On applying machine learning techniques for design pattern detection, Journal of Systems and Software, 103, pp. 102-117, (2015); Selvarani R., Mangayarkarasi P., A dynamic optimization technique for redesigning OO software for reusability, ACM SIGSOFT Software Engineering Notes, 40, 2, pp. 1-6, (2015); Agashe R., Iyer S., Zettlemoyer L., Juice: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation, (2019); Shin E.C., Allamanis M., Brockschmidt M., Polozov A., Program Synthesis and Semantic Parsing with Learned Code Idioms, (2019); Takahashi A., Shiina H., Kobayashi N., Automatic Generation of Program Comments Based on Problem Statements for Computational Thinking, pp. 629-634, (2019); Shido Y., Kobayashi Y., Yamamoto A., Miyamoto A., Matsumura T., Automatic Source Code Summarization with Extended Tree-lstm, pp. 1-8, (2019); Tufano M., Watson C., Bavota G., Penta M.D., White M., Poshyvanyk D., An empirical study on learning bug-fixing patches in the wild via neural machine translation, ACM Transactions on Software Engineering and Methodology, 28, 4, pp. 1-29, (2019); Zhu Z., Xue Z., Yuan Z., Jawahar C., Li H., Mori G., Schindler K., Computer Vision-ACCV 2018. ACCV 2018. Lecture Notes in Computer Science, 11366, pp. 181-196, (2019); Kim Y., Kim H., Translating CUDA to Opencl for Hardware Generation Using Neural Machine Translation, pp. 285-286, (2019); Gozalo-Brizuela R., Garrido-Merchan E.C., ChatGPT is not all you need, A State of the Art Review of Large Generative AI Models, (2023); Chen M., Tworek J., Jun H., Yuan Q., Pinto D.P.H.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F.P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W.H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Li Y., Choi D., Chung J., Kushman N., Schrittwieser J., Leblond R., Eccles T., Keeling J., Gimeno F., Dal Lago A., Hubert T., Choy P., D'Autume C.D.M., Babuschkin I., Chen X., Huang P.-S., Welbl J., Gowal S., Cherepanov A., Molloy J., Mankowitz D.J., Robson E.S., Kohli P., De Freitas N., Kavukcuoglu K., Vinyals O., Competition-level code generation with alphacode, Science, 378, 6624, pp. 1092-1097, (2022); Bhavya B., Xiong J., Zhai C., Analogy Generation by Prompting Large Language Models: A Case Study of InstructGPT, (2022); Dehaerne E., Dey B., Halder S., De Gendt S., Meert W., Code generation using machine learning: A systematic review, IEEE Access, 10, pp. 82434-82455, (2022); Alaqail H., Ahmed S., Overview of software testing standard ISO/IEC/IEEE 29119, International Journal of Computer Science and Network Securit, 18, 2, pp. 112-116, (2018); Baskiotis N., Sebag M., Gaudel M.C., Gouraud S.D., A Machine Learning Approach for Statistical Software Testing, pp. 2274-2279, (2007); Moghadam M.H., Saadatmand M., Borg M., Bohlin M., Lisper B., Machine Learning to Guide Performance Testing: An Autonomous Test Framework, pp. 164-167, (2019); Tuncali C.E., Fainekos G., Ito H., Kapinski J., Simulation-based Adversarial Test Generation for Autonomous Vehicles with Machine Learning Components, pp. 1555-1562, (2018); Battina D.S., Artificial intelligence in software test automation: A systematic literature review, International Journal of Emerging Technologies and Innovative Research, 6, 12, pp. 1329-1332; Rankin C., The software testing automation framework, IBM Systems Journal, 41, 1, pp. 126-139, (2002); Briand L.C., Labiche Y., Bawar Z., 2008 the Eighth International Conference on Quality Software, pp. 135-144, (2008); IEEE Standard for Software Maintenance, pp. 1-45, (1993); Levin S., Yehudai A., Towards Software Analytics: Modeling Maintenance Activities, (2019); Kukkar A., Mohana R., Kumar Y., Nayyar A., Bilal M., Kwak K.S., Duplicate bug report detection and classification system based on deep learning technique, IEEE Access, 8, pp. 200749-200763, (2020); Immaculate S.D., Begam M.F., Floramary M., Software Bug Prediction Using Supervised Machine Learning Algorithms, pp. 1-7, (2019); Sidhu B.K., Singh K., Sharma N., A machine learning approach to software model refactoring, International Journal of Computers and Applications, 44, 2, pp. 166-177, (2022); Akhmetshin E., Klochko E., Andryushchenko I., A novel machine learning algorithms to assist traders and investors on forecasting stock market launches, Lecture Notes in Networks and Systems, 758, pp. 354-362; Abdullaev I.S., Prodanova N.A., Bhaskar K.A., Lydia E.L., Kadry S., Kim J., Task offloading and resource allocation in iot based mobile edge computing using deep learning, Computers, Materials & Continua, 76, 2, pp. 1463-1477, (2023)","Abdullayev I.; Kukhar V.; Akhmetshin E.; Akhmetshin E.; Bekjanov D.; Carballo-Penela A.","EDP Sciences","","2023 International Scientific and Practical Conference on Priority Directions of Complex Socio-Economic Development of the Region, PDSED 2023","27 April 2023 through 29 April 2023","Urgench","194692","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85178611846"
"Song W.; Gan L.; Bao T.","Song, Wei (57219623872); Gan, Lu (58766135400); Bao, Tie (16063370700)","57219623872; 58766135400; 16063370700","Software Defect Prediction via Code Language Models","2023","2023 3rd International Conference on Communication Technology and Information Technology, ICCTIT 2023","","","","97","102","5","0","10.1109/ICCTIT60726.2023.10435711","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186959703&doi=10.1109%2fICCTIT60726.2023.10435711&partnerID=40&md5=5db616d84f1902f7a0b51771486e0039","Software defect prediction has been effective practice to improve software quality and avoid attacks. Traditional defect prediction models with static or other features cannot understand syntactic and semantic structures well. Recently, large language models like GPT-series show impressive energy on considerable number of tasks. In the realm of software engineering, it has been shown that code language models largely benefit a broad set of code-related downstream tasks. In this paper, we employ code language models with distinct architectures for defect prediction. we propose a unified bi-modal input representation to enhance the comprehension of semantic information. Furthermore, a new bimodal dataset is proposed based on the PROMISE repository and the engineering files. A large number of experiments are conducted on both within and cross project for evaluation and comparison. The results demonstrate the effectiveness of our proposed method for software defect prediction, which outperforms the state-of-the-art baselines. Among the three architectures, encoder-only achieve the most effective and efficient. © 2023 IEEE.","bimodal representation; code language models; semantic information; software defect prediction","Computational linguistics; Computer software selection and evaluation; Defects; Forecasting; Bimodal representation; Code language model; Code languages; Defect prediction models; Effective practices; Language model; Semantics Information; Software defect prediction; Software Quality; Syntactic structure; Semantics","Fenton N.E., Neil M., A critique of software defect prediction models, IEEE Transactions on software engineering, 25, 5, pp. 675-689, (1999); Perera A., Aleti A., Turhan B., Bohme M., An experimental assessment of using theoretical defect predictors to guide search-based software testing, IEEE Transactions on Software Engineering, 49, 1, pp. 131-146, (2022); Ferreira F., Silva L.L., Valente M.T., Software engineering meets deep learning: a mapping study, Proceedings of the 36th annual ACM symposium on applied computing, pp. 1542-1549, (2021); Dam H.K., Tran T., Pham T., Ng S.W., Grundy J., Ghose A., Automatic feature learning for predicting vulnerable software components, IEEE Transactions on Software Engineering, 47, 1, pp. 67-85, (2021); Deng J., Lu L., Qiu S., Software defect prediction via LSTM, IET software, 14, 4, pp. 443-450, (2020); Qiu S., Huang H., Jiang W., Zhang F., Zhou W., Defect prediction via tree-based encoding with hybrid granularity for software sustainability, IEEE Transactions on Sustainable Computing, (2023); Zhao G., Huang J., Deepsim: deep learning code functional similarity, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 141-151, (2018); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Transactions on Software Engineering, 46, 12, pp. 1267-1293, (2018); Zhao Z., Yang B., Li G., Liu H., Jin Z., Precise learning of source code contextual semantics via hierarchical dependence structure and graph attention networks, Journal of Systems and Software, 184, (2022); Vaswani A., Et al., Attention is all you need, (2017); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: pre-training of deep bidirectional Transformers for language understanding, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, (2019); Liu Y., Et al., Roberta: A robustly optimized bert pretraining approach, (2019); Radford A., Narasimhan K., Salimans T., Sutskever I., Improving language understanding by generative pre-training, (2018); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language models are unsupervised multitask learners; Brown T.B., Et al., Language models are few-shot learners, (2020); McCabe T.J., A complexity measure, IEEE Transactions on Software Engineering, SE-2, 4, pp. 308-320, (1976); Elements of software science (Operating and programming systems series), Guide books; Jureczko M., Spinellis D.D., Using object-oriented design metrics to Predict Software Defects; Compressed C4.5 models for software defect prediction; Xu Z., Et al., Software defect prediction based on kernel PCA and weighted extreme learning machine, Information and Software Technology, 106, pp. 182-200, (2019); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, 2017 IEEE International Conference on Software Quality, Reliability and Security (QRS), pp. 318-328, (2017); Uddin M.N., Li B., Ali Z., Kefalas P., Khan I., Zada I., Software defect prediction employing BiLSTM and BERT-based semantic feature, Soft Comput, 26, 16, pp. 7877-7891, (2022); Fu M., Tantithamthavorn C., Linevul: A transformer-based line-level vulnerability prediction, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 608-620, (2022); Liu J., Ai J., Lu M., Wang J., Shi H., Semantic feature learning for software defect prediction from source code and external knowledge, Journal of Systems and Software, 204, (2023); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and evaluating contextual embedding of source code, International conference on machine learning, PMLR, pp. 5110-5121, (2020); Buratti L., Et al., Exploring software naturalness through neural language models, (2020); Feng Z., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Lu S., Et al., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation, the Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1), (2021); Tunstall L., von Werra L., Wolf T., Natural language processing with Transformers, (2022); Chen M., Et al., Evaluating large language models trained on code, (2021); Nijkamp E., Et al., CodeGen: An open large language model for code with multi-Turn program synthesis, (2023); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., Unixcoder: Unified cross-modal pre-training for code representation, (2022); Wang Y., Wang W., Joty S., Hoi S.C., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Wang Y., Le H., Gotmare A.D., Bui N.D., Li J., Hoi S.C., Codet5+: Open code large language models for code understanding and generation, (2023); Jureczko M., Madeyski L., Towards identifying software project clusters with regard to defect prediction, Proceedings of the 6th international conference on predictive models in software engineering, pp. 1-10, (2010); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proceedings of the ACM on Programming Languages, 3, OOPSLA, pp. 1-30, (2019)","","Institute of Electrical and Electronics Engineers Inc.","IEEE","3rd International Conference on Communication Technology and Information Technology, ICCTIT 2023","24 November 2023 through 26 November 2023","Virtual, Online","197524","Conference paper","Final","","Scopus","2-s2.0-85186959703"
"Scutari M.; Malvestio M.","Scutari, Marco (55865783400); Malvestio, Mauro (58846076200)","55865783400; 58846076200","The Pragmatic Programmer for Machine Learning: Engineering Analytics and Data Science Solutions","2023","The Pragmatic Programmer for Machine Learning: Engineering Analytics and Data Science Solutions","","","","1","340","339","0","10.1201/9780429292835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183218511&doi=10.1201%2f9780429292835&partnerID=40&md5=8d4692d72420d4b30ed26d6a7d295edb","Machine learning has redefined the way we work with data and is increasingly becoming an indispensable part of everyday life. The Pragmatic Programmer for Machine Learning: Engineering Analytics and Data Science Solutions discusses how modern software engineering practices are part of this revolution both conceptually and in practical applictions. Comprising a broad overview of how to design machine learning pipelines as well as the state-of-the-art tools we use to make them, this book provides a multi-disciplinary view of how traditional software engineering can be adapted to and integrated with the workflows of domain experts and probabilistic models. From choosing the right hardware to designing effective pipelines architectures and adopting software development best practices, this guide will appeal to machine learning and data science specialists, whilst also laying out key high-level principlesin a way that is approachable for students of computer science and aspiring programmers. © 2023 Marco Scutari and Mauro Malvestio.","","","Abid A., Abdalla A., Ali A., Khan D., Alfozan A., Zou J., Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild, (2022); Aggarwal C.C., Machine Learning for Text, (2018); Alam S., Balan L., Chan N.L., Comym G., Dada Y., Danov I., Hoang L., Kanchwala R., Klein J., Milne A., Schwarzmann J., Theisen M., Wong S., Kedro, (2022); nbdime - Diffing and Merging of Jupyter Notebooks, (2022); Alquraan A., Takruri H., Alfatafta M., Al-Kiswany S., An Analysis of Network-Partitioning Failures in Cloud Systems, 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18), pp. 51-68, (2018); Altair: Declarative Visualization in Python, (2022); Dynamic A/B Testing for Machine Learning Models with Amazon SageMaker MLOps Projects, (2021); Amazon Redshift Documentation, (2022); Amazon SageMaker Examples, (2022); AWS Cloud9 Documentation, (2022); Machine Learning: Amazon Sagemaker, (2022); Amazon Elastic Kubernetes Service Documentation, (2022); Amazon Machine Images (AMI), (2022); AWS Trainium, (2022); Conda for Data Scientists, (2022); Package, Dependency and Environment Management for Any Language, (2022); Anderson E., Bai Z., Bishof C., Blackford S., Demmel J., Dongarra J., Du Croz J., Greenbaum A., Hammarling S., McKenney A., Sorensen D., LAPACK Users' Guide, (1999); Ansible Documentation, (2022); Celery Executor, (2022); Impala Documentation, (2022); TensorFlow 2 Conversion, (2022); Trivy Documentation, (2022); Argo Workflow Documentation, (2022); Arisholm E., Gallis H., Dyba T., Sjoberg D.I.K., Evaluating Pair Programming with Respect to System Complexity and Programmer Expertise, IEEE Transactions on Software Engineering, 33, 2, pp. 5-86, (2007); Arpteg A., Brinne B., Crnkovic-Friis L., Bosch J., Software Engineering Challenges of Deep Learning, Euromicro Conference on Software Engineering and Advanced Applications, pp. 50-59, (2018); arXiv API Access, (2022); A hackable text editor for the 21st Century, (2022); Ayer A., git-crypt: Transparent File Encryption in Git, (2022); Batchelder N., Et al., A Static Type Analyzer for Python Code, (2022); Bates D., Maechler M., Matrix: Sparse and Dense Matrix Classes and Methods, (2021); Amazon Scrapped 'Sexist AI' Tool, (2018); Facebook Apology as AI Labels Black Men 'Primates', (2021); Twitter Finds Racial Bias in Image-Cropping AI, (2021); Beam A.L., Manrai A.K., Ghassemi M., Challenges to the Reproducibility of Machine Learning Models in Health Care, Journal of the American Medical Association, 323, 4, pp. 305-306, (2020); Beck K., Test-Driven Development by Example, (2002); Beck K., Beedle M., Van Bennekum A., Cockburn A., Cunningham W., Fowler M., Grenning J., Highsmith J., Hunt A., Jeffries R., Kern J., The Agile Manifesto, (2001); Bento M.L., Unified Model Serving Framework, (2022); Bezanson J., Karpinski S., Shah V.B., Et al., Style Guide: The Julia Language, (2022); Bhupinder K., Dugre M., Hanna A., Glatard T., An Analysis of Security Vulnerabilities in Container Images for Scientific Data Analysis, GigaScience, 10, 6, (2021); Bishop C.M., Training with Noise is Equivalent to Tikhonov Regularization, Neural Computation, 7, 1, pp. 108-116, (1995); Blackford L.S., Demmel J., Dongarra J., Duff I., Hammarling S., Henry G., Heroux K.L., Lumsdaine A., Petitet A., Pozo R., Remington K., Whaley R.C., An Updated Set of Basic Linear Algebra Subprograms (BLAS), ACM Transactions on Mathematical Software, 28, 2, pp. 135-151, (2002); Blagotic A., Valle-Jones D., Breen J., Lundborg J., White J.M., Bode J., White K., Mueller K., Redaelli M., Lorang N., Schalk P., Schneider D., Hepp G., Jamile Z., ProjectTemplate: Automates the Creation of New Statistical Analysis Projects, (2021); Blei D.M., Kucukelbir A., McAuliffe J.D., Variational Inference: A Review for Statisticians, Journal of American Statistical Association, 112, 518, pp. 859-877, (2017); Blischak J.D., Carbonetto P., Stephens M., workflowr: A Framework for Reproducible and Collaborative Data Science, (2022); Bogner J., Verdecchia R., Gerostathopoulos I., Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study, 2021 IEEE/ACM International Conference on Technical Debt (TechDebt), pp. 64-73, (2021); Bokeh Documentation, (2022); Bonawitz K., Eichner H., Grieskamp W., Huba D., Ingerman A., Ivanov V., Kiddon C., Koneccny J., Mazzocchi S., McMahan H.B., Van Overveldt T., Petrou D., Ramage D., Roselander J., Towards Federated Learning at Scale: System Design, Proceedings of Machine Learning and Systems, pp. 374-388, (2019); Braiek H.B., Khomh F., On Testing Machine Learning Programs, Journal of Systems and Software, 164, (2020); Sphinx: Python Documentation Generator, (2022); Brass P., Advanced Data Structures, (2008); Breck E., Cai S., Nielsen E., Salib M., Sculley D., The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction, IEEE International Conference on Big Data, pp. 1123-1132, (2017); Breiman L., Out-of-Bag Estimation, (1996); Breiman L., Random Forests, Machine Learning, 45, 1, pp. 5-32, (2001); Breiman L., Statistical Modeling: The Two Cultures, Statistical Science, 16, 3, pp. 199-231, (2001); Callon R., The Twelve Networking Truths, (1996); Cloud-Init Documentation, (2022); MicroK8s Documentation, (2022); Carpenter B., Gelman A., Hoffman M.D., Lee D., Goodrich B., Betancourt M., Brubaker M., Guo J., Li P., Riddell A., Stan: A Probabilistic Programming Language, Journal of Statistical Software, 76, 1, pp. 1-32, (2017); Cass S., Taking AI to the Edge: Google's TPU Now Comes in a Maker-Friendly Package, IEEE Spectrum, 56, 5, pp. 16-17, (2019); Castillo E., Gutierrez J.M., Hadi A.S., Expert Systems and Probabilistic Network Models, (1997); Chang A.C., Li P., Is Economics Research Replicable? Sixty Published Papers from Thirteen Journals Say 'Usually Not, Federal Reserve Board Finance and Economics Discussion Paper, (2015); Chang W., Cheng J., Allaire J.J., Sievert C., Schloerke B., Xie Y., Allen J., McPherson J., Dipert A., Borges B., shiny: Web Application Framework for R, (2022); Cheney J., Chiticariu L., Tan W.C., Provenance in Databases: Why, How and Where, Foundations and Trends in Databases, 1, 4, pp. 379-474, (2009); Clements P., Bachmann F., Bass L., Garlan D., Ivers J., Little R., Merson P., Nord R., Stafford J., Documenting Software Architectures: Views and Beyond, (2011); Cloudera: The Hybrid Data Company, (2022); Cohen A.G.V., Pavlick E., Tellex S., OpenGPT-2: We Replicated GPT-2 Because You Can Too, (2019); Comet Documentation, (2022); Cormen T.H., Algorithms Unlocked, (2013); Cortes-Ortuno D., Laslett O., Kluyver T., Fauske V., Albert M., Min R.K., Hovorka O., Fangohr H., IPython Notebook Validation for py.test: Documentation, (2022); The Comprehensive R Archive Network, (2022); Crook J., Banasik J., Does Reject Inference Really Improve the Performance of Application Scoring Models?, Journal of Banking and Finance, 28, pp. 857-874, (2004); Crosley T., A Python Utility and Library to Sort Imports, (2022); Cunningham W., The WyCash Portfolio Management System, Addendum to the Proceedings of ACM Object-Oriented Programming, Systems, Languages & Applications Conference, pp. 29-30, (1992); Cunningham W., Ward Explains the Debt Metaphor, (2011); Welcome to the DagsHub Docs, (2022); Databricks Documentation, (2022); Pair Programming vs. Solo Programming: What Do We Know After 15 Years of Research?, Proceedings of the Annual Hawaii International Conference on System Sciences, pp. 5398-5406, (2016); Devlin J., Chang M.W., Lee K., Toutanova K., BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NNACL-HLT), pp. 4171-4186, (2019); Dimakopoulou M., Zhou Z., Athey S., Imbens G., Estimation Considerations in Contextual Bandits, (2018); Dimakopoulou M., Zhou Z., Athey S., Imbens G., Balanced Linear Contextual Bandits, Proceedings of the AAAI Conference on Artificial Intelligence, pp. 3445-3453, (2019); Open Virtualization Format, (2022); Docker, (2022); Docker Registry HTTP API V2 Documentation, (2022); Overview of Docker Compose, (2022); Dusserre E., Padro M., Bigger Does Not Mean Better! We Prefer Specificity, Proceedings of the 12th International Conference on Computational Semantics, pp. 1-6, (2017); Duvall P.M., Matyas S., Glover A., Continuous Integration: Improving Software Quality and Reducing Risk, (2007); Che E., Run your favorite IDE on Kubernetes, (2022); Desktop IDEs, (2022); Theia: Cloud & Desktop IDE, (2022); Edmundson A., The Rise (and Lessons Learned) of ML Models to Personalize Content on Home, (2021); Free and Open Search: The Creators of Elasticsearch, ELK & Kibana, (2022); Dagster Documentation, (2022); Espe L., Jindal A., Podolskiy V., Gerndt M., Performance Evaluation of Container Runtimes, Proceedings of the 10th International Conference on Cloud Computing and Services Science, pp. 273-281, (2020); Espeholt L., Soyer H., Munos R., Simonyan K., Mnih V., Ward T., Doron Y., Firoiu V., Harley T., Dunning I., Legg S., Kavukcuoglu K., IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures, Proceedings of the 35th International Conference on Machine Learning (ICML), pp. 1407-1416, (2018); OAuth 2.0, (2022); Evans E., Domain-Driven Design: Tackling Complexity in the Heart of Software, (2003); Spacy: Industrial-Strength Natural Language Processing, (2021); Feast Documentation, (2022); Fenniak M., PyPDF2 Documentation, (2022); Fernandez A., Garcia S., Herrera F., Chawla N.V., SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-Year Anniversary, Journal of Artificial Intelligence Research, 61, pp. 863-905, (2018); Firke S., Denney B., Haid C., Knight R., Grosser M., Zadra J., janitor: Simple Tools for Examining and Cleaning Dirty Data, (2022); Airtable Is a Modern Spreadsheet Platform with Database Functionalities, (2022); Fortin P., Fleury A., Lemaire F., Monagan M., High- Performance SIMD Modular Arithmetic for Polynomial Evaluation, Concurrency and Computation: Practice and Experience, 33, 16, (2021); Fowler M., UML Distilled, (2003); Fowler M., Refactoring: Improving the Design of Existing Code, (2018); Galassi M., Davies J., Theiler J., Gough B., Jungman G., Alken P., Booth M., Rossi F., Ulerich R., GNU Scientific Library, (2021); Gama J., Zliobaite I., Bifet A., Pechenizkiy M., Bouchachia A., A Survey on Concept Drift Adaptation, ACM Computing Surveys, 46, 4, (2014); Ganiev A., Chapin C., Andrade A., Liu C., An Architecture for Accelerated Large-Scale Inference of Transformer-Based Language Models, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics, pp. 163-169, (2021); Gelman A., Carlin B., Stern H.S., Dunson D.B., Vehtari A., Bayesian Data Analysis, (2013); Ghahramani Z., Probabilistic Machine Learning and Artificial Intelligence, Nature, 521, pp. 452-459, (2015); GitHub Codespaces, (2022); Storing Workflow Data as Artifacts, (2022); Working with the Container Registry, (2022); GitLab Artifacts, (2022); GitLab Container Registry, (2022); GitLab Runner Documentation, (2022); Group Direction: MLOps, (2022); What Is GitOps?, (2022); Gitpod: Always Ready to Code, (2022); GNU EMacs, (2022); Gong M., Xie Y., Pan K., Feng K., A Survey on Differentially Private Machine Learning, IEEE Computational Intelligence Magazine, 15, 2, pp. 49-64, (2020); Goodfellow I., Bengio Y., Courville A., Deep Learning, (2016); Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Courville A., Bengio Y., Generative Adversarial Nets, Advances in Neural Information Processing Systems (NIPS), pp. 2672-2680, (2014); Goodger D., van Rossum G., PEP 257: Docstring Conventions, (2022); BigQuery Documentation, (2022); Deep Learning Containers, (2022); Google Kubernetes Engine, (2022); Google Python Style Guide, (2022); repo: The Multiple Git Repository Tool, (2022); Vertex AI Documentation, (2022); Welcome to Colab!, (2022); Grafana Loki Documentation, (2022); Grafana: The Open Observability Platform, (2022); Greenfeld A.R., Cookiecutter Data Science, (2022); Gregg B., Systems Performance: Enterprise and the Cloud, (2021); Grotov K., Titov S., Sotnikov V., Golubev Y., Bryksin T., A Large-Scale Comparison of Python Code in Jupyter Notebooks and Scripts, Proceedings of the 19th Working Conference on Mining Software Repositories, pp. 1-12, (2022); Groves R.M., Fowler F.J., Couper M.P., Lepkowski J.M., Singer E., Tourangeau R., Survey Methodology, (2009); Hammant P., Trunk Based Development, (2020); Hao J., Anang T.J., Kim K., An Empirical Analysis of VM Startup Times in Public IaaS Clouds: An Extended Report, Proceedings of the 14th IEEE International Conference on Cloud Computing, pp. 398-403, (2021); Harbor Documentation, (2022); Harris C.R., Millman K.J., van der Walt S.J., Gommers R., Virtanen P., Cournapeau D., Wieser E., Taylor J., Berg S., Smith N.J., Kern R., Picus M., Hoyer S., van Kerkwijk M.H., Brett M., Haldane A., Fernandez del Rio J., Wiebe M., Peterson P., Gerard-Marchant P., Sheppard K., Reddy T., Weckesser W., Abbasi H., Gohlke C., Oliphant T.E., Array Programming with NumPy, Nature, 585, 7285, pp. 357-362, (2020); Data Scientist: The Sexiest Job of the 21st Century, (2012); Packer Documentation, (2022); Terraform Documentation, (2022); Terraform Registry, (2022); Vagrant Documentation, (2022); Hastie T., Tibshirani R., Friedman J., The Elements of Statistical Learning: Data Mining, Inference, and Prediction, (2009); Hazelwood K., Bird S., Brooks D., Chintala S., Diril U., Dzhulgakov D., Fawzy M., Jia B., Jia Y., Kalro A., Law J., Lee K., Lu J., Noordhuis P., Smelyanskiy M., Xiong L., Wang X., Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective, Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 620-629, (2018); He X., Zhao K., Chu X., AutoML: A Survey of the State-of-the-Art, Knowledge-Based Systems, 212, (2021); Hester J., Angly F., Hyde R., Chirico M., Ren K., Rosenstock A., A Linter for R Code, (2022); Panel User Guide, (2022); Hopsworks Documentation, (2022); Humble J., Farley D., Continuous Delivery, (2011); Hunt E., Tay, Microsoft's AI Chatbot, Gets a Crash Course in Racism from Twitter, (2016); Hunter J.D., Matplotlib API Reference, (2022); Intel oneAPI Math Kernel Library, (2021); CML Documentation, (2022); DVC: Data Version Control. Git for Data & Models, (2022); DVC Python API, (2022); MLEM Documentation, (2022); Jacek C., Greiler M., Bird C., Panjer L., Coatta T., CodeFlow: Improving the Code Review Process at Microsoft, ACM Queue, 6, 5, pp. 1-20, (2018); Jain P., Mo X., Jain A., Subbaraj H., Durrani R., Tumanov A., Gonzalez J., Stoica I., Dynamic Space-Time Scheduling for GPU Inference, Workshop on Systems for ML and Open Source Software, NeurIPS 2018, pp. 1-9, (2018); A Command Line Tool to Run Jenkinsfile as a Function, (2022); Jenkins User Documentation, (2022); IntelliJ IDEA, (2022); PyCharm, (2022); Jouppi N.P., Yoon D.H., Kurian G., Li S., Patil N., Laudon J., Young C., Patterson D., A Domain-Specific Supercomputer for Training Deep Neural Networks, Communications of the ACM, 63, 7, pp. 67-78, (2020); Jouppi N.P., Young C., Patil N., Patterson D., A Domain-Specific Architexture for Deep Neural Networks, Communications of the ACM, 61, 9, pp. 50-59, (2018); An Implementation of the Microsoft Language Server Protocol for the Julia Language, (2022); Julia for Visual Studio Code, (2022); Pkg: Package Manager for the Julia Programming Language, (2022); Kaji N., Kobayashi H., Incremental Skip-gram Model with Negative Sampling, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 363-371, (2017); Kalnytskyi I., Poetry Documentation, (2022); Kalnytskyi I., sphinxcontrib-openapi Is a Sphinx Extension to Generate APIs Docs from OpenAPI, (2022); Kalnytskyi I., The Sphinx Extension that Renders OpenAPI Specs Using ReDoc, (2022); Kanagawa M., Hennig P., Sejdinovic D., Sriperumbudur B.K., Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences, (2018); Kang S., Jin R., Deng X., Kenett R.S., Challenges of Modeling and Analysis in Cybermanufacturing: A Review from a Machine Learning and Computation Perspective, Journal of Intelligent Manufacturing, (2021); Katal A., Wazid M., Goudar R.H., Big Data: Issues, Challenges, Tools and Good Practices, Proceedings of the International Conference on Contemporary Computing, pp. 404-409, (2013); Kenett R.S., Redman T.C., The Real Work of Data Science, (2019); Kernigham B.W., Pike R., The Practice of Programming, (1999); Khan W.Z., Ahmed E., Hakak S., Yaqoob I., Ahmed A., Edge Computing: A Survey, Future Generation Computer Systems, 97, pp. 219-235, (2019); Kibirige H., Plotnine API Reference, (2022); Knuth D.E., Big Omicron and Big Omega and Big Theta, ACM Sigact News, 8, 2, pp. 18-24, (1976); Knuth D.E., The Art of Computer Programming, Volume 1: Fundamental Algorithms, (1997); Kramer S., Julia Autodoc, (2022); Folder Structure Conventions, (2016); Kuhn D.R., Kacker R.N., Lei Y., Introduction to Combinatorial Testing, (2013); Kuhn M., Johnson K., Applied Predictive Modeling, (2013); Lai R., Ren K., An Implementation of the Language Server Protocol for R, (2022); Langa L., Et al., Black: The Uncompromising Code Formatter, (2022); Li J., Chen X., Hovy E., Jurafsky D., Visualizing and Understanding Neural Models in NLP, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 681-691, (2016); Li Q., Wen Z., Wu Z., Hu S., Wang N., Li Y., Liu X., He B., A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection, IEEE Transactions on Knowledge and Data Engineering, (2021); Linardatos P., Papastefanopoulos V., Kotsiantis S., Explainable AI: A Review of Machine Learning Interpretability Methods, Entropy, 23, 1, (2021); The Linux Kernel Archives, (2022); Lipizzi C., Behrooz H., Dressman M., Vishwakumar A.G., Batra K., Acquisition Research: Creating Synergy for Informed Change, Proceedings of the 19th Annual Acquisition Research Symposium, pp. 242-255, (2022); Lipizzi C., Borrelli D., de Oliveira Capela F., A Computational Model Implementing Subjectivity with the 'Room Theory': The case of Detecting Emotion from Text, (2021); Pylint is a Static Code Analyser for Python 2 or 3, (2022); Lohr S.L., Sampling: Design and Analysis, (2021); Lopes C.V., Exercises in Programming Style, (2020); Loria S., Et al., A Pluggable API Specification Generator, (2022); Lundberg S.M., Lee S.I., A Unified Approach to Interpreting Model Predictions, Advances in Neural Information Processing Systems (NIPS), pp. 4765-4774, (2017); Lyttle I., Jeppson H., Developers A., altair: Interface to Altair, (2022); Manohar A., asdf Documentation, (2022); Marin J.M., Robert C.P., Bayesian Essentials with R, (2014); Martin R.C., Clean Code, (2008); McConnell S., Code Complete, (2004); McKinney W., Python for Data Analysis, (2017); Mehrabi N., Morstatter F., Saxena N., Lerman K., Galstyan A., A Survey on Bias and Fairness in Machine Learning, ACM Computing Surveys, 54, 6, (2021); Melancon G., Dutour I., Bousquet-Melou M., Random Generation of Directed Acyclic Graphs, Electronic Notes in Discrete Mathematics, 10, pp. 202-207, (2001); A Performant Type-Checker for Python 3, (2022); React: A JavaScript Library for Building User Interfaces, (2022); A performant, Feature-Rich Language Server for Python in VS Code, (2022); Azure Kubernetes Service (AKS), (2022); Azure Machine Learning, (2022); Code editing. Redefined, (2022); Data Visualization: Microsoft PowerBI, (2022); Language Server Protocol, (2022); Shadow Testing, (2022); Virtualization Documentation, (2022); Visual Studio Code: Code Editing, Redefined, (2022); VS Code in the Web, (2022); Project InnerEye- Democratizing Medical Imaging AI, (2022); Min I.O., MinIO Documentation, (2022); Milkowski M., Hensel W.M., Hohol M., Replicability or Reproducibility? On the Replication Crisis in Computational Neuroscience and Sharing Only Relevant Detail, Journal of Computational Neuroscience, 45, pp. 163-172, (2018); Design and Analysis of Experiments; Mood C., Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It, European Sociological Review, 26, 1, pp. 67-82, (2010); Mujtaba H., Samsung Powers NVIDIA Quadro RTX Graphics Cards With 16Gb GDDR6 Memory, (2018); Muller K., Walthert L., Non-Invasive Pretty Printing of R Code, (2022); Muller K., Walthert L., Third-Party Integrations, (2022); Muth C., Oravecz Z., Gabry J., User-Friendly Bayesian Regression Modeling: A Tutorial with rstanarm and shinystan, The Quantitative Methods for Psychology, 14, 2, pp. 99-119, (2018); Myers G.J., Badgett T., Sandler C., The Art of Software Testing, (2012); Narayanan A., Shmatikov V., Robust De- Anonymization of Large Sparse Datasets, Proceedings of the IEEE Symposium on Security and Privacy, pp. 111-125, (2008); Natekin A., Knoll A., Gradient Boosting Machines, a Tutorial, Frontiers in Neurorobotics, 7, 21, pp. 1-21, (2013); Reality Check on Reproducibility, Nature, 533, 437, (2016); Run isort, pyupgrade, mypy, pylint, flake8, and More on Jupyter Notebooks, (2022); Run Your GitHub Actions Locally, (2022); Hyperextensible Vim-Based Text Editor, (2022); Neptune Documentation, (2022); Newman S., Building Microservices: Designing Fine-Grained Systems, (2021); NLTK: A Natural Language Toolkit, (2021); Papermill Is a Tool for Parameterizing and Executing Jupyter Notebooks, (2022); Testbook, (2022); Nvidia Turing GPU Architecture: Graphics Reinvented, (2018); CUDA Toolkit Documentation, (2021); A C++ Fixed Point Math Library Suitable for Financial Applications, (2018); Odena A., Olsson C., Andersen D., Goodfellow I., TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing, Proceedings of Machine Learning Research (ICML 2018), 97, pp. 4901-4911, (2019); Open Neural Network Exchange, (2021); Open Container Initiative, (2022); Documents, (2022); A Free, Open Source, Powerful Tool for Working with Messy Data, (2022); Oracle VM Virtualbox, (2022); Ousterhout J., A Philosophy of Software Design, (2018); Overton M.L., Numerical Computing with IEEE Floating Point Arithmetic, (2001); Data-Centric Pipelines and Data Versioning, (2022); PagerDuty: Uptime Is Money, (2022); Python Language Server, (2022); Flask Documentation, (2022); Papernot N., McDaniel P., Sinha A., Wellman M.P., SoK: Security and Privacy in Machine Learning, Proceedings of the IEEE European Symposium on Security and Privacy, pp. 399-414, (2018); Paszke A., Gross S., Massa F., Lerer A., Bradbury J., Chanan G., Killeen T., Lin Z., Gimelshein N., Antiga L., Desmaison A., Kopf A., Yang E., DeVito Z., Raison M., Tejani A., Chilamkurthy S., Steiner B., Fang L., Bai J., Chintala S., PyTorch: An Imperative Style, High- Performance Deep Learning Library, Advances in Neural Information Processing Systems (NIPS), 32, pp. 8026-8037, (2019); Pennington J., Socher R., Manning C., Glove: Global Vectors for Word Representation, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543, (2014); Pineau J., Vincent-Lamarre P., Sinha K., Lariviere V., Beygelzimer A., d'Alche-Buc F., Fox E., Larochelle H., Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program), Journal of Machine Learning Research, 22, pp. 1-20, (2021); Analytical Web Apps for Python, R, Julia, and Jupyter. No JavaScript Required, (2022); Dash Python User Guide, (2022); Plotly Open Source Graphing Library for Python, (2022); Polyaxon Documentation, (2022); Popejoy A., Fullerton S.M., Genomics Is Failing on Diversity, Nature, 538, pp. 161-164, (2016); Popescu M., Pair Programming Explained, (2019); Typhoon Documentation, (2022); Potvin R., Levenberg J., Why Google Stores Billions of Lines of Code in a Single Repository, Communications of the ACM, 59, 7, pp. 78-87, (2016); Prefect 2.0 Documentation, (2022); Preston-Werner T., Semantic Versioning, (2022); Prinz F., Schlange T., Asadullah K., Believe It or Not: How Much Can We Rely on Published Data on Potential Drug Targets?, Nature Reviews Drug Discovery, 10, (2011); Chef Documentation, (2022); Jupyter, (2022); Prometheus: Monitoring System and Time Series Databases, (2022); Puppet Documentation, (2022); Static Type Checker for Python, (2022); Building and Distributing Packages with Setuptools, (2022); Virtualenv Documentation, (2022); PyPI: The Python Package Index, (2022); Test Interactive Python Examples, (2022); unittest: Unit Testing Framework, (2022); QS World University Rankings, (2022); Quest K., Standard Go Project Layout, (2022); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language Models Are Unsupervised Multitask Learners, (2019); Ramirez S., FastAPI Framework, High Performance, Easy to Learn, Fast to Code, Ready for Production, (2022); Ranganathan P., Pramesh C.S., Aggarwal R., Common Pitfalls in Statistical Analysis: Logistic Regression, Perspectives in Clinical Research, 8, 3, pp. 148-151, (2017); Rasmussen C.E., Williams C.K.I., Gaussian Processes for Machine Learning, (2006); Rathgeber F., Strip Output from Jupyter and IPython Notebooks, (2022); Read the Docs: Documentation Simplified, (2022); R in Visual Studio Code, (2022); Rehurek R., Sojka P., Gensim Documentation, (2022); Rehurek R., Sojka P., Gensim Documentation, (2022); Pipenv: Python Dev Workflow for Humans, (2022); Reuther A., Michaleas P., Jones M., Gadepally V., Samsi S., Kepner J., Survey of Machine Learning Accelerators, Proceedings of the 2020 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-12, (2020); Ribeiro M.T., Singh S., Guestrin C., Why Should I Trust You? Explaining the Predictions of Any Classifier, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144, (2016); Rice L., Container Security: Fundamental Technology Concepts that Protect Containerized Applications, (2020); Rigby P., Bird C., Convergent Contemporary Software Peer Review Practices, Proceedings of the 9th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, pp. 202-212, (2013); Rong X., Word2vec Parameter Learning Explained, (2014); Royce W.W., Managing the Development of Large Software Systems: Concepts and Techniques, Proceedings of the 9th International Conference on Software Engineering, pp. 328-338, (1987); Open Source and Enterprise-Ready Professional Software for Data Science, (2022); RStudio Server, (2022); Rump S.M., Addendum to 'On Recurrences Converging to the Wrong Limit in Finite Precision, Electronic Transactions on Numerical Analysis, 52, pp. 571-575, (2020); Rump S.M., On Recurrences Converging to the Wrong Limit in Finite Precision, Electronic Transactions on Numerical Analysis, 52, pp. 358-369, (2020); Russell S.J., Norvig P., Artificial Intelligence: A Modern Approach, (2009); Sadowski C., Soderberg E., Church L., Sipko M., Bacchelli A., Modern Code Review: A Case Study at Google, Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice, pp. 181-190, (2018); Saltz J.S., Shamshurin I., Does Pair Programming Work in a Data Science Context? An Initial Case Study, Proceedings of the IEEE International Conference on Big Data, pp. 2348-2354, (2017); Santner T.J., Williams B.J., Notz E.I., The Design and Analysis of Computer Experiments, (2018); Satyanarayan A., Moritz D., Wongsuphasawat K., Heer J., A High-Level Grammar of Interactive Graphics, (2022); Schubert E., Sander J., Ester M., Kriegel H.P., Xu X., DBSCAN Revisited, Revisited: Why and How You Should (Still) Use DBSCAN, ACM Transactions on Database Systems, 42, 3, (2017); Scikit-learn: Machine Learning in Python, (2022); Sculley D., Holt G., Golovin D., Davydov E., Phillips T., Ebner D., Chaudhary V., Young M., Machine Learning: The High Interest Credit Card of Technical Debt, SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop), (2014); Sculley D., Holt G., Golovin D., Davydov E., Phillips T., Ebner D., Chaudhary V., Young M., Crespo J.F., Dennison D., Hidden Technical Debt in Machine Learning Systems, Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS), 2, pp. 2503-2511, (2015); Scutari M., Denis J.B., Bayesian Networks with Examples in R, (2021); Seldon Core, (2022); AWS Deep Learning Containers, (2022); Seven D., Knightmare: A DevOps Cautionary Tale, (2014); Shelton K., The Value of Search Results Rankings, (2017); Sherman E., What Zillow's Failed Algorithm Means for the Future of Data Science, (2022); Shinyama Y., Guglielmetti P., Marsman P., Pdfminer.six's Documentation, (2022); Shiraishi M., Washizaki H., Fukazawa Y., Yoder J., Mob Programming: A Systematic Literature Review, Proceedings of the IEEE 43rd Annual Computer Software and Applications Conference, pp. 616-621, (2019); Kubernetes Fury Distribution, (2022); Velocity: The Documentation and Docset Viewer for Windows, (2022); Simmons A.J., Barnett S., Rivera-Villicana J., Bajaj A., Vasa R., A Large-Scale Comparative Analysis of Coding Standard Conformance in Open-Source Data Science Projects, Proceedings of the 14th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), pp. 1-11, (2020); Simonyan K., Vedaldi A., Zisserman A., Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, Proceedings of the 2nd International Conference on Learning Representations (ICLR), Workshop Track, (2014); OpenAPI Specification, (2021); Snowflake Documentation, (2022); Nexus Repository Manager, (2022); Luigi Documentation, (2022); Spotify Engineering Blog, (2022); Stapleton Cordasco I., Flake8: Your Tool for Style Guide Enforcement, (2022); Stevens J.R., Replicability and Reproducibility in Comparative Psychology, Frontiers in Psychology, 8, (2017); Streamlit Documentation, (2022); Great Expectations, (2022); Swoboda S., Connecting with Mob Programming, (2021); Execute Python Code on The Fly and Display Results in Tableau Visualizations, (2022); Tableau, (2022); Tabuchi A., Kasagi A., Yamazaki M., Honda T., Miwa M., Shiraishi T., Kosaki M., Fukumoto N., Tabaru T., Ike A., Nakashima K., Extremely Accelerated Deep Learning: ResNet-50 Training in 70.4 Seconds, (2019); Tang Y., Khatchadouriant R., Bagherzadeh M., Singh R., Stewart A., Raja A., An Empirical Study of Refactorings and Technical Debt in Machine Learning Systems, Proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering, pp. 238-250, (2021); Tatman R., VanderPlas J., Dane S., A Practical Taxonomy of Reproducibility for Machine Learning Research, Proceedings of 2nd the Reproducibility in Machine Learning Workshop at ICML 2018, (2018); TensorFlow, (2021); TensorFlow Extended (TFX), (2021); XLA: Optimizing Compiler for Machine Learning, (2021); ML Metadata, (2022); Serving Models, (2022); TensorBoard: TensorFlow's Visualization Toolkit, (2022); The TFX User Guide, (2022); Airflow Documentation, (2022); Apache Beam Documentation, (2022); Apache Hadoop, (2022); Apache Hive Documentation, (2022); Apache Pig Documentation, (2022); Apache Spark Documentation, (2022); podman, (2022); Delta Lake Documentation, (2022); Zeal Is an Offline Documentation Browser for Software Developers, (2022); The World's Most Valuable Resource Is No Longer Oil, but Data, (2017); An Understanding of AI's Limitations Is Starting to Sink In, (2020); Fluentd: Open Source Data Collector, (2022); Git Source Code Mirror, (2022); Hadolint: Haskell Dockerfile Linter Documentation, (2022); KServe Control Plane, (2022); All of Kubeflow documentation, (2022); Kubernetes, (2022); Kubernetes Documentation: Schedule GPUs, (2022); minikube, (2022); mypy: Optional Static Typing for Python, (2014); Twilio: Someone Waltzed into Our Unsecured AWS S3 Silo, Added Dodgy Code to Our JavaScript SDK for Customers, (2020); Thomas D., Hunt A., The Pragmatic Programmer: Your Journey to Mastery, (2019); Tian Y., Zhang Y., Stol K.J., Jiang L., Liu H., What Makes a Good Commit Message?, Proceedings of the 44th International Conference on Software Engineering, pp. 1-13, (2022)","","CRC Press","","","","","","Book","Final","","Scopus","2-s2.0-85183218511"
"Purba M.D.; Ghosh A.; Radford B.J.; Chu B.","Purba, Moumita Das (58730719900); Ghosh, Arpita (58730310700); Radford, Benjamin J. (57208026628); Chu, Bill (36918104500)","58730719900; 58730310700; 57208026628; 36918104500","Software Vulnerability Detection using Large Language Models","2023","Proceedings - 2023 IEEE 34th International Symposium on Software Reliability Engineering Workshop, ISSREW 2023","","","","112","119","7","3","10.1109/ISSREW60843.2023.00058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178239225&doi=10.1109%2fISSREW60843.2023.00058&partnerID=40&md5=c294d2931500625acdfe43679b8fe7db","Software development is among the first demonstrations of using Large Language Models (LLMs) to enhance human productivity. Such a co-pilot paradigm envisions LLM working side-by-side with human developers to assist in programming tasks. Ensuring the security of software products is a critical factor for the success of such a paradigm. There have been various anecdotal reports on the success of using LLMs to detect vulnerabilities in programs. This paper reports a set of experiments applying four well-known LLMs to two widely referenced public datasets to evaluate the performance of LLMs in detecting software vulnerabilities. Our results show a significant performance gap between these LLMs and those from popular static analysis tools, primarily due to their high false positive rates. However, LLMs show great promise in identifying subtle patterns commonly associated with software vulnerabilities. This observation suggests a possible path forward by combining LLMs and other program analysis techniques to achieve better software vulnerability detection.  © 2023 IEEE.","AI; Cybersecurity; Large language model; software vulnerability","Computational linguistics; Cybersecurity; Software design; Critical factors; Cyber security; Human productivity; Language model; Large language model; Programming tasks; Side by sides; Software products; Software vulnerabilities; Vulnerability detection; Static analysis","Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., Language models are few-shot learners, Advances in neural information processing systems, 33, pp. 1877-1901, (2020); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Advances in neural information processing systems, 30, (2017); Kenton J.D.M.-W.C., Toutanova L.K., Bert: Pre-training of deep bidirectional transformers for language understanding, Proceedings of naacL-HLT, 1, (2019); Radford A., Narasimhan K., Salimans T., Sutskever I., Et al., Improving language understanding by generative pre-training, (2018); GPT-4 Technical Report, OpenAI, (2023); Chen M., Tworek J., Jun H., Yuan Q., Pinto H.P.D.O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, (2021); chrisanley; Chatgpt: Enhancing code security and detect vulnerabilities; Cheshkov A., Zadorozhny P., Levichev R., Evaluation of chatgpt model for vulnerability detection, (2023); Rough audit tool for security; Hp fortify; Grieco G., Grinblat G.L., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning, Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy, pp. 85-96, (2016); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, 2018 17th IEEE international conference on machine learning and applications (ICMLA), pp. 757-762, (2018); Wang S., Chollak D., Movshovitz-Attias D., Tan L., Bugram: bug detection with n-gram language models, Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering, pp. 708-719, (2016); Lin G., Wen S., Han Q.-L., Zhang J., Xiang Y., Software vulnerability detection using deep neural networks: A survey, Proceedings of the IEEE, 108, 10, pp. 1825-1848, (2020); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, 19, 4, pp. 2244-2258, (2021); Thapa C., Jang S.I., Ahmed M.E., Camtepe S., Pieprzyk J., Nepal S., Transformer-based language models for software vulnerability detection, Proceedings of the 38th Annual Computer Security Applications Conference, pp. 481-496, (2022); Li X., Wang L., Xin Y., Yang Y., Chen Y., Automated vulnerability detection in source code using minimum intermediate representation learning, Applied Sciences, 10, 5, (2020); Tang G., Meng L., Wang H., Ren S., Wang Q., Yang L., Cao W., A comparative study of neural network techniques for automatic software vulnerability detection, 2020 International symposium on theoretical aspects of software engineering (TASE), pp. 1-8, (2020); Fu M., Tantithamthavorn C., Linevul: A transformer-based linelevel vulnerability prediction, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 608-620, (2022); Ziems N., Wu S., Security vulnerability detection using deep learning natural language processing, IEEE INFOCOM 2021-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS), pp. 1-6, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Pan C., Lu M., Xu B., An empirical study on software defect prediction using codebert model, Applied Sciences, 11, 11, (2021); Bhandari G., Naseer A., Moonen L., Cvefixes: Automated collection of vulnerabilities and their fixes from open-source software, Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering, pp. 30-39, (2021); Grishina A., Enabling automatic repair of source code vulnerabilities using data-driven methods, Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings, pp. 275-277, (2022); Nijkamp E., Pang B., Hayashi H., Tu L., Wang H., Zhou Y., Savarese S., Xiong C., Codegen: An open large language model for code with multi-turn program synthesis, The Eleventh International Conference on Learning Representations, (2023)","","Institute of Electrical and Electronics Engineers Inc.","","34th IEEE International Symposium on Software Reliability Engineering Workshop, ISSREW 2023","9 October 2023 through 12 October 2023","Florence","194254","Conference paper","Final","","Scopus","2-s2.0-85178239225"
"Jain R.; Gervasoni N.; Ndhlovu M.; Rawat S.","Jain, Ridhi (57198836900); Gervasoni, Nicole (57207845217); Ndhlovu, Mthandazo (58121898000); Rawat, Sanjay (23061507500)","57198836900; 57207845217; 58121898000; 23061507500","A Code Centric Evaluation of C/C++ Vulnerability Datasets for Deep Learning Based Vulnerability Detection Techniques","2023","ACM International Conference Proceeding Series","","","6","","","","3","10.1145/3578527.3578530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149146683&doi=10.1145%2f3578527.3578530&partnerID=40&md5=7d1e97964bea1c391f50bba5987ea988","Recent years have witnessed tremendous progress in NLP-based code comprehension via deep neural networks (DNN) learning, especially Large Language Models (LLMs). While the original application of LLMs is focused on code generation, there have been attempts to extend the application to more specialized tasks, like code similarity, author attribution, code repairs, and so on. As data plays an important role in the success of any machine learning approach, researchers have also proposed several benchmarks which are coupled with a specific task at hand. It is well known in the machine learning (ML) community that the presence of biases in the dataset affects the quality of the ML algorithm in a real-world scenario. This paper evaluates several existing datasets from DNN's application perspective. We specifically focus on training datasets of C/C++ language code. Our choice of language stems from the fact that while LLM-based techniques have been applied and evaluated on programming languages like Python, JavaScript, and Ruby, there is not much LLM research for C/C++. As a result, datasets generated synthetically or from real-world codes are in individual research work. Consequently, in the absence of a uniform dataset, such works are hard to compare with each other. In this work, we aim to achieve two main objectives- 1. propose code-centric features that are relevant to security program analysis tasks like vulnerability detection; 2. a thorough (qualitative and quantitative) examination of the existing code datasets that demonstrate the main characteristics of the individual datasets to have a clear comparison. Our evaluation finds exciting facts about existing datasets highlighting gaps that need to be addressed. © 2023 ACM.","datasets; program graphs; software metrics; software vulnerability","Codes (symbols); Deep neural networks; Learning systems; Python; Code comprehension; Code similarities; Codegeneration; Dataset; Language model; Neural network learning; Program graph; Software metrics; Software vulnerabilities; Vulnerability detection; C++ (programming language)","Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning Distributed Representations of Code, Proc. ACM Program. Lang., 3, (2019); Arp D., Quiring E., Pendlebury F., Warnecke A., Pierazzi F., Wressnegger C., Cavallaro L., Rieck K., Dos and Don'ts of Machine Learning in Computer Security, Proc. of USENIX Security'22, (2022); Barchi F., Urgese G., Macii E., Acquaviva A., Code mapping in heterogeneous platforms using deep learning and llvm-ir, 2019 56th ACM/IEEE Design Automation Conference (DAC). IEEE, pp. 1-6, (2019); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural Code Comprehension: A Learnable Representation of Code Semantics, NeurIPS 2018, pp. 3589-3601, (2018); Brown T.B., Language Models are Few-Shot Learners, (2020); Buczak A.L., Guven E., A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection, IEEE Communications Surveys & Tutorials, 18, 2, pp. 1153-1176, (2016); Chakraborty S., Krishna R., Ding Y., Ray B., Deep learning based vulnerability detection: Are we there yet, IEEE Transactions on Software Engineering, (2021); Chen M., Et al., Evaluating Large Language Models Trained on Code, (2021); Chowdhery A., Et al., PaLM: Scaling Language Modeling with Pathways, (2022); Cruz-Benito J., Vishwakarma S., Martin-Fernandez F., Faro I., Automated source code generation and auto-completion using deep learning: Comparing and discussing current language model-related approaches, AI, 2, 1, pp. 1-16, (2021); Cummins C., Fisches Z.V., Ben-Nun T., Hoefler T., O'Boyle P.M.F., Leather H., ProGraML: A Graph-based Program Representation for Data Flow Analysis and Compiler Optimizations, Proc. 38th ICML (Proceedings of Machine Learning Research, 139, pp. 2244-2253, (2021); Fan J., Li Y., Wang S., Nguyen T.N., A C/C++Code Vulnerability Dataset with Code Changes and CVE Summaries, Proc. Int. Conf. MSR (MSR '20), pp. 508-512, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Code-BERT: A Pre-Trained Model for Programming and Natural Languages, (2020); Forrest S., Hofmeyr S.A., Somayaji A., Longstaff T.A., A sense of self for Unix processes, Proc. IEEE S&P, pp. 120-128, (1996); clangd GitHub repository, (2022); Eclipse Java development tools (JDT), (2012); Grahn D., Zhang J., An Analysis of C/C++Datasets for Machine Learning-Assisted Software Vulnerability Detection, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., GraphCodeBERT: Pre-training code representations with data flow, (2020); Gupta R., Pal S., Kanade A., Shevade S., Deepfix: Fixing common c language errors by deep learning, AAAI Conference on Artificial Intelligence, (2017); Hindle A., Barr E.T., Gabel M., Su Z., Devanbu P., On the naturalness of software, Commun. ACM, 59, 5, pp. 122-131, (2016); cquey GitHub repository, (2018); Kimmig M., Monperrus M., Mezini M., Querying source code with natural language, ASE'11). IEEE, pp. 376-379, (2011); Lee W., Stolfo S.J., Data Mining Approaches for Intrusion Detection, USENIX Security'98, (1998); Li Z., Zou D., Tang J., Zhang Z., Sun M., Jin H., A comparative study of deep learning-based vulnerability detection system, IEEE Access, 7, pp. 103184-103197, (2019); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, IEEE Transactions on Dependable and Secure Computing, (2021); Liu L., Li Z., Wen Y., Chen P., Investigating the impact of vulnerability datasets on deep learning-based vulnerability detectors, PeerJ Computer Science, 8, (2022); Mahoney M.V., Chan P.K., An Analysis of the 1999 DARPA/Lincoln Laboratory Evaluation Data for Network Anomaly Detection, RAID, pp. 220-237, (2003); Marcelli A., Graziano M., Ugarte-Pedrero X., Fratantonio Y., Mansouri M., Balzarotti D., How Machine Learning Is Solving the Binary Function Similarity Problem, USENIX Security, 22, pp. 2099-2116, (2022); Mashhadi E., Hemmati H., Applying codebert for automated program repair of java simple bugs, 2021 IEEE/ACM MSR. IEEE, pp. 505-509, (2021); ccls GitHub repository, (2021); Omri S., Sinz C., Deep learning for software defect prediction: A survey, Proc. ICSE Workshops, pp. 209-214, (2020); Peng D., Zheng S., Li Y., Ke G., He D., Liu T., How could Neural Networks understand Programs?, Proc. 38th ICML, 139, pp. 8476-8486, (2021); Pornprasit C., Tantithamthavorn C., DeepLineDP: Towards a Deep Learning Approach for Line-Level Defect Prediction, IEEE Transactions on Software Engineering, (2022); Rae J.W., Et al., Scaling Language Models: Methods, Analysis & Insights from Training Gopher, (2021); Russell R., Kim L., Hamilton L., Lazovich T., Harer J., Ozdemir O., Ellingwood P., McConley M., Automated vulnerability detection in source code using deep representation learning, ICMLA. IEEE, pp. 757-762, (2018); Sessions V., Valtorta M., The Effects of Data Quality on Machine Learning Algorithms, ICIQ, (2006); Wang Y., Li H., Code completion by modeling flattened abstract syntax trees as graphs, AAAI Conference on Artificial Intelligence, 35, pp. 14015-14023, (2021); Wardat M., Dantas Cruz B., Le W., Rajan H., Deep-Diagnosis: Automatically diagnosing faults and recommending actionable fixes in deep learning programs, ICSE'22, pp. 561-572, (2022); Xu S., Yao Y., Xu F., Gu T., Tong H., Combining Code Context and Fine-grained Code Difference for Commit Message Generation, 13th Asia-Pacific Symposium on Internetware, pp. 242-251, (2022); Yu B., Qi H., Guo Q., Juefei-Xu F., Xie X., Ma L., Zhao J., Deeprepair: Style-guided repairing for deep neural networks in the real-world operational environment, IEEE Transactions on Reliability, (2021); Zhang H., Sakurai K., A survey of software clone detection from security perspective, IEEE Access, 9, pp. 48157-48173, (2021); Zhou Y., Liu S., Siow J., Du X., Liu Y., Devign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks, Advances in neural information processing systems, 32, (2019)","Agarwal S.; Roychoudhury A.; Purandare R.","Association for Computing Machinery","ACM SIGSOFT; India SERB; TCS Research","16th Innovations in Software Engineering Conference, ISEC 2023","23 February 2023 through 25 February 2023","Allahabad","186807","Conference paper","Final","","Scopus","2-s2.0-85149146683"
"Du Y.; Ma Y.-F.; Xie Z.; Li M.","Du, Yali (57226543642); Ma, Yi-Fan (57456232500); Xie, Zheng (57199323707); Li, Ming (56994181000)","57226543642; 57456232500; 57199323707; 56994181000","Beyond Lexical Consistency: Preserving Semantic Consistency for Program Translation","2023","Proceedings - IEEE International Conference on Data Mining, ICDM","","","","91","100","9","0","10.1109/ICDM58522.2023.00018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185399070&doi=10.1109%2fICDM58522.2023.00018&partnerID=40&md5=d85a8083a6540cebb137ca91dd6fa437","Program translation aims to convert the input programs from one programming language to another. Automatic program translation is a prized target of software engineering research, which leverages the reusability of projects and improves the efficiency of development. Recently, thanks to the rapid development of deep learning model architectures and the availability of large-scale parallel corpus of programs, the performance of program translation has been greatly improved. However, the existing program translation models are still far from satisfactory, in terms of the quality of translated programs. In this paper, we argue that a major limitation of the current approaches is the lack of consideration of semantic consistency. Beyond lexical consistency, semantic consistency is also critical for the task. To make the program translation model more semantically aware, we propose a general framework named Preserving Semantic Consistency for Program Translation (PSCPT), which considers semantic consistency with regularization in the training objective of program translation and can be easily applied to all encoder-decoder methods with various neural networks (e.g., LSTM, Transformer) as the backbone. We conduct extensive experiments in 7 general programming languages. Experimental results show that with CodeBERT as the backbone, our approach outperforms not only the state-of-the-art open-source models but also the commercial closed large language models (e.g., textdavinci-002, text-davinci-003) on the program translation task. Our replication package (including code, data, etc.) is publicly available at https://github.com/duyali2000/PSCPT.  © 2023 IEEE.","Large Language Model; Program Translation; Regularization; Semantic Consistency","Computational linguistics; Computer software reusability; Long short-term memory; Neural machine translation; Open source software; Open systems; Program translators; Semantics; Automatic program translation; Input programs; Language model; Large language model; Learning models; Program translation; Regularisation; Semantic consistency; Software engineering research; Translation models; Reusability","Chen X., Liu C., Song D., Tree-to-tree neural networks for program translation, Advances in Neural Information Processing Systems 31, pp. 2552-2562, (2018); Ma Y., Du Y., Li M., Capturing the long-distance dependency in the control flow graph via structural-guided attention for bug localization, Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, IJCAI 2023, pp. 2242-2250, (2023); Roziere B., Lachaux M., Chanussot L., Lample G., Unsupervised translation of programming languages, Advances in Neural Information Processing Systems, NeurIPS, virtual, (2020); Waters R.C., Program translation via abstraction and reimplementation, IEEE Trans. Software Eng., 14, 8, pp. 1207-1228, (1988); Chu W.C., A re-engineering approach to program translation, Proceedings of the Conference on Software Maintenance, ICSM 1993, pp. 42-50, (1993); Nguyen T.D., Nguyen A.T., Nguyen T.N., Mapping API elements for code migration with vector representations, Proceedings of the 38th International Conference on Software Engineering, ACM, (2016); Allamanis M., Barr E.T., Devanbu P.T., Sutton C., A survey of machine learning for big code and naturalness, ACM Comput. Surv., pp. 811-8137, (2018); Karaivanov S., Raychev V., Vechev M.T., Phrase-based statistical translation of programming languages, Proceedings of the 2014 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming & Software, part of SPLASH '14, pp. 173-184, (2014); Nguyen A.T., Nguyen T.T., Nguyen T.N., Lexical statistical machine translation for language migration, Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ESEC/FSE'13, pp. 651-654, (2013); Nguyen A.T., Nguyen T.T., Nguyen T.N., Divide-and-conquer approach for multi-phase statistical migration for source code (T), 30th IEEE/ACM International Conference on Automated Software Engineering, pp. 585-596, (2015); Zhu M., Suresh K., Reddy C.K., Multilingual code snippets training for program translation, Thirty-Sixth AAAI Conference on Artificial Intelligence, (2022); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data flow, 9th International Conference on Learning Representations, (2021); Haque S., Eberhart Z., Bansal A., McMillan C., Semantic similarity metrics for evaluating source code summarization, ICPC, (2022); Ling X., Wu L., Wang S., Pan G., Ma T., Xu F., Liu A.X., Wu C., Ji S., Deep graph matching and searching for semantic code retrieval, ACM Trans. Knowl. Discov. Data, (2021); Du C., Zhuang F., He Q., Shi Z., Multi-task semi-supervised semantic feature learning for classification, 2012 IEEE 12th International Conference on Data Mining, pp. 191-200, (2012); Huo X., Yang Y., Li M., Zhan D.-C., Learning semantic features for software defect prediction by code comments embedding, 2018 IEEE international conference on data mining (ICDM), IEEE, (2018); Luo X., Wu J., Zhou C., Zhang X., Wang Y., Deep semantic network representation, 2020 IEEE International Conference on Data Mining (ICDM), pp. 1154-1159, (2020); Papineni K., Roukos S., Ward T., Zhu W., Bleu: A method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., Learning to generate pseudo-code from source code using statistical machine translation (T), 30th IEEE/ACM International Conference on Automated Software Engineering, pp. 574-584, (2015); Oda Y., Fudaba H., Neubig G., Hata H., Sakti S., Toda T., Nakamura S., Learning to generate pseudo-code from source code using statistical machine translation (T), 30th IEEE/ACM International Conference on Automated Software Engineering, (2015); Lample G., Conneau A., Denoyer L., Ranzato M., Unsupervised machine translation using monolingual corpora only, 6th International Conference on Learning Representations, (2018); Wen Y., Guo Q., Fu Q., Li X., Xu J., Tang Y., Zhao Y., Hu X., Du Z., Li L., Wang C., Zhou X., Chen Y., Babeltower: Learning to auto-parallelized program translation, International Conference on Machine Learning, (2022); Weisz J.D., Muller M.J., Houde S., Richards J.T., Ross S.I., Martinez F., Agarwal M., Talamadupula K., Perfection not required? human-ai partnerships in code translation, IUI '21: 26th International Conference on Intelligent User Interfaces, pp. 402-412, (2021); Roziere B., Zhang J., Charton F., Harman M., Synnaeve G., Lample G., Leveraging automated unit tests for unsupervised code translation, ICLR, (2022); Szafraniec M., Roziere B., Leather H., Charton F., Labatut P., Synnaeve G., Code translation with compiler representations, (2022); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifieraware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 8696-8708, (2021); Yin P., Neubig G., A syntactic neural model for general-purpose code generation, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pp. 440-450, (2017); Brockschmidt M., Allamanis M., Gaunt A.L., Polozov O., Generative code modeling with graphs, 7th International Conference on Learning Representations, (2019); Jiang X., Zheng Z., Lyu C., Li L., Lyu L., Treebert: A treebased pre-trained model for programming language, Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence, pp. 54-63, (2021); Du Y., Yu Z., Pre-training code representation with semantic flow graph for effective bug localization, (2023); Feng Z., Guo D., Tang D.-Y., Duan N., Feng X.-C., Gong M., Shou L.-J., Qin B., Liu T., Jiang D., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP, Online Event, pp. 1536-1547, (2020); Shore J., Johnson R., Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy, IEEE Transactions on information theory, 26, 1, pp. 26-37, (1980); Ren S., Guo D., Lu S., Zhou L., Liu S., Tang D., Sundaresan N., Zhou M., Blanco A., Ma S., Codebleu: A method for automatic evaluation of code synthesis, (2020); James W., Stein C., Estimation with quadratic loss, Breakthroughs in statistics: Foundations and basic theory, pp. 443-460, (1992); Lachaux M., Roziere B., Szafraniec M., Lample G., DOBF: A deobfuscation pre-training objective for programming languages, Advances in Neural Information Processing Systems 34, virtual, (2021); Loshchilov I., Hutter F., Decoupled weight decay regularization, 7th International Conference on Learning Representations, OpenReview. net, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C.B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S.K., Fu S., Liu S., Codexglue: A machine learning benchmark dataset for code understanding and generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, virtual, (2021); An P., Wang Z., Zhang C., Ensemble unsupervised autoencoders and gaussian mixture model for cyberattack detection, Information Processing & Management, 59, 2, (2022); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Proceedings of the 31st International Conference on Neural Information Processing Systems, pp. 6000-6010, (2017)","Chen G.; Khan L.; Gao X.; Qiu M.; Pedrycz W.; Wu X.","Institute of Electrical and Electronics Engineers Inc.","IEEE Computer Society; Technology Innovation Institute; TWO SIGMA; US National Science Foundation (NSF)","23rd IEEE International Conference on Data Mining, ICDM 2023","1 December 2023 through 4 December 2023","Shanghai","197131","Conference paper","Final","","Scopus","2-s2.0-85185399070"
"Manh D.N.; Le Hai N.; Dau A.T.V.; Nguyen A.M.; Nghiem K.; Guo J.; Bui N.D.Q.","Manh, Dung Nguyen (57556765400); Le Hai, Nam (58071715800); Dau, Anh T.V. (57970609500); Nguyen, Anh Minh (58310629400); Nghiem, Khanh (58310052100); Guo, Jin (57203289380); Bui, Nghi D.Q. (57202916441)","57556765400; 58071715800; 57970609500; 58310629400; 58310052100; 57203289380; 57202916441","The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation","2023","Findings of the Association for Computational Linguistics: EMNLP 2023","","","","4763","4788","25","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183289625&partnerID=40&md5=bb8ecb34b5109470ddb9b47acbb7482b","We present The Vault, a dataset of high-quality code-text pairs in multiple programming languages for training large language models to understand and generate code. We present methods for thoroughly extracting samples that use both rule-based and deep learning-based methods to ensure that they contain high-quality pairs of code and text, resulting in a dataset of 43 million high-quality code-text pairs. Our extensive evaluations on common coding tasks including code generation, code search and code summarization show that when fine-tuning Code Large Language Models on The Vault, such models outperform the same models trained on other datasets such as CodeSearchNet. We also provide detailed analyses of our datasets to assess the effects of various programming languages and docstrings on the performance of such models. © 2023 Association for Computational Linguistics.","","Codes (symbols); Computational linguistics; Deep learning; Code search; Code understanding; Codegeneration; Docstrings; Fine tuning; High quality; Language model; Learning-based methods; Quality codes; Rule based; Large datasets","Ahmad W. U., Chakraborty S., Ray B., Chang K., Unified pre-training for program understanding and generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, pp. 2655-2668, (2021); Ahmad W. U., Chakraborty S., Ray B., Chang K., Unified Pre-training for Program Understanding and Generation, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021, pp. 2655-2668, (2021); Ahmed T., Devanbu P., Multilingual training for software engineering, Proceedings of the 44th International Conference on Software Engineering, pp. 1443-1455, (2022); Brown T. B., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D. M., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language models are few-shot learners, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, (2020); Bui N. D., Yu Y., Jiang L., Sar: learning cross-language api mappings with little knowledge, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 796-806, (2019); Bui N. D., Yu Y., Jiang L., Infercode: Self-supervised learning of code representations by predicting subtrees, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 1186-1197, (2021); Bui N. D., Yu Y., Jiang L., Self-supervised contrastive learning for code retrieval and summarization via semantic-preserving transformations, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 511-521, (2021); Bui N. D., Yu Y., Jiang L., Treecaps: Tree-based capsule networks for source code processing, Proceedings of the AAAI Conference on Artificial Intelligence, 35, pp. 30-38, (2021); Chakraborty S., Ahmed T., Ding Y., Devanbu P. T., Ray B., Natgen: generative pre-training by “naturalizing” source code, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 18-30, (2022); Chen M., Tworek J., Jun H., Yuan Q., Pinto H. P. d. O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, (2021); Ciurumelea A., Proksch S., Gall H. C., Suggesting comment completions for python using neural language models, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 456-467, (2020); Clement C. B., Drain D., Timcheck J., Svyatkovskiy A., Sundaresan N., Pymt5: multi-mode translation of natural language and python code with transformers, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, pp. 9052-9065, (2020); Dau A. T. V., Bui N. D. Q., Nguyen-Duc T., Thanh-Tung H., Towards using data-influence methods to detect noisy samples in source code corpora, 37th IEEE/ACM International Conference on Automated Software Engineering, ASE 2022, pp. 148:1-148:3, (2022); Elnaggar A., Ding W., Jones L., Gibbs T., Feher T., Angerer C., Severini S., Matthes F., Rost B., Codetrans: Towards cracking the language of silicon's code through self-supervised deep learning and high performance computing, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Code-bert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020, volume EMNLP 2020 of Findings of ACL, pp. 1536-1547; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Gao L., Biderman S., Black S., Golding L., Hoppe T., Foster C., Phang J., He H., Thite A., Nabeshima N., Et al., The pile: An 800gb dataset of diverse text for language modeling, (2020); Gao Z., Xia X., Grundy J., Lo D., Li Y., Generating question titles for stack overflow from mined code snippets, ACM Trans. Softw. Eng. Methodol, 29, 4, pp. 1-26:37, (2020); Gordon M. A., Duh K., Kaplan J., Data and parameter scaling laws for neural machine translation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 5915-5922, (2021); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S. K., Clement C. B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, (2021); Guo D., Lu S., Duan N., Wang Y., Zhou M., Yin J., Unixcoder: Unified cross-modal pre-training for code representation, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022, pp. 7212-7225; Hasan M., Muttaqueen T., Ishtiaq A. A., Mehrab K. S., Haque M. M. A., Hasan T., Ahmad W. U., Iqbal A., Shahriyar R., Codesc: A large code-description parallel dataset, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021, volume ACL/IJCNLP 2021 of Findings of ACL, pp. 210-218; Hendrycks D., Basart S., Kadavath S., Mazeika M., Arora A., Guo E., Burns C., Puranik S., He H., Song D., Steinhardt J., Measuring coding challenge competence with APPS, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021; Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empir. Softw. Eng, 25, 3, pp. 2179-2217, (2020); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Mapping language to code in programmatic context, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1643-1652, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Mapping language to code in programmatic context, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1643-1652, (2018); Kanade A., Maniatis P., Balakrishnan G., Shi K., Learning and evaluating contextual embedding of source code, International Conference on Machine Learning, pp. 5110-5121, (2020); Kaplan J., McCandlish S., Henighan T., Brown T. B., Chess B., Child R., Gray S., Radford A., Wu J., Amodei D., Scaling laws for neural language models, (2020); Khan S. S., Niloy N. T., Azmain M. A., Kabir A., Impact of label noise and efficacy of noise filters in software defect prediction, The 32nd International Conference on Software Engineering and Knowledge Engineering, SEKE 2020, pp. 347-352, (2020); Kocetkov D., Li R., Allal L. B., Li J., Mou C., Ferrandis C. M., Jernite Y., Mitchell M., Hughes S., Wolf T., Et al., The stack: 3 tb of permissively licensed source code, (2022); Laurencon H., Saulnier L., Wang T., Akiki C., del Moral A. V., Scao T. L., Werra L. V., Mou C., Ponferrada E. G., Nguyen H., Frohberg J., Sasko M., Lhoest Q., McMillan-Major A., Dupont G., Biderman S., Rogers A., allal L. B., Toni F. D., Pistilli G., Nguyen O., Nikpoor S., Masoud M., Colombo P., de la Rosa J., Villegas P., Thrush T., Longpre S., Nagel S., Weber L., Munoz M., Zhu J., Strien D. V., Alyafeai Z., Almubarak K., Vu M. C., Gonzalez-Dios I., Soroa A., Lo K., Dey M., Suarez P. O., Gokaslan A., Bose S., Adelani D., Phan L., Tran H., Yu I., Pai S., Chim J., Lepercq V., Ilic S., Mitchell M., Luccioni S. A., Jernite Y., The bigscience roots corpus: A 1.6tb composite multilingual dataset, (2023); LeClair A., McMillan C., Recommendations for datasets for source code summarization, pp. 3931-3937, (2019); LeClair A., Jiang S., McMillan C., A neural model for generating natural language summaries of program subroutines, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 795-806, (2019); Lin C.-Y., Rouge: A package for automatic evaluation of summaries, Text summarization branches out, pp. 74-81, (2004); Lin C.-Y., Och F. J., Orange: a method for evaluating automatic evaluation metrics for machine translation, COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, pp. 501-507, (2004); Liu K., Yang G., Chen X., Yu C., Sotitle: A transformer-based post title generation approach for stack overflow, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, pp. 577-588, (2022); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: a robustly optimized bert pretraining approach, (2019); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A robustly optimized bert pretraining approach, (2019); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C. B., Drain D., Jiang D., Tang D., Li G., Zhou L., Shou L., Zhou L., Tufano M., Gong M., Zhou M., Duan N., Sundaresan N., Deng S. K., Fu S., Liu S., Codexglue: A machine learning benchmark dataset for code understanding and generation, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021; Luo Z., Xu C., Zhao P., Sun Q., Geng X., Hu W., Tao C., Ma J., Lin Q., Jiang D., Wizardcoder: Empowering code large language models with evol-instruct, (2023); Mahmud J., Faisal F., Arnob R. I., Anastasopoulos A., Moran K., Code to comment translation: A comparative study on model effectiveness & errors, (2021); Nguyen C., Ngo L., Nguyen T., Retrieving relevant context to align representations for cross-lingual event detection, Findings of the Association for Computational Linguistics: ACL 2023, pp. 2157-2170, (2023); Nijkamp E., Pang B., Hayashi H., Tu L., Wang H., Zhou Y., Savarese S., Xiong C., Code-gen: An open large language model for code with multi-turn program synthesis, The Eleventh International Conference on Learning Representations, (2023); Niu C., Li C., Ng V., Ge J., Huang L., Luo B., Sptcode: sequence-to-sequence pre-training for learning source code representations, Proceedings of the 44th International Conference on Software Engineering, pp. 2006-2018, (2022); Peng D., Zheng S., Li Y., Ke G., He D., Liu T.-Y., How could neural networks understand programs?, International Conference on Machine Learning, pp. 8476-8486, (2021); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P. J., Exploring the limits of transfer learning with a unified text-to-text transformer, (2019); Roziere B., Lachaux M.-A., Chanussot L., Lample G., Unsupervised translation of programming languages, Advances in Neural Information Processing Systems, 33, pp. 20601-20611, (2020); Scao T. L., Fan A., Akiki C., Pavlick E., Ilic S., Hesslow D., Castagne R., Luccioni A. S., Yvon F., Galle M., Et al., Bloom: A 176b-parameter open-access multilingual language model, (2022); Shen B., Zhang J., Chen T., Zan D., Geng B., Fu A., Zeng M., Yu A., Ji J., Zhao J., Et al., Pangu-coder2: Boosting large language models for code with ranking feedback, (2023); Sorscher B., Geirhos R., Shekhar S., Ganguli S., Morcos A., Beyond neural scaling laws: beating power law scaling via data pruning, Advances in Neural Information Processing Systems, 35, pp. 19523-19536, (2022); To H., Bui N., Guo J., Nguyen T., Better language models of code through self-improvement, (2023); Touvron H., Lavril T., Izacard G., Martinet X., Lachaux M.-A., Lacroix T., Roziere B., Goyal N., Ham-bro E., Azhar F., Rodriguez A., Joulin A., Grave E., Lample G., Llama: Open and efficient foundation language models, (2023); Tunstall L., Von Werra L., Wolf T., Natural language processing with transformers, (2022); Van L. N., Hai N. L., Pham H., Than K., Auxiliary local variables for improving regularization/prior approach in continual learning, Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 16-28, (2022); Wang Y., Wang W., Joty S. R., Hoi S. C. H., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Wang Y., Le H., Gotmare A. D., Bui N. D. Q., Li J., Hoi S. C. H., Codet5+: Open code large language models for code understanding and generation, (2023); Xia C. S., Wei Y., Zhang L., Practical program repair in the era of large pre-trained language models, (2022); Yadav P., Sun Q., Ding H., Li X., Zhang D., Tan M., Bhatia P., Ma X., Nallapati R., Ramanathan M. K., Bansal M., Xiang B., Exploring continual learning for code generation models, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pp. 782-792; Zhang T., Kishore V., Wu F., Weinberger K. Q., Artzi Y., Bertscore: Evaluating text generation with BERT, (2020); Zhang Z., Yu W., Yu M., Guo Z., Jiang M., A survey of multi-task learning in natural language processing: Regarding task relatedness and training methods, Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, pp. 943-956, (2023); Zhou C., Liu P., Xu P., Iyer S., Sun J., Mao Y., Ma X., Efrat A., Yu P., Yu L., Et al., Lima: Less is more for alignment, (2023); Zhu E., Markovtsev V., Astafiev A., Ha C., Lukasiewicz W., Foster A., Oriekhov A., Halliwell J., Mann K., Joshi K., Rosenthal M. J., TianHuan Q., Ibraimoski S., Thakur S., Ortolani S., Letal V., Bentley Z., Assa R., (2023)","","Association for Computational Linguistics (ACL)","Apple; Colossal-AI; et al.; Google Research; GTCOM; King Salman Global Academy for Arabic Language","2023 Findings of the Association for Computational Linguistics: EMNLP 2023","6 December 2023 through 10 December 2023","Singapore","196127","Conference paper","Final","","Scopus","2-s2.0-85183289625"
"Kumar R.; Joshi A.; Sharan H.O.; Peng S.-L.; Dudhagara C.R.","Kumar, Rajeev (58973251200); Joshi, Ankush (58385092300); Sharan, Hari Om (58026381300); Peng, Sheng-Lung (58973097400); Dudhagara, Chetan R. (58402594800)","58973251200; 58385092300; 58026381300; 58973097400; 58402594800","The ethical frontier of AI and data analysis","2024","The Ethical Frontier of AI and Data Analysis","","","","1","475","474","0","10.4018/979-8-3693-2964-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189601406&doi=10.4018%2f979-8-3693-2964-1&partnerID=40&md5=c591996a91637e79d3e1dd27cc10b011","In the advancing fields of artificial intelligence (AI) and data science, a pressing ethical dilemma arises. As technology continues its relentless march forward, ethical considerations within these domains become increasingly complex and critical. Bias in algorithms, lack of transparency, data privacy breaches, and the broader societal repercussions of AI applications are demanding urgent attention. This ethical quandary poses a formidable challenge for researchers, academics, and industry professionals alike, threatening the very foundation of responsible technological innovation. Navigating this ethical minefield requires a comprehensive understanding of the multifaceted issues at hand. The Ethical Frontier of AI and Data Analysis is an indispensable resource crafted to address the ethical challenges that define the future of AI and data science. Researchers and academics who find themselves at the forefront of this challenge are grappling with the evolving landscape of AI and data science ethics. Underscoring the need for this book is the current lack of clarity on ethical frameworks, bias mitigation strategies, and the broader societal implications, which hinder progress and leave a void in the discourse. As the demand for responsible AI solutions intensifies, the imperative for this reliable guide that consolidates, explores, and advances the dialogue on ethical considerations grows exponentially. Tailored for researchers, academics, and professionals, this publication serves as a beacon of ethical excellence. With a comprehensive exploration of bias, fairness, transparency, and accountability, it guides readers through the intricate web of ethical considerations. From foundational philosophical frameworks to real-world case studies, the book offers a roadmap to not only understand but actively shape the ethical trajectory of AI and data science. It is more than a book; it serves as a transformative tool for those seeking to align technological innovation with ethical standards and societal values. © 2024 by IGI Global. All rights reserved.","","","Chen M., Zhang Z., Wang T., Backe M., When Machine Unlearning Jeopardizes Privacy, (2021); Aaronson D., Faber J., Hartley D., Mazumder B., Sharkey P., The long-run effects of the 1930s HOLC ""redlining"" maps on place-based measures of economic opportunity and socioeconomic success, Regional Science and Urban Economics, 86, (2021); Aa S., Ahmad S., Cybersecurity Threats and Attacks in Healthcare, (2021); Abbasi-Sureshjani S., Raumanns R., Michels B., Schouten G., Cheplygina V., Risk of Training Diagnostic Algorithms on Data with Demographic Bias, Interpretable and Annotation-Efficient Learning for Medical Image Computing: Third International Workshop iMIMIC 2020, (2020); Abd El Kader I., Xu G., Shuai Z., Saminu S., Javaid I., Ahmad I.S., Kamhi S., Brain Tumor Detection and Classification on MR Images by a Deep Wavelet Auto-Encoder Model, Diagnostics (Basel), 11, 9, (2021); Abdulkarim B., Kamberov R., Hay G.J., Supporting Urban Energy Efficiency with Volunteered Roof Information and the Google Maps API, Remote Sensing (Basel), 6, 10, pp. 9691-9711, (2014); Abdulwahid A.H., Pattnaik M., Palav M.R., Babu S.T., Manoharan G., Selvi G.P., Library Management System Using Artificial Intelligence, 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM), pp. 1-7, (2023); Abrokwah-Larbi K., Awuku-Larbi Y., The impact of artificial intelligence in marketing on the performance of business organizations: Evidence from SMEs in an emerging economy, Journal of Entrepreneurship in Emerging Economies, (2023); Achar A., Artificial intelligence for early literacy in India: A case study of Pratham, (2017); Acikkar M., Akay M.F., Support vector machines for predicting the admission decision of a candidate to the School of Physical Education and Sports at Cukurova University, Expert Systems with Applications, 36, 3, pp. 7228-7233, (2009); Adadi A., A survey on data-efficient algorithms in big data era, Journal of Big Data, 8, 1, (2021); Adams A., Adelfio A., Barnes B., Berlien R., Branco D., Coogan A., Garson L., Ramirez N., Stansbury N., Stewart J., Worman G., Butler P.J., Brown D., Risk-Based Monitoring in Clinical Trials: 2021 Update, Therapeutic Innovation & Regulatory Science, 57, 3, pp. 529-537, (2023); Adel T., Ghahramani Z., Weller A., Discovering interpretable representations for both deep generative and discriminative models, International Conference on Machine Learning, pp. 50-59, (2018); Agarwal A., Gans J., Goldfarb A., The Obama Administration's Roadmap for AI Policy, Harvard Business Review, (2016); Agbo C., Mahmoud Q., Eklund J., Blockchain Technology in Healthcare: A Systematic Review, Health Care, 7, 2, (2019); Agostini M., Pucciarelli S., Enzo M.V., Del Bianco P., Briarava M., Bedin C., Maretto I., Friso M.L., Lonardi S., Mescoli C., Toppan P., Urso E., Nitti D., Circulating Cell-Free DNA: A Promising Marker of Pathologic Tumor Response in Rectal Cancer Patients Receiving Preoperative Chemoradiotherapy, Annals of Surgical Oncology, 18, 9, pp. 2461-2468, (2011); Aguilar-Esteva V., Acosta-Banda A., Carreno Aguilera R., Patino Ortiz M., Sustainable Social Development through the Use of Artificial Intelligence and Data Science in Education during the COVID Emergency: A Systematic Review Using PRISMA, 15, 8, (2023); Aguilar J., Garces-Jimenez A., Moreno M.D., Garcia R., A systematic literature review on using artificial intelligence in energy self-management in smart buildings, Renewable & Sustainable Energy Reviews, 151, (2021); Ahasan R., Hossain M.M., Leveraging GIS and spatial analysis for informed decision-making in COVID-19 pandemic, Health Policy and Technology, 10, 1, pp. 7-9, (2021); Ahmad B., The UAE Federal Government's E-Participation Roadmap: Developments in UAE Empowerment Initiatives With VGI/PGIS and Location Based Services (LBS), Canadian Social Science, 11, 5, (2015); Ahmad H.A., Hanandeh R., Alazzawi F.R., Al-Daradkah A., ElDmrat A.T., Ghaith Y.M., Darawsheh S.R., The effects of big data, artificial intelligence, and business intelligence on e-learning and business performance: Evidence from Jordanian telecommunication firms, International Journal of Data and Network Science, (2023); Ahmad M., Exploring the Potential of Spatial Data for Enhancing Higher Education Learners' Learning Outcomes, Design and Implementation of Higher Education Learners' Learning Outcomes (HELLO), pp. 128-145, (2023); Ahmad M., Leveraging Social Media Geographic Information for Smart Governance and Policy Making:Opportunities and Challenges, Global Perspectives on Social Media Usage Within Governments, pp. 192-213, (2023); Ahmad M., Spatial Data as a Catalyst to Drive Entrepreneurial Growth and Sustainable Development, Technological Innovation Driving Sustainable Entrepreneurial Growth in Developing Nations, pp. 79-104, (2023); Ahmad M., Unlocking the Power of Spatial Big Data for Sustainable Development:From Capacity Building to Food Security and Food Traceability, Crafting a Sustainable Future Through Education and Sustainable Development, pp. 204-218, (2023); Ahmad M., Khayal M.S.H., Tahir A., Analysis of Factors Affecting Adoption of Volunteered Geographic Information in the Context of National Spatial Data Infrastructure, ISPRS International Journal of Geo-Information, 11, 2, (2022); Ai'vodji U., Arai H., Fortineau O., Gambs S., Hara S., Tapp A., Fairwashing: The risk of rationalization, Proceedings of the International Conference on Machine Learning, pp. 161-170, (2019); Ajzen I., From intentions to actions: A theory of planned behavior. Action control, (1985); Ajzen I., The theory of planned behavior, Organizational Behavior and Human Decision Processes, 50, 2, pp. 179-211, (1991); Ajzen I., Perceived behavioral control, self-efficacy, locus of control, and the theory of planned behavior 1, Journal of Applied Social Psychology, 32, 4, pp. 665-683, (2002); Akgun S., Greenhow C., Artificial Intelligence in Education: Addressing Ethical Challenges in K-12 Settings, AI and Ethics, pp. 1-10, (2021); Akgun S., Greenhow C., Artificial Intelligence (AI) in Education: Addressing Societal and Ethical Challenges in K-12 Settings, Proceedings of the 16th International Conference of the Learning Sciences-ICLS 2022, pp. 1373-1376, (2022); Akgun S., Greenhow C., Artificial intelligence in education: Addressing ethical challenges in K-12 settings, AI and Ethics, 2, 3, pp. 431-440, (2022); Home; Akter S., McCarthy G., Sajib S., Michael K., Dwivedi Y.K., D'Ambra J., Shen K.N., Algorithmic bias in data-driven innovation in the age of AI, International Journal of Information Management, 60, (2021); Alblooshi M.A., Mohamed A.M., Yusr M.M., Moderating Role of Artificial Intelligence Between Leadership Skills and Business Continuity, International Journal of Professional Business Review, (2023); Albuquerque R., Koskinen Y., Zhang C., Corporate social responsibility and firm risk: Theory and empirical evidence, Management Science, 65, 10, pp. 4451-4469, (2019); Aldaghri N., Coded Machine Unlearning, IEEE Access Practical Innovations Open Solutions, (2021); Aler Tubella A., Mora-Cantallops M., Nieves J.C., How to teach responsible AI in Higher Education: Challenges and opportunities, Ethics and Information Technology, 26, 1, (2024); Alexandron G., Yoo L.Y., Ruiperez-Valiente J.A., Lee S., Pritchard D.E., Are MOOC learning analytics results trustworthy? With fake learners, they might not be!, International Journal of Artificial Intelligence in Education, 29, 4, pp. 484-506, (2019); Alexopoulos G.S., Artificial Intelligence in Geriatric Psychiatry Through the Lens of Contemporary Philosophy, The American Journal of Geriatric Psychiatry, (2023); Aliakbari Sani S., Khorram A., Jaffari A., Ebrahimi G., Development of processing map for InX-750 superalloy using hyperbolic sinus equation and ANN model, Rare Metals, 40, 12, pp. 3598-3607, (2021); Allen B., Agarwal S., Coombs L., Wald C., Dreyer K., 2020 ACR Data Science Institute Artificial Intelligence Survey, Journal of the American College of Radiology, 18, 8, pp. 1153-1159, (2021); Allioui H., Mourdi Y., Unleashing the potential of AI: Investigating cutting-edge technologies that are transforming businesses. [IJCEDS], International Journal of Computer Engineering and Data Science, 3, 2, pp. 1-12, (2023); Al-Mahairah M.S., Manoharan G., Singh J., Krishna S.H., Principles of Management, (2022); Alnssyan B., Ahmad Z., Malela-Majika J.C., Seong J.T., Shafik W., On the identifiability and statistical features of a new distributional approach with reliability applications, AIP Advances, 13, 12, (2023); Alzamil H., Aloraini K., AlAgeel R., Ghanim A., Alsaaran R., Alsomali N., Albahlal R.A., Alnuaim L., Disparity among endocrinologists and gynaecologists in the diagnosis of polycystic ovarian syndrome, Sultan Qaboos University Medical Journal, 20, 3, (2020); Amifor J., Political Advertising Design in Nigeria, 1960-2007, International Journal of Arts and Humanities, 4, 2, pp. 149-163, (2016); Anadioti E., Musharbash L., Blatz M.B., Papavasiliou G., Kamposiora P., 3D printed complete removable dental prostheses: A narrative review, BMC Oral Health, 20, 1, (2020); Ananth M., Mathioudakis M., Certifiable Machine Un-learningfor Linear Models, (2021); Andre Q., Carmon Z., Wertenbroch K., Crum A., Frank D., Goldstein W., Huber J., van Boven L., Weber B., Yang H., Consumer choice and autonomy in the age of artificial intelligence and big data, Customer Needs and Solutions, 5, 1, pp. 28-37, (2018); Andrushia A.D., Neebha T.M., Patricia A.T., Sagayam K.M., Pramanik S., Capsule Network based Disease Classification for VitisVinifera Leaves, Neural Computing & Applications, (2023); Angwin J., Larson J., Mattu S., Kirchner L., Machine Bias, (2016); Anitha C., Komala C., Vivekanand C.V., Lalitha S., Boopathi S., Artificial Intelligence driven security model for Internet of Medical Things (IoMT), IEEE Explore, pp. 1-7, (2023); An L., Grimm V., Bai Y., Sullivan A., Turner B.L., Malleson N., Heppenstall A., Vincenot C., Robinson D., Ye X., Liu J., Lindkvist E., Tang W., Modeling agent decision and behavior in the light of data science and artificial intelligence, Environmental Modelling & Software, 166, (2023); Annis A., Nardi F., Integrating VGI and 2D hydraulic models into a data assimilation framework for real time flood forecasting and mapping, Geo-Spatial Information Science, 22, 4, pp. 223-236, (2019); Antoniou V., Fonte C.C., See L., Estima J., Arsanjani J.J., Lupia F., Minghini M., Foody G., Fritz S., Investigating the feasibility of geo-Tagged photographs as sources of land cover input data, ISPRS International Journal of Geo-Information, 5, 5, (2016); Antunes P., Sapateiro C., Zurita G., Baloian N., Integrating spatial data and decision models in an e-planning tool, (2010); Anu S., Literature Review and Challenges of Data Mining Techniques for Social Network Analysis, Journal Advances in Computational Sciences and Technology, 10, 5, (2017); Anu S., Hybrid Neuro-Fuzzy Classification Algorithm for Social Network. International, Journal of Engineering and Advanced Technology, 8, 6, (2019); Appelgren E., Jonsson A.M., Engaging Citizens for Climate Change-Challenges for Journalism, Digital Journalism (Abingdon, England), 9, 6, pp. 755-772, (2021); Baker R., Hawn A., Algorithmic Bias in Education, International Journal of Artificial Intelligence in Education, pp. 1-41, (2021); Bandura A., Social foundation of thought and action: A social-cognitive view, (1986); Bandura A., Social cognitive theory of self-regulation, Organizational Behavior and Human Decision Processes, 50, 2, pp. 248-287, (1991); Barbosa L., Nguyen H., Nguyen T., Pinnamaneni R., Freire J., Creating and exploring web form repositories, Proc. ACM SIGMOD Int. Conf. Manage, (2010); Barocas S., Hardt M., Narayanan A., Fairness in machine learning, Nips tutorial, (2017); Baroody R.A., Sensory experiences and the development of mathematical reasoning, (2004); Bates T., Cobo C., Marino O., Wheeler S., Can artificial intelligence transform higher education?, International Journal of Educational Technology in Higher Education, 17, 1, (2020); 5G support in healthcare system, (2022); Bautista Y.J.P., Theran C., Alo R., Lima V., Health Disparities Through Generative AI Models: A Comparison Study Using a Domain Specific Large Language Model, Proceedings of the Future Technologies Conference, pp. 220-232, (2023); Beauchamp T.L., Childress J.F., Principles of Biomedical Ethics, (1995); Begum A., Kumar R., Design an Archetype to Predict the impact of diet and lifestyle interventions in autoimmune diseases using Deep Learning and Artificial Intelligence, (2022); Belenguer L., AI bias: Exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry, AI and Ethics, 2, 4, pp. 771-787, (2022); Bellamy R.K., Dey K., Hind M., Hoffman S.C., Houde S., Kannan K., Lohia P., Martino J., Mehta S., Mojsilovic A., Nagar S., Ramamurthy K.N., Richards J., Saha D., Sattigeri P., Singh M., Varshney K.R., Zhang Y., AI Fairness 360: An extensible toolkit for detecting and mitigating algorithmic bias, IBM Journal of Research and Development, 63, 4-5, pp. 4-1, (2019); Benabed A., Artificial Intelligence's Relevance for Energy Optimization Companies and Business Internationalization, (2023); Benke I., Feine J., Venable J.R., Maedche A., On implementing ethical principles in design science research, AIS Transactions on Human-Computer Interaction, 12, 4, pp. 206-227, (2020); Berelson B., The Debates in the Light of Research: A Survey of Surveys, The Great Debates, Bloomington, Indiana University Press, 1962; Jay Blumler and Denis McQuail Television in Politics, (1969); Berente N., Gu B., Recker J., Santhanam R., Managing artificial intelligence, Management Information Systems Quarterly, 45, 3, (2021); Bergman M., White paper: The deep web: Surfacing hidden value, J. Electron, 7, 1, (2001); Berman G., de la Rosa S., Accone T., Ethical considerations when using geospatial technologies for evidence generation, Innocenti Discussion Papers: Vol. no. 2018-02, (2018); Bhakri S., Shri D., Artificial Intelligence(Ai): Applications And Implications (Ai) For Indian Economy, (2021); Bharadiya J.P., Machine learning and AI in business intelligence: Trends and opportunities. [IJC], International Journal of Computer, 48, 1, pp. 123-134, (2023); Bhatia S.N., Ingber D.E., Microfluidic organs-on-chips, Nature Biotechnology, 32, 8, pp. 760-772, (2014); Bhattacharya S., Dimensions of Political Marketing: A Study from the Indian Perspective, International Journal of Current Advanced Research, 7, pp. 11138-11143, (2018); Bhattacharyya D., Brain Tumor Detection Using MRI Image Analysis, (2011); Bird S., Dudik M., Edgar R., Horn B., Lutz R., Milan V., Walker K., Fairlearn: A toolkit for assessing and improving fairness in AI, Microsoft Tech. Rep. MSR-TR-2020-32, (2020); Biswas G., Segedy J.R., Bunchongchit K., From design to implementation to practice a learning by teaching system: Betty's Brain, International Journal of Artificial Intelligence in Education, 26, 1, pp. 350-364, (2016); Bittner C., Michel B., Turk C., Turning the spotlight on the crowd: Examining the participatory ethics and practices of crisis mapping, ACME, 15, 1, (2016); Bizer C., Vidal M.-E., Skaf-Molli H., Linked Open Data, (2018); Black P., Wiliam D., Assessment and classroom learning, (1998); Bodenstedt S., Wagner M., Muller-Stich B.P., Weitz J., Speidel S., Artificial intelligence-assisted surgery: Potential and challenges, Visceral Medicine, 36, 6, pp. 450-455, (2020); Boehmke B.C., Greenwell B.M., Interpretable Machine Learning, (2019); Bohr A., Memarzadeh K., Chapter 2-The rise of artificial intelligence in healthcare applications, (2020); Boje D., Narrative Methods for Organizational & Communication Research, (2011); Bolander T., What do we lose when machines take the decisions?, The Journal of Management and Governance, 23, 4, pp. 849-867, (2019); Bongard A., Automating talent acquisition: Smart recruitment, predictive hiring algorithms, and the data-driven nature of artificial intelligence, Psychosociological Issues in Human Resource Management, 7, 1, pp. 36-41, (2019); Boopathi S., Experimental study and multi-objective optimization of near-dry wire-cut electrical discharge machining process, (2013); Boopathi S., Cryogenically treated and untreated stainless steel grade 317 in sustainable wire electrical discharge machining process: A comparative study, Environmental Science and Pollution Research, pp. 1-10, (2022); Boopathi S., Kumar P.K.S., Meena R.S., Sudhakar M., Sustainable Developments of Modern Soil-Less Agro-Cultivation Systems: Aquaponic Culture, pp. 69-87, (2023); Boopathi S., An extensive review on sustainable developments of dry and near-dry electrical discharge machining processes, ASME: Journal of Manufacturing Science and Engineering, 144, 5, (2022); Boopathi S., An investigation on gas emission concentration and relative emission rate of the near-dry wire-cut electrical discharge machining process, Environmental Science and Pollution Research International, 29, 57, pp. 86237-86246, (2022); Boopathi S., Alqahtani A.S., Mubarakali A., Panchatcharam P., Sustainable developments in near-dry electrical discharge machining process using sunflower oil-mist dielectric fluid, Environmental Science and Pollution Research International, pp. 1-20, (2023); Boopathi S., Davim J.P., Applications of Nanoparticles in Various Manufacturing Processes, Sustainable Utilization of Nanoparticles and Nanofluids in Engineering Applications, pp. 1-31, (2023); Boopathi S., Davim J.P., Sustainable Utilization of Nanoparticles and Nanofluids in Engineering Applications, (2023); Boopathi S., Kanike U.K., Applications of Artificial Intelligent and Machine Learning Techniques in Image Processing, Handbook of Research on Thrust Technologies' Effect on Image Processing, pp. 151-173, (2023); Boopathi S., Sivakumar K., Experimental investigation and parameter optimization of near-dry wire-cut electrical discharge machining using multi-objective evolutionary algorithm, International Journal of Advanced Manufacturing Technology, 67, 9-12, pp. 2639-2655, (2013); Boopathi S., Sureshkumar M., Sathiskumar S., Parametric Optimization of LPG Refrigeration System Using Artificial Bee Colony Algorithm, International Conference on Recent Advances in Mechanical Engineering Research and Development, pp. 97-105, (2022); Boopathi S., Umareddy M., Elangovan M., Applications of Nano-Cutting Fluids in Advanced Machining Processes, Sustainable Utilization of Nanoparticles and Nanofluids in Engineering Applications, pp. 211-234, (2023); Borrego-Diaz J., Galan-Paez J., Explainable Artificial Intelligence in Data Science, Minds and Machines, 32, 3, pp. 485-531, (2022); Bostrom N., Yudkowsky E., The ethics of artificial intelligence, pp. 316-334, (2014); Brei V.A., Machine learning in marketing: Overview, learning strategies, applications, and future developments, Foundations and Trends® in Marketing, 14, 3, pp. 173-236, (2020); Brey P.A.E., Anticipatory Ethics for Emerging Technologies, NanoEthics, 6, 1, pp. 1-13, (2012); Briel M., Elger B.S., McLennan S., Schandelmaier S., von Elm E., Satalkar P., Exploring reasons for recruitment failure in clinical trials: A qualitative study with clinical trial stakeholders in Switzerland, Germany, and Canada, Trials, 22, 1, (2021); Brock D.W., Ethical Issues in the Use of Cost Effectiveness Analysis for the Prioritisation of Health Care Resources, (2019); Brodie M.L., What Is Data Science? In Applied Data Science: Lessons Learned for the Data-Driven Business, (2019); Brophy J., Lowd D., Machine Unlearning for Random Forests, (2021); Brundage M., Avin S., Wang J., Belfield H., Krueger G., Hadfield G., Anderljung M., Toward trustworthy AI development: Mechanisms for supporting verifiable claims, (2020); Brynjolfsson E., Li D., Raymond L.R., Generative AI at work (No, (2023); Brynjolfsson E., Mcafee A., Artificial intelligence, for real, Harvard Business Review, 1, pp. 1-31, (2017); Brzezinski M., Krzeminska I., The strategies for innovating with virtual reality and artificial intelligence: A literature review, Technium, 8, pp. 72-83, (2023); Buallay A., Fadel S.M., Al-Ajmi J.Y., Saudagaran S., Sustainability reporting and performance of MENA banks: Is there a trade-off?, Measuring Business Excellence, 24, 2, pp. 197-221, (2020); Buchanan B.G., Artificial intelligence as an experimental science, Aspects of artificial intelligence, pp. 209-250, (1988); Bugaj M., Kliestik T., Lazaroiu G., Generative Artificial Intelligence-based Diagnostic Algorithms in Disease Risk Detection, Personalized and Targeted Healthcare Procedures, and Patient Care Safety and Quality, Contemporary Readings in Law and Social Justice, 15, 1, pp. 9-26, (2023); Bugaj M., Kliestik T., Lazaroiu G., Generative Artificial Intelligence-based Diagnostic Pagano, S., Holzapfel, S., Kappenschneider, T., Meyer, M., Maderbacher, G., Grifka, J., & Holzapfel, D. E. (2023). Arthrosis diagnosis and treatment recommendations in clinical practice: An exploratory investigation with the generative AI model GPT-4, Journal of Orthopaedics and Traumatology, 24, 1, (2023); Bughin J., Hazan E., Sree Ramaswamy P., Artificial intelligence the next digital frontier, (2017); Bull S., Kay J., SMILI©: A framework for interfaces to learning data in open learner models, learning analytics and related fields, International Journal of Artificial Intelligence in Education, 26, 1, pp. 293-331, (2016); Buolamwini J., Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification, 81, (2018); Burkhardt G., Boy F., Doneddu D., Hajli N., Privacy Behaviour: A Model for Online Informed Consent, Journal of Business Ethics, 186, 1, pp. 237-255, (2022); Burton R.R., Brown J.S., An investigation of computer coaching for informal learning activities, International Journal of Man-Machine Studies, 11, 1, pp. 5-24, (1979); Cai Y., Using a self-organizing artificial neural network model to distinguish the onset period of citrus canker disease, Journal of Plant Pathology, 1, pp. 43-46, (1995); Calcagni F., Amorim Maia A.T., Connolly J.J.T., Langemeyer J., Digital co-construction of relational values: Understanding the role of social media for sustainability, Sustainability Science, 14, 5, pp. 1309-1321, (2019); Cao L., Data Science: A Comprehensive Overview, ACM Computing Surveys (CSUR), 50, 3, pp. 1-42, (2017); Cao L., Data science: A comprehensive overview, ACM Computing Surveys, 50, 3, pp. 1-42, (2017); Cao L., Trans-AI/DS: Transformative, transdisciplinary and translational artificial intelligence and data science, International Journal of Data Science and Analytics, 15, 2, pp. 119-132, (2023); Cao Y., Yang J., Towards making systems forget with machine unlearning, Proc. IEEE Symposium, (2015); Carbonell J.R., AI in CAI: An artificial-intelligence approach to computer-assisted instruction, IEEE Transactions on Man-Machine Systems, 11, 4, pp. 190-202, (1970); Carney M., Value(s): Building a Better World for All, (2021); Carter S.M., Rogers W., Win K.T., Frazer H., Richards B., Houssami N., The ethical, legal and social implications of using artificial intelligence systems in breast cancer care, The Breast, 49, pp. 25-32, (2020); Castello-Sirvent F., Garcia Felix V., Canos-Daros L., AI In Higher Education: New Ethical Challenges For Students And Teachers, EDULEARN23 Proceedings, pp. 4463-4470, (2023); Cate F., Mayer-Schonberger V., Notice and consent in a world of Big Data, International Data Privacy Law, 3, 2, pp. 67-73, (2013); Cath C., Governing artificial intelligence: Ethical, legal and technical opportunities and challenges, Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences, 376, 2133, (2018); Cath C., Wachter S., Mittelstadt B., Taddeo M., Floridi L., Artificial intelligence and the 'good society': The US, EU, and UK approach, Science and Engineering Ethics, 24, pp. 505-528, (2018); Cavazos J.G., Phillips P.J., Castillo C.D., O'Toole A.J., Accuracy comparison across face recognition algorithms: Where are we on measuring race bias?, IEEE Transactions on Biometrics, Behavior, and Identity Science, 3, 1, pp. 101-111, (2020); Cen L., Research on the Recognition of Cucumber Anthracnose and Brown Spot Based on Color Statistical Features of Color Images, Journal of Horticulture, 34, 6, pp. 124-124, (2007); Chacko A., Hayajneh T., Security and Privacy Issues with IoT in Healthcare, EAI Endorsed Transactions on Pervasive Health and Technology, 4, 14, (2018); Chandgude V., Kawade B., Role of Artificial Intelligence and Machine Learning in Decision Making for Business Growth, International Journal of Advanced Research in Science, (2023); Chang K., He B., Li C., Patel M., Zhang Z., Structured databases on the web: Observations and implications, ACM SIGMOD Rec, (2004); Chankoson T., Chen F., Wang Z., Wang M., Sukpasjaroen K., Knowledge Mapping for the Study of Artificial Intelligence in Education Research: Literature Reviews, Journal of Intelligence Studies in Business, (2023); Chao C.Y., Wang S., Using OpenStreetMap data for the location analysis on public bicycle stations-A case study on the Youbike system in downtown Taipei city, Proceedings-39th Asian Conference on Remote Sensing: Remote Sensing Enabling Prosperity ACRS 2018, (2018); Chatila R., Firth-Butterfield K., Havens J.C., Ethically aligned design: A vision for prioritizing human wellbeing with autonomous and intelligent systems version 2, (2018); Chattopadhyay A., Maitra M., MRI-based brain tumour image detection using CNN based deep learning method, Neuroscience Informatics (Online), 2, 4, (2022); Chauhan N.R., Shukla R.K., Sengar A.S., Gupta A., Classification of Nutritional Deficiencies in Cabbage Leave Using Random Forest, 2022 11th International Conference on System Modeling & Advancement in Research Trends (SMART), pp. 1314-1319, (2022); Chawla R.N., Goyal P., Emerging trends in digital transformation: A bibliometric analysis, Benchmarking, 29, 4, pp. 1069-1112, (2022); Chen D., Qi E.Y., Innovative highlights of clinical drug trial design, Translational Research; the Journal of Laboratory and Clinical Medicine, 224, pp. 71-77, (2020); Chen M., Decary M., Artificial intelligence in healthcare: An essential guide for health leaders, Healthcare Management Forum, 33, 1, pp. 10-18, (2020); Chenthara S., Ahmed K., Wang H., Whittaker F., Security and Privacy-Preserving Challenges of e-Health Solutions in Cloud Computing, IEEE Access Practical Innovations, Open Solutions, 7, pp. 74361-74382, (2019); Chen X., Elmes G., Ye X., Chang J., Implementing a Real-Time Twitter-Based System for Resource Dispatch in Disaster Management, GeoJournal, 81, 6, pp. 863-873, (2016); Chheang V., Marquez-Hernandez R., Patel M., Rajasekaran D., Sharmin S., Caulfield G., Barmaki R.L., Towards anatomy education with generative AI-based virtual assistants in immersive virtual reality environments, (2023); Chiarello F., Belingheri P., Fantoni G., Data science for engineering design: State of the art and future directions, Computers in Industry, 129, (2021); Chkoniya V., Handbook of research on applied data science and artificial intelligence in business and industry, (2021); Choi Y., Kamal A.E., Louta M., Series Editorial: Artificial Intelligence and Data Science for Communications, IEEE Communications Magazine, 59, 11, (2021); Choi Y., Kamal A.E., Louta M., Series Editorial: Artificial Intelligence and Data Science for Communications, IEEE Communications Magazine, 60, 11, (2022); Choi Y., Kamal A.E., Louta M., Series Editorial: Artificial Intelligence and Data Science for Communications, IEEE Communications Magazine, 60, 7, (2022); Choi Y., Kamal A.E., Louta M., Series Editorial: Artificial Intelligence and Data Science for Communications, IEEE Communications Magazine, 61, 3, (2023); Choi Y., Kamal A., Louta M., Series Editorial: Artificial Intelligence and Data Science for Communications, IEEE Communications Magazine, 61, 6, (2023); Chong S., Rahman A., Narayan A.K., Guest editorial: Accounting in transition: Influence of technology, sustainability and diversity, Pacific Accounting Review, 34, 4, pp. 517-525, (2022); Chui M., Manyika J., Miremadi M., What AI can and can't do (yet) for your business, McKinsey Quarterly, 1, 97-108, (2018); Clancey W.J., Tutoring rules for guiding a case method dialogue, International Journal ofMan-Machine Studies, 11, 1, pp. 25-50, (1979); Clandinin D.J., Caine V., Lessard S., Huber J., Engaging in narrative inquiries with children and youth, (2016); Clark M., Severn M., Artificial Intelligence in Prehospital Emergency Health Care, Canadian Journal of Health Technologies, 3, 8, (2023); Cockburn I.M., Henderson R., Stern S., The impact of artificial intelligence on innovation: An exploratory analysis, The economics of artificial intelligence: An agenda, pp. 115-146, (2018); Collins A., Halverson J., Rethinking the Future of Learning: Augmented Reality and Mixed Reality in Education, (2019); Collins F.S., Varmus H., A new initiative on precision medicine, The New England Journal of Medicine, 372, 9, pp. 793-795, (2015); Comendador B.E.V., Rabago L.W., Tanguilig B.T., An educational model based on Knowledge Discovery in Databases (KDD) to predict learner's behavior using classification techniques, 2016 IEEE International Conference on Signal Processing Communications and Computing (ICSPCC), pp. 1-6, (2016); Cooke L., Ethics in information technology, ISACA Journal, 6, pp. 69-106, (2020); Copeland B., The turing test*, Minds and Machines, 10, 4, pp. 519-539, (2000); Cordeschi R., AI TURNS FIFTY: REVISITING ITS ORIGINS, Applied Artificial Intelligence, 21, 4-5, pp. 259-279, (2007); Coston A., Mishler A., Kennedy E.H., Chouldechova A., Counterfactual risk assessments, evaluation, and fairness, Proceedings of the 2020 conference on fairness, accountability and transparency, pp. 582-593, (2020); Crawford K., Finn M., The limits of crisis data: Analytical and ethical challenges of using social and mobile data to understand disasters, GeoJournal, 80, 4, pp. 491-502, (2015); Crofts P., van Rijswijk H., Negotiating'evil': Google, project maven and the corporate form, Law, technology and humans, 2, 1, pp. 75-90, (2020); Croskerry P., The importance of cognitive errors in diagnosis and strategies to minimize them, 78, 8, (2003); Crowley D.N., Breslin J.G., Corcoran P., Young K., Gamification of citizen sensing through mobile social reporting, 4th International IEEE Consumer Electronic Society-Games Innovation Conference IGiC 2012, (2012); Cruz-Jesus F., Castelli M., Oliveira T., Mendes R., Nunes C., Sa-Velho M., Rosa-Louro A., Using artificial intelligence methods to assess academic achievement in public high schools of a European Union country, Heliyon, 6, 6, (2020); Cui M., Zhang D.Y., Artificial intelligence and computational pathology, Laboratory Investigation, 101, 4, pp. 412-422, (2021); Cui X., Li W., Gu C., Big Data of Food Science and Artificial Intelligence Technology, Journal of Chinese Institute of Food Science and Technology, 21, 2, (2021); Cummiskey D., Kantian consequentialism, Ethics, 100, 3, pp. 586-615, (1990); d'Amato C., Fernandez M., Tamma V., Lecue F., Cudre-Mauroux P., Sequeda J., Heflin J., The Semantic Web-ISWC 2017: 16th International Semantic Web Conference, 10587, (2017); Dastile X., Celik T., Potsane M., Statistical and machine learning models in credit scoring: A systematic literature survey, Applied Soft Computing, 91, (2020); Dastin J., Amazon scraps secret AI recruiting tool that showed bias against women, pp. 296-299, (2022); Datta A., Tschantz M.C., Datta A., Automated Experiments on Ad Privacy Settings-A Tale of Opacity, Choice, and Discrimination, Proceedings on Privacy Enhancing Technologies. Privacy Enhancing Technologies Symposium, 1, 1, pp. 92-112, (2015); Dave B., Patel S., Shivani R., Purohit S., Chaudhury B., Synthetic data generation using generative adversarial network for tokamak plasma current quench experiments, Contributions to Plasma Physics, 63, 5-6, (2023); Davenport T.H., From analytics to artificial intelligence, Journal of Business Analytics, 1, 2, pp. 73-80, (2018); Davenport T.H., Ronanki R., Artificial intelligence for the real world, Harvard Business Review, 96, 1, pp. 108-116, (2018); Davenport T., Guha A., Grewal D., Bressgott T., How artificial intelligence will change the future of marketing, Journal of the Academy of Marketing Science, 48, 1, pp. 24-42, (2020)","","IGI Global","","","","","","Book","Final","","Scopus","2-s2.0-85189601406"
"Kaboré A.K.; Barr E.T.; Klein J.; Bissyandé T.F.","Kaboré, Abdoul Kader (57219785363); Barr, Earl T. (7005643860); Klein, Jacques (56282553000); Bissyandé, Tegawendé F. (36080354200)","57219785363; 7005643860; 56282553000; 36080354200","CodeGrid: A Grid Representation of Code","2023","ISSTA 2023 - Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis","","","","1357","1369","12","0","10.1145/3597926.3598141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167651924&doi=10.1145%2f3597926.3598141&partnerID=40&md5=653845b18e5bad5f147e9760a6587f9b","Code representation is a key step in the application of AI in software engineering. Generic NLP representations are effective but do not exploit all the rich structure inherent to code. Recent work has focused on extracting abstract syntax trees (AST) and integrating their structural information into code representations.These AST-enhanced representations advanced the state of the art and accelerated new applications of AI to software engineering. ASTs, however, neglect important aspects of code structure, notably control and data flow, leaving some potentially relevant code signal unexploited. For example, purely image-based representations perform nearly as well as AST-based representations, despite the fact that they must learn to even recognize tokens, let alone their semantics. This result, from prior work, is strong evidence that these new code representations can still be improved; it also raises the question of just what signal image-based approaches are exploiting. We answer this question. We show that code is spatial and exploit this fact to propose , a new representation that embeds tokens into a grid that preserves code layout. Unlike some of the existing state of the art, is agnostic to the downstream task: whether that task is generation or classification, can complement the learning algorithm with spatial signal. For example, we show that CNNs, which are inherently spatially-aware models, can exploit outputs to effectively tackle fundamental software engineering tasks, such as code classification, code clone detection and vulnerability detection. PixelCNN leverages 's grid representations to achieve code completion. Through extensive experiments, we validate our spatial code hypothesis, quantifying model performance as we vary the degree to which the representation preserves the grid. To demonstrate its generality, we show that augments models, improving their performance on a range of tasks, On clone detection, improves ASTNN's performance by 3.3% F1 score.  © 2023 Owner/Author.","Code TypeSetting; Spatial-Aware Neural Network","Application programs; Cloning; Codes (symbols); Image enhancement; Network coding; Trees (mathematics); Abstract Syntax Trees; Applications of AI; Code representation; Code typesetting; Neural-networks; Performance; Rich structure; Spatial-aware neural network; State of the art; Structural information; Semantics","Uddin Ahmad W., Chakraborty S., Ray B., Chang K., A transformer-based approach for source code summarization, (2020); Allamanis M., Graph Neural Networks on Program Analysis, Graph Neural Networks: Foundations, Frontiers, and Applications, (2021); Allamanis M., Barr E.T., Bird C., Sutton C., Learning Natural Coding Conventions, Proceedings of the 22nd ACM SIGSOFT Inter-national Symposium on Foundations of Software Engineering (Hong Kong, China) (FSE 2014), pp. 281-293, (2014); Alon U., Sadaka R., Levy O., Yahav E., Structural language models of code, International Conference on Machine Learning. PMLR, pp. 245-256, (2020); Alon U., Zilberstein M., Levy O., Yahav E., code2vec: Learning distributed representations of code, Proceedings of the ACM on Programming Languages, 3, POPL, pp. 1-29, (2019); Ambient Software Evoluton Group, (2013); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, (2018); Bengio Y., Simard P., Frasconi P., Learning long-term dependencies with gradient descent is difficult, IEEE transactions on neural networks, 5, 2, pp. 157-166, (1994); Bezryadin S., Bourov P., Ilinih D., Brightness calculation in digital image processing, International symposium on technologies for digital photo fulfillment, 2007, pp. 10-15, (2007); Boogerd C., Moonen L., Assessing the value of coding standards: An empirical study, 2008 IEEE International Conference on Software Maintenance, pp. 277-286, (2008); Bruch M., Monperrus M., Mezini M., Learning from Examples to Improve Code Completion Systems, pp. 213-222, (2009); Burtt H.E., Typography and Readability, Elementary English, 26, 4, pp. 212-221, (1949); Casalnuovo C., Barr E.T., Kumar Dash S., Devanbu P., Morgan E., A Theory of Dual Channel Constraints, 2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER), pp. 25-28, (2020); Checkmarx; Chen J., Hu K., Yu Y., Chen Z., Xuan Q., Liu Y., Filkov V., Software Visualization and Deep Transfer Learning for Effiective Software Defect Prediction, 2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE), pp. 578-589, (2020); Chen M., Tworek J., Jun H., Yuan Q., De Oliveira Pinto H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Petroski Such F., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Hebgen Guss W., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A.N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Chen Z., Monperrus M., A Literature Study of Embeddings on Source Code, (2019); Coleman C., Narayanan D., Kang D., Zhao T., Zhang J., Nardi L., Bailis P., Olukotun K., Re C., Zaharia M., Dawnbench: An end-to-end deep learning benchmark and competition, Training, 100, 101, (2017); Python (programming language) Indentation, (2021); Daoudi N., Samhi J., Kader Kabore A., Allix K., Bissyande T.F., Klein J., DexRay: A Simple, yet Effiective Deep Learning Approach to Android Malware Detection based on Image Representation of Bytecode, The 2nd International Workshop on Deployable Machine Learning for Security Defense (MLHat@KDD), (2021); Devlin J., Chang M., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Duff I.S., Maurice Erisman A., Ker Reid J., Direct methods for sparse matrices, (2017); Eden R., Mitchell R., Paragraphing for the reader. College Composition and Communication, 37, 4, pp. 416-441; Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Fu M., Tantithamthavorn C., LineVul: A Transformer-Based Line-Level Vulnerability Prediction, Proceedings of the 19th International Conference on Mining Software Repositories (Pittsburgh, Pennsylvania) (MSR '22), pp. 608-620, (2022); Ghosh R., Gupta A.K., Investigating convolutional neural networks using spatial orderness, Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, (2019); Grieco G., Luis Grinblat G., Uzal L., Rawat S., Feist J., Mounier L., Toward large-scale vulnerability discovery using machine learning, Proceedings of the Sixth ACM Conference on Data and Application Security and Privacy, pp. 85-96, (2016); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016); Hindle A., Godfrey MichaelW., Holt R.C., Reading beside the lines: Using indentation to rank revisions by complexity, Science of Computer Pro-gramming, 74, 7, pp. 414-429, (2009); Hovsepyan A., Scandariato R., Joosen W., Walden J., Software vulnerability prediction using text analysis techniques, Proceedings of the 4th international workshop on Security measurements and metrics, pp. 7-10, (2012); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation with hybrid lexical and syntactical information, Empirical Software Engineering, 25, 3, pp. 2179-2217, (2020); Huang T.H., Kao H., R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections, 2018 IEEE International Conference on Big Data (Big Data), pp. 2633-2642, (2018); Jesse K., Devanbu P.T., Ahmed T., Learning type annotation: is big data enough?, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1483-1486, (2021); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate tree-based detection of code clones, 29th International Conference on Software Engineering (ICSE'07). IEEE, pp. 96-105, (2007); Jones J., Abstract Syntax Tree Implementation Idioms, Proceedings of the 10th Conference on Pattern Languages of Programs (PLoP2003), (2003); Kahneman D., Thinking, fast and slow, (2011); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, IEEE Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Wang K., Jiang J., R -Y M., A code classification method based on TF-IDF, DEStech Transactions on Economics, Business and Management eced, (2018); Keller P., Plein L., Bissyande T.F., Klein J., Le Traon Y., What You See is What it Means! Semantic Representation Learning of Code based on Visualization and Transfer Learning, ACM Transactions on Software Engineering and Methodology-To appear, (2021); Ketkar N., Introduction to pytorch, Deep learning with python, pp. 195-208, (2017); Ahmed Khan F., Abubakar A., Machine Translation in Natural Language Processing by Implementing Artificial Neural Network Modelling Techniques: An Analysis, International Journal on Perceptive and Cognitive Computing, 6, 1, pp. 9-18, (2020); Kim S., Woo S., Lee H., Oh H., Vuddy: A scalable approach for vulnerable code clone discovery, 2017 IEEE Symposium on Security and Privacy (SP). IEEE, pp. 595-614, (2017); Le Q., Mikolov T., Distributed representations of sentences and documents, International conference on machine learning. PMLR, pp. 1188-1196, (2014); LeCun Y., Boser B., Denker J.S., Henderson D., Howard R.E., Hubbard W., Jackel L.D., Backpropagation applied to handwritten zip code recognition, Neural computation, 1, 4, pp. 541-551, (1989); Li J., Wang Y., Lyu M.R., King I., Code completion with neural attention and pointer networks, (2017); Li X., Wang L., Xin Y., Yang Y., Chen Y., Automated Vulnerability Detection in Source Code Using Minimum Intermediate Representation Learning, Applied Sciences, 10, 5, (2020); Li Z., Zou D., Xu S., Jin H., Qi H., Hu J., Vulpecker: An automated vulnerability detection system based on code similarity analysis, Proceedings of the 32nd Annual Conference on Computer Security Applications, pp. 201-213, (2016); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Sysevr: A framework for using deep learning to detect software vulnerabilities, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., Vuldeepecker: A deep learning-based system for vulnerability detection, (2018); Liu F., Li G., Wei B., Xia X., Fu Z., Jin Z., A self-attentional neural architecture for code completion with multi-task learning, Proceedings of the 28th International Conference on Program Comprehension, pp. 37-47, (2020); Liu F., Li G., Zhao Y., Jin Z., Multi-task Learning based Pre-trained Language Model for Code Completion, (2020); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in neural information processing systems, 26, (2013); Mou L., Li G., Jin Z., Zhang L., Wang T., TBCNN: A Tree-Based Convolutional Neural Network for Programming Language Processing, (2014); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, Thirtieth AAAI Conference on Artificial Intelligence, (2016); National Vulnerability Database, (2018); Software Assurance Reference Dataset, (2018); Neuhaus S., Zimmermann T., Holler C., Zeller A., Predicting vulnerable software components, Proceedings of the 14th ACM conference on Computer and communications security, pp. 529-540, (2007); Ngugi L.C., Abelwahab M., Abo-Zahhad M., Recent advances in image processing techniques for automated leaf pest and disease recognition-A review, Information processing in agriculture, 8, 1, pp. 27-51, (2021); Thanh Nguyen T., Tuan Nguyen A., Anh Nguyen H., Nguyen T.N., A statistical semantic language model for source code, Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering, pp. 532-542, (2013); Van Den Oord A., Kalchbrenner N., Vinyals O., Espeholt L., Graves A., Kavukcuoglu K., Conditional image generation with pixelcnn decoders, (2016); GitHub Copilot-Your AI Pair Programmer, OpenAI, (2021); O'Toole A.J., Castillo C.D., Face Recognition by Humans and Machines: Three Fundamental Advances from Deep Learning, Annual Review of Vision Science, 7, (2021); Ramos J., Et al., Using tf-idf to determine word relevance in document queries, Proceedings of the first instructional conference on machine learning, 242, pp. 29-48, (2003); Rattan D., Bhatia R., Singh M., Software clone detection: A systematic review, Information and Software Technology, 55, 7, pp. 1165-1199, (2013); Rehrek R., Sojka P., Et al., Gensim-statistical semantics in python, (2011); Kumar Roy C., Cordy J.R., A survey on software clone detection research, Queen's School of Computing TR, 541, 115, pp. 64-68, (2007); Sajnani H., Saini V., Svajlenko J., Roy C.K., Lopes C.V., Sourcerercc: Scaling code clone detection to big-code, Proceedings of the 38th International Conference on Software Engineering, pp. 1157-1168, (2016); Sueno H.T., Gerardo B.D., Medina R.P., Converting Text to Numerical Representation using Modified Bayesian Vectorization Technique for Multi-Class Classification, International Journal, 9, 4, (2020); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mamun Mia M., Towards a big data curated benchmark of inter-project code clones, 2014 IEEE International Conference on Software Maintenance and Evolution. IEEE, pp. 476-480, (2014); Neylon T., Vertical code alignment, (2015); Van Den Oord A., Kalchbrenner N., Vinyals O., Espeholt L., Graves A., Kavukcuoglu K., Conditional Image Generation with PixelCNN Decoders, (2016); Waldinger R.J., Lee R.C.T., PROW: A step toward automatic program writing, Proceedings of the 1st international joint conference on Artificial intelligence, pp. 241-252, (1969); Wei H., Li M., Supervised Deep Features for Software Functional Clone Detection by Exploiting Lexical and Syntactical Information in Source Code, IJCAI, pp. 3034-3040, (2017); Yoo H., Deep convolution neural networks in computer vision: A review, IEIE Transactions on Smart Processing and Computing, 4, 1, pp. 35-43, (2015); Yu H., Lam W., Chen L., Li G., Xie T., Wang Q., Neural detection of semantic code clones via tree-based convolution, 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC). IEEE, pp. 70-80, (2019); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, European conference on computer vision, pp. 818-833, (2014); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, pp. 783-794, (2019)","Just R.; Fraser F.","Association for Computing Machinery, Inc","ACM SIGSOFT; AITO","32nd ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2023","17 July 2023 through 21 July 2023","Seattle","190710","Conference paper","Final","All Open Access; Green Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85167651924"
"Kotsiantis S.; Verykios V.; Tzagarakis M.","Kotsiantis, Sotiris (35584345800); Verykios, Vassilios (6602452651); Tzagarakis, Manolis (6602618070)","35584345800; 6602452651; 6602618070","AI-Assisted Programming Tasks Using Code Embeddings and Transformers","2024","Electronics (Switzerland)","13","4","767","","","","0","10.3390/electronics13040767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187279862&doi=10.3390%2felectronics13040767&partnerID=40&md5=0a633ab6517ef2e40906d0eac3176645","This review article provides an in-depth analysis of the growing field of AI-assisted programming tasks, specifically focusing on the use of code embeddings and transformers. With the increasing complexity and scale of software development, traditional programming methods are becoming more time-consuming and error-prone. As a result, researchers have turned to the application of artificial intelligence to assist with various programming tasks, including code completion, bug detection, and code summarization. The utilization of artificial intelligence for programming tasks has garnered significant attention in recent times, with numerous approaches adopting code embeddings or transformer technologies as their foundation. While these technologies are popular in this field today, a rigorous discussion, analysis, and comparison of their abilities to cover AI-assisted programming tasks is still lacking. This article discusses the role of code embeddings and transformers in enhancing the performance of AI-assisted programming tasks, highlighting their capabilities, limitations, and future potential in an attempt to outline a future roadmap for these specific technologies. © 2024 by the authors.","AI-assisted programming; code embeddings; transformers","","Hindle A., Barr E.T., Su Z., Gabel M., Devanbu P., On The Naturalness of Software, Proceedings of the 34th International Conference on Software Engineering (ICSE), pp. 837-847; Shani I., Survey Reveals AI’s Impact on the Developer Experience, (2023); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., IntelliCode compose: Code generation using transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering; Bird C., Ford D., Zimmermann T., Forsgren N., Kalliamvakou E., Lowdermilk T., Gazit I., Taking Flight with Copilot, Commun. ACM, 66, pp. 56-62, (2023); Friedman N., Introducing GitHub Copilot: Your AI Pair Programmer, (2021); Chen M., Tworek J., Jun H., Yuan Q., de Oliveira Pinto H.P., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Et al., Evaluating large language models trained on code, arXiv, (2021); Li Y., Choi D., Chung J., Kushman N., Schrittwieser J., Leblond R., Eccles T., Keeling J., Gimeno F., Dal Lago A., Et al., Competition-level Code Generation with Alphacode, Science, 378, pp. 1092-1097, (2022); Parashar B., Kaur I., Sharma A., Singh P., Mishra D., Revolutionary transformations in twentieth century: Making AI-assisted software development, Computational Intelligence in Software Modeling, (2022); Gulwani S., AI-assisted programming: Applications, user experiences, and neuro-symbolic techniques (keynote), Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering; Vaithilingam P., Zhang T., Glassman E.L., Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models, Proceedings of the CHI Conference on Human Factors in Computing Systems Extended Abstracts, pp. 1-7, (2022); Fernandez R.C., Elmore A.J., Franklin M.J., Krishnan S., Tan C., How Large Language Models Will Disrupt Data Management, Proc. VLDB Endow, 16, pp. 3302-3309, (2023); Zhou H., Li J., A Case Study on Scaffolding Exploratory Data Analysis for AI Pair Programmers, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1-7; Kazemitabaar M., Chow J., Ma C.K.T., Ericson B.J., Weintrop D., Grossman T., Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming, Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp. 1-23; Daun M., Brings J., How ChatGPT Will Change Software Engineering Education, Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1, pp. 110-116; Prather J., Reeves B.N., Denny P., Becker B.A., Leinonen J., Luxton-Reilly A., Powell G., Finnie-Ansley J., Santos E.A., It’s Weird That It Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers, ACM Trans. Comput. Interact, 31, pp. 1-31, (2023); Sui Y., Cheng X., Zhang G., Wang H., Flow2Vec: Value-flow-based precise code embedding, Proc. ACM Program. Lang, 4, (2020); Rabin M.R.I., Mukherjee A., Gnawali O., Alipour M.A., Towards demystifying dimensions of source code embeddings, Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages; Azcona D., Arora P., Hsiao I.-H., Smeaton A., user2code2vec: Embedding for Profiling Students Based on Distributinal Representations of Source Code, Proceedings of the 9th International Conference on Learning Analytics and Knowledge; Ding Z., Li H., Shang W., Chen T.-H., Towards Learning Generalizable Code Embeddings Using Task-agnostic Graph Convolutional Networks, ACM Trans. Softw. Eng. Methodol, 32, (2023); Wolf T., Debut L., Sanh V., Chaumond J., Delangue C., Moi A., Cistac P., Rault T., Louf R., Funtowicz M., Et al., Transformers: State-of-the-Art Natural Language Processing, EMNLP 2020—Conference on Empirical Methods in Natural Language Processing: Systems Demonstrations, pp. 38-45, (2020); Chirkova N., Troshin S., Empirical study of transformers for source code, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering; Song Y., Shi S., Li J., Zhang H., Directional skip-gram: Explicitly distinguishing left and right context forword embeddings, Proceedings of the NAACL HLT 2018—2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 175-180; Hu H., Chen Q., Liu Z., Code Generation from Supervised Code Embeddings, Neural Information Processing, pp. 388-396, (2019); Sikka J., Satya K., Kumar Y., Uppal S., Shah R.R., Zimmermann R., Learning Based Methods for Code Runtime Complexity Prediction, Advances in Information Retrieval, pp. 313-325, (2020); Kang H.J., Bissyande T.F., Lo D., Assessing the Generalizability of Code2vec Token Embeddings, Proceedings of the 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE); Romanov V., Ivanov V., Prediction of Types in Python with Pre-trained Graph Neural Networks, Proceedings of the 2022 Ivannikov Memorial Workshop (IVMEM); Ding Z., Li H., Shang W., Chen T.-H.P., Can pre-trained code embeddings improve model performance? Revisiting the use of code embeddings in software engineering tasks, Empir. Softw. Eng, 27, (2022); Shaw P., Uszkoreit J., Vaswani A., Self-attention with relative position representations, Proceedings of the NAACL HLT 2018—2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 464-468; Yang H., Kuang L., CCMC: Code Completion with a Memory Mechanism and a Copy Mechanism, Proceedings of the EASE 2021: Evaluation and Assessment in Software Engineering; Ciniselli M., Cooper N., Pascarella L., Mastropaolo A., Aghajani E., Poshyvanyk D., Di Penta M., Bavota G., An Empirical Study on the Usage of Transformer Models for Code Completion, IEEE Trans. Softw. Eng, 48, pp. 4818-4837, (2021); Gong Z., Gao C., Wang Y., Gu W., Peng Y., Xu Z., Source Code Summarization with Structural Relative Position Guided Transformer, Proceedings of the 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER); Hassan M.H., Mahmoud O.A., Mohammed O.I., Baraka A.Y., Mahmoud A.T., Yousef A.H., Neural Machine Based Mobile Applications Code Translation, Proceedings of the 2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES); Devlin J., Chang M.-W., Lee K., Toutanova K., BERT: Pre-training of deep bidirectional transformers for language understanding, Proceedings of the NAACL HLT 2019—2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186; Sengupta A., Kumar A., Bhattacharjee S.K., Roy S., Gated Transformer for Robust De-noised Sequence-to-Sequence Modelling, Proceedings of the 2021 Findings of the Association for Computational Linguistics; Wu C., Wu F., Ge S., Qi T., Huang Y., Xie X., Neural news recommendation with multi-head self-attention, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing; Chernyavskiy A., Ilvovsky D., Nakov P., Transformers: ‘The End of History’ for Natural Language Processing?, Machine Learning and Knowledge Discovery in Databases, pp. 677-693, (2021); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., CodeBERT: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics Findings of ACL: EMNLP 2020, pp. 1536-1547, (2020); Zhou X., Han D., Lo D., Assessing Generalizability of CodeBERT, Proceedings of the 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, J. Mach. Learn. Res, 21, pp. 1-67, (2020); Brown T.B., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., Language models are few-shot learners, Adv. Neural Inf. Process. Syst, 33, pp. 1877-1901, (2020); Yang Z., Dai Z., Yang Y., Carbonell J., Salakhutdinov R., Le Q.V., XLNet: Generalized autoregressive pretraining for language understanding, Adv. Neural Inf. Process. Syst, 32, pp. 5753-5763, (2019); Zhang F., Yu X., Keung J., Li F., Xie Z., Yang Z., Ma C., Zhang Z., Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information, Inf. Softw. Technol, 148, (2022); Liu K., Yang G., Chen X., Zhou Y., EL-CodeBert: Better Exploiting CodeBert to Support Source Code-Related Classification Tasks, Proceedings of the 13th Asia-Pacific Symposium on Internetware; Wang R., Zhang H., Lu G., Lyu L., Lyu C., Fret: Functional Reinforced Transformer with BERT for Code Summarization, IEEE Access, 8, pp. 135591-135604, (2020); Yang Z., Keung J., Yu X., Gu X., Wei Z., Ma X., Zhang M., A Multi-Modal Transformer-based Code Summarization Approach for Smart Contracts, Proceedings of the 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC); Hou S., Chen L., Ye Y., Summarizing Source Code from Structure and Context, Proceedings of the 2022 International Joint Conference on Neural Networks (IJCNN); Wang Y., Dong Y., Lu X., Zhou A., GypSum: Learning hybrid representations for code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension; Gu J., Salza P., Gall H.C., Assemble Foundation Models for Automatic Code Summarization, Proceedings of the 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER); Ma Z., Gao Y., Lyu L., Lyu C., MMF3: Neural Code Summarization Based on Multi-Modal Fine-Grained Feature Fusion, Proceedings of the 16th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement; Gao Y., Lyu C., M2TS: Multi-scale multi-modal approach based on transformer for source code summarization, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension; Ferretti C., Saletta M., Naturalness in Source Code Summarization. How Significant is it?, Proceedings of the 2023 IEEE/ACM 31st International Conference on Program Comprehension (ICPC); Choi Y., Na C., Kim H., Lee J.-H., READSUM: Retrieval-Augmented Adaptive Transformer for Source Code Summarization, IEEE Access, 11, pp. 51155-51165, (2023); Aladics T., Jasz J., Ferenc R., Bug Prediction Using Source Code Embedding Based on Doc2Vec, Computational Science and Its Applications, pp. 382-397, (2021); Cheng X., Zhang G., Wang H., Sui Y., Path-sensitive code embedding via contrastive learning for software vulnerability detection, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis; Hegedus P., Ferenc R., Static Code Analysis Alarms Filtering Reloaded: A New Real-World Dataset and its ML-Based Utilization, IEEE Access, 10, pp. 55090-55101, (2022); Bagheri A., Hegedus P., A Comparison of Different Source Code Representation Methods for Vulnerability Prediction in Python, Quality of Information and Communications Technology, pp. 267-281, (2021); Gomes L., da Silva Torres R., Cortes M.L., BERT- and TF-IDF-based feature extraction for long-lived bug prediction in FLOSS: A comparative study, Inf. Softw. Technol, 160, (2023); Pan C., Lu M., Xu B., An Empirical Study on Software Defect Prediction Using CodeBERT Model, Appl. Sci, 11, (2021); Ma X., Keung J.W., Yu X., Zou H., Zhang J., Li Y., AttSum: A Deep Attention-Based Summarization Model for Bug Report Title Generation, IEEE Trans. Reliab, 72, pp. 1663-1677, (2023); Mahbub P., Shuvo O., Rahman M.M., Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation, Proceedings of the 2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE); Csuvik V., Horvath D., Lajko M., Vidacs L., Exploring Plausible Patches Using Source Code Embeddings in JavaScript, Proceedings of the 2021 IEEE/ACM International Workshop on Automated Program Repair (APR); Mashhadi E., Hemmati H., Applying CodeBERT for Automated Program Repair of Java Simple Bugs, Proceedings of the 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR); Chakraborty S., Ray B., On Multi-Modal Learning of Editing Source Code, Proceedings of the 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE); Lajko M., Csuvik V., Vidacs L., Towards JavaScript program repair with generative pre-trained transformer (GPT-2), Proceedings of the Third International Workshop on Automated Program Repair; Chi J., Qu Y., Liu T., Zheng Q., Yin H., SeqTrans: Automatic Vulnerability Fix Via Sequence to Sequence Learning, IEEE Trans. Softw. Eng, 49, pp. 564-585, (2023); Chen Z., Kommrusch S., Monperrus M., Neural Transfer Learning for Repairing Security Vulnerabilities in C Code, IEEE Trans. Softw. Eng, 49, pp. 147-165, (2023); Kim T., Yang G., Predicting Duplicate in Bug Report Using Topic-Based Duplicate Learning with Fine Tuning-Based BERT Algorithm, IEEE Access, 10, pp. 129666-129675, (2022); Dinella E., Ryan G., Mytkowicz T., Lahiri S.K., TOGA: A neural method for test oracle generation, Proceedings of the 44th International Conference on Software Engineering; da Silva A.F., Borin E., Pereira F.M.Q., Queiroz N.L., Napoli O.O., Program representations for predictive compilation: State of affairs in the early 20’s, J. Comput. Lang, 73, (2022); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., RoBERTa: A Robustly Optimized BERT Pretraining Approach, arXiv, (2019); Dai Z., Yang Z., Yang Y., Carbonell J., Le Q.V., Salakhutdinov R., Transformer-XL: Attentive language models beyond a fixed-length context, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 2978-2988; Izadi M., Gismondi R., Gousios G., CodeFill: Multi-token code completion by jointly learning from structure and naming sequences, Proceedings of the 44th International Conference on Software Engineering; Liu F., Li G., Zhao Y., Jin Z., Multi-task learning based pre-trained language model for code completion, Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering; Lewis M., Liu Y., Goyal N., Ghazvininejad M., Mohamed A., Levy O., Stoyanov V., Zettlemoyer L., BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 7871-7880; Kim S., Zhao J., Tian Y., Chandra S., Code Prediction by Feeding Trees to Transformers, Proceedings of the 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE); Gemmell C., Rossetto F., Dalton J., Relevance Transformer: Generating Concise Code Snippets with Relevance Feedback, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval; Soliman A.S., Hadhoud M.M., Shaheen S.I., MarianCG: A code generation transformer model inspired by machine translation, J. Eng. Appl. Sci, 69, (2022); Yang G., Zhou Y., Chen X., Zhang X., Han T., Chen T., ExploitGen: Template-augmented exploit code generation based on CodeBERT, J. Syst. Softw, 197, (2023); Laskari N.K., Reddy K.A.N., Indrasena Reddy M., Seq2Code: Transformer-Based Encoder-Decoder Model for Python Source Code Generation, Third Congress on Intelligent Systems, pp. 301-309, (2023); Bui N.D.Q., Yu Y., Jiang L., Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification, Proceedings of the 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER); Yang G., Zhou Y., Chen X., Yu C., Fine-grained Pseudo-code Generation Method via Code Feature Extraction and Transformer, Proceedings of the 2021 28th Asia-Pacific Software Engineering Conference (APSEC); Alokla A., Gad W., Nazih W., Aref M., Salem A.-B., Retrieval-Based Transformer Pseudocode Generation, Mathematics, 10, (2022); Gad W., Alokla A., Nazih W., Aref M., Salem A., DLBT: Deep Learning-Based Transformer to Generate Pseudo-Code from Source Code, Comput. Mater. Contin, 70, pp. 3117-3132, (2022); Acharjee U.K., Arefin M., Hossen K.M., Uddin M.N., Uddin M.A., Islam L., Sequence-to-Sequence Learning-Based Conversion of Pseudo-Code to Source Code Using Neural Translation Approach, IEEE Access, 10, pp. 26730-26742, (2022); Shahbazi R., Sharma R., Fard F.H., API2Com: On the Improvement of Automatically Generated Code Comments Using API Documentations, Proceedings of the 2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC); Yang G., Chen X., Cao J., Xu S., Cui Z., Yu C., Liu K., ComFormer: Code Comment Generation via Transformer and Fusion Method-based Hybrid Code Representation, Proceedings of the 2021 8th International Conference on Dependable Systems and Their Applications (DSA); Chakraborty S., Ahmed T., Ding Y., Devanbu P.T., Ray B., NatGen: Generative pre-training by “naturalizing” source code, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering; Geng M., Wang S., Dong D., Wang H., Cao S., Zhang K., Jin Z., Interpretation-based Code Summarization, Proceedings of the 2023 IEEE/ACM 31st International Conference on Program Comprehension (ICPC); Thongtanunam P., Pornprasit C., Tantithamthavorn C., AutoTransform: Automated code transformation to support modern code review process, Proceedings of the 44th International Conference on Software Engineering; Yu C., Yang G., Chen X., Liu K., Zhou Y., BashExplainer: Retrieval-Augmented Bash Code Comment Generation based on Fine-tuned CodeBERT, In Proceeding of the 2022 IEEE International Conference on Software Maintenance and Evolution (ICSME); Lin B., Wang S., Liu Z., Xia X., Mao X., Predictive Comment Updating with Heuristics and AST-Path-Based Neural Learning: A Two-Phase Approach, IEEE Trans. Softw. Eng, 49, pp. 1640-1660, (2023); Karakatic S., MiloA¡evic A., Hericko T., Software system comparison with semantic source code embeddings, Empir. Softw. Eng, 27, (2022); Siddiq M.L., Majumder S.H., Mim M.R., Jajodia S., Santos J.C.S., An Empirical Study of Code Smells in Transformer-based Code Generation Techniques, Proceedings of the 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM); Yu L., Lu Y., Shen Y., Huang H., Zhu K., BEDetector: A Two-Channel Encoding Method to Detect Vulnerabilities Based on Binary Similarity, IEEE Access, 9, pp. 51631-51645, (2021); Mateless R., Tsur O., Moskovitch R., Pkg2Vec: Hierarchical package embedding for code authorship attribution, Future Gener. Comput. Syst, 116, pp. 49-60, (2021); Arshad S., Abid S., Shamail S., CodeBERT for Code Clone Detection: A Replication Study, Proceedings of the 2022 IEEE 16th International Workshop on Software Clones (IWSC); Kovacevic A., Slivka J., Vidakovic D., Grujic K.-G., Luburic N., Prokic S., Sladic G., Automatic detection of Long Method and God Class code smells through neural source code embeddings, Expert Syst. Appl, 204, (2022); Zhang A., Fang L., Ge C., Li P., Liu Z., Efficient transformer with code token learner for code clone detection, J. Syst. Softw, 197, (2023); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Le Traon Y., Learning to Spot and Refactor Inconsistent Method Names, Proceedings of the 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE); Cabrera Lozoya R., Baumann A., Sabetta A., Bezzi M., Commit2Vec: Learning Distributed Representations of Code Changes, SN Comput. Sci, 2, (2021); Wang S., Wen M., Lin B., Mao X., Lightweight global and local contexts guided method name recommendation with prior knowledge, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering; Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (ICSE ‘20). Association for Computing Machinery, pp. 1372-1384, (2020); Xie R., Chen L., Ye W., Li Z., Hu T., Du D., Zhang S., DeepLink: A Code Knowledge Graph Based Deep Learning Approach for Issue-Commit Link Recovery, Proceedings of the 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER); Borovits N., Kumara I., Krishnan P., Palma S.D., Di Nucci D., Palomba F., Tamburri D.A., van den Heuvel W.-J., DeepIaC: Deep learning-based linguistic anti-pattern detection in IaC, Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation; Ma W., Zhao M., Soremekun E., Hu Q., Zhang J.M., Papadakis M., Cordy M., Xie X., Traon Y.L., GraphCode2Vec: Generic code embedding via lexical and program dependence analysis, Proceedings of the 19th International Conference on Mining Software Repositories; Wan Y., He Y., Bi Z., Zhang J., Sui Y., Zhang H., Hashimoto K., Jin H., Xu G., Xiong C., Et al., NaturalCC: An Open-Source Toolkit for Code Intelligence, Proceedings of the 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion); Zaharia S., Rebedea T., Trausan-Matu S., CWE Pattern Identification using Semantical Clustering of Programming Language Keywords, Proceedings of the 2021 23rd International Conference on Control Systems and Computer Science (CSCS); Zaharia S., Rebedea T., Trausan-Matu S., Machine Learning-Based Security Pattern Recognition Techniques for Code Developers, Appl. Sci, 12, (2022); Barr J.R., Shaw P., Abu-Khzam F.N., Thatcher T., Yu S., Vulnerability Rating of Source Code with Token Embedding and Combinatorial Algorithms, Int. J. Semant. Comput, 14, pp. 501-516, (2020); Saletta M., Ferretti C., A Neural Embedding for Source Code: Security Analysis and CWE Lists, Proceedings of the 2020 IEEE International Conference on Dependable, Autonomic and Secure Computing, International Conference on Pervasive Intelligence and Computing, International Conference on Cloud and Big Data Computing, International Conference on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech); Hamed A.A., Zachara-Szymanska M., Wu X., Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI, IScience, 27, (2024)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85187279862"
"Lee S.-C.; Lee D.-G.; Seo Y.-S.","Lee, Seung-Cheol (57962057200); Lee, Dong-Gun (57211757925); Seo, Yeong-Seok (25723680700)","57962057200; 57211757925; 25723680700","Determining the best feature combination through text and probabilistic feature analysis for GPT-2-based mobile app review detection","2024","Applied Intelligence","54","2","","1219","1246","27","0","10.1007/s10489-023-05201-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180499028&doi=10.1007%2fs10489-023-05201-3&partnerID=40&md5=ec0d9c5d041610c261ed3d998ab57662","Mobile apps, used by many people worldwide, have become an essential part of life. Before using a mobile app, users judge the reliability of apps according to their reviews. Therefore, app reviews are essential components of management for companies. Unfortunately, some fake reviewers write negative reviews for competing apps. Moreover, artificial intelligence (AI)-based macro bot programs that generate app reviews have emerged and can create large numbers of reviews with malicious purposes in a short time. One notable AI technology that can generate such reviews is Generative Pre-trained Transformer-2 (GPT-2). The reviews generated by GPT-2 use human-like grammar; therefore, it is difficult to detect them with only text mining techniques, which use tools like part-of-speech (POS) tagging and sentiment scores. Thus, probability-based sampling techniques in GPT-2 must be used. In this study, we identified features to detect reviews generated by GPT-2 and determined the optimal feature combination for improving detection performance. To achieve this, based on the analysis results, we built a training dataset to find the best feature combination for detecting the generated reviews. Various machine learning models were then trained and evaluated using this dataset. As a result, the model that used both text mining and probability-based sampling techniques detected generated reviews more effectively than the model that used only text mining techniques. This model achieved a top classification accuracy of 90% and a macro F1 of 0.90. We expect the results of this study to help app developers maintain a more stable mobile app ecosystem. Graphical abstract: (Figure presented.) © The Author(s) 2023.","Artificial intelligence; Fake review; Language model; Machine learning; Software engineering","Abstracting; Data mining; Fake detection; Feature extraction; Text processing; BOT project; Fake review; Feature analysis; Feature combination; Language model; Machine-learning; Mobile app; Probabilistics; Sampling technique; Text mining techniques; Application programs","Jorayeva M., Akbulut A., Catal C., Mishra A., Machine learning-based software defect prediction for mobile applications: A systematic literature review, Sensors, 22, 7, (2022); Alqarni M.A., Chauhdary S.H., Malik M.N., Ehatisham-ul-Haq M., Azam M.A., Identifying smartphone users based on how they interact with their phones, Human-centric Comput Inform Sci, 10, pp. 1-14, (2020); Javed A.R., Sarwar M.U., Beg M.O., Asim M., Baker T., Tawfik H., A collaborative healthcare framework for shared healthcare plan with ambient intelligence, Human-centric Comput Inform Sci, 10, pp. 1-21, (2020); Talal M., Zaidan A., Zaidan B., Albahri O.S., Alsalem M., Albahri A.S., Alamoodi A.H., Kiah M.L.M., Jumaah F., Alaa M., Comprehensive review and analysis of antimalware apps for smartphones, Telecommun Syst, 72, pp. 285-337, (2019); Tavakoli M., Zhao L., Heydari A., Nenadic G., Extracting useful software development information from mobile application reviews: A survey of intelligent mining techniques and tools, Expert Syst Applic, 113, pp. 186-199, (2018); Salminen J., Kandpal C., Kamel A.M., Jung S.-G., Jansen B.J., Creating and detecting fake reviews of online products, J Retail Consum Serv, 64, (2022); Liu T., Wang C., Huang K., Liang P., Zhang B., Daneva M., Sinderen M., RoseMatcher: Identifying the impact of user reviews on app updates, Inf Softw Technol, 161, (2023); Choi S.-Y., Lim C.G., Kim Y.-M., Automated link tracing for classification of malicious websites in malware distribution networks, J Inform Process Syst, 15, 1, pp. 100-115, (2019); Zhang Z., Wan J., Zhou M., Lai Z., Tessone C.J., Chen G., Liao H., Temporal burstiness and collaborative camouflage aware fraud detection, Inform Process Manag, 60, 2, (2023); Zhang Y., Hao S., Wang H., Detecting incentivized review groups with co-review graph, High-Confidence Comput, 1, 1, (2021); He D., Pan M., Hong K., Cheng Y., Chan S., Liu X., Guizani N., Fake review detection based on pu learning and behavior density, IEEE Netw, 34, 4, pp. 298-303, (2020); Mewada A., Dewang R.K., Research on false review detection methods: A state-of-the-art review, J King Saud Univ-Comput Inform Sci, 34, 9, pp. 7530-7546, (2022); Kudugunta S., Ferrara E., Deep neural networks for bot detection, Inform Sci, 467, pp. 312-322, (2018); Di Domenico G., Sit J., Ishizaka A., Nunan D., Fake news, social media and marketing: A systematic review, J Bus Res, 124, pp. 329-341, (2021); Paka W.S., Bansal R., Kaushik A., Sengupta S., Chakraborty T., Cross-SEAN: A cross-stitch semi-supervised neural attention model for covid-19 fake news detection, Appl Soft Comput, 107, (2021); Orabi M., Mouheb D., Al Aghbari Z., Kamel I., Detection of bots in social media: a systematic review, Inform Process Manag, 57, 4, (2020); Fang Y., Wang H., Zhao L., Yu F., Wang C., Dynamic knowledge graph based fake-review detection, Appl Intell, 50, pp. 4281-4295, (2020); Zhong M., Tan L., Qu X., Identification of opinion spammers using reviewer reputation and clustering analysis, Int J Comput Commun Control, 14, 6, pp. 759-772, (2019); Javed M.S., Majeed H., Mujtaba H., Beg MO (2021) Fake reviews classification using deep learning ensemble of shallow convolutions, J Comput Soc Sc, 4, pp. 883-902, (2021); Radford A., Narasimhan K., Improving Language Understanding by Generative Pre-Training, (2018); Shevlane T., Dafoe A., The offense-defense balance of scientific knowledge: Does publishing ai research reduce misuse?, In: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pp. 173-179, (2020); Vosoughi S., Roy D., Aral S., The spread of true and false news online, Science, 359, 6380, pp. 1146-1151, (2018); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Et al., Language models are unsupervised multitask learners, OpenAI Blog, 1, 8, (2019); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., Language models are few-shot learners, Adv Neural Inform Process Syst, 33, pp. 1877-1901, (2020); GPT-4 Technical Report, (2023); Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A.N., Kaiser L., Polosukhin I., Attention is all you need, Adv Neural Inform Process Syst, 30, pp. 5998-6008, (2017); Hu J., Sun M., Generating major types of Chinese classical poetry in a uniformed framework, Proceedings of the Twelfth Language Resources and Evaluation Conference, pp. 4658-4663, (2020); Kreps S., McCain R.M., Brundage M., All the news that’s fit to fabricate: Ai-generated text as a tool of media misinformation, J Exp Polit Sci, 9, 1, pp. 104-117, (2022); Littman Z.N.M., Context-driven satirical headline generation, ACL, 2020, (2020); Zellers R., Holtzman A., Rashkin H., Bisk Y., Farhadi A., Roesner F., Choi Y., Defending against neural fake news, Advances in Neural Information Processing Systems, pp. 9054-9065, (2019); Fagni T., Falchi F., Gambini M., Martella A., Tesconi M., Tweepfake: About detecting deepfake tweets, Plos one, 16, 5, (2021); Bayer M., Kaufhold M.-A., Reuter C., A survey on data augmentation for text classification, ACM Comput Surv, 55, 7, pp. 1-39, (2022); Ippolito D., Duckworth D., Callison-Burch C., Eck D., Automatic detection of generated text is easiest when humans are fooled, In: Proceedings of the 58Th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, pp. 1808-1822, (2020); Baly R., Karadzhov G., Alexandrov D., Glass J., Nakov P., Predicting factuality of reporting and bias of news media sources, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018), pp. 3528-3539, (2018); Gehrmann S., Strobelt H., Rush A.M., Gltr: Statistical detection and visualization of generated text, Proceedings of the 57Th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pp. 111-116, (2019); Tian E., Cui A., GPTZero: Towards detection of AI-generated text using zero-shot and supervised methods, Gptzero., (2023); Biswas S.S., Role of chat gpt in public health, Ann Biomed Eng, 51, 5, pp. 868-869, (2023); Lu J., Zhan X., Liu G., Zhan X., Deng X., Bstc: A fake review detection model based on a pre-trained language model and convolutional neural network, Electronics, 12, 10, (2023); Adelani D.I., Mai H., Fang F., Nguyen H.H., Yamagishi J., Echizen I., Generating sentiment-preserving fake online reviews using neural language models and their human-and machine-based detection, Advanced information networking and applications. AINA 2020. Advances in intelligent systems and computing, (2020); Wang J., Kan H., Meng F., Mu Q., Shi G., Xiao X., Fake review detection based on multiple feature fusion and rolling collaborative training, IEEE Access, 8, pp. 182625-182639, (2020); Alsubari S.N., Deshmukh S.N., Alqarni A.A., Alsharif N., Aldhyani T.H., Alsaade F.W., Khalaf O.I., Data analytics for the identification of fake reviews using supervised learning, Comput Mater Continua, 70, 2, pp. 3189-3204, (2022); Yogish D., Manjunath T., Hegadi R.S., Review on natural language processing trends and techniques using NLTK, Recent trends in image processing and pattern recognition. RTIP2R 2018. Communications in computer and information science, (2019); Bolucu N., Can B., Unsupervised joint pos tagging and stemming for agglutinative languages, ACM Trans Asian Low-Resource Lang Inform Process (TALLIP), 18, 3, pp. 1-21, (2019); Pano T., Kashef R., A complete vader-based sentiment analysis of bitcoin (btc) tweets during the era of covid-19, Big Data Cogn Comput, 4, 4, (2020); Fayed H.A., Atiya A.F., Speed up grid-search for parameter selection of support vector machines, Appl Soft Comput, 80, pp. 202-210, (2019)","","Springer","","","","","","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85180499028"
"Hussain T.; Faiz R.B.; Aljaidi M.; Khattak A.; Samara G.; Alsarhan A.; Alazaidah R.","Hussain, Talha (58512723300); Faiz, Rizwan Bin (57789894600); Aljaidi, Mohammad (57203092682); Khattak, Adnan (58511996300); Samara, Ghassan (36549085000); Alsarhan, Ayoub (35118743100); Alazaidah, Raed (57202802309)","58512723300; 57789894600; 57203092682; 58511996300; 36549085000; 35118743100; 57202802309","Maximizing Test Coverage for Security Threats Using Optimal Test Data Generation","2023","Applied Sciences (Switzerland)","13","14","8252","","","","0","10.3390/app13148252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166177521&doi=10.3390%2fapp13148252&partnerID=40&md5=dc3de7d5c117341ed6a23e575a7d691f","As time continues to advance, the need for robust security threat mitigation has become increasingly vital in software. It is a constant struggle to maximize test coverage through optimal data generation. We conducted explanatory research to maximize test coverage of security requirements as modeled in the structured misuse case description (SMCD). The acceptance test case is designed through the structured misuse case description for mitigation of security threats. Mal activity is designed from SMCD upon which constraints are specified in object constraint language (OCL) in order to minimize human dependency and improve consistency in the optimal test case design. The study compared two state-of-the-art test coverage maximization approaches through optimal test data generation. It was evident through the results that MC/DC generated optimal test data, i.e., n + 1 test conditions in comparison to the decision coverage approach, i.e., 2n test conditions for security threats. Thus, MC/DC resulted in a significantly lower number of test cases yet maximized test coverage of security threats. We, therefore, conclude that MC/DC maximizes test coverage through optimal test data in comparison to decision coverage at the design level for security threat mitigation. © 2023 by the authors.","decision coverage; modified condition/decision coverage; object constraint language; structured misuse case description; system under test; test coverage; test data","","Bharathi M., Hybrid Particle Swarm and Ranked Firefly Metaheuristic Optimization-Based Software Test Case Minimization, Int. J. Appl. Metaheuristic Comput, 13, pp. 1-20, (2022); Habib A.S., Khan S.U.R., Felix E.A., A systematic review on search-based test suite reduction: State-of-the-art, taxonomy, and future directions, IET Softw, 17, pp. 93-136, (2023); Huang T., Fang C.C., Optimization of Software Test Scheduling under Development of Modular Software Systems, Symmetry, 15, (2023); Aghababaeyan Z., Abdellatif M., Briand L., Ramesh S., Bagherzadeh M., Black-Box Testing of Deep Neural Networks Through Test Case Diversity, IEEE Trans. Softw. Eng, 49, pp. 3182-3204, (2023); Mohi-Aldeen S.M., Mohamad R., Deris S., Optimal path test data generation based on hybrid negative selection algorithm and genetic algorithm, PLoS ONE, 15, (2020); Wang J., Lutellier T., Qian S., Pham H.V., Tan L., EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries, Proceedings of the 44th International Conference on Software Engineering, pp. 798-810; Khari M., Sinha A., Verdu E., Crespo R.G., Performance analysis of six meta-heuristic algorithms over automated test suite generation for path coverage-based optimization, Soft Comput, 24, pp. 9143-9160, (2020); Alomar E.A., Wang T., Raut V., Mkaouer M.W., Newman C., Ouni A., Refactoring for reuse: An empirical study, Innov. Syst. Softw. Eng, 18, pp. 105-135, (2022); Sidhu B.K., Singh K., Sharma N., A machine learning approach to software model refactoring, Int. J. Comput. Appl, 44, pp. 166-177, (2022); Pachouly J., Ahirrao S., Kotecha K., Selvachandran G., Abraham A., A systematic literature review on software defect prediction using artificial intelligence: Datasets, Data Validation Methods, Approaches, and Tools, Eng. Appl. Artif. Intell, 111, (2022); Khan M.U., Sartaj H., Iqbal M.Z., Usman M., Arshad N., AspectOCL: Using aspects to ease maintenance of evolving constraint specification, Empir. Softw. Eng, 24, pp. 2674-2724, (2019); Barisal S.K., Dutta A., Godboley S., Sahoo B., Mohapatra D.P., MC/DC guided Test Sequence Prioritization using Firefly Algorithm, Evol. Intell, 14, pp. 105-118, (2021); Suhail S., Malik S.U.R., Jurdak R., Hussain R., Matulevicius R., Svetinovic D., Towards situational aware cyber-physical systems: A security-enhancing use case of blockchain-based digital twins, Comput. Ind, 141, (2022); Ami A.S., Cooper N., Kafle K., Moran K., Poshyvanyk D., Nadkarni A., Why Crypto-detectors Fail: A Systematic Evaluation of Cryptographic Misuse Detection Techniques, Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP), pp. 614-631; Canakci S., Delshadtehrani L., Eris F., Taylor M.B., Egele M., Joshi A., DirectFuzz: Automated Test Generation for RTL Designs using Directed Graybox Fuzzing, Proceedings of the 2021 58th ACM/IEEE Design Automation Conference (DAC) 2021, pp. 529-534; Aleman J.L.M., Agenjo A., Carretero S., Kosmidis L., On the MC/DC Code Coverage of Vulkan SC GPU Code, Proceedings of the 41st Digital Avionics System Conference; Tatale S., Prakash V.C., Automatic Generation and Optimization of Combinatorial Test Cases from UML Activity Diagram Using Particle Swarm Optimization, Ing. Syst. d’Inform, 27, pp. 49-59, (2022); Avdeenko T., Serdyukov K., Automated test data generation based on a genetic algorithm with maximum code coverage and population diversity, Appl. Sci, 11, (2021); Lemieux C., Inala J.P., Lahiri S.K., Sen S., CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models, pp. 1-13, (2023); Fadhil H.M., Abdullah M.N., Younis M.I., Innovations in t-way test creation based on a hybrid hill climbing-greedy algorithm, IAES Int. J. Artif. Intell, 12, pp. 794-805, (2023); Gupta N., Sharma A., Pachariya M.K., Multi-objective test suite optimization for detection and localization of software faults, J. King Saud Univ.-Comput. Inf. Sci, 34, pp. 2897-2909, (2022); Khaleel S.I., Anan R., A review paper: Optimal test cases for regression testing using artificial intelligent techniques, Int. J. Electr. Comput. Eng, 13, pp. 1803-1816, (2023); Barisal S.K., Chauhan S.P.S., Dutta A., Godboley S., Sahoo B., Mohapatra D.P., BOOMPizer: Minimization and prioritization of CONCOLIC based boosted MC/DC test cases, J. King Saud Univ.-Comput. Inf. Sci, 34, pp. 9757-9776, (2022); Sartaj H., Iqbal M.Z., Jilani A.A.A., Khan M.U., A Search-Based Approach to Generate MC/DC Test Data for OCL Constraints, Proceedings of the Search-Based Software Engineering: 11th International Symposium, SSBSE 2019, pp. 105-120, (2019); Zafar M.N., Afzal W., Enoiu E., Evaluating System-Level Test Generation for Industrial Software: A Comparison between Manual, Combinatorial and Model-Based Testing, Proceedings of the 3rd ACM/IEEE International Conference on Automation of Software Test, pp. 148-159; Jha P., Sahu M., Isobe T., A UML Activity Flow Graph-Based Regression Testing Approach, Appl. Sci, 13, (2023); Tiwari R.G., Pratap Srivastava A., Bhardwaj G., Kumar V., Exploiting UML Diagrams for Test Case Generation: A Review, Proceedings of the 2021 2nd International Conference on Intelligent Engineering and Management (ICIEM), pp. 457-460; Liu Y., Li Y., Deng G., Liu Y., Wan R., Wu R., Ji D., Xu S., Bao M., Morest: Model-Based RESTful API Testing with Execution Feedback, 2022-May, (2022); El-Attar M., Abdul-Ghani H.A., Using security robustness analysis for early-stage validation of functional security requirements, Requir. Eng, 21, pp. 1-27, (2016); Afrose S., Xiao Y., Rahaman S., Miller B.P., Yao D., Evaluation of Static Vulnerability Detection Tools With Java Cryptographic API Benchmarks, IEEE Trans. Softw. Eng, 49, pp. 485-497, (2023); Ribeiro V., Cruzes D.S., Travassos G.H., Understanding Factors and Practices of Software Security and Performance Verification, Proceedings of the 19th Brazilian Symposium on Software Quality; Szugyi Z., Porkolab Z., Comparison of DC and MC/DC Code Coverages, Acta Electrotech. Inform, 13, pp. 57-63, (2013); Marques F., Morgado A., Fragoso Santos J., Janota M., TestSelector: Automatic Test Suite Selection for Student Projects, Proceedings of the Runtime Verification: 22nd International Conference, RV 2022, pp. 283-292, (2022); Senjyu T., Mahalle P.N., Perumal T., Joshi A., ICT with Intelligent Applications, 1, (2020); Yang Y., Xia X., Lo D., Grundy J., A Survey on Deep Learning for Software Engineering, ACM Comput. Surv, 54, pp. 1-73, (2022); Elyasaf A., Farchi E., Margalit O., Weiss G., Weiss Y., Generalized Coverage Criteria for Combinatorial Sequence Testing, IEEE Trans. Softw. Eng, pp. 1-12, (2023)","","Multidisciplinary Digital Publishing Institute (MDPI)","","","","","","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85166177521"
"Wang S.; Huang L.; Gao A.; Ge J.; Zhang T.; Feng H.; Satyarth I.; Li M.; Zhang H.; Ng V.","Wang, Simin (57923812500); Huang, Liguo (7404735614); Gao, Amiao (57758958100); Ge, Jidong (13404777700); Zhang, Tengfei (57219790444); Feng, Haitao (57219793227); Satyarth, Ishna (57759153500); Li, Ming (56994181000); Zhang, He (55685593500); Ng, Vincent (55432380800)","57923812500; 7404735614; 57758958100; 13404777700; 57219790444; 57219793227; 57759153500; 56994181000; 55685593500; 55432380800","Machine/Deep Learning for Software Engineering: A Systematic Literature Review","2023","IEEE Transactions on Software Engineering","49","3","","1188","1231","43","6","10.1109/TSE.2022.3173346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132507335&doi=10.1109%2fTSE.2022.3173346&partnerID=40&md5=635eb559263a653bdd90543131162571","Since 2009, the deep learning revolution, which was triggered by the introduction of ImageNet, has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12-year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers published between 2009 and 2020. Our trend analysis demonstrated the impacts that ML/DL brought to SE. We examined the complexity of applying ML/DL solutions to SE problems and how such complexity led to issues concerning the reproducibility and replicability of ML/DL studies in SE. Specifically, we investigated how ML and DL differ in data preprocessing, model training, and evaluation when applied to SE tasks, and what details need to be provided to ensure that a study can be reproduced or replicated. By categorizing the rationales behind the selection of ML/DL techniques into five themes, we analyzed how model performance, robustness, interpretability, complexity, and data simplicity affected the choices of ML/DL models.  © 2022 IEEE.","deep learning; machine learning; Software engineering","Deep learning; Engineering education; Job analysis; Learning systems; Software engineering; Code; Complexity theory; Critical review; Deep learning; Engineering learning; Machine-learning; Predictive models; Software; Systematic literature review; Task analysis; Data structures","Hassan A.E., Xie T., Software intelligence: The future of mining software engineering data, Proc. FSE/SDP Workshop Future Softw. Eng. Res., pp. 161-166, (2010); Zhang D., Tsai J.J., Machine learning and software engineering, Softw. Qual. J., 11, 2, pp. 87-119, (2003); Hassan A.E., Xie T., Mining software engineering data, Proc. IEEE/ACM 32nd Int. Conf. Softw. Eng., pp. 503-504, (2010); Niyaz Q., Sun W., Javaid A.Y., A deep learning based DDoS detection system in software-defined networking (SDN), (2016); Charte D., Charte F., Garcia S., Del Jesus M.J., Herrera F., A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines, Informat. Fusion, 44, pp. 78-96, (2018); Martinez-Fernandez S., Et al., Software engineering for AI-based systems: A survey, (2021); Niu H., Keivanloo I., Zou Y., Learning to rank code examples for code search engines, Empirical Softw. Eng., 22, 1, pp. 259-291, (2017); Kim Y., Mun S., Yoo S., Kim M., Precise learn-to-rank fault localization using dynamic and static features of target programs, ACM Trans. Softw. Eng. Methodol., 28, 4, (2019); Tian Y., Wijedasa D., Lo D., Le Goues C., Learning to rank for bug report assignee recommendation, Proc. IEEE 24th Int. Conf. Prog. Comprehension, pp. 1-10, (2016); Bertolino A., Guerriero A., Miranda B., Pietrantuono R., Russo S., Learning-to-rank versus ranking-to-learn: Strategies for regression testing in continuous integration, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 1-12, (2020); Zhao G., Da Costa D.A., Zou Y., Improving the pull requests review process using learning-to-rank algorithms, Empirical Softw. Eng., 24, 4, pp. 2140-2170, (2019); Perini A., Ricca F., Susi A., Tool-supported requirements prioritization: Comparing the AHP and CBRank methods, Informat. Softw. Technol., 51, 6, pp. 1021-1032, (2009); Ye X., Bunescu R., Liu C., Mapping bug reports to relevant files: A ranking model, a fine-grained benchmark, and feature evaluation, IEEE Trans. Softw. Eng., 42, 4, pp. 379-402, (2016); Sun W., Yan X., Khan A.A., Generative ranking based sequential recommendation in software crowdsourcing, Proc. Eval. Assessment Softw. Eng., pp. 419-426, (2020); Song L., Minku L.L., Yao X., Software effort interval prediction via Bayesian inference and synthetic bootstrap resampling, ACM Trans. Softw. Eng. Methodol., 28, 1, pp. 1-46, (2019); Yu X., Liu J., Yang Z., Jia X., Ling Q., Ye S., Learning from imbalanced data for predicting the number of software defects, Proc. IEEE 28th Int. Symp. Softw. Rel. Eng., pp. 78-89, (2017); Zhang H., Gong L., Versteeg S., Predicting bug-fixing time: An empirical study of commercial software projects, Proc. 35th Int. Conf. Softw. Eng., pp. 1042-1051, (2013); Wang H., Wang L., Yu Q., Zheng Z., Bouguettaya A., Lyu M.R., Online reliability prediction via motifs-based dynamic Bayesian networks for service-oriented systems, IEEE Trans. Softw. Eng., 43, 6, pp. 556-579, (2017); Romansky S., Borle N.C., Chowdhury S., Hindle A., Greiner R., Deep green: Modelling time-series of software energy consumption, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 273-283, (2017); Wan Y., Et al., Improving automatic source code summarization via deep reinforcement learning, Proc. 33rd ACM/IEEE Int. Conf. Automated Softw. Eng., pp. 397-407, (2018); Yin P., Neubig G., A syntactic neural model for general-purpose code generation, Proc. 55th Annu. Meeting Assoc. Comput. Linguistics, pp. 440-450, (2017); Liang Y., Zhu K.Q., Automatic generation of text descriptive comments for code blocks, Proc. 32nd AAAI Conf. Artif. Intell., pp. 5229-5236, (2018); Samuel A.L., Some Studies in Machine Learning Using the Game of Checkers. II-Recent Progress, (1988); Mitchell T.M., Et al., Machine learning. 1997, pp. 870-877, (1997); Bishop C.M., Pattern Recognition and Machine Learning, (2006); Brownlee J., Difference between classification and regression in machine learning, (2021); Zou Y., Ye T., Lu Y., Mylopoulos J., Zhang L., Learning to rank for question-oriented software text retrieval (t), Proc. IEEE/ACM 30th Int. Conf. Automated Softw. Eng., pp. 1-11, (2015); Dietterich T.G., Ensemble methods in machine learning, Proc. Int. Workshop Mult. Classifier Syst., pp. 1-15, (2000); Kocaguneli E., Menzies T., Keung J.W., On the value of ensemble effort estimation, IEEE Trans. Softw. Eng., 38, 6, pp. 1403-1416, (2012); Thung F., Le X.-B.D., Lo D., Active semi-supervised defect categorization, Proc. IEEE 23rd Int. Conf. Prog. Comprehension, pp. 60-70, (2015); Cohn D.A., Atlas L.E., Ladner R.E., Improving generalization with active learning, Mach. Learn., 15, 2, pp. 201-221, (1994); Li M., Zhang H., Wu R., Zhou Z.-H., Sample-based software defect prediction with active and semi-supervised learning, Automated Softw. Eng., 19, 2, pp. 201-230, (2012); Jamshidi P., Siegmund N., Velez M., Kastner C., Patel A., Agarwal Y., Transfer learning for performance modeling of configurable systems: An exploratory analysis, Proc. IEEE/ACM 32nd Int. Conf. Automated Softw. Eng., pp. 497-508, (2017); Krishna R., Menzies T., Fu W., Too much automation? The bellwether effect and its implications for transfer learning, Proc. IEEE/ACM 31st Int. Conf. Automated Softw. Eng., pp. 122-131, (2016); Rahman F., Posnett D., Devanbu P., Recalling the ""imprecision"" of cross-project defect prediction, Proc. ACM SIGSOFT 20th Int. Symp. Found. Softw. Eng., pp. 1-11, (2012); Xue K.-X., Su L., Jia Y.-F., Cai K.-Y., A neural network approach to forecasting computing-resource exhaustion with workload, Proc. 9th Int. Conf. Qual. Softw., pp. 315-324, (2009); Le Cun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, (2015); Lam A.N., Nguyen A.T., Nguyen H.A., Nguyen T.N., Bug localization with combination of deep learning and information retrieval, Proc. IEEE/ACM 25th Int. Conf. Prog. Comprehension, pp. 218-229, (2017); Wang S., Liu T., Tan L., Automatically learning semantic features for defect prediction, Proc. IEEE/ACM 38th Int. Conf. Softw. Eng., pp. 297-308, (2016); Chen C., Su T., Meng G., Xing Z., Liu Y., From UI design image to GUI skeleton: A neural machine translator to bootstrap mobile GUI implementation, Proc. 40th Int. Conf. Softw. Eng., pp. 665-676, (2018); Guo J., Cheng J., Cleland-Huang J., Semantically enhanced software traceability using deep learning techniques, Proc. IEEE/ACM 39th Int. Conf. Softw. Eng., pp. 3-14, (2017); Hochreiter S., Schmidhuber J., Long short-term memory, Neural Comput., 9, 8, pp. 1735-1780, (1997); Wen M., Wu R., Cheung S.-C., How well do change sequences predict defects? sequence learning from software changes, IEEE Trans. Softw. Eng., 46, 11, pp. 1155-1175, (2020); Cho K., Et al., Learning phrase representations using RNN encoder-decoder for statistical machine translation, (2014); Wu Y., Et al., SCDetector: Software functional clone detection based on semantic tokens analysis, Proc. 35th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 821-833, (2020); Kitchenham B., Charters S., Guidelines for performing systematic literature reviews in software engineering (version 2.3), (2007); Zhang H., Babar M.A., Tell P., Identifying relevant studies in software engineering, Informat. Softw. Technol., 53, 6, pp. 625-637, (2011); Parloff R., Why deep learning is suddenly changing your life, (2016); Xie T., Thummalapenta S., Lo D., Liu C., Data mining for software engineering, Comput., 42, 8, pp. 55-62, (2009); Gonzalez D., Zimmermann T., Nagappan N., The state of the ML-universe: 10 years of artificial intelligence & machine learning software development on github, Proc. 17th Int. Conf. Mining Softw. Repositories, pp. 431-442, (2020); Maldonado E.D.S., Shihab E., Tsantalis N., Using natural language processing to automatically detect self-admitted technical debt, IEEE Trans. Softw. Eng., 43, 11, pp. 1044-1062, (2017); Xia X., Lo D., Pan S.J., Nagappan N., Wang X., HYDRA: Massively compositional model for cross-project defect prediction, IEEE Trans. Softw. Eng., 42, 10, pp. 977-998, (2016); Mirakhorli M., Cleland-Huang J., Detecting, tracing, and monitoring architectural tactics in code, IEEE Trans. Softw. Eng., 42, 3, pp. 205-220, (2016); IEEE Std 610.12-1990, pp. 1-84, (1990); Xie X., Ho J.W., Murphy C., Kaiser G., Xu B., Chen T.Y., Testing and validating machine learning classifiers by metamorphic testing, J. Syst. Softw., 84, 4, pp. 544-558, (2011); Unterkalmsteiner M., Gorschek T., Islam A.K.M.M., Cheng C.K., Permadi R.B., Feldt R., Evaluation and measurement of software process improvement- A systematic literature review, IEEE Trans. Softw. Eng., 38, 2, pp. 398-424, (2012); Cohen J., A coefficient of agreement for nominal scales, Educ. Psychol. Meas., 20, 1, pp. 37-46, (1960); Landis J.R., Koch G.G., The measurement of observer agreement for categorical data, Biometrics, 33, pp. 159-174, (1977); Kitchenham B., Procedures for performing systematic reviews, 33, pp. 1-26, (2004); Yang L., Et al., Quality assessment in systematic literature reviews: A software engineering perspective, Informat. Softw. Technol., 130, (2021); Huang X., Zhang H., Zhou X., Ali Babar M., Yang S., Synthesizing qualitative research in software engineering: A critical review, Proc. IEEE/ACM 40th Int. Conf. Softw. Eng., pp. 1207-1218, (2018); Gonzalez-Barahona J.M., Robles G., On the reproducibility of empirical software engineering studies based on data retrieved from development repositories, Empir. Softw. Eng., 17, 1, pp. 75-89, (2012); Amershi S., Et al., Software engineering for machine learning: A case study, Proc. 41st Int. Conf. Softw. Eng. Softw. Eng. Pract., pp. 291-300, (2019); Saldana J., Fundamentals of Qualitative Research, (2011); Wang S., Supplemental data for TSE paper, (2022); White M., Vendome C., Linares-Vasquez M., Poshyvanyk D., Toward deep learning software repositories, Proc. 12th Work. Conf. Mining Softw. Repositories, pp. 334-345, (2015); Bao L., Xing Z., Xia X., Lo D., Hassan A.E., Inference of development activities from interaction with uninstrumented applications, Empir. Softw. Eng., 23, 3, pp. 1313-1351, (2018); Girardi D., Novielli N., Fucci D., Lanubile F., Recognizing developers' emotions while programming, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 666-677, (2020); Blincoe K., Valetto G., Damian D., Facilitating coordination between software developers: A study and techniques for timely and efficient recommendations, IEEE Trans. Softw. Eng., 41, 10, pp. 969-985, (2015); Bao L., Xing Z., Xia X., Lo D., Li S., Who will leave the company?: A large-scale industry study of developer turnover by mining monthly work report, Proc. IEEE/ACM 14th Int. Conf. Mining Softw. Repositories, pp. 170-181, (2017); Bhat M., Shumaiev K., Koch K., Hohenstein U., Biesdorf A., Matthes F., An expert recommendation system for design decision making: Who should be involved in making a design decision?, Proc. IEEE Int. Conf. Softw. Archit., pp. 85-8509, (2018); Ye X., Shen H., Ma X., Bunescu R., Liu C., From word embeddings to document similarities for improved information retrieval in software engineering, Proc. 38th Int. Conf. Softw. Eng., pp. 404-415, (2016); Wang J., Li M., Wang S., Menzies T., Wang Q., Images don't lie: Duplicate crowdtesting reports detection with screenshot information, Informat. Softw. Technol., 110, pp. 139-155, (2019); Wahba Y., Madhavji N.H., Steinbacher J., Evaluating the Effectiveness of Static Word Embeddings on the Classification of IT Support Tickets, pp. 198-206, (2020); Liu Z., Xia X., Lo D., Grundy J., Automatic, highly accurate app permission recommendation, Automated Softw. Eng., 26, 2, pp. 241-274, (2019); Mikolov T., Sutskever I., Chen K., Corrado G., Dean J., Distributed representations of words and phrases and their compositionality, Proc. Int. Conf. Neural Inf. Process. Syst., pp. 3111-3119, (2013); Pennington J., Socher R., Manning C.D., GloVe: Global vectors for word representation, Proc. Conf. Empir. Methods Natural Lang. Process., pp. 1532-1543, (2014); Ye D., Xing Z., Foo C.Y., Li J., Kapre N., Learning to extract API mentions from informal natural language discussions, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 389-399, (2016); Han Z., Li X., Liu H., Xing Z., Feng Z., Deepweak: Reasoning common software weaknesses via knowledge graph embedding, Proc. IEEE 25th Int. Conf. Softw. Anal., Evol. Reengineering, pp. 456-466, (2018); Reddy S., Lemieux C., Padhye R., Sen K., Quickly generating diverse valid test inputs with reinforcement learning, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 1410-1421, (2020); Emam S.S., Miller J., Test case prioritization using extended digraphs, ACM Trans. Softw. Eng. Methodol., 25, 1, pp. 1-41, (2015); Carino S., Andrews J.H., Dynamically testing GUIs using ant colony optimization (t), Proc. IEEE/ACM 30th Int. Conf. Automated Softw. Eng., pp. 138-148, (2015); Barriga A., Heldal R., Iovino L., Marthinsen M., Rutle A., An extensible framework for customizable model repair, Proc. IEEE/ACM 23rd Int. Conf. Model Driven Eng. Lang. Syst., pp. 24-34, (2020); Wu Z., Et al., REINAM: Reinforcement learning for input-grammar inference, Proc. 27th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 488-498, (2019); Honel S., Ericsson M., Lowe W., Wingkvist A., Using source code density to improve the accuracy of automatic commit classification into maintenance activities, J. Syst. Softw., 168, (2020); Chen X., Et al., A systemic framework for crowdsourced test report quality assessment, Empir. Softw. Eng., 25, 2, pp. 1382-1418, (2020); Zhang Z., Sun H., Zhang H., Developer recommendation for topcoder through a meta-learning based policy model, Empir. Softw. Eng., 25, 1, pp. 859-889, (2020); Hey T., Keim J., Koziolek A., Tichy W.F., Norbert: Transfer learning for requirements classification, Proc. IEEE 28th Int. Requirements Eng. Conf., pp. 169-179, (2020); Sainani A., Anish P.R., Joshi V., Ghaisas S., Extracting and classifying requirements from software engineering contracts, Proc. IEEE 28th Int. Requirements Eng. Conf., pp. 147-157, (2020); Shi L., Xing M., Li M., Wang Y., Li S., Wang Q., Detection of hidden feature requests from massive chat messages via deep siamese network, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 641-653, (2020); Li M., Shi L., Yang Y., Wang Q., A deep multitask learning approach for requirements discovery and annotation from open forum, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 336-348, (2020); Fakhoury S., Arnaoudova V., Noiseux C., Khomh F., Antoniol G., Keep it simple: Is deep learning good for linguistic smell detection?, Proc. IEEE 25th Int. Conf. Softw. Anal., Evol. ReEng., pp. 602-611, (2018); Hadj-Kacem M., Bouassida N., Deep representation learning for code smells detection using variational auto-encoder, Proc. Int. Joint Conf. Neural Netw., pp. 1-8, (2019); Zampetti F., Serebrenik A., Di Penta M., Automatically learning patterns for self-admitted technical debt removal, Proc. IEEE 27th Int. Conf. Softw. Anal., Evol. Reeng., pp. 355-366, (2020); Chen Y., Poskitt C.M., Sun J., Adepu S., Zhang F., Learning-guided network fuzzing for testing cyber-physical system defences, Proc. IEEE/ACM 34th Int. Conf. Automated Softw. Eng., pp. 962-973, (2019); Chekam T.T., Papadakis M., Bissyande T.F., Le Traon Y., Sen K., Selecting fault revealing mutants, Empir. Softw. Eng., 25, 1, pp. 434-487, (2020); Mao D., Chen L., Zhang L., An extensive study on crossproject predictive mutation testing, Proc. IEEE 12th Conf. Softw. Testing Validation Verification, pp. 160-171, (2019); Zheng Y., Et al., Wuji: Automatic online combat game testing using evolutionary deep reinforcement learning, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 772-784, (2019); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Learning how to mutate source code from bugfixes, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 301-312, (2019); Tan M., Tan L., Dara S., Mayeux C., Online defect prediction for imbalanced data, Proc. IEEE/ACM 37th Int. Conf. Softw. Eng., pp. 99-108, (2015); Zhang F., Hassan A.E., McIntosh S., Zou Y., The use of summation to aggregate software metrics hinders the performance of defect prediction models, IEEE Trans. Softw. Eng., 43, 5, pp. 476-491, (2017); Nam J., Pan S.J., Kim S., Transfer defect learning, Proc. 35th Int. Conf. Softw. Eng., pp. 382-391, (2013); Chen J., Et al., Software visualization and deep transfer learning for effective software defect prediction, Proc. ACM/IEEE 42nd Int. Conf. Softw. Eng., pp. 578-589, (2020); Wang S., Liu T., Nam J., Tan L., Deep semantic feature learning for software defect prediction, IEEE Trans. Softw. Eng., 46, 12, pp. 1267-1293, (2020); Xu Z., Et al., LDFR: Learning deep feature representation for software defect prediction, J. of Syst. Softw., 158, (2019); Zhu K., Within-project and cross-project just-in-time defect prediction based on denoising autoencoder and convolutional neural network, IET Softw., 14, pp. 185-195, (2020); Zhou T., Sun X., Xia X., Li B., Chen X., Improving defect prediction with deep forest, Informat. Softw. Technol., 114, pp. 204-216, (2019); Xu J., Wang F., Ai J., Defect prediction with semantics and context features of codes based on graph representation learning, IEEE Trans. Rel., 70, 2, pp. 613-625, (2021); Heo K., Oh H., Yi K., Machine-learning-guided selectively unsound static analysis, Proc. IEEE/ACM 39th Int. Conf. Softw. Eng., pp. 519-529, (2017); Natella R., Cotroneo D., Duraes J.A., Madeira H.S., On fault representativeness of software fault injection, IEEE Trans. Softw. Eng., 39, 1, pp. 80-96, (2013); Kim D., Tao Y., Kim S., Zeller A., Where should we fix this bug? a two-phase recommendation model, IEEE Trans. Softw. Eng., 39, 11, pp. 1597-1610, (2013); Mu D., Et al., Renn: Efficient reverse execution with neural-network-assisted alias analysis, Proc. IEEE/ACM 34th Int. Conf. Automated Softw. Eng., pp. 924-935, (2019); Zhang Z., Lei Y., Mao X., Li P., CNN-FL: An effective approach for localizing faults using convolutional neural networks, Proc. IEEE 26th Int. Conf. Softw. Anal., Evol. Reengineering, pp. 445-455, (2019); Kapur R., Sodhi B., A defect estimator for source code: Linking defect reports with programming constructs usage metrics, ACM Trans. Softw. Eng. Methodol., 29, 2, pp. 1-35, (2020); Lin Y., Sun J., Tran L., Bai G., Wang H., Dong J., Break the dead end of dynamic slicing: Localizing data and control omission bug, Proc. IEEE/ACM 33rd Int. Conf. Automated Softw. Eng., pp. 509-519, (2018); Li Y., Wang S., Nguyen T.N., Van Nguyen S., Improving bug detection via context-based code representation learning and attention-based neural networks, Proc. ACM Prog. Lang., 3, pp. 1-30, (2019); Zhang J., Xie R., Ye W., Zhang Y., Zhang S., Exploiting Code Knowl. Graph for Bug Localization via Bi-Directional Attention, pp. 219-229, (2020); Zhang J., Wang X., Zhang H., Sun H., Pu Y., Liu X., Learning to handle exceptions, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 29-41, (2020); Liang H., Sun L., Wang M., Yang Y., Deep learning with customized abstract syntax tree for bug localization, IEEE Access, 7, pp. 116309-116320, (2019); Chen J., Ma H., Zhang L., Enhanced Compiler Bug Isolation via Memoized Search, pp. 78-89, (2020); Xiao Y., Keung J., Bennin K.E., Mi Q., Improving bug localization with word embedding and enhanced convolutional neural networks, Informat. Softw. Technol., 105, pp. 17-29, (2019); Kurtanovic Z., Maalej W., Mining user rationale from software reviews, Proc. IEEE 25th Int. Requirements Eng. Conf., pp. 61-70, (2017); Lin B., Zampetti F., Bavota G., Di Penta M., Lanza M., Oliveto R., Sentiment analysis for software engineering: How far can we go?, Proc. 40th Int. Conf. Softw. Eng., pp. 94-104, (2018); Qian Z., Shen B., Mo W., Chen Y., Satiindicator: Leveraging user reviews to evaluate user satisfaction of sourceforge projects, Proc. IEEE 40th Annu. Comput. Softw. Appl. Conf., pp. 93-102, (2016); Gao C., Zeng J., Xia X., Lo D., Lyu M.R., King I., Automating app review response generation, Proc. 34th IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 163-175, (2019); Gu Y., Yang K., Fu S., Chen S., Li X., Marsic I., Multimodal affective analysis using hierarchical attention strategy with word-level alignment, Proc. 56th Annu. Meeting Assoc. Comput. Linguistics, pp. 2225-2235, (2018); Pecorelli F., Palomba F., Di Nucci D., De Lucia A., Comparing heuristic and machine learning approaches for metric-based code smell detection, Proc. IEEE/ACM 27th Int. Conf. Prog. Comprehension, pp. 93-104, (2019); White M., Tufano M., Vendome C., Poshyvanyk D., Deep learning code fragments for code clone detection, Proc. 31st IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 87-98, (2016); Liu B., Et al., DIFF: Cross-version binary code similarity detection with dnn, Proc. IEEE/ACM 33rd Int. Conf. Automated Softw. Eng., pp. 667-678, (2018); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proc. 26th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., (2018); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, Proc. IEEE/ACM 15th Int. Conf. Mining Softw. Repositories, pp. 542-553, (2018); Wang W., Li G., Ma B., Xia X., Jin Z., Detecting code clones with graph neural network and flow-augmented abstract syntax tree, Proc. IEEE 27th Int. Conf. Softw. Anal., Evol. Reengineering, pp. 261-271, (2020); Scandariato R., Walden J., Hovsepyan A., Joosen W., Predicting vulnerable software components via text mining, IEEE Trans. Softw. Eng., 40, 10, pp. 993-1006, (2014); Zheng W., Et al., The impact factors on the performance of machine learning-based vulnerability detection: A comparative study, J. Syst. Softw., 168, (2020); Han Z., Li X., Xing Z., Liu H., Feng Z., Learning to predict severity of software vulnerability using only vulnerability description, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 125-136, (2017); Chen Z., Wang H., Xu C., Ma X., Cao C., Vision: Evaluating scenario suitableness for DNN models by mirror synthesis, Proc. 26th Asia-Pacific Softw. Eng. Conf., pp. 78-85, (2019); Mashhadi M.J., Hemmati H., Hybrid deep neural networks to infer state models of black-box systems, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 299-311, (2020); Kang H.J., Bissyand T.F., Lo D., Assessing the generalizability of code2vec token embeddings, Proc. IEEE/ACM 34th Int. Conf. Automated Softw. Eng., pp. 1-12, (2019); Le T., Et al., Maximal divergence sequential autoencoder for binary software vulnerability detection, Proc. Int. Conf. Learn. Representations, (2019); Tang G., Et al., A comparative study of neural network techniques for automatic software vulnerability detection, Proc. Int. Symp. Theor. Aspects Softw. Eng., pp. 1-8, (2020); Fan Y., Xia X., Lo D., Hassan A.E., Chaff from the wheat: Characterizing and determining valid bug reports, IEEE Trans. Softw. Eng., 46, 5, pp. 495-525, (2020); Ye X., Fang F., Wu J., Bunescu R., Liu C., Bug report classification using LSTM architecture for more accurate software defect locating, Proc. IEEE 17th Int. Conf. Mach. Learn. Appl., pp. 1438-1445, (2018); He J., Xu L., Yan M., Xia X., Lei Y., Duplicate bug report detection using dual-channel convolutional neural networks, Proc. 28th Int. Conf. Prog. Comprehension, (2020); Soleimani Neysiani B., Babamir S.M., Aritsugi M., Efficient feature extraction model for validation performance improvement of duplicate bug report detection in software bug triage systems, Informat. Softw. Technol., 126, (2020); Koc U., Wei S., Foster J.S., Carpuat M., Porter A.A., An empirical assessment of machine learning approaches for triaging reports of a java static analysis tool, Proc. IEEE 12th Conf. Softw. Testing, Validation Verification, pp. 288-299, (2019); Chaparro O., Et al., Assessing the quality of the steps to reproduce in bug reports, Proc. 27th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., (2019); Rodrigues I.M., Aloise D., Fernandes E.R., Dagenais M., A Soft Alignment Model for Bug Deduplication, (2020); Anvik J., Murphy G.C., Reducing the effort of bug report triage: Recommenders for development-oriented decisions, ACM Trans. Softw. Eng. Methodol., 20, 3, pp. 1-35, (2011); Zaidi S.F.A., Awan F.M., Lee M., Woo H., Lee C.-G., Applying convolutional neural networks with different word representation techniques to recommend bug fixers, IEEE Access, 8, pp. 213729-213747, (2020); Zhang W., Efficient bug triage for industrial environments, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 727-735, (2020); Vendome C., Linares-Vasquez M., Bavota G., Di Penta M., German D., Poshyvanyk D., Machine learning-based detection of open source license exceptions, Proc. IEEE/ACM 39th Int. Conf. Softw. Eng., pp. 118-129, (2017); Zhang X., Et al., Robust log-based anomaly detection on unstable log data, Proc. 27th ACM Joint Meeting Eur. Softw. Eng. Conf. Symp. Found. Softw. Eng., pp. 807-817, (2019); Liu Z., Chen C., Wang J., Huang Y., Hu J., Wang Q., Owl eyes: Spotting ui display issues via visual understanding, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 398-409, (2020); Yan R., Xiao X., Hu G., Peng S., Jiang Y., New deep learning method to detect code injection attacks on hybrid applications, J. Syst. Softw., 137, pp. 67-77, (2018); Xia H., Et al., How android developers handle evolution-induced API compatibility issues: A large-scale study, Proc. IEEE/ ACM 42nd Int. Conf. Softw. Eng., pp. 886-898, (2020); Liu Z., Xia X., Hassan A.E., Lo D., Xing Z., Wang X., Neural-machine-translation-based commit message generation: How far are we?, Proc. IEEE/ACM 33rd Int. Conf. Automated Softw. Eng., pp. 373-384, (2018); Iyer S., Konstas I., Cheung A., Zettlemoyer L., Summarizing source code using a neural attention model, Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, pp. 2073-2083, (2016); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, Proc. IEEE/ACM 32nd Int. Conf. Automated Softw. Eng., pp. 135-146, (2017); Le Clair A., Haque S., Wu L., McMillan C., Improved Code Summarization via a Graph Neural Network, pp. 184-195, (2020); Ahmad W., Chakraborty S., Ray B., Chang K.-W., A transformer-based approach for source code summarization, Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, pp. 4998-5007, (2020); Zhou Z., Yu H., Fan G., Effective approaches to combining lexical and syntactical information for code summarization, Softw. Pract. Experience, 50, 12, pp. 2313-2336, (2020); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proc. 33rd Int. Conf. Mach. Learn., pp. 2091-2100, (2016); Bielik P., Raychev V., Vechev M., PHOG: Probabilistic model for code, Proc. 33rd Int. Conf. Mach. Learn., pp. 2933-2942, (2016); Han S., Wallace D.R., Miller R.C., Code completion from abbreviated input, Proc. IEEE/ACM Int. Conf. Automated Softw. Eng., pp. 332-343, (2009); Hellendoorn V.J., Proksch S., Gall H.C., Bacchelli A., When code completion fails: A case study on real-world completions, Proc. IEEE/ACM 41st Int. Conf. Softw. Eng., pp. 960-970, (2019); Liu F., Li G., Zhao Y., Jin Z., Multi-Task Learning Based Pre-Trained Language Model for Code Completion, pp. 473-485, (2020); Ling W., Et al., Latent predictor networks for code generation, Proc. 54th Annu. Meeting Assoc. Comput. Linguistics, pp. 599-609, (2016); Sun Z., Zhu Q., Mou L., Xiong Y., Li G., Zhang L., A grammar-based structural CNN decoder for code generation, Proc. AAAI Conf. Artif. Intell., pp. 7055-7062, (2019); Lacomis J., Et al., Dire: A neural approach to decompiled identifier naming, Proc. IEEE/ACM 34th Int. Conf. Automated Softw. Eng., pp. 628-639, (2019); Jia Y., Cohen M.B., Harman M., Petke J., Learning combinatorial interaction test generation strategies using hyperheuristic search, Proc. IEEE/ACM 37th IEEE Int. Conf. Softw. Eng., pp. 540-550, (2015); Godefroid P., Peleg H., Singh R., Learn&fuzz: Machine learning for input fuzzing, Proc. IEEE/ACM 32nd Int. Conf. Automated Softw. Eng., pp. 50-59, (2017); Liu X., Li X., Prajapati R., Wu D., DeepFuzz: Automatic generation of syntax valid C programs for fuzz testing, Proc. AAAI Conf. Artif. Intell., pp. 1044-1051, (2019); Liu M., Li K., Chen T., DeepSQLi: Deep semantic learning for testing SQL injection, Proc. 29th ACM SIGSOFT Int. Symp. Softw. Testing Anal., pp. 286-297, (2020); Li Z., Zhao H., Shi J., Huang Y., Xiong J., An intelligent fuzzing data generation method based on deep adversarial learning, IEEE Access, 7, pp. 49327-49340, (2019); Ahmad T., Ashraf A., Truscan D., Domi A., Porres I., Using deep reinforcement learning for exploratory performance testing of software systems with multi-dimensional input spaces, IEEE Access, 8, pp. 195000-195020, (2020); Bhatia S., Kohli P., Singh R., Neuro-symbolic program corrector for introductory programming assignments, Proc. IEEE/ACM 40th Int. Conf. Softw. Eng., pp. 60-70, (2018); Chen Z., Kommrusch S., Tufano M., Pouchet L.-N., Poshyvanyk D., Monperrus M., Sequencer: Sequence-to-sequence learning for end-to-end program repair, IEEE Trans. Softw. Eng., 47, 9, pp. 1943-1959, (2021); Wu L., Li F., Wu Y., Zheng T., GGF: A Graph-Based Method for Program. Lang. Syntax Error Correction, pp. 139-148, (2020); Li Y., Wang S., Nguyen T.N., DLFix: Context-based code transformation learning for automated program repair, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 602-614, (2020); White M., Tufano M., Martinez M., Monperrus M., Poshyvanyk D., Sorting and transforming program repair ingredients via deep learning code similarities, Proc. IEEE 26th Int. Conf. Softw. Anal., Evol. ReEng., pp. 479-490, (2019); Tian H., Et al., Evaluating representation learning of code changes for predicting patch correctness in program repair, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 981-992, (2020); McCabe T., A complexity measure, IEEE Trans. Softw. Eng., SE-2, 4, pp. 308-320, (1976); Ghotra B., McIntosh S., Hassan A.E., Revisiting the impact of classification techniques on the performance of defect prediction models, Proc. 37th Int. Conf. Softw. Eng., pp. 789-800, (2015); Yang X., Lo D., Xia X., Zhang Y., Sun J., Deep learning for just-in-time defect prediction, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur., pp. 17-26, (2015); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur., pp. 318-328, (2017); Li J., He P., Zhu J., Lyu M.R., Software defect prediction via convolutional neural network, Proc. IEEE Int. Conf. Softw. Qual., Rel. Secur., pp. 318-328, (2017); Li L., Feng H., Zhuang W., Meng N., Ryder B., Cclearner: A deep learning-based clone detection approach, Proc. IEEE Int. Conf. Softw. Maintenance Evol., pp. 249-260, (2017); Viet Phan A., Le Nguyen M., Thu Bui L., Convolutional neural networks over control flow graphs for software defect prediction, Proc. IEEE 29th Int. Conf. Tools Artif. Intell., pp. 45-52, (2017); Xiao Y., Keung J., Mi Q., Bennin K.E., Bug localization with semantic and structural features using convolutional neural network and cascade forest, Proc. 22nd Int. Conf. Eval. Assessment Softw. Eng., pp. 101-111, (2018); Xiao Y., Keung J., Mi Q., Bennin K.E., Improving bug localization with an enhanced convolutional neural network, Proc. 24th Asia-Pacific Softw. Eng. Conf., pp. 338-347, (2017); Mikolov T., Chen K., Corrado G., Dean J., Efficient estimation of word representations in vector space, (2013); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans. Assoc. Comput. Linguistics, 5, pp. 135-146, (2017); Wang X., Liu J., Li L., Chen X., Liu X., Wu H., Detecting and explaining self-admitted technical debts with attention-based neural networks, Proc. IEEE/ACM 35th Int. Conf. Automated Softw. Eng., pp. 871-882, (2020); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Prog. Lang., 3, pp. 1-29, (2019); Le Q., Mikolov T., Distributed representations of sentences and documents, Proc. 31st Int. Conf. Mach. Learn., pp. 1188-1196, (2014); Hoang T., Kang H.J., Lo D., Lawall J., Cc2vec: Distributed representations of code changes, Proc. IEEE/ACM 42nd Int. Conf. Softw. Eng., pp. 518-529, (2020)","","Institute of Electrical and Electronics Engineers Inc.","","","","","","Review","Final","","Scopus","2-s2.0-85132507335"
"Keller P.; Kaboré A.K.; Plein L.; Klein J.; Le Traon Y.; Bissyandé T.F.","Keller, Patrick (57219508754); Kaboré, Abdoul Kader (57219785363); Plein, Laura (57219508910); Klein, Jacques (56282553000); Le Traon, Yves (55884641800); Bissyandé, Tegawendé F. (36080354200)","57219508754; 57219785363; 57219508910; 56282553000; 55884641800; 36080354200","What You See is What it Means! Semantic Representation Learning of Code based on Visualization and Transfer Learning","2022","ACM Transactions on Software Engineering and Methodology","31","2","31","","","","10","10.1145/3485135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130697770&doi=10.1145%2f3485135&partnerID=40&md5=52a1303320e21c7950828ae961ad8df7","Recent successes in training word embeddings for Natural Language Processing (NLP) tasks have encouraged a wave of research on representation learning for source code, which builds on similar NLP methods. The overall objective is then to produce code embeddings that capture the maximum of program semantics. State-of-the-art approaches invariably rely on a syntactic representation (i.e., raw lexical tokens, abstract syntax trees, or intermediate representation tokens) to generate embeddings, which are criticized in the literature as non-robust or non-generalizable. In this work, we investigate a novel embedding approach based on the intuition that source code has visual patterns of semantics. We further use these patterns to address the outstanding challenge of identifying semantic code clones. We propose the WySiWiM (What You See Is What It Means"") approach where visual representations of source code are fed into powerful pre-trained image classification neural networks from the field of computer vision to benefit from the practical advantages of transfer learning. We evaluate the proposed embedding approach on the task of vulnerable code prediction in source code and on two variations of the task of semantic code clone identification: code clone detection (a binary classification problem), and code classification (a multi-classification problem). We show with experiments on the BigCloneBench (Java), Open Judge (C) that although simple, our WySiWiM approach performs as effectively as state-of-the-art approaches such as ASTNN or TBCNN. We also showed with data from NVD and SARD that WySiWiM representation can be used to learn a vulnerable code detector with reasonable performance (accuracy 1/490%). We further explore the influence of different steps in our approach, such as the choice of visual representations or the classification algorithm, to eventually discuss the promises and limitations of this research direction.  © 2021 Copyright held by the owner/author(s).","embedding; representation learning; Semantic clones; visual representation","C (programming language); Classification (of information); Cloning; Codes (symbols); Embeddings; Natural language processing systems; Syntactics; Trees (mathematics); Code clone; Embeddings; Representation learning; Semantic clone; Semantic codes; Semantic representation; Source codes; State-of-the-art approach; Transfer learning; Visual representations; Semantics","Allamanis M., The Adverse Effects of Code Duplication in Machine Learning Models of Code, (2018); Alon U., Levy O., Yahav E., Code2seq: Generating Sequences from Structured Representations of Code, (2018); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proceedings of the Acm on Programming Languages, 3, (2019); IJaDataset 2.0, (2013); Arandjelovic R., Zisserman A., Look, listen and learn, The Ieee International Conference on Computer Vision (ICCV'17), (2017); Baker B.S., A program for identifying duplicated code, Computing Science and Statistics: Proceedings of the 24th Symposium on the Interface, 24, pp. 49-57, (1992); Baxter I.D., Yahin A., Moura L., Sant'Anna M., Bier L., Clone detection using abstract syntax trees, Proceedings of the International Conference on Software Maintenance., pp. 368-377, (1998); Bellon S., Koschke R., Antoniol G., Krinke J., Merlo E., Comparison and evaluation of clone detection tools, Ieee Transactions on Software Engineering, 33, 9, pp. 577-591, (2007); Ben-David S., Blitzer J., Crammer K., Kulesza A., Pereira F., Wortman Vaughan J., A theory of learning from different domains, Machine Learning, 79, 1, pp. 151-175, (2010); Ben-Nun T., Shoshana Jakobovits A., Hoefler T., Neural code comprehension: A learnable representation of code semantics, Advances in Neural Information Processing Systems., pp. 3585-3597, (2018); Chen J., Hu K., Yu Y., Chen Z., Xuan Q., Liu Y., Filkov V., Software visualization and deep transfer learning for effective software defect prediction, 2020 IEEE/ACM42nd International Conference on Software Engineering (ICSE'20)., pp. 578-589, (2020); Chen Z., Monperrus M., A Literature Study of Embeddings on Source Code, (2019); Coleman C., Narayanan D., Kang D., Zhao T., Zhang J., Nardi L., Bailis P., Olukotun K., Re C., Zaharia M., Dawnbench: An end-To-end deep learning benchmark and competition, Training, 100, 101, (2017); Cortes C., Vapnik V., Support-vector networks, Machine Learning, 20, 3, pp. 273-297, (1995); Cover T.M., Hart P., Et al., Nearest neighbor pattern classification, Ieee Transactions on Information Theory, 13, 1, pp. 21-27, (1967); Deng J., Dong W., Socher R., Li L., Li K., Fei-Fei L., ImageNet: A large-scale hierarchical image database, 2009 Ieee Conference on Computer Vision and Pattern Recognition., pp. 248-255, (2009); FaCoY., (2017); Gao Y., Liu S., Wang Z., Wei S., Yang L., Cai Y., TECCD: A tree embedding approach for code clone detection, 2019 Ieee International Conference on Software Maintenance and Evolution (ICSME'19)., (2019); Haykin S., Neural Networks: A Comprehensive Foundation., (1994); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition., pp. 770-778, (2016); Huh M., Agrawal P., Efros A.A., What Makes ImageNet Good for Transfer Learning?, (2016); Jegou S., Drozdzal M., Vazquez D., Romero A., Bengio Y., The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation, Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition Workshops., pp. 11-19, (2017); Jiang L., Misherghi G., Su Z., Glondu S., Deckard: Scalable and accurate treebased detection of code clones, Proceedings of the 29th International Conference on Software Engineering., pp. 96-105, (2007); Jiang L., Su Z., Automatic mining of functionally equivalent code fragments via random testing, Proceedings of the 18th International Symposium on Software Testing and Analysis., pp. 81-92, (2009); Juergens E., Deissenboeck F., Hummel B., Code similarities beyond copy & paste, 2010 14th European Conference OnvSoftware Maintenance and Reengineering (CSMR'10)., pp. 78-87, (2010); Kamavisdar P., Saluja S., Agrawal S., A survey on image classification approaches and techniques, International Journal of Advanced Research in Computer and Communication Engineering, 2, 1, pp. 1005-1009, (2013); Kamiya T., Kusumoto S., Inoue K., CCFinder: A multilinguistic token-based code clone detection system for large scale source code, Ieee Transactions on Software Engineering, 28, 7, pp. 654-670, (2002); Kim H., Jung Y., Kim S., Yi K., MeCC: Memory comparison-based clone detector, Proceedings of the 33rd International Conference on Software Engineering., pp. 301-310, (2011); Krinke J., Identifying similar codewith program dependence graphs, Proceedings of the 8thWorking Conference on Reverse Engineering., pp. 301-309, (2001); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Advances in Neural Information Processing Systems, 25, pp. 1097-1105, (2012); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet classification with deep convolutional neural networks, Communications of the Acm, 60, 6, pp. 84-90, (2017); Krutz D.E., Shihab E., CCCD: Concolic code clone detection, 2013 20th Working Conference on Reverse Engineering (WCRE'13)., pp. 489-490, (2013); Li L., Feng H., Zhuang W., Meng N., Ryder B., CClearner: A deep learning-based clone detection approach, 2017 Ieee International Conference on Software Maintenance and Evolution (ICSME'17)., pp. 249-260, (2017); Li S., Xiao X., Bassett B., Xie T., Tillmann N., Measuring code behavioral similarity for programming and software engineering education, Proceedings of the 38th International Conference on Software Engineering Companion., pp. 501-510, (2016); Li X., Wang L., Xin Y., Yang Y., Chen Y., Automated vulnerability detection in source code using minimum intermediate representation learning, Applied Sciences, 10, 5, (2020); Li Z., Lu S., Myagmar S., Zhou Y., CP-Miner: A tool for finding copy-paste and related bugs in operating system code, Proceedings of the 6th Conference on Symposium on Operating Systems Design & Implementation, 6, (2004); Li Z., Zou D., Xu S., Jin H., Zhu Y., Chen Z., Wang S., Wang J., SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities, (2018); Li Z., Zou D., Xu S., Ou X., Jin H., Wang S., Deng Z., Zhong Y., VulDeePecker: A Deep Learning-Based System for Vulnerability Detection., (2018); Liu C., Chen C., Han J., Yu P.S., GPLAG: Detection of software plagiarism by program dependence graph analysis, Proceedings of the 12th Acm Sigkdd International Conference on Knowledge Discovery and Data Mining., pp. 872-881, (2006); Lu D., Weng Q., A survey of image classification methods and techniques for improving classification performance, International Journal of Remote Sensing, 28, 5, pp. 823-870, (2007); Marcus A., Maletic J.I., Identification of high-level concept clones in source code, Proceedings of the 16th Annual International Conference on Automated Software Engineering (ASE'01)., pp. 107-114, (2001); Martin R.C., Design principles and design patterns, Object Mentor, 1, 34, (2000); McGuffie K., Newhouse A., The Radicalization Risks of GPT-3 and Advanced Neural Language Models, (2020); Mikolov T., Chen K., Corrado G., Dean J., Efficient Estimation Ofword Representations in Vector Space., (2013); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Advances in Neural Information Processing Systems., pp. 3111-3119, (2013); Mou L., Li G., Zhang L., Wang T., Jin Z., Convolutional neural networks over tree structures for programming language processing, 30th Aaai Conference on Artificial Intelligence, (2016); National Vulnerability Database, (2018); Software Assurance Reference Dataset, (2018); Pan S.J., Yang Q., A survey on transfer learning, Ieee Transactions on Knowledge and Data Engineering, 22, 10, pp. 1345-1359, (2009); Paszke A., Gross S., Chintala S., Chanan G., Pytorch, Computer Software. Vers. 0., 3, (2017); Pedregosa F., Varoquaux G., Gramfort A., Michel V., Thirion B., Grisel O., Blondel M., Prettenhofer P., Vincent Dubourg R., Et al., Scikit-learn: Machine learning in Python, Journal of Machine Learning Research, 12, pp. 2825-2830, (2011); Ponta S.E., Plate H., Sabetta A., Bezzi M., Dangremont C., A manually-curated dataset of fixes to vulnerabilities of open-source software, Proceedings of the 16th International Conference on Mining Software Repositories, (2019); Ragkhitwetsagul C., Krinke J., Marnette B., A picture is worth a thousand words: Code clone detection based on image similarity, 2018 Ieee 12th International Workshop on Software Clones (IWSC'18)., pp. 44-50, (2018); Roy C.K., Cordy J.R., Koschke R., Comparison and evaluation of code clone detection techniques and tools: A qualitative approach, Science of Computer Programming, 74, 7, pp. 470-495, (2009); Saini V., Farmahinifarahani F., Lu Y., Baldi P., Lopes C.V., Oreo: Detection of clones in the twilight zone, Proceedings of the 2018 26th Acm Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering., pp. 354-365, (2018); Su F., Bell J., Harvey K., Sethumadhavan S., Kaiser G., Jebara T., Code relatives: Detecting similarly behaving software, Proceedings of the 2016 24th Acm Sigsoft International Symposium on Foundations of Software Engineering., pp. 702-714, (2016); Su F., Bell J., Harvey K., Sethumadhavan S., Kaiser G., Jebara T., Code relatives: Detecting similarly behaving software, Proceedings of the 2016 24th Acm Sigsoft International Symposium on Foundations of Software Engineering (FSE'16)., pp. 702-714, (2016); Svajlenko J., Islam J.F., Keivanloo I., Roy C.K., Mia M., Towards a big data curated benchmark of inter-project code clones, 2014 Ieee International Conference on Software Maintenance and Evolution (ICSME'14)., pp. 476-480, (2014); CommonWeakness Enumeration, (2018); Tufano M., Watson C., Bavota G., Di Penta M., White M., Poshyvanyk D., Deep learning similarities from different representations of source code, 2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR'18)., pp. 542-553, (2018); Wei H., Li M., Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code, IJCAI., pp. 3034-3040, (2017); Zhang J., Wang X., Zhang H., Sun H., Wang K., Liu X., A novel neural source code representation based on abstract syntax tree, Proceedings of the 41st International Conference on Software Engineering., pp. 783-794, (2019); Zhu X., Sobihani P., Guo H., Long short-Term memory over recursive structures, International Conference on Machine Learning., pp. 1604-1612, (2015); Zhuang F., Qi Z., Duan K., Xi D., Zhu Y., Zhu H., Xiong H., He Q., A comprehensive survey on transfer learning, Proceedings of the Ieee, 109, 1, pp. 43-76, (2020)","","Association for Computing Machinery","","","","","","Article","Final","All Open Access; Bronze Open Access; Green Open Access","Scopus","2-s2.0-85130697770"
"Khalfi M.F.; Tabbiche M.N.; Adjoudj R.","Khalfi, Mohammed Fethi (54585535500); Tabbiche, Mohammed Nadjib (55557726300); Adjoudj, Reda (14015234700)","54585535500; 55557726300; 14015234700","From programming-To-modeling-To-prompts smart ubiquitous applications","2024","Journal of Ambient Intelligence and Smart Environments","16","1","","111","149","38","0","10.3233/AIS-220355","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188189633&doi=10.3233%2fAIS-220355&partnerID=40&md5=d9e92d908bb255b07120b68df8be7a15","Since its introduction by Mark Weiser, ubiquitous computing has received increased interest in the dawn of technological advancement. Supported by wireless technology advancement, embedded systems, miniaturization, and the integration of various intelligent and communicative devise, context-Aware ubiquitous applications actively and intelligently use rich contextual information to assist their users. However, their designs are subject to continuous changes imposed by external factors. Nowadays, software engineering, particularly in the fields of Model-Driven Engineering, displays a strong tendency towards developing applications for pervasive computing. This trend is also fueled by the rise of generative artificial intelligence, paving the way for a new generation of no-code development tools and models specifically trained on open-source code repositories to generate applications from their descriptions. The specificities of our approach lies in starting with a graphical model expressed using a domain-specific language (DSL) composed of symbols and formal notations. This allows for graphically instantiating and editing applications, guiding and assisting experts from various engineering fields in defining ubiquitous applications that are eventually transformed into peculiar models. We believe that creating intelligent models is the best way to promote software development efficiency. We have used and evaluated recurrent neural networks, leveraging the recurrence of processing the same contextual information collected within this model, and enabling iterative adaptation to future evolutions in ubiquitous systems. We propose a prototype instantiated by our meta-model which tracks the movements of individuals who were positive for COVID-19 and confirmed to be contagious. Different deep learning models and classical machine learning techniques are considered and compared for the task of detection/classification of COVID-19. Results obtained from all techniques were evaluated with confusion matrices, accuracy, precision, recall and F1-score. In summary, most of the results are very impressive. Our deep learning approach used a RNN architecture produced up to 92.1% accuracy. With the recent development of OpenAI Codex, optimized for programming languages, we provided the same requirements to the Codex model and asked it to generate the source code for the COVID-19 application, comparing it with the application generated by our workshop.  © 2024-IOS Press. All rights reserved.","ChatGPT; Codex; concrete syntax; COVID-19; deep learning; domain-specific language; GPT-4; graphics editors; MDE; model-driven engineering; OpenAI; playground; recurrent neural networks; Ubiquitous systems","Application programs; Embedded systems; Iterative methods; Learning systems; Modeling languages; Open source software; Open systems; Problem oriented languages; Recurrent neural networks; Software design; Ubiquitous computing; ChatGPT; Codex; Concrete syntax; Deep learning; Domains specific languages; GPT-4; Graphic editors; MDE; Model-driven Engineering; Openai; Playground; Ubiquitous systems; COVID-19","Abdelhay M., Mohammed A., Hefny H.A., Deep learning for Arabic healthcare: Medicalbot, Soc. Netw. Anal. Min., 13, 2023; Achilleos A., Kapitsaki G.M., Papadopoulos G.A., A model-driven framework for developing web service oriented applications, Current Trends in: Web Engineering. ICWE 2011, 7059; Achilleos A., Yang K., Georgalas N., Context modelling and a context-aware framework for pervasive service creation: A model-driven approach, Pervasive and Mobile Computing, 6, pp. 281-296, (2010); Alazba A., Aljamaan H., Alshayeb M., Deep learning approaches for bad smell detection: A systematic literature review, Empir Software Eng, 28, 2023; Alizadehsani R., Sharifrazi D., Izadi N.H., Joloudari J.H., Shoeibi A., Gorriz J.M., Hussain S., Arco J.E., Sani Z.A., Khozeimeh F., Et al., Uncertainty-aware semi-supervised method using large unlabelled and limited labeled covid-19 data; Almeida J.P.A., Iacob M.E., Jonkers H., Quartel D., Model-Driven Development of context-aware services, Distributed Applications and Interoperable Systems., 4025, (2006); Alti A., Boukerram A., Enabling self-management in context-aware quality model driven approach, 10th International Symposium on Programming and Systems, pp. 75-83, (2011); Asgharnezhad H., Shamsi A., Alizadehsani R., Et al., Objective evaluation of deep uncertainty predictions for Covid-19 detection, Sci Rep, 12, 1, (2022); Asudani D.S., Nagwani N.K., Singh P., Impact of word embedding models on text analytics in deep learning environment: A review, Artif Intell Rev, (2023); Autili M., Caporuscio M., Issarny V., Et al., Model-driven engineering of middleware-based ubiquitous services, Softw Syst Model, 13, pp. 481-511, (2014); Ayoobi N., Sharifrazi D., Alizadehsani R., Shoeibi A., Time series forecasting of new cases and new deaths rate for Covid-19 using deep learning methods, Results Phys, 27, 2021, pp. 1-15; Baddour A.M., Et al., CIM-CSS: A formal modeling approach to context identification and management for intelligent context- sensitive systems, IEEE Access, 7, pp. 116056-116077, (2019); Baidouri H., Hafiddi H., Nassar M., Kriouile A., A model-driven approach for context-aware services composition, International Conference on Multimedia Computing and Systems, pp. 693-698, (2012); Bedini F., Maschotta R., Zimmermann A., A generative approach for creating eclipse Sirius editors for generic systems, IEEE International Systems Conference (SysCon), 2021, pp. 1-8; Hlaoui Y.B., Zouhaier L., Ayed L.B., Model driven approach for adapting user interfaces to the context of accessibility: Case of visually impaired users, J Multimodal User Interfaces, 13, pp. 293-320, (2019); Bertin E., Hussein D., Sengul C., Et al., Access control in the Internet of things: A survey of existing approaches and open research questions, Ann. Telecommun., 74, pp. 375-388, (2019); Boudaa B., Hammoudi S., Mebarki L.A., Bouguessa A., Chikh M.A., An aspect-oriented model-driven approach for building adaptable context-aware service-based applications, Science of Computer Programming, 136, pp. 17-42, (2017); Bouraoui A., Gharbi I., Model driven engineering of accessible and multi-platform graphical user interfaces by parameterized model transformations, Science of Comp. Prog., 172, pp. 63-101, (2019); Brennan R.W., Lesage J., Exploring the implications of OpenAI codex on education for industry 4.0, Oriented, Holonic and Multi-Agent Manufacturing Systems for Industry of the Future. SOHOMA, Studies in Computational Intelligence, 1083; Broy M., Havelund K., Kumar R., Steffen B., Towards a unified view of modeling and programming (ISoLA 2018 track introduction), Leveraging Applications of Formal Methods, Verification and Validation, 11244, (2018); Bruneliere H., Burger E., Cabot J., Et al., A feature-based survey of model view approaches, Softw Syst Model, 18, pp. 1931-1952, (2019); Carton A., Clarke S., Senart A., Cahill V., Aspect-oriented model-driven development for mobile context-aware computing, First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments (SEPCASE’07), (2007); Ceri S., Daniel F., Facca F.M., Et al., Model-driven engineering of active context-awareness, World Wide Web, 10, pp. 387-413, (2007); Chabridon S., Conan D., Abid Z., Taconet C., Building ubiquitous QoC-aware applications through model-driven software engineering, Science of Computer Programming Journal, 78, 10, pp. 1912-1929, (2013); Chabridon S., Laborde R., Desprats T., Et al., A survey on addressing privacy together with quality of context for context management in the Internet of things, Ann. Telecommun., 69, pp. 47-62, (2014); Choi J.-W., Lim D.-J., A study on the development of embedded system software for ubiquitous sensor networks using UML, IFAC Proceedings Volumes, (2009); Cirilo C.E., Prado A.F.D., Souza W.L.D., Zaina L.A.M., Model Driven RichUbi – a Model-Driven Process to Construct Rich Interfaces for Context-Sensitive Ubiquitous Applications, 2010 Brazilian Symposium on Software Engineering, pp. 100-109, (2010); Dae-Kyoo K., Using ChatGPT to develop software systems: Alert to software engineers?; David I., Latifaj M., Pietron J., Et al., Blended modeling in commercial and open-source model-driven software engineering tools: A systematic study, Softw Syst Model, 22, 2023, pp. 415-447; do Nascimento F.A.M., Oliveira M.F.S., Wagner F.R., A model-driven engineering framework for embedded systems design, Innovations Syst Softw Eng, 8, pp. 19-33, (2012); Dorndorfer J., Hopfensperger F., Seel C., The SenSoMod-Modeler – a Model-Driven Architecture Approach for Mobile Context-Aware Business Applications, Information Systems Engineering in Responsible Information Systems, 350, (2019); Duarte P.A.S., Barreto F.M., Gomes F., Gomes A.A., Carvalho W.V., Trinta F.A.M., A model-driven approach to generate context-aware applications, Proceedings of the 20th Brazilian Symposium on Multimedia and the Web (WebMedia’14), pp. 99-102, (2014); Dwivedi Y.K., Kshetri N., Hughes L., Slade E.L., Jeyaraj A., Kar A.K., Baabdullah A.M., Koohang A., Raghavan V., Ahuja M., Et al., So what if ChatGPT wrote it? Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy, Int. J. Inf. Manag., 71, 2023; Elaasar M., Definition of modeling vs. programming languages, Leveraging Applications of Formal Methods, Verification and Validation, 11244, (2018); Elhannani S., Benslimane S.M., Khalfi M.F., Fechfouch M., QASIS: A QoC aware stress identification system using machine learning approach, International Journal of High Performance Systems Architecture, 11, 1, pp. 12-25, (2022); Khalfi M.F., Tabbiche M.N., Adjoudj R., Vers une modélisation graphique des applications ubiquitaires basée sur un Dsml intelligent: Covid-19 Contact-Tracer, Colloque sur les Objets et systèmes Connectés – COC’2021; Floridi L., AI as agency without intelligence: On ChatGPT, large language models, and other generative models, Philos. Technol, 36, 2023; Georgalas N., Ou S., Azmoodeh M., Yang K., Towards a model-driven approach for ontology-based context-aware application development: A case study, Fourth International Workshop on Model-Based Methodologies for Pervasive and Embedded Software (MOMPES’07), pp. 21-32, (2007); Gerbert-Gaillard E., Chollet S., Lalanda P., Model-driven approach for self-aware pervasive systems, IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS), pp. 1-6, (2016); Granada D., Vara J.M., Merayo M., Et al., CEViNEdit: Improving the process of creating cognitively effective graphical editors with GMF, Softw Syst Model, 20, 2021, pp. 867-895; Grassi V., Sindico A., Towards model driven design of service-based context-aware applications, International Workshop on Engineering of Software Services for Pervasive Environments: In Conjunction with the 6th ESEC/FSE Joint Meeting (ESSPE’07), pp. 69-74, (2007); Haddad M.R., Baazaoui H., Ziou D., Ghezala H.B., A model-driven approach for context-aware recommendation, International Conference on Multimedia Computing and Systems, pp. 693-698, (2012); Hafiddi H., Baidouri H., Nassar M., Asri B.E., Kriouile A., A model driven approach for context-aware services development, International Conference on Multimedia Computing and Systems, pp. 1-6, (2011); Hallsteinsen S.O., Geihs K., Paspallis N., Eliassen F., Horn G., Lorenzo J., Mamelli A., Papadopoulos G.A., A development framework and methodology for self-adapting applications, in ubiquitous computing environments, J. Syst. Softw., 85, pp. 2840-2859, (2012); Hamad M.M., Aktar S., Rashed-Al-Mahfuz M., Et al., A machine learning model to identify early stage symptoms of Sars-cov-2 infected patients, Expert Systems with Applications, 160, 2020; Harrington A., Cahill V., Model-driven engineering of planning and optimisation algorithms for pervasive computing environments, IEEE International Conference on Pervasive Computing and Communications (PerCom), pp. 172-180, (2011); Hartmann T., Moawad A., Fouquet F., Et al., The next evolution of MDE: A seamless integration of machine learning into domain modeling, Softw Syst Model, 18, pp. 1285-1304, (2019); Hoyos J., Molina J., Botia J., Preuveneers D., A model-driven approach for quality of context in pervasive systems, Computers and Electrical Engineering journal, 55, pp. 39-58, (2016); Hoyos J.R., Garcia-Molina J., Botia J.A., A domain-specific language for context modeling in context-aware systems, J. Syst. Softw., 86, 11, pp. 2890-2905, (2013); Idani A., Dependability of model-driven executable DSLs, Computer and Information Science, Software Architecture, 1269; Iung A., Carbonell J., Marchezan L., Et al., Systematic mapping study on domain-specific language development tools, Empir Software Eng, 25, 2020, pp. 4205-4249; Jaouadi I., Djemaa R.B., Ben-Abdallah H., Model-driven development approach for context-aware systems, Softw Syst Model, 17, pp. 1169-1195, (2018); Javan R., Kim T., Mostaghni N., Et al., ChatGPT’s Potential Role in Interventional Radiology, Cardiovasc Intervent Radiol; Joloudari J.H., Et al., DNN-GFE: A deep neural network model combined with global feature extractor for Covid-19 diagnosis based on CT scan images, EasyChair, 6330, (2021); Joloudari J.H., Hussain S., Nematollahi M.A., Bagheri R., Fazl F., Alizadehsani R., Et al., BERT-deep CNN: State-of-the-art for sentiment analysis of COVID-19 tweets; Junaid M., Ali S., Siddiqui I.F., Et al., Performance evaluation of data-driven intelligent algorithms for big data ecosystem, Wireless Pers Commun, 126, 2022, pp. 2403-2423; Kahani N., Bagherzadeh M., Cordy J.R., Et al., Survey and classification of model transformation tools, Softw Syst Model, 18, pp. 2361-2397, (2019); Kalnins A., Barzdins J., Metamodel specialization for graphical language support, Softw Syst Model, 18, pp. 1699-1735, (2019); Kapitsaki G.M., Achilleos A., Applying model-driven engineering for linking web service and context models: Position paper, Proceedings of the 13th International Conference on Information Integration and Web-Based Applications and Services (iiWAS’11), pp. 511-514, (2011); Karkouch A., Mousannif H., Al Moatassime H., Et al., A model-driven framework for data quality management in the Internet of things, J Ambient Intell Human Comput, 9, pp. 977-998, (2018); Khalfi M., Benslimane S.M., Systèmes d’information pervasifs: Architecture et challenges, UbiMob, 14, (2014); Khalfi M.F., Benslimane S.M., Evaluating characteristics adherence level to design framework for pervasive projects, International Journal of Advanced Pervasive and Ubiquitous Computing (IJAPUC), 7, 4, pp. 18-29, (2015); Khalfi M.F., Benslimane S.M., Meta model context based space for ubiquitous computing, International Journal of Advanced Pervasive and Ubiquitous Computing (IJAPUC), 7, 2, pp. 51-66, (2015); Khalfi M.F., Benslimane S.M., Meta model context based space for ubiquitous computing, International Journal of Advanced Pervasive and Ubiquitous Computing (IJAPUC), 7, 2, pp. 51-66, (2015); Khalfi M.F., Benslimane S.M., Spontaneous service-providing using WS4D in smart environments, International Journal of Advanced Pervasive and Ubiquitous Computing (IJAPUC), 6, 4, pp. 71-87, (2014); Khalfi M.F., Benslimane S.M., Toward a generic infrastructure for ubiquitous computing, International Journal of Advanced Pervasive and Ubiquitous Computing (IJAPUC), 5, 1, pp. 66-85, (2013); Khalfi M.F., Benslimane S.M., A framework for ambient computing, CLOSER, pp. 170-178, (2014); Khalfi M.F., Benslimane S.M., Proactive approach for service discovery using web service for devices on pervasive computing, Proceedings of the 3rd International Conference on Context-Aware Systems and Applications, pp. 123-129, (2014); Khalfi M.F., Tabbiche M.N., Adjoudj R., Vers une modélisation graphique des applications ubiquitaires basée sur un Dsml intelligent: Covid-19 contact-tracer, Colloque sur les Objets et Systèmes Connectés-COC’2021; Khozeimeh F., Sharifrazi D., Izadi N.H., Joloudari J.H., Shoeibi A., Alizadehsani R., Gorriz J.M., Hussain S., Sani Z.A., Moosaei H., Khosravi A., Nahavandi S., Islam S.M.S., Combining a convolutional neural network with autoencoders to predict the survival chance of Covid-19 patients, Scientific Reports, 11, 1, (2021); Kolides A., Nawaz A., Rathor A., Beeman D., Hashmi M., Fatima S., Berdik D., Al-Ayyoub M., Jararweh Y., Artificial intelligence foundation and pre-trained models: Fundamentals, applications, opportunities, and social impacts, simulation, Simulation Modelling Practice and Theory, 126, 2023; Kovalev A.K., Panov A.I., Application of pretrained large language models in embodied artificial intelligence, Dokl. Math., 106, pp. S85-S90, (2022); Lahat A., Shachar E., Avidan B., Et al., Evaluating the use of large language model in identifying top research questions, Gastroenterology Sci Rep, 13, 2023; Lalanda P., Vega G., Cervantes H., Morand D., Architecture and pervasive platform for machine learning services in industry 4.0, IEEE International Conference on Pervasive Computing and Communications Workshops and Other Affiliated Events (PerCom Workshops), 2021, pp. 293-298; Le Goaer O., Cariou E., Brunschwig L., Xmodeling studio: Un outil pour définir des DSL exécutables, 7ème Conférence En IngénieriE Du Logiciel (CIEL 2018), (2018); Li X., Tao X., Song W., Et al., AocML: A domain-specific language for model-driven development of activity-oriented context-aware applications, J. Comput. Sci. Technol., 33, pp. 900-917, (2018); Lin Y.C., Hoffmann P., Rahm E., Enhancing Cross-lingual biomedical concept normalization using deep neural network pretrained language models, SN COMPUT. SCI., 3, 2022; Liu B., Zhang Y., Cao X., Et al., A survey of model-driven techniques and tools for cyber-physical systems, Front Inform Technol Electron Eng, 21, 2020, pp. 1567-1590; Ma Q., Kaczmarek-Hess M., de Kinderen S., Validation and verification in domain-specific modeling method engineering: An integrated life-cycle view, Softw Syst Model, 22, 2023, pp. 647-666; Malek J., Laroussi M., Derycke A., Ghezala H.B., Model-Driven Development of Context-Aware Adaptive Learning Systems, 10th IEEE International Conference on Advanced Learning Technologies, pp. 432-434, (2010); Mettouris C., Achilleos A., Kapitsaki G., Papadopoulos G.A., The UbiCARS model-driven framework: Automating development of recommender systems for commerce, Ambient Intelligence, 11249; Mich L., Garigliano R., ChatGPT for e-tourism: A technological perspective, Inf Technol Tourism, 25, 2023, pp. 1-12; Mohammadi F.G., Amini M.H., Arabnia H.R., Introduction to advanced machine learning: Meta-learning algorithms, applications, and promises,, Optimization, Learning, and Control for Interdependent Complex Networks. Advances in Intelligent Systems and Computing, 1123; Moin A., Data analytics and machine learning methods, techniques and tool for model-driven engineering of smart IoT services, IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), 2021, pp. 287-292; Monfort V., Hammoudi S., Towards adaptable SOA: Model driven development, context and aspect, Service-Oriented Computing, 5900, (2009); Moradi H., Zamani B., Zamanifar K., CaaSSET: A framework for model-driven development of context as a service, Future Generation Computer Systems, 105, 2020, pp. 61-95; Nageba E., Fayn J., Rubel P., A model driven ontology-based architecture for supporting the quality of services in pervasive telemedicine applications, 3rd International Conference on Pervasive Computing Technologies for Healthcare, pp. 1-8, (2009); Ni J., Young T., Pandelea V., Et al., Recent advances in deep learning based dialogue systems: A systematic survey, Artif Intell Rev, 56, 2023, pp. 3055-3155; Ogrodniczuk M., Krynska K., Evaluating machine translation of Latin interjections in the digital library of Polish and Poland-related news pamphlets, From Born-Physical to Born-Virtual: Augmenting Intelligence in Digital Libraries, 13636; Ozkaya M., Akdur D., What do practitioners expect from the meta-modeling tools? A survey, J. Comput. Lang., 63, 2021; Parc P.L., Touil A., Vareille J., A model-driven approach for building ubiquitous applications, Third International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies, pp. 324-328, (2009); Pham H.N., Mahmoud Q.H., Ferworn A., Sadeghian A., Applying model-driven development to pervasive system engineering, First International Workshop on Software Engineering for Pervasive Computing Applications, Systems, and Environments (SEPCASE’07), (2007); Prezerakos G.N., Tselikas N.D., Cortese G., Model-driven composition of context-aware web services using ContextUML and aspects, IEEE International Conference on Web Services (ICWS 2007), pp. 320-329, (2007); Qadir J., Engineering education in the era of ChatGPT: Promise and pitfalls of generative AI for education, 2023 IEEE Global Engineering Education Conference (EDUCON), pp. 1-9, (2023); Ray P.P., ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope, Internet of Things and Cyber-Physical Systems; Rodriguez-Dominguez C., Ruiz-Lopez T., Benghazi K., Noguera M., Garrido J.L., A Model-Driven Approach for the Development of Middleware Technologies for Ubiquitous Systems, 9th International Conference on Intelligent Environments, pp. 16-23, (2013); Rodriguez-Dominguez C., Ruiz-Lopez T., Garrido J.L., Noguera M., Benghazi K., Leveraging the model-driven architecture for service choreography in ubiquitous systems, Ubiquitous Computing and Ambient Intelligence., 8276; Ruiz J., Serral E., Snoeck M., Evaluating user interface generation approaches: Model-based versus model-driven development, Softw Syst Model, 18, pp. 2753-2776, (2019); Schuster S., Brinkschulte U., Model-driven development of ubiquitous applications for sensor-actuator-networks with abstract state machines, Model-Driven Development of Ubiquitous Applications for Sensor-Actuator-Networks with Abstract State Machines, 4761, (2007); Seghiri R., Boulanger F., Lecocq C., Godefroy V., An executable model driven framework for enterprise architecture application to the smart grids context, 49th Hawaii International Conference on System Sciences (HICSS), pp. 4546-4555, (2016); Senturk S., Yasar H., Sogukpinar I., Model driven security in a mobile banking application context, Proceedings of the 14th International Conference on Availability, Reliability and Security (ARES’19), pp. 1-7, (2019); Serral E., Valderas P., Pelechano V., Towards the model driven development of context-aware pervasive systems, Pervasive Mob. Comput., 6, 2, pp. 254-280, (2010); Sharifrazi D., Alizadehsani R., Roshanzamir M., Joloudari J.H., Shoeibi A., Jafari M., Hussain S., Sani Z.A., Hasanzadeh F., Khozeimeh F., Khosravi A., Nahavandi S., Panahiazar M., Zare A., Islam S.M.S., Acharya U.R., Fusion of convolution neural network, support vector machine and Sobel filter for accurate detection of Covid-19 patients using X-ray images, Biomed Signal Process Control, 68, 2021; Sheng Q.Z., Benatallah B., ContextUML: A UML-based modeling language for model-driven development of context-aware web services, International Conference on Mobile Business (ICMB’05), pp. 206-212, (2005); Shoeibi A., Khodatars M., Alizadehsani R., Ghassemi N., Jafari M., Moridian P., Khadem A., Sadeghi D., Hussain S., Zare A., Automated detection and forecasting of COVID-19 using deep learning techniques: A review, 2020; Sindico A., Grassi V., Model driven development of context aware software systems, Proceedings of the 1st ACM International Workshop on Context-Oriented Programming (COP’09), pp. 1-5, (2009); Sobieszek A., Price T., Playing games with Ais: The limits of GPT-3 and similar large language models, Minds & Machines, 32, 2022, pp. 341-364; Tabbiche M.N., Khalfi M.F., Adjoudj R., A smart modeling tool for model-driven engineering of ubiquitous applications: Covid-19 contact-tracer, International Conference on Recent Advances in Mathematics and Informatics (ICRAMI), 2021, pp. 1-6; Tabbiche M.N., Khalfi M.F., Adjoudj R., Applying machine learning and model-driven approach for the identification and diagnosis of Covid-19, International Journal of Distributed Systems and Technologies (IJDST), 14, 1, pp. 1-27, (2023); Taconet C., Kazi-Aoul Z., Context-awareness and model driven engineering: Illustration by an E-commerce application scenario, Third International Conference on Digital Information Management, pp. 864-869, (2008); Teubner T., Flath C.M., Weinhardt C., Et al., Welcome to the era of ChatGPT, Bus Inf Syst Eng, 65, 2023, pp. 95-101; Thalheim B., Jaakkola H., Model-based fifth generation programming, Information Modelling and Knowledge Bases XXXI, pp. 381-400, (2020); Tuomi A., AI-generated content, creative freelance work and hospitality and tourism marketing, Information and Communication Technologies in Tourism, pp. 323-328, (2023); Vale S., Hammoudi S., Model driven development of context-aware service oriented architecture, 11th IEEE International Conference on Computational Science and Engineering – Workshops, pp. 412-418, (2008); Vale S., Hammoudi S., Towards context independence in distributed context-aware applications by the model driven approach, Proceedings of the 3rd International Workshop on Services Integration in Pervasive Environments (SIPE’08), pp. 31-36, (2008); Vaupel S., Taentzer G., Gerlach R., Et al., Model-driven development of mobile applications for Android and iOS supporting role-based app variability, Softw Syst Model, 17, pp. 35-63, (2018); Weiser M., The computer for the 21st century, SIGMOBILE Mob. Comput. Commun. Rev., 3, 3, pp. 3-11, (1999); Zhou N., Chee Y.-M., Zhang L.-J., Coding-free model-driven enablement framework and engineering practices of a context-aware SOA modeling environment, IEEE International Conference on Web Services, pp. 553-560, (2008)","","IOS Press BV","","","","","","Article","Final","","Scopus","2-s2.0-85188189633"
"Hort M.; Grishina A.; Moonen L.","Hort, Max (57218601709); Grishina, Anastasiia (57205678390); Moonen, Leon (7003285889)","57218601709; 57205678390; 7003285889","An Exploratory Literature Study on Sharing and Energy Use of Language Models for Source Code","2023","International Symposium on Empirical Software Engineering and Measurement","","","","","","","1","10.1109/ESEM56168.2023.10304803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174881692&doi=10.1109%2fESEM56168.2023.10304803&partnerID=40&md5=4885114c68615e8fcb045a469f58c63f","Context: Large language models trained on source code can support a variety of software development tasks, such as code recommendation and program repair. Large amounts of data for training such models benefit the models' performance. However, the size of the data and models results in long training times and high energy consumption. While publishing source code allows for replicability, users need to repeat the expensive training process if models are not shared. Goals: The main goal of the study is to investigate if publications that trained language models for software engineering (SE) tasks share source code and trained artifacts. The second goal is to analyze the transparency on training energy usage. Methods: We perform a snowballing-based literature search to find publications on language models for source code, and analyze their reusability from a sustainability standpoint. Results: From a total of 494 unique publications, we identified 293 relevant publications that use language models to address code-related tasks. Among them, 27% (79 out of 293) make artifacts available for reuse. This can be in the form of tools or IDE plugins designed for specific tasks or task-agnostic models that can be fine-tuned for a variety of downstream tasks. Moreover, we collect insights on the hardware used for model training, as well as training time, which together determine the energy consumption of the development process. Conclusion: We find that there are deficiencies in the sharing of information and artifacts for current studies on source code models for software engineering tasks, with 40% of the surveyed papers not sharing source code or trained artifacts. We recommend the sharing of source code as well as trained artifacts, to enable sustainable reproducibility. Moreover, comprehensive information on training times and hardware configurations should be shared for transparency on a model's carbon footprint.  © 2023 IEEE.","DL4SE; energy; replication; reuse; sustainability","Carbon footprint; Computational linguistics; Computer programming languages; Energy utilization; Publishing; Reusability; Software design; Sustainable development; DL4SE; Energy; Energy use; Engineering tasks; Language model; Literature studies; Replication; Reuse; Source codes; Training time; Transparency","Wilkinson M.D., Et al., The FAIR Guiding Principles for Scientific Data Management and Stewardship, Scientific Data, 3, 1, (2016); Lamprecht A.-L., Et al., Towards FAIR Principles for Research Software, Data Science, 3, 1, pp. 37-59, (2020); Sun C., Et al., VideoBERT: A Joint Model for Video and Language Representation Learning, Int'l Conf. Comp. Vision, pp. 7464-7473, (2019); Brown T.B., Et al., Language Models Are Few-Shot Learners, Int'l Conf. Neural Information Processing Sys. Curran, pp. 1877-1901, (2020); Strubell E., Et al., Energy and Policy Considerations for Deep Learning in NLP, Meeting of the Association for Computational Linguistics, pp. 3645-3650, (2019); Schwartz R., Et al., Green AI, Comm. ACM, 63, 12, pp. 54-63, (2020); Georgiou S., Et al., Green AI: Do Deep Learning Frameworks Have Different Costs, Int'l Conf. Softw. Eng, pp. 1082-1094, (2022); Tipirneni S., Et al., StructCoder: Structure-Aware Transformer for Code Generation, (2022); Mikolov T., Et al., Distributed Representations of Words and Phrases and Their Compositionality, Int'l Conf. Neural Information Processing Sys. Curran, pp. 3111-3119, (2013); Chen M., Et al., Evaluating Large Language Models Trained on Code, (2021); Lu S., Et al., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, Neural Information Processing Sys. Track on Datasets and Benchmarks, (2021); Zhou X., Et al., HULK: An Energy Efficiency Benchmark Platform for Responsible Natural Language Processing, (2020); Le Scao T., Et al., BLOOM: A 176B-Parameter Open-Access Multilingual Language Model, (2022); Katz D.S., Et al., Working towards Understanding the Role of FAIR for Machine Learning, Ws. Data and Research Objects Management for Linked Open Science, pp. 1-6, (2021); Liu C., Et al., On the Reproducibility and Replicability of Deep Learning in Software Engineering, ACM Trans. Softw. Eng. and Methodology, 31, 1, pp. 151-1546, (2021); Condori-Fernandez N., Et al., Towards a Software Sustainability-Quality Model: Insights from a Multi-Case Study, Int'l Conf. Research Challenges in Information Science, (2019); Lago P., Et al., Framing Sustainability as a Property of Software Quality, Comm. ACM, 58, 10, pp. 70-78, (2015); Condori-Fernandez N., Et al., A Software Sustainability-Quality Model. Vrije Universiteit Amsterdam, (2018); Tomlinson B., Greening through IT: Information Technology for Environmental Sustainability, (2010); Dick M., Et al., Enhancing Software Engineering Processes towards Sustainable Software Product Design, Integration of Environmental Information in Europe, (2010); Hindle A., Green Mining: A Methodology of Relating Software Change and Configuration to Power Consumption, Emp. Softw. Eng, 20, 2, pp. 374-409, (2015); Verdecchia R., Et al., Empirical Evaluation of the Energy Impact of Refactoring Code Smells, Int'l Conf. ICT for Sustainability, 52, pp. 365-383, (2018); Naumann S., Et al., The GREENSOFT Model: A Reference Model for Green and Sustainable Software and Its Engineering, Sustainable Computing: Informatics and Systems, 1, 4, pp. 294-304, (2011); Martinez M., Et al., Energy Consumption of Automated Program Repair. 2022; Verdecchia R., Et al., Data-Centric Green AI: An Exploratory Empirical Study, Int'l Conf. ICT for Sustainability, pp. 1-11, (2022); Garca-Martn E., Et al., Estimation of Energy Consumption in Machine Learning, J. Parallel and Distributed Computing, 134, pp. 75-88, (2019); Li D., Et al., Evaluating the Energy Efficiency of Deep Convolutional Neural Networks on CPUs and GPUs, IEEE Int'l Conf.s on Big Data and Cloud Computing (BDCloud), pp. 477-484, (2016); Henderson P., Et al., Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning, J. Machine Learning Research, 21, 1, pp. 24810039-24810081, (2022); Gutierrez M., Et al., Analysing the Energy Impact of Different Optimisations for Machine Learning Models, Int'l Conf. ICT for Sustainability. IEEE, pp. 46-52, (2022); Garcia-Martin E., Et al., Identification of Energy Hotspots: A Case Study of the Very Fast Decision Tree, Green, Pervasive, and Cloud Computing, pp. 267-281, (2017); Verdecchia R., Et al., A Systematic Review of Green AI, (2023); Jalali S., Et al., Systematic Literature Studies: Database Searches vs. Backward Snowballing, Int'l Symp. Empirical Softw. Eng. and Measurement. ACM, pp. 29-38, (2012); Wohlin C., Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering, Int'l Conf. Evaluation and Assessment in Softw. Eng. ACM, pp. 1-10, (2014); Petersen K., Et al., Guidelines for Conducting Systematic Mapping Studies in Software Engineering: An Update, Information and Softw. Technology, 64, pp. 1-18, (2015); Chen Z., Et al., A Literature Study of Embeddings on Source Code, (2019); Sharma T., Et al., A Survey on Machine Learning Techniques for Source Code Analysis, (2021); Watson C., Et al., A Systematic Literature Review on the Use of Deep Learning in Software Engineering Research, ACM Trans. Softw. Eng. and Methodology, 31, 2, pp. 321-3258, (2022); Niu C., Et al., Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code, (2022); Zhao G., Et al., DeepSim: Deep Learning Code Functional Similarity, ACM J. Meeting Eur. Softw. Eng. Conf. and Symp. Found. Softw. Eng. ACM, pp. 141-151, (2018); Fang C., Et al., Functional Code Clone Detection with Syntax and Semantics Fusion Learning, ACM SIGSOFT Int'l Symp. Softw. Testing and Analysis. ACM, pp. 516-527, (2020); DeFreez D., Et al., Path-Based Function Embedding and Its Application to Specification Mining, (2018); Yu H., Et al., Neural Detection of Semantic Code Clones Via Tree-Based Convolution, IEEE/ACM 27th Int'l Conf. Program Comprehension. IEEE, pp. 70-80, (2019); Brody S., Et al., A Structural Model for Contextual Code Changes, (2020); Alon U., Et al., Structural Language Models of Code, Int'l Conf. Machine Learning. PMLR, pp. 245-256, (2020); Hashimoto T.B., Et al., A Retrieve-and-Edit Framework for Predicting Structured Outputs, Int'l Conf. Neural Information Processing Sys. Curran, pp. 10073-10083, (2018); Chakraborty S., Et al., CODIT: Code Editing With Tree-Based Neural Models, IEEE Trans. Softw. Eng, 48, 4, pp. 1385-1399, (2022); Svyatkovskiy A., Et al., IntelliCode Compose: Code Generation Using Transformer, (2020); Svyatkovskiy A., Et al., Pythia: AI-assisted Code Completion System, ACM SIGKDD Int'l Conf. Knowledge Discovery & Data Mining. ACM, pp. 2727-2735, (2019); Murali V., Et al., Neural Sketch Learning for Conditional Program Generation, (2018); Xu F.F., Et al., Incorporating External Knowledge through Pretraining for Natural Language to Code Generation, Annual Meeting of the Association for Computational Linguistics. ACL, pp. 6045-6052, (2020); Yin P., Et al., A Syntactic Neural Model for General-Purpose Code Generation, (2017); Jiang N., Et al., CURE: Code-Aware Neural Machine Translation for Automatic Program Repair, IEEE/ACM 43rd Int'l Conf. Softw. Eng, pp. 1161-1173, (2021); Gupta R., Et al., Deep Reinforcement Learning for Syntactic Error Repair in Student Programs, AAAI Conf. Artificial Intelligence, 33, pp. 930-937, (2019); Berabi B., Et al., TFix: Learning to Fix Coding Errors with a Textto-Text Transformer, Int'l Conf. Machine Learning, 139, pp. 780-791, (2021); Chen Z., Et al., SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair, IEEE Trans. Softw. Eng, (2019); White M., Et al., Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities, Int'l Conf. Softw. Analysis, Evolution and Reengineering, pp. 479-490, (2019); Hoang T., Et al., CC2Vec: Distributed Representations of Code Changes, Int'l Conf. Softw. Eng, pp. 518-529, (2020); Tian H., Et al., Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair, IEEE/ACM Int'l Conf. Autom. Softw. Eng. ACM, pp. 981-992, (2020); Ye H., Et al., Neural Program Repair with Execution-Based Backpropagation, Int'l Conf. Softw. Eng. ACM, pp. 1506-1518, (2022); Chen Z., Et al., Neural Transfer Learning for Repairing Security Vulnerabilities in C Code, IEEE Trans. Softw. Eng, 49, 1, pp. 147-165, (2023); Tufano M., Et al., On Learning Meaningful Code Changes Via Neural Machine Translation, Int'l Conf. Softw. Eng, pp. 25-36, (2019); Haldar R., Et al., A Multi-Perspective Architecture for Semantic Code Search, Annual Meeting of the Association for Computational Linguistics. ACL, pp. 8563-8568, (2020); Huang J., Et al., CoSQA: 20, 000+ Web Queries for Code Search and Question Answering, (2021); Yao Z., Et al., CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning, Int'l World Wide Web Conf. ACM, pp. 2203-2214, (2019); Heyman G., Et al., Neural Code Search Revisited: Enhancing Code Snippet Retrieval through Natural Language Intent, (2020); Shi E., Et al., CAST: Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees, (2021); LeClair A., Et al., Improved Code Summarization via a Graph Neural Network, (2020); Haque S., Et al., Improved Automatic Summarization of Subroutines via Attention to File Context, Int'l Conf. Mining Softw. Repositories. ACM, pp. 300-310, (2020); Yang Z., Et al., A Multi-Modal Transformer-based Code Summarization Approach for Smart Contracts, (2021); Lachaux M.-A., Et al., Unsupervised Translation of Programming Languages, (2020); Liu C., Et al., CodeQA: A Question Answering Dataset for Source Code Comprehension, (2021); Yao Z., Et al., StaQC: A Systematically Mined Question-Code Dataset from Stack Overflow, Int'l World Wide Web Conf. ACM, pp. 1693-1703, (2018); Li Y., Et al., Vulnerability Detection with Fine-Grained Interpretations, ACM J. Meeting Eur. Softw. Eng. Conf. and Symp. Found. Softw. Eng. ACM, pp. 292-303, (2021); Hanif H., Et al., VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection, (2022); Cheng X., Et al., DeepWukong: Statically Detecting Software Vulnerabilities Using Deep Graph Neural Network, ACM Trans. Softw. Eng. and Methodology, 30, 3, pp. 1-33, (2021); Li Y., Et al., Improving Bug Detection via Context-Based Code Representation Learning and Attention-Based Neural Networks, Proceedings of the ACM on Progr. Languages 3.OOPSLA, pp. 1-30, (2019); Lin G., Et al., Cross-Project Transfer Representation Learning for Vulnerable Function Discovery, IEEE Trans. Industrial Informatics, 14, 7, pp. 3289-3297, (2018); Wang H., Et al., Combining Graph-Based Learning With Automated Data Collection for Code Vulnerability Detection, IEEE Trans. Information Forensics and Security, 16, pp. 1943-1958, (2021); Pradel M., Et al., DeepBugs: A Learning Approach to Name-Based Bug Detection, Proceedings of the ACM on Progr. Languages 2.OOPSLA, pp. 1-25, (2018); Chakraborty S., Et al., Deep Learning Based Vulnerability Detection: Are We There Yet, (2020); Liu Z., Et al., Automating Just-in-Time Comment Updating, Int'l Conf. Autom. Softw. Eng. ACM, pp. 585-597, (2020); Panthaplackel S., Et al., Deep Just-In-Time Inconsistency Detection between Comments and Source Code, (2020); Li B., Et al., DeepCommenter: A Deep Code Comment Generation Tool with Hybrid Lexical and Syntactical Information, ACM J. Meeting Eur. Softw. Eng. Conf. and Symp. Found. Softw. Eng. ACM, pp. 1571-1575, (2020); Alon U., Et al., A General Path-Based Representation for Predicting Program Properties, (2018); Mir A.M., Et al., Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python, Int'l Conf. Softw. Eng. ACM, pp. 2241-2252, (2022); Raychev V., Et al., Predicting Program Properties from"" Big Code, Symp. Princ. Prog. Lang, 50, pp. 111-124, (2015); Malik R.S., Et al., NL2Type: Inferring JavaScript Function Types from Natural Language Information, Int'l Conf. Softw. Eng. IEEE, pp. 304-315, (2019); Hellendoorn V.J., Et al., Deep Learning Type Inference, Joint Eur. Softw. Eng. Conf. and Symp. Found. Softw. Eng. ACM, pp. 152-162, (2018); Wei J., Et al., LambdaNet: Probabilistic Type Inference Using Graph Neural Networks, (2020); Allamanis M., Et al., Suggesting Accurate Method and Class Names, Joint Eur. Softw. Eng. Conf. and Symp. Found. Softw. Eng. ACM, pp. 38-49, (2015); Qi W., Et al., ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation, (2021); Feng Z., Et al., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, (2020); Roziere B., Et al., DOBF: A Deobfuscation Pre-Training Objective for Programming Languages, (2021); Wang Y., Et al., CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation, (2021); Ahmad W.U., Et al., Unified Pre-training for Program Understanding and Generation, (2021); Mastropaolo A., Et al., Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks, (2021); Guo D., Et al., GraphCodeBERT: Pre-training Code Representations with Data Flow, (2021); Elnaggar A., Et al., CodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised Deep Learning and High Performance Computing, (2021); Hellendoorn V.J., Et al., Global Relational Models of Source Code, Int'l Conf. Learning Representations, (2022); De Sousa N.T., Et al., JavaBERT: Training a Transformer-Based Model for the Java Programming Language, (2021); Alon U., Et al., Code2vec: Learning Distributed Representations of Code, Princ. Prog. Lang. ACM, pp. 1-29, (2019); Karampatsis R.-M., Et al., Big Code != Big Vocabulary: Open-Vocabulary Models for Source Code, ACM/IEEE 42nd Int'l Conf. Softw. Eng. ACM, pp. 1073-1085, (2020); Ma W., Et al., GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence Analyses, Int'l Conf. Mining Softw. Repositories. ACM, pp. 524-536, (2022); Niu C., Et al., SPT-code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations, Int'l Conf. Softw. Eng. ACM, pp. 2006-2018, (2022); Phan L., Et al., CoTexT: Multi-task Learning with Code-Text Transformer, (2021); Kanade A., Et al., Learning and Evaluating Contextual Embedding of Source Code, Int'l Conf. Machine Learning. PMLR, pp. 5110-5121, (2020); Shrivastava D., Et al., On-the-Fly Adaptation of Source Code Models, NeurIPS 2020 Ws. Comp.-Assisted Prog, (2020); Lu S., Et al., CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation, (2021); Jain P., Et al., Contrastive Code Representation Learning, Conf. Empirical Methods in Natural Lang. Processing. ACL, pp. 5954-5971, (2021); Zugner D., Et al., Language-Agnostic Representation Learning of Source Code from Structure and Context, (2021); Yefet N., Et al., Adversarial Examples for Models of Code, Proceedings of the ACM on Progr. Languages, pp. 1-30, (2020); Compton R., Et al., Embedding Java Classes with Code2vec: Improvements from Variable Obfuscation, Int'l Conf. Mining Softw. Repositories. ACM, pp. 243-253, (2020); Alon U., Et al., Code2seq: Generating Sequences from Structured Representations of Code, (2019); Efstathiou V., Et al., Semantic Source Code Models Using Identifier Embeddings, (2019); Lannelongue L., Et al., Green Algorithms: Quantifying the Carbon Footprint of Computation, Adv. Science, 8, 12, (2021); Lacoste A., Et al., Quantifying the Carbon Emissions of Machine Learning, (2019); Luccioni A.S., Et al., Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model, (2022); Lakim I., Et al., A Holistic Assessment of the Carbon Footprint of Noor, a Very Large Arabic Language Model, BigScience Episode #5-Ws. Challenges & Perspectives in Creating Large Lang. Models. ACL, pp. 84-94, (2022); Posani L., Et al., The Carbon Footprint of Distributed Cloud Storage, (2019); Baliga J., Et al., Green Cloud Computing: Balancing Energy in Processing, Storage, and Transport, Proceedings of the IEEE, 99, 1, pp. 149-167, (2011); Hilty L.M., Et al., The Five Most Neglected Issues in"" Green IT, CEPIS Upgrade, 12, 4, (2011); Feng Z., Et al., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Zhou X., Et al., A Map of Threats to Validity of Systematic Literature Reviews in Software Engineering, Asia-Pacific Softw. Eng. Conf, pp. 153-160, (2016); Martin W., Et al., A Survey of App Store Analysis for Software Engineering, IEEE Trans. Softw. Eng, 43, 9, pp. 817-847, (2017); Kalaitzoglou G., Et al., A Practical Model for Evaluating the Energy Efficiency of Software Applications, Int'l Conf. ICT for Sustainability, (2014); Pineau J., Et al., Improving Reproducibility in Machine Learning Research (a Report from the NeurIPS 2019 Reproducibility Program), J. Machine Learning Research, 22, 1, pp. 1647459-1647478, (2022); Bender E.M., Et al., On the Dangers of Stochastic Parrots: Can Language Models Be Too Big, Conf. Fairness, Accountability, and Transparency. ACM, pp. 610-623, (2021)","","IEEE Computer Society","","17th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2023","26 October 2023 through 27 October 2023","New Orleans","194365","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85174881692"
"Olaleye T.O.; Arogundade O.T.; Misra S.; Abayomi-Alli A.; Kose U.","Olaleye, T.O. (57216846632); Arogundade, O.T. (36805695100); Misra, Sanjay (7401768596); Abayomi-Alli, A. (57218001210); Kose, Utku (36544118500)","57216846632; 36805695100; 7401768596; 57218001210; 36544118500","Predictive Analytics and Software Defect Severity: A Systematic Review and Future Directions","2023","Scientific Programming","2023","","6221388","","","","4","10.1155/2023/6221388","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148108224&doi=10.1155%2f2023%2f6221388&partnerID=40&md5=88c2e0d44c12690f89ccf21e118dc0b8","Software testing identifies defects in software products with varying multiplying effects based on their severity levels and sequel to instant rectifications, hence the rate of a research study in the software engineering domain. In this paper, a systematic literature review (SLR) on machine learning-based software defect severity prediction was conducted in the last decade. The SLR was aimed at detecting germane areas central to efficient predictive analytics, which are seldom captured in existing software defect severity prediction reviews. The germane areas include the analysis of techniques or approaches which have a significant influence on the threats to the validity of proposed models, and the bias-variance tradeoff considerations techniques in data science-based approaches. A population, intervention, and outcome model is adopted for better search terms during the literature selection process, and subsequent quality assurance scrutiny yielded fifty-two primary studies. A subsequent thoroughbred systematic review was conducted on the final selected studies to answer eleven main research questions, which uncovers approaches that speak to the aforementioned germane areas of interest. The results indicate that while the machine learning approach is ubiquitous for predicting software defect severity, germane techniques central to better predictive analytics are infrequent in literature. This study is concluded by summarizing prominent study trends in a mind map to stimulate future research in the software engineering industry.  © 2023 T. O. Olaleye et al.","","Defects; Machine learning; Quality assurance; Software testing; Germanes; Machine-learning; On-machines; Research studies; Software defects; Software engineering domain; Software products; Software testings; Systematic literature review; Systematic Review; Predictive analytics","Khari M., Kumar N., Comparison of six prioritization techniques for software requirements, Journal of Global Research in Computer Science, 4, 1, pp. 38-43, (2013); Arif M., Naseem I., Moinuddin M., Al-Saggaf U.M., Design of an intelligent q-LMS algorithm for tracking a non-stationary channel, Arabian Journal for Science and Engineering, 43, 6, pp. 2793-2803, (2018); Ali S., Khan S.U., Critical success factors for software outsourcing partnership (sop): A systematic literature review, Proceedings of the 2014 IEEE 9th International Conference on Global Software Engineering, pp. 153-162, (2014); Ali S., Baseer S., Abbasi I.A., Alouffi B., Alosaimi W., Huang J., Analyzing the interactions among factors affecting cloud adoption for software testing: A two-stage ISM-ANN approach, Soft Computing, 26, 16, pp. 8047-8075, (2022); Azeem M.I., Palomba F., Shi L., Wang Q., Machine learning techniques for code smell detection: A systematic literature review and meta-analysis, Information and Software Technology, 108, pp. 115-138, (2019); Tarhan G.G.A., On the use of ontologies in software process assessment: A systematic literature review, Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering, (2017); Yaseen M., Ali S., Mustapha A., Mazhar N., Success factors analysis for requirement elicitation in global software development paradigm: An empirical study, Journal of Software: Evolution and Process, 34, 7, (2022); Mustapha A.M., Arogundade O.T., Misra S., Damasevicius R., Maskeliunas R., A systematic literature review on compliance requirements management of business processes, International Journal of System Assurance Engineering and Management, 11, 3, pp. 561-576, (2020); Akmel F., Birihanu E., Siraj B., A literature review study of software defect prediction using machine learning techniques, International Journal of Emerging Research in Management and Technology, 6, 6, pp. 300-9359, (2018); Wahono R.S., Suryana N., Ahmad S., A systematic literature review of software defect prediction: Research trends, datasets, methods and frameworks, Journal of Software, 9, 5, (2014); Ali S., Hongqi L., Khan S.U., Zhongguo Y., Liping Z., Success factors for software outsourcing partnership management: An exploratory study using systematic literature review, IEEE Access, 5, pp. 23589-23612, (2017); Ali S., Ullah N., Abrar M.F., Majeed M.F., Umar M.A., Huang J., Barriers to software outsourcing partnership formation: An exploratory analysis, IEEE Access, 7, pp. 164556-164594, (2019); Ali S., Li H., Khan S.U., Abrar M.F., Zhao Y., Practitioner's view of barriers to software outsourcing partnership formation: An empirical exploration, Journal of Software: Evolution and Process, 32, 5, (2020); Koksal G., Batmaz I., Testik M.C., A review of data mining applications for quality improvement in manufacturing industry, Expert Systems with Applications, 38, 10, pp. 13448-13467, (2011); Olaleye T., Arogundade T., Abayomi-Alli A.A., An ensemble predictive analytics of covid-19 infodemic tweets using bag of words, Data Science Book for COVID-19, (2021); Ali S., Adeel M., Johar S., Zeeshan M., Baseer S., Irshad A., Classification and prediction of software incidents using machine learning techniques, Security and Communication Networks, 2021, (2021); Kamal M., Ali S., Nasir A., Samad A., Basser S., Irshad A., An automated approach for the prediction of the severity level of bug reports using GPT-2, Security and Communication Networks, 2022, (2022); Olaleye T., Ajayi F., Aromolaran A., Solanke I., Akintunde S., Johnbosco A., Semantic relation evaluation of data science articles using network of mention, Proceedings of the 2022 IEEE Nigeria 4th International Conference on Disruptive Technologies for Sustainable Development (NIGERCON), pp. 1-9, (2022); Olaleye T., Abayomi-Alli A., Adesemowo K., Arogundade O.T., Misra S., Kose U., SCLAVOEM: Hyper parameter optimization approach to predictive modelling of COVID-19 infodemic tweets using smote and classifier vote ensemble, Soft Computing, 15, pp. 1-20, (2022); Kitchenham B., Brereton P., A systematic review of systematic review process research in software engineering, Information and Software Technology, 55, 12, pp. 2049-2075, (2013); Son L.H., Pritam N., Khari M., Kumar R., Phuong P.T.M., Thong P.H., Empirical study of software defect prediction: A systematic mapping, Symmetry, 212, (2019); Rawat M.S., Dubey S.K., Software defect prediction models for quality improvement: A literature study, International Journal of Computer Science Issues, 9, 5, (2012); Malhotra R., A systematic review of machine learning techniques for software fault prediction, Applied Soft Computing, 27, pp. 504-518, (2015); Kalaivani N., Beena D.R., Overview of software defect prediction using machine learning algorithms, International Journal of Pure and Applied Mathematics, 118, 20, pp. 3863-3873, (2018); Son L.H., Pritam N., Khari M., Kumar R., Phuong P.T.M., Thong P.H., Empirical study of software defect prediction: A systematic mapping, Symmetry, 11, 2, (2019); Hall T., Beecham S., Bowes D., Gray D., Counsell S., A systematic literature review on fault prediction performance in software engineering, IEEE Transactions on Software Engineering, 38, 6, pp. 1276-1304, (2012); Kitchenham, Guidelines for Performing Systematic Literature Reviews, (2007); Wohlin C., Guidelines for snowballing in systematic literature studies and a replication in software engineering, Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering, (2014); Kitchenham S.C.B., Guidelines for performing systematic literature reviews in software engineering, School of Computer Science and Mathematics, (2007); Malhotra R., Severity prediction of software vulnerabilities using textual data, International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications, (2021); Mehta S., Patnaik K.S., Improved prediction of software defects using ensemble machine learning techniques, Neural Computing & Applications, 33, 16, pp. 10551-10562, (2021); Prabha C., Shivakumar D.N., Software defect prediction using machine learning techniques, Proceedings of the 4th International Conference on Trends in Electronics and Informatics, (2020); Kaur A., Jindal S.G., Text analytics based severity prediction of software bugs for Apache projects, Int J Syst Assur Eng Manag, 10, 4, pp. 765-782, (2019); Tan Y., Xu S., Wang Z., Zhang T., Xu Z., Luo X., Bug severity prediction using question-and-answer pairs from Stack Overflow, Journal of Systems and Software, 165, (2020); Ihsan Aquil M.A., Ishak W.H.W., Predicting software defects using machine learning techniques, International Journal of Advanced Trends in Computer Science and Engineering, 9, 4, pp. 6609-6616, (2020); Gai J., Zheng S., Yu H., Yang H., Software defect prediction based on weighted extreme learning machine, Multiagent and Grid Systems, 16, 1, pp. 67-82, (2020); Alsawalqah H., Hijazi N., Eshtay M., Faris H., Radaideh A.A., Aljarah I., Alshamaileh Y., Software defect prediction using heterogeneous ensemble classification based on segmented patterns, Applied Sciences, 10, 5, (2020); Balogun A.O., Basri S., Abdulkadir S.J., Hashim A.S., Performance analysis of feature selection methods in software defect prediction: A search method approach, Applied Sciences, 9, 13, (2019); Shaikh S., Changan L., Malik M.R., Khan M.A., Software defect-prone classification using machine learning: A virtual classification study between LibSVM & LibLinear, Proceedings of the 13th International Conference on Mathematics, Actuarial Science, (2019); Gupta H., Kumar L., Neti L.B.M., An empirical framework for code smell prediction using extreme learning machine, Proceedings of the 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON), (2019); Kukkar A., Mohana R., Nayyar A., Kim J., Kang B.-G., A novel deep-learning-based bug severity classification technique using convolutional neural networks and random forest with boosting, Sensors, 19, 13, (2019); Baarah A., Aloqaily A., Salah Z., Zamzeer M., Sallam M., Machine learning approaches for predicting the severity level of software bug reports in closed source projects, International Journal of Advanced Computer Science and Applications, 10, 8, (2019); Wang F., Ai J., Zou Z., Reliability and security, Proceedings of the IEEE 19th International Conference on Software Quality, (2019); Ha D.A., Chen T.-H., Yuan S.-M., Unsupervised methods for software defect prediction, Proceedings of the 10th International Symposium on Information and Communication Technology, (2019); Kukkara A., Mohana R., A supervised bug report classification with incorporate and textual field knowledge, Proceedings of the International Conference on Computational Intelligence and Data Science, (2018); Qiu S., Lu L., Jiang S., Guo Y., An investigation of imbalanced ensemble learning methods for crossproject defect prediction, International Journal of Pattern Recognition and Artificial Intelligence, 33, 12, (2019); Wu F., Jing X.-Y., Sun Y., Sun J., Huang L., Cui F., Sun Y., Cross-project and within-project semisupervised software defect prediction: A unified approach, IEEE Transactions on Reliability, 67, 2, pp. 581-597, (2018); El-Shorbagy S.A., El-Gammal W.M., Abdelmoez W.M., Using smote and heterogeneous stacking in ensemble learning for software defect prediction, Proceedings of the 7th International Conference on Software and Information Engineering, (2018); Huda S., Abdelrazek K.L.M., Abdelrazek M., Ibrahim A., Sultan H.A.-D., Ahmad S., An Ensemble Oversampling Model for Class An Oversampling Ensemble Model for Class, IEEE Access, 6, pp. 24184-24195, (2018); Han Z., Li X., Xing Z., Liu H., Feng Z., Learning to predict severity of software vulnerability using only vulnerability description, Proceedings of the IEEE International Conference on Software Maintenance and Evolution, (2017); Arar O.F., Ayan K., A feature dependent naive bayes approach and its application to the software defect prediction problem, Applied Soft Computing, 59, pp. 197-209, (2017); Fontana F.A., Zanoni M., Code smell severity classification using machine learning techniques, Knowledge-Based Systems, 128, pp. 43-58, (2017); Singh V.B., Misra S., Sharma M., Bug severity assessment in cross project context and identifying training candidates, Journal of Information and Knowledge Management, 16, 1, (2017); Alsawalqah H., Faris H., Aljarah I., Alnemer L., Alhindawi N., Hybrid SMOTE-ensemble approach for software defect prediction advances in intelligent systems and computing, Software Engineering Trends and Techniques in Intelligent Systems, 575, (2017); Fu W., Menzies T., Revisiting unsupervised learning for defect prediction, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, (2017); Petrie J., Bowes D., Hall T., Christianson B., Baddoo N., Building an ensemble for software defect prediction based on diversity selection, Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, (2016); Choeikiwong T., Vateekul P., Improve accuracy of defect severity categorization using semi-supervised approach on imbalanced data sets, Proceedings of the International MultiConference of Engineers and Computer Scientists, (2016); Malhotra R., An empirical framework for defect prediction using machine learning techniques with Android software, Applied Soft Computing, 49, pp. 1034-1050, (2016); Kaur P., Singh C., A systematic approach for bug severity classification using machine learning's text mining techniques, International Journal of Computer Science and Mobile Computing, 5, 7, pp. 523-528, (2016); Jindal R., Malhotra R., Jain A., Prediction of defect severity by mining software project reports, International Journal of Systems Assurance Engineering and Management, 8, 2, (2016); Petrie J., Bowes D., Hall T., Christianson B., Baddoo N., Building an ensemble for software defect prediction, Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, (2016); Sharma G., Sharma S., Gujral S., A novel way of assessing software bug severity using dictionary of critical terms, Proceedings of the 4th International Conference on Eco-Friendly Computing and Communication Systems, ICECCS, (2015); Jing X.Y., Ying S., Zhang Z.-W., Wu S.-S., Liu j., Dictionary learning based software defect prediction, Proceedings of the 36th International Conference on Software Engineering, (2014); Wang H., Software Defects Classification Prediction Based on Mining Software Repository, (2014); Jindal R., Malhotra R., Jain A., Software defect prediction using neural networks, Proceedings of the 3rd International Conference on Reliability, Infocom Technologies and Optimization, (2014); Duksan Ryu O.C., Improving prediction robustness of VAB-SVM for cross-project defect prediction, Proceedings of the IEEE 17th International Conference on Computational Science and Engineering, (2014); Seiffert C., Khoshgoftaar T.M., Van Hulse J., Folleco A., An empirical study of the classification performance of learners on imbalanced and noisy software quality data, Information Sciences, 259, pp. 571-595, (2014); Ren J., Qin K., Ma Y., Luo G., On software defect prediction using machine learning, Journal of Applied Mathematics, 2014, (2014); Malhotra R., Comparative analysis of statistical and machine learning methods, Applied Soft Computing Predicting Faulty Modules, 21, pp. 286-297, (2014); Sudha A., Software defect prediction system using, International Journal of Recent Technology and Engineering, 3, 2, pp. 2277-3878, (2014); Khoshgoftaar T.M., Gao K., Napolitano A., Wald R., A comparative study of iterative and non-iterative feature selection techniques for software defect prediction, Information System Frontiers, 16, 5, (2013); Naidu M.S., Geethanjali D., Classification of defects in software using decision tree algorithm, International Journal of Engineering Science and Technology, 5, 6, pp. 1332-1340, (2013); Chug A., Dhall S., Software Defect Prediction Using Supervised Learning Algorithm and Unsupervised Learning Algorithm, (2013); Chaturvedi K.K., Singh V.B., Determining bug severity using machine learning techniques, Proceedings of the 2012 CSI 6th International Conference on Software Engineering (CONSEG), (2019); Verma R., Gupta A., Software defect prediction using two level data pre-processing, Proceedings of the International Conference on Recent Advances in Computing and Software Systems, (2012); Bowes D., Hall T., Petric J., Software defect prediction: Do different classifiers find the same defects?, Software Quality Journal, 26, 5, (2012); Sun Z., Song Q., Zhu X., Using coding-based ensemble learning to improve software defect prediction, IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 42, 6, pp. 1806-1817, (2012); Yang C.Z., Kao C., Chen I.-X., An empirical study on improving severity prediction of defect reports using feature selection, Proceedings of the Asia-Pacific Software Engineering Conference, (2012); Peng Y., Kou G., Wang G., Wu W., Shi Y., Ensemble of software defect predictors: An ahp-based evaluation method, International Journal of Information Technology and Decision Making, 10, 1, pp. 187-206, (2011); Alshammari F.H., Software defect prediction and analysis using enhanced random forest (extrf) technique: A business process management and improvement concept in iot-based application processing environment, Mobile Information Systems, 2022, (2022)","","Hindawi Limited","","","","","","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85148108224"
"Tang L.; Bao L.; Xia X.; Huang Z.","Tang, Lingxiao (58751352300); Bao, Lingfeng (56609745200); Xia, Xin (54586248800); Huang, Zhongdong (58751352400)","58751352300; 56609745200; 54586248800; 58751352400","Neural SZZ Algorithm","2023","Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023","","","","1024","1035","11","1","10.1109/ASE56229.2023.00037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179002966&doi=10.1109%2fASE56229.2023.00037&partnerID=40&md5=030f0b1f4d36876b885904ddbf223d0c","The SZZ algorithm has been widely used for identifying bug-inducing commits. However, it suffers from low precision, as not all deletion lines in the bug-fixing commit are related to the bug fix. Previous studies have attempted to address this issue by using static methods to filter out noise, e.g., comments and refactoring operations in the bug-fixing commit. However, these methods have two limitations. First, it is challenging to include all refactoring and non-essential change patterns in a tool, leading to the potential exclusion of relevant lines and the inclusion of irrelevant lines. Second, applying these tools might not always improve performance. In this paper, to address the aforementioned challenges, we propose NEURALSZZ, a deep learning approach for detecting the root cause deletion lines in a bug-fixing commit and using them as input for the SZZ algorithm. NEURALSZZ first constructs a heterogeneous graph attention network model that captures the semantic relationships between each deletion line and the other deletion and addition lines. To pinpoint the root cause of a bug, Neuralszz uses a learning-to-rank technique to rank all deletion lines in the commit. To evaluate the effectiveness of NEURALSZZ, we utilize three datasets containing high-quality bug-fixing and bug-inducing commits. The experiment results show that NEURALSZZ outperforms various baseline methods, e.g., traditional machine learning-based approaches and BI-LSTM in identifying the root cause of bugs. Moreover, by utilizing the top-ranked deletion lines and applying the SZZ algorithm, Neuralszz demonstrates better precision and F1-score compared to previous SZZ algorithms.  © 2023 IEEE.","Deep Learning; Heterogeneous Graph Attention Network; Learning to Rank; SZZ Algorithm","Learning algorithms; Long short-term memory; Bug fixes; Bug-fixing; Deep learning; Deletion lines; Heterogeneous graph; Heterogeneous graph attention network; Lower precision; Refactorings; Root cause; SZZ algorithm; Semantics","Kamei Y., Shihab E., Adams B., Hassan A.E., Mockus A., Sinha A., Ubayashi N., A large-scale empirical study of just-in-time quality assurance, IEEE Transactions on Software Engineering, 39, 6, pp. 757-773, (2012); Kim S., Whitehead E.J., Zhang Y., Classifying software changes: Clean or buggy, IEEE Transactions on software engineering, 34, 2, pp. 181-196, (2008); Asaduzzaman M., Bullock M.C., Roy C.K., Schneider K.A., Bug introducing changes: A case study with android, 2012 9th IEEE Working Conference on Mining Software Repositories (MSR). IEEE, pp. 116-119, (2012); Bernardi M.L., Canfora G., Di Lucca G.A., Di Penta M., Distante D., Do developers introduce bugs when they do not communicate. The case of eclipse and mozilla, 2012 16th European Conference on Software Maintenance and Reengineering. IEEE, pp. 139-148, (2012); Canfora G., Ceccarelli M., Cerulo L., Di Penta M., How long does a bug survive. An empirical study, 2011 18th Working Conference on Reverse Engineering. IEEE, pp. 191-200, (2011); Ell J., Identifying failure inducing developer pairs within developer networks, 2013 35th International Conference on Software Engineering (ICSE). IEEE, pp. 1471-1473, (2013); Jiang T., Tan L., Kim S., Personalized defect prediction, 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). Ieee, pp. 279-289, (2013); McIntosh S., Kamei Y., Are fix-inducing changes a moving target. A longitudinal case study of just-in-time defect prediction, Proceedings of the 40th International Conference on Software Engineering, pp. 560-560, (2018); Fan Y., Xia X., Da Costa D.A., Lo D., Hassan A.E., Li S., The impact of mislabeled changes by szz on just-in-time defect prediction, IEEE transactions on software engineering, 47, 8, pp. 1559-1586, (2019); Bao L., Xia X., Hassan A.E., Yang X., V-szz: Automatic identification of version ranges affected by cve vulnerabilities, Proceedings of the 44th International Conference on Software Engineering, pp. 2352-2364, (2022); Sliwerski J., Zimmermann T., Zeller A., When do changes induce fixes, ACM sigsoft software engineering notes, 30, 4, pp. 1-5, (2005); Kim S., Zimmermann T., Pan K., James E., Et al., Automatic identification of bug-introducing changes, 21st IEEE/ACM international conference on automated software engineering (ASE'06). IEEE, pp. 81-90, (2006); Da Costa D.A., McIntosh S., Shang W., Kulesza U., Coelho R., Hassan A.E., A framework for evaluating the results of the szz approach for identifying bug-introducing changes, IEEE Transactions on Software Engineering, 43, 7, pp. 641-657, (2016); Neto E.C., Da Costa D.A., Kulesza U., The impact of refactoring changes on the szz algorithm: An empirical study, 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, pp. 380-390, (2018); Silva D., Valente M.T., Refdiff: detecting refactorings in version histories, 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). IEEE, pp. 269-279, (2017); Neto E.C., Da Costa D.A., Kulesza U., Revisiting and improving szz implementations, 2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM). IEEE, pp. 1-12, (2019); Tsantalis N., Mansouri M., Eshkevari L.M., Mazinanian D., Dig D., Accurate and efficient refactoring detection in commit history, Proceedings of the 40th international conference on software engineering, pp. 483-494, (2018); Fowler M., Refactoring: Improving the design of existing code, 11th European Conference., (1997); Rosa G., Pascarella L., Scalabrino S., Tufano R., Bavota G., Lanza M., Oliveto R., Evaluating szz implementations through a developerinformed oracle, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, pp. 436-447, (2021); Wang X., Ji H., Shi C., Wang B., Ye Y., Cui P., Yu P.S., Heterogeneous graph attention network, The world wide web conference, pp. 2022-2032, (2019); Wen M., Wu R., Liu Y., Tian Y., Xie X., Cheung S.-C., Su Z., Exploring and exploiting the correlations between bug-inducing and bug-fixing commits, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 326-337, (2019); Song X., Lin Y., Ng S.H., Wu Y., Peng X., Dong J.S., Mei H., Regminer: Towards constructing a large regression dataset from code evolution history, Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 314-326, (2022); Replication package; The commit of the motivation example; Tools for your Java code; Allen F.E., Control flow analysis, ACM Sigplan Notices, 5, 7, pp. 1-19, (1970); Ferrante J., Ottenstein K.J., Warren J.D., The program dependence graph and its use in optimization, ACM Transactions on Programming Languages and Systems (TOPLAS), 9, 3, pp. 319-349, (1987); Ryder B.G., Constructing the call graph of a program, IEEE Transactions on Software Engineering, 3, pp. 216-226, (1979); Yamaguchi F., Golde N., Arp D., Rieck K., Modeling and discovering vulnerabilities with code property graphs, 2014 IEEE Symposium on Security and Privacy. IEEE, pp. 590-604, (2014); Falleri J., Morandat F., Blanc X., Martinez M., Monperrus M., Fine-grained and accurate source code differencing, ACM/IEEE International Conference on Automated Software Engineering, ASE '14, pp. 313-324, (2014); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Advances in neural information processing systems, 29, (2016); Hamilton W., Ying Z., Leskovec J., Inductive representation learning on large graphs, Advances in neural information processing systems, 30, (2017); Kipf T.N., Welling M., Semi-supervised classification with graph convolutional networks, (2016); Sun Y., Han J., Mining heterogeneous information networks: A structural analysis approach, Acm Sigkdd Explorations Newsletter, 14, 2, pp. 20-28, (2013); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Burges C.J., From ranknet to lambdarank to lambdamart: An overview, Learning, 11, 23, (2010); Chapelle O., Chang Y., Yahoo! learning to rank challenge overview, Proceedings of the learning to rank challenge. PMLR, pp. 1-24, (2011); Song Y., Wang H., He X., Adapting deep ranknet for personalized search, Proceedings of the 7th ACM international conference on Web search and data mining, pp. 83-92, (2014); Karmaker Santu S.K., Sondhi P., Zhai C., On application of learning to rank for e-commerce search, Proceedings of the 40th international ACM SIGIR conference on research and development in information retrieval, pp. 475-484, (2017); Just R., Jalali D., Ernst M.D., Defects4j: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 international symposium on software testing and analysis, pp. 437-440, (2014); Pan S., Bao L., Xia X., Lo D., Li S., Fine-grained commit-level vulnerability type prediction by cwe tree structure; Tan X., Zhang Y., Mi C., Cao J., Sun K., Lin Y., Yang M., Locating the security patches for disclosed oss vulnerabilities with vulnerability-commit correlation ranking, Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pp. 3282-3299, (2021); Fushiki T., Estimation of prediction error by using k-fold crossvalidation, Statistics and Computing, 21, pp. 137-146, (2011); Zhou J., Pacheco M., Wan Z., Xia X., Lo D., Wang Y., Hassan A.E., Finding a needle in a haystack: Automated mining of silent vulnerability fixes, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 705-716, (2021); Le T.H.M., Hin D., Croft R., Babar M.A., Deepcva: Automated commit-level vulnerability assessment with deep multi-task learning, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, pp. 717-729, (2021); Wu X., Zheng W., Xia X., Lo D., Data quality matters: A case study on data label correctness for security bug report prediction, IEEE Transactions on Software Engineering, 48, 7, pp. 2541-2556, (2021); Graves A., Mohamed A.-R., Hinton G., Speech recognition with deep recurrent neural networks, 2013 IEEE international conference on acoustics, speech and signal processing. Ieee, pp. 6645-6649, (2013); Pennington J., Socher R., Manning C.D., Glove: Global vectors for word representation, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp. 1532-1543, (2014); Parnin C., Orso A., Are automated debugging techniques actually helping programmers, Proceedings of the 2011 international symposium on software testing and analysis, pp. 199-209, (2011); Woolson R.F., Wilcoxon signed-rank test, Wiley encyclopedia of clinical trials, pp. 1-3, (2007); Lau J.H., Baldwin T., An empirical evaluation of doc2vec with practical insights into document embedding generation, (2016); Haque M.U., Dharmadasa I., Sworna Z.T., Rajapakse R.N., Ahmad H., i think this is the most disruptive technology"": Exploring sentiments of chatgpt early adopters using twitter data, (2022); Surameery N.M.S., Shakor M.Y., Use chat gpt to solve programming bugs, International Journal of Information Technology & Computer Engineering (IJITC), 3, 1, pp. 17-22, (2023); Jalil S., Rafi S., LaToza T.D., Moran K., Lam W., Chatgpt and software testing education: Promises & perils, (2023); Hindle A., German D.M., Holt R., What do large commits tell us. A taxonomical study of large commits, Proceedings of the 2008 international working conference on Mining software repositories, pp. 99-108, (2008); Rodriguez-Perez G., Robles G., Serebrenik A., Zaidman A., German D.M., Gonzalez-Barahona J.M., How bugs are born: A model to identify how bugs are introduced in software components, Empirical Software Engineering, 25, pp. 1294-1340, (2020); Bavota G., Russo B., Four eyes are better than two: On the impact of code reviews on software quality, 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, pp. 81-90, (2015); Palomba F., Bavota G., Di Penta M., Fasano F., Oliveto R., De Lucia A., On the diffuseness and the impact on maintainability of code smells: A large scale empirical investigation, Proceedings of the 40th International Conference on Software Engineering, pp. 482-482, (2018); Bernardi M.L., Canfora G., Di Lucca G.A., Di Penta M., Distante D., The relation between developers' communication and fixinducing changes: An empirical study, Journal of Systems and Software, 140, pp. 111-125, (2018); Caglayan B., Bener A.B., Effect of developer collaboration activity on software quality in two large scale projects, Journal of Systems and Software, 118, pp. 288-296, (2016); Wehaibi S., Shihab E., Guerrouj L., Examining the impact of selfadmitted technical debt on software quality, 2016 IEEE 23Rd international conference on software analysis, evolution, and reengineering (SANER), 1, pp. 179-188, (2016); Keshavarz H., Nagappan M., Apachejit: A large dataset for justin-time defect prediction, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 191-195, (2022); Kawrykow D., Robillard M.P., Non-essential changes in version histories, Proceedings of the 33rd International Conference on Software Engineering, pp. 351-360, (2011); Sejfia A., Zhao Y., Medvidovic N., Identifying casualty changes in software patches, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 304-315, (2021); Balagtas-Fernandez F., Hussmann H., A methodology and framework to simplify usability analysis of mobile applications, 2009 IEEE/ACM international conference on automated software engineering. IEEE, pp. 520-524, (2009); Herzig K., Zeller A., The impact of tangled code changes, 2013 10th Working Conference on Mining Software Repositories (MSR). IEEE, pp. 121-130, (2013); Barnett M., Bird C., Brunet J., Lahiri S.K., Helping developers help themselves: Automatic decomposition of code review changesets, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 134-144, (2015); Guo B., Song M., Interactively decomposing composite changes to support code review and regression testing, 2017 IEEE 41st annual computer software and applications conference (COMPSAC), 1, pp. 118-127, (2017)","","Institute of Electrical and Electronics Engineers Inc.","","38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023","11 September 2023 through 15 September 2023","Echternach","194295","Conference paper","Final","","Scopus","2-s2.0-85179002966"
"Sandoval G.; Pearce H.; Nys T.; Karri R.; Garg S.; Dolan-Gavitt B.","Sandoval, Gustavo (57856192300); Pearce, Hammond (57190837137); Nys, Teo (57854949000); Karri, Ramesh (7006419874); Garg, Siddharth (20435727500); Dolan-Gavitt, Brendan (17134620000)","57856192300; 57190837137; 57854949000; 7006419874; 20435727500; 17134620000","Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants","2023","32nd USENIX Security Symposium, USENIX Security 2023","3","","","2205","2222","17","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164468296&partnerID=40&md5=26aa03d1dbcebb145c8fbbcdb431c6b9","Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers’ code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N=58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked ‘shopping list’ structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks. © USENIX Security 2023. All rights reserved.","","C (programming language); Cybersecurity; Cyber security; Language model; List structures; Real world projects; Relative frequencies; Security bugs; Security implications; Security risks; Shopping lists; User study; Computational linguistics","Brown T. B., Mann B., Ryder N., Subbiah M., Kaplan J., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Agarwal S., Herbert-Voss A., Krueger G., Henighan T., Child R., Ramesh A., Ziegler D. M., Wu J., Winter C., Hesse C., Chen M., Sigler E., Litwin M., Gray S., Chess B., Clark J., Berner C., McCandlish S., Radford A., Sutskever I., Amodei D., Language Models are Few-Shot Learners, (2020); Radford A., Wu J., Child R., Luan D., Amodei D., Sutskever I., Language Models are Unsupervised Multitask Learners, (2019); Chen M., Tworek J., Jun H., Yuan Q., Pinto H. P. d. O., Kaplan J., Edwards H., Burda Y., Joseph N., Brockman G., Ray A., Puri R., Krueger G., Petrov M., Khlaaf H., Sastry G., Mishkin P., Chan B., Gray S., Ryder N., Pavlov M., Power A., Kaiser L., Bavarian M., Winter C., Tillet P., Such F. P., Cummings D., Plappert M., Chantzis F., Barnes E., Herbert-Voss A., Guss W. H., Nichol A., Paino A., Tezak N., Tang J., Babuschkin I., Balaji S., Jain S., Saunders W., Hesse C., Carr A. N., Leike J., Achiam J., Misra V., Morikawa E., Radford A., Knight M., Brundage M., Murati M., Mayer K., Welinder P., McGrew B., Amodei D., McCandlish S., Sutskever I., Zaremba W., Evaluating Large Language Models Trained on Code, (2021); Discover Use Cases for AI21 Studio and Jurassic-1; Examples - OpenAI API; Torres R., GitHub Copilot adds 400K subscribers in first month, (2022); Siddiq M. L., Majumder S. H., Mim M. R., Jajodia S., Santos J. C. S., An Empirical Study of Code Smells in Transformer-based Code Generation Techniques, (2022); Pearce H., Ahmad B., Tan B., Dolan-Gavitt B., Karri R., Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions, 2022 IEEE Symposium on Security and Privacy (SP), pp. 754-768, (2022); Thomas G., A proactive approach to more secure code – Microsoft Security Response Center, (2019); 2022 CWE Top 25 Most Dangerous Software Weaknesses, (2022); CWE - Common Weakness Enumeration, (2022); Sandoval G., Pearce H., Nys T., Karri R., Garg S., Dolan-Gavitt B., Lost at C: Data from the Security-focused User Study, (2022); Lieber O., Sharir O., Lentz B., Shoham Y., Jurassic-1: Technical Details and Evaluation, (2021); Jurassic-1 Language Models - AI21 Studio Docs, (2021); Nijkamp E., Pang B., Hayashi H., Tu L., Wang H., Zhou Y., Savarese S., Xiong C., A Conversational Paradigm for Program Synthesis, (2022); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., CodeBERT: A Pre-Trained Model for Programming and Natural Languages, (2020); Finnie-Ansley J., Denny P., Becker B. A., Luxton-Reilly A., Prather J., The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming, Australasian Computing Education Conference, pp. 10-19, (2022); Sarsa S., Denny P., Hellas A., Leinonen J., Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models, Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1, ser. ICER’22, pp. 27-43, (2022); Dakhel A. M., Majdinasab V., Nikanjam A., Khomh F., Desmarais M. C., Ming Z., Jiang, GitHub Copilot AI pair programmer: Asset or Liability?, (2022); Vaithilingam P., Zhang T., Glassman E. L., Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models, CHI Conference on Human Factors in Computing Systems Extended Abstracts, pp. 1-7, (2022); Imai S., Is GitHub Copilot a Substitute for Human Pair-programming? An Empirical Study, 2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSECompanion), pp. 319-321, (2022); Ziegler A., Kalliamvakou E., Li X. A., Rice A., Rifkin D., Simister S., Sittampalam G., Aftandilian E., Productivity assessment of neural code completion, Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, ser. MAPS 2022, pp. 21-29, (2022); Tabachnyk M., Nikolov S., ML-Enhanced Code Completion Improves Developer Productivity, (2022); Gage P., A New Algorithm for Data Compression, C Users Journal, 12, 2, pp. 23-38, (1994); CodeQL for research, (2021); Welcome to Bandit — Bandit documentation, (2022); Pearce H., Tan B., Ahmad B., Karri R., Dolan-Gavitt B., Examining Zero-Shot Vulnerability Repair with Large Language Models, 2023 IEEE Symposium on Security and Privacy (SP), pp. 1-18, (2023); Ernst N. A., Bavota G., AI-Driven Development Is Here: Should You Worry?, IEEE Software, 39, 2, pp. 106-110, (2022); Ciniselli M., Pascarella L., Bavota G., To What Extent do Deep Learning-based Code Recommenders Generate Predictions by Cloning Code from the Training Set?, (2022); Topham C., Publication of the FSF-funded white papers on questions around Copilot, (2022); Biderman S., Raff E., Neural Language Models are Effective Plagiarists, (2022); Aiken A., A System for Detecting Software Similarity, (2021); Wahle J. P., Ruas T., Meuschke N., Gipp B., Are Neural Language Models Good Plagiarists? A Benchmark for Neural Paraphrase Detection, 2021 ACM/IEEE Joint Conference on Digital Libraries (JCDL), pp. 226-229, (2021); Pistoia M., Chandra S., Fink S. J., Yahav E., A survey of static analysis methods for identifying security vulnerabilities in software systems, IBM Systems Journal, 46, 2, pp. 265-288, (2007); Source Code Analysis Tools; Serebryany K., Bruening D., Potapenko A., Vyukov D., AddressSanitizer: A Fast Address Sanity Checker, 2012 USENIX Annual Technical Conference (USENIX ATC 12), pp. 309-318, (2012); Polacek M., GCC Undefined Behavior Sanitizer - ubsan, (2014); Zalewski M., American fuzzy lop, (2020); Aizatsky M., Serebryany K., Chang O., Arya A., Whittaker M., Announcing OSS-Fuzz: Continuous fuzzing for open source software, (2016); Black P. E., Guttman B., Okun V., Guidelines on Minimum Standards for Developer Verification of Software, (2021); Manes V. J., Han H., Han C., Cha S. K., Egele M., Schwartz E. J., Woo M., The Art, Science, and Engineering of Fuzzing: A Survey, IEEE Transactions on Software Engineering, 47, 11, pp. 2312-2331, (2021); Tuma K., Sion L., Scandariato R., Yskout K., Automating the early detection of security design flaws, Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, ser. MODELS’20, pp. 332-342, (2020); di Biase M., Bruntink M., Bacchelli A., A Security Perspective on Code Review: The Case of Chromium, 2016 IEEE 16th International Working Conference on Source Code Analysis and Manipulation (SCAM), pp. 21-30, (2016); Tahaei M., Vaniea K., Recruiting Participants With Programming Skills: A Comparison of Four Crowdsourcing Platforms and a CS Student Mailing List, Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, ser. CHI ’22, pp. 1-15, (2022); Ko A. J., LaToza T. D., Burnett M. M., A practical guide to controlled experiments of software engineering tools with human participants, Empirical Software Engineering, 20, 1, pp. 110-141, (2015); Salman I., Misirli A. T., Juristo N., Are Students Representatives of Professionals in Software Engineering Experiments?, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, 1, pp. 666-676, (2015); Doderlein J.-B., Acher M., Khelladi D. E., Combemale B., Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?, (2022); Bavarian M., Jun H., Tezak N., Schulman J., McLeavey C., Tworek J., Chen M., Efficient Training of Language Models to Fill in the Middle, (2022); Walker E., Nowacki A. S., Understanding Equivalence and Noninferiority Testing, Journal of General Internal Medicine, 26, 2, pp. 192-196, (2011); Hung H. M. J., Wang S.-J., O'Neill R., A Regulatory Perspective on Choice of Margin and Statistical Inference Issue in Non-inferiority Trials, Biometrical Journal, 47, 1, pp. 28-36, (2005); Acar Y., Stransky C., Wermke D., Mazurek M. L., Fahl S., Security Developer Studies with GitHub Users: Exploring a Convenience Sample, pp. 81-95, (2017); Assaraf A., This is what your developers are doing 75% of the time, and this is the cost you pay, (2015); Fangohr H., A Comparison of C, MATLAB, and Python as Teaching Languages in Engineering, Computational Science - ICCS 2004, ser. Lecture Notes in Computer Science, pp. 1210-1217, (2004)","","USENIX Association","et al.; Futurewei Technologies; Google; Meta; NSF; TikTok","32nd USENIX Security Symposium, USENIX Security 2023","9 August 2023 through 11 August 2023","Anaheim","193590","Conference paper","Final","","Scopus","2-s2.0-85164468296"
"Arakelyan S.; Mao Y.; Das R.J.; Ren X.","Arakelyan, Shushan (57203384900); Mao, Yi (57210641199); Das, Rocktim Jyoti (58153876600); Ren, Xiang (55559545700)","57203384900; 57210641199; 58153876600; 55559545700","Exploring Distributional Shifts in Large Language Models for Code Analysis","2023","EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings","","","","16298","16314","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184815816&partnerID=40&md5=d2b56de68b4fac4c5a4350688ec1af84","We systematically study how three large language models with code capabilities - CodeT5, Codex, and ChatGPT - generalize to out-of-domain data. We consider two fundamental applications - code summarization, and code generation. We split data into domains following its natural boundaries - by an organization, by a project, and by a module within the software project. We establish that samples from each new domain present all the models with a significant challenge of distribution shift. We study how established methods adapt models to better generalize to new domains. Our experiments show that while multitask learning alone is a reasonable baseline, combining it with few-shot finetuning on examples retrieved from training data can achieve very strong performance. Moreover, this solution can outperform direct finetuning for very low-data scenarios. Finally, we consider variations of this approach to create a more broadly applicable method to adapt to multiple domains at once. We find that for code generation, a model adapted to multiple domains simultaneously performs on par with those adapted to a single domain. ©2023 Association for Computational Linguistics.","","Codes (symbols); Learning systems; Application codes; Code analysis; Code capability; Codegeneration; Language model; Multiple domains; Multitask learning; Natural boundary; Software project; Training data; Computational linguistics","Angioni Daniele, Demetrio Luca, Pintor Maura, Biggio Battista, Robust machine learning for malware detection over time, Proceedings of the Italian Conference on Cybersecurity (ITASEC 2022), 3260, pp. 169-180, (2022); Antoniou Antreas, Edwards Harrison, Storkey Amos J., How to train your maml, (2018); Bapna Ankur, Arivazhagan N., Firat Orhan, Simple, scalable adaptation for neural machine translation, Conference on Empirical Methods in Natural Language Processing, (2019); Brown Tom B., Mann Benjamin, Ryder Nick, Subbiah Melanie, Kaplan Jared, Dhariwal Prafulla, Neelakantan Arvind, Shyam Pranav, Sastry Girish, Askell Amanda, Agarwal Sandhini, Herbert-Voss Ariel, Krueger Gretchen, Henighan T. J., Child Rewon, Ramesh Aditya, Ziegler Daniel M., Wu Jeff, Winter Clemens, Hesse Christopher, Chen Mark, Sigler Eric, Litwin Mateusz, Gray Scott, Chess Benjamin, Clark Jack, Berner Christopher, McCandlish Sam, Radford Alec, Sutskever Ilya, Amodei Dario, Language models are few-shot learners, (2020); Caruana Rich, Algorithms and applications for multitask learning, Machine Learning, Proceedings of the Thirteenth International Conference (ICML'96), pp. 87-95, (1996); Caruana Rich, Multitask learning, Machine Learning, 28, pp. 41-75, (1997); Chen Mark, Tworek Jerry, Jun Heewoo, Yuan Qiming, Ponde Henrique, Kaplan Jared, Edwards Harrison, Burda Yura, Joseph Nicholas, Brockman Greg, Ray Alex, Puri Raul, Krueger Gretchen, Petrov Michael, Khlaaf Heidy, Sastry Girish, Mishkin Pamela, Chan Brooke, Gray Scott, Ryder Nick, Pavlov Mikhail, Power Alethea, Kaiser Lukasz, Bavarian Mohammad, Winter Clemens, Tillet Philippe, Such Felipe Petroski, Cummings David W., Plappert Matthias, Chantzis Fotios, Barnes Elizabeth, Herbert-Voss Ariel, Guss William H., Nichol Alex, Babuschkin Igor, Arun Balaji S., Jain Shantanu, Carr Andrew, Leike Jan, Achiam Joshua, Misra Vedant, Morikawa Evan, Radford Alec, Knight Matthew M., Brundage Miles, Murati Mira, Mayer Katie, Welinder Peter, McGrew Bob, Amodei Dario, McCandlish Sam, Sutskever Ilya, Zaremba Wojciech, Evaluating large language models trained on code, (2021); Christiano Paul Francis, Leike Jan, Brown Tom B., Martic Miljan, Legg Shane, Amodei Dario, Deep reinforcement learning from human preferences, (2017); Das Rajarshi, Zaheer Manzil, Thai Dung Ngoc, Godbole Ameya, Perez Ethan, Lee Jay Yoon, Tan Lizhen, Polymenakos Lazaros, McCallum Andrew, Case-based reasoning for natural language queries over knowledge bases, Conference on Empirical Methods in Natural Language Processing, (2021); Evtikhiev Mikhail, Bogomolov Egor, Sokolov Yaroslav, Bryksin Timofey, Out of the BLEU: how should we assess quality of the code generation models?, (2022); Finn Chelsea, Abbeel P., Levine Sergey, Model-agnostic meta-learning for fast adaptation of deep networks, International Conference on Machine Learning, (2017); Finn Chelsea, Xu Kelvin, Levine Sergey, Probabilistic model-agnostic meta-learning, Neural Information Processing Systems, (2018); Houlsby Neil, Giurgiu Andrei, Jastrzebski Stanislaw, Morrone Bruna, de Laroussilhe Quentin, Gesmundo Andrea, Attariyan Mona, Gelly Sylvain, Parameter-efficient transfer learning for nlp, International Conference on Machine Learning, (2019); Hu Edward J., Shen Yelong, Wallis Phillip, Allen-Zhu Zeyuan, Li Yuanzhi, Wang Shean, Chen Weizhu, Lora: Low-rank adaptation of large language models, (2021); Hu Qiang, Guo Yuejun, Xie Xiaofei, Cordy Maxime, Ma Lei, Papadakis Mike, Le Traon Yves, Codes: A distribution shift benchmark dataset for source code learning, (2022); Husain Hamel, Wu Hongqi, Gazit Tiferet, Allamanis Miltiadis, Brockschmidt Marc, Code-searchnet challenge: Evaluating the state of semantic code search, (2019); Koch Gregory R., Siamese neural networks for one-shot image recognition, (2015); Le Hung, Wang Yue, Gotmare Akhilesh Deepak, Savarese Silvio, Hoi Steven C. H., Coderl: Mastering code generation through pretrained models and deep reinforcement learning, CoRR, (2022); Lester Brian, Al-Rfou Rami, Constant Noah, The power of scale for parameter-efficient prompt tuning, (2021); Li Xiang Lisa, Liang Percy, Prefix-tuning: Optimizing continuous prompts for generation, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), (2021); Li Yan-Fu, Xie Min, Goh T. N., A study of mutual information based feature selection for case based reasoning in software cost estimation, Expert Syst. Appl, 36, 3, pp. 5921-5931, (2009); Li Yufei, Chen Simin, Yang Wei, Estimating predictive uncertainty under program data distribution shift, CoRR, (2021); Lin Chin-Yew, Rouge: A package for automatic evaluation of summaries, Text summarization branches out, pp. 74-81, (2004); Liu Jiachang, Shen Dinghan, Zhang Yizhe, Dolan Bill, Carin Lawrence, Chen Weizhu, What makes good in-context examples for gpt-3?, Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, (2021); Ma Ying, Luo Guangchun, Zeng Xue, Chen Aiguo, Transfer learning for cross-company software defect prediction, Inf. Softw. Technol, 54, 3, pp. 248-256, (2012); Mair Carolyn, Kadoda Gada F., Lefley Martin, Phalp Keith, Schofield Chris, Shepperd Martin J., Webster Steve, An investigation of machine learning based prediction systems, J. Syst. Softw, 53, 1, pp. 23-29, (2000); Manh Dung Nguyen, Hai Nam Le, Dau Anh T. V., Nguyen Anh Minh, Nghiem Khanh, Guo Jin, Bui Nghi D. Q., The vault: A comprehensive multilingual dataset for advancing code understanding and generation, CoRR, (2023); Meyerson Elliot, Miikkulainen Risto, Modular universal reparameterization: Deep multitask learning across diverse domains, (2019); Nie Pengyu, Zhang Jiyang, Li Junyi Jessy, Mooney Raymond J., Gligoric Milos, Impact of evaluation methodologies on code summarization, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, pp. 4936-4960, (2022); Ouyang Long, Wu Jeff, Jiang Xu, Almeida Diogo, Wainwright Carroll L., Mishkin Pamela, Zhang Chong, Agarwal Sandhini, Slama Katarina, Ray Alex, Schulman John, Hilton Jacob, Kelton Fraser, Miller Luke E., Simens Maddie, Askell Amanda, Welinder Peter, Christiano Paul Francis, Leike Jan, Lowe Ryan J., Training language models to follow instructions with human feedback, (2022); Papineni Kishore, Roukos Salim, Ward Todd, Zhu Wei-Jing, Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Popovic Maja, chrf: character n-gram f-score for automatic MT evaluation, Proceedings of the Tenth Workshop on Statistical Machine Translation, WMT@EMNLP 2015, pp. 392-395, (2015); Raffel Colin, Shazeer Noam M., Roberts Adam, Lee Katherine, Narang Sharan, Matena Michael, Zhou Yanqi, Li Wei, Liu Peter J., Exploring the limits of transfer learning with a unified text-to-text transformer, (2019); Ren Shuo, Guo Daya, Lu Shuai, Zhou Long, Liu Shujie, Tang Duyu, Zhou M., Blanco Ambrosio, Ma Shuai, Codebleu: a method for automatic evaluation of code synthesis, (2020); Rudman William, Gillman Nate, Rayne Taylor, Eickhoff Carsten, Isoscore: Measuring the uniformity of embedding space utilization, Findings of the Association for Computational Linguistics: ACL 2022, pp. 3325-3339, (2022); Santoro Adam, Bartunov Sergey, Botvinick Matthew M., Wierstra Daan, Lillicrap Timothy P., Meta-learning with memory-augmented neural networks, International Conference on Machine Learning, (2016); Shin Richard, Lin C. H., Thomson Sam, Chen Charles C., Roy Subhro, Platanios Emmanouil Antonios, Pauls Adam, Klein Dan, Van Durme Benjamin, Constrained language models yield few-shot semantic parsers, (2021); Silver Daniel L., The parallel transfer of task knowledge using dynamic learning rates based on a measure of relatedness, Connect. Sci, 8, 2, pp. 277-294, (1996); Snell Jake, Swersky Kevin, Zemel Richard S., Prototypical networks for few-shot learning, (2017); Su Hongjin, Kasai Jungo, Wu Chen Henry, Shi Weijia, Wang Tianlu, Xin Jiayi, Zhang Rui, Ostendorf Mari, Zettlemoyer Luke, Smith Noah A., Yu Tao, Selective annotation makes language models better few-shot learners, CoRR, (2022); Sung Flood, Yang Yongxin, Zhang Li, Xiang Tao, Torr Philip H. S., Hospedales Timothy M., Learning to compare: Relation network for few-shot learning, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1199-1208, (2017); Thrun Sebastian, Pratt Lorien Y., Learning to learn: Introduction and overview, Learning to Learn, pp. 3-17, (1998); Turhan Burak, On the dataset shift problem in software engineering prediction models, Empir. Softw. Eng, 17, 1-2, pp. 62-74, (2012); Vilalta Ricardo, Drissi Youssef, A perspective view and survey of meta-learning, Artif. Intell. Rev, 18, 2, pp. 77-95, (2002); Vinyals Oriol, Blundell Charles, Lillicrap Timothy, Kavukcuoglu Koray, Wierstra Daan, Matching networks for one shot learning, (2017); Wang Yue, Wang Weishi, Joty Shafiq R., Hoi Steven C. H., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Yang Yongxin, Hospedales Timothy M., Deep multi-task representation learning: A tensor factorisation approach, (2016); Zhou Shuyan, Alon Uri, Agarwal Sumit, Neubig Graham, Codebertscore: Evaluating code generation with pretrained models of code, (2023); Zimmermann Thomas, Nagappan Nachiappan, Gall Harald C., Giger Emanuel, Murphy Brendan, Cross-project defect prediction: a large scale experiment on data vs. domain vs. process, Proceedings of the 7th joint meeting of the European Software Engineering Conference and the ACM SIG-SOFT International Symposium on Foundations of Software Engineering, 2009, pp. 91-100, (2009)","Bouamor H.; Pino J.; Bali K.","Association for Computational Linguistics (ACL)","ahrefs; Amazon; Bloomberg; et al.; Google Research; GTCOM","2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023","6 December 2023 through 10 December 2023","Hybrid, Singapore","196512","Conference paper","Final","","Scopus","2-s2.0-85184815816"
"Mashhadi E.; Ahmadvand H.; Hemmati H.","Mashhadi, Ehsan (57223724998); Ahmadvand, Hossein (57201356410); Hemmati, Hadi (15046849800)","57223724998; 57201356410; 15046849800","Method-Level Bug Severity Prediction using Source Code Metrics and LLMs","2023","Proceedings - International Symposium on Software Reliability Engineering, ISSRE","","","","635","646","11","1","10.1109/ISSRE59848.2023.00055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178028189&doi=10.1109%2fISSRE59848.2023.00055&partnerID=40&md5=54985bed489d70de3549a7671e32fff6","In the past couple of decades, significant research efforts are devoted to the prediction of software bugs. However, most existing work in this domain treats all bugs the same, which is not the case in practice. It is important for a defect prediction method to estimate the severity of the identified bugs so that the higher-severity ones get immediate attention. In this study, we investigate source code metrics, source code representation using large language models (LLMs), and their combination in predicting bug severity labels of two prominent datasets. We leverage several source metrics at method-level granularity to train eight different machine-learning models. Our results suggest that Decision Tree and Random Forest models outperform other models regarding our several evaluation metrics. We then use the pre-trained CodeBERT LLM to study the source code representations' effectiveness in predicting bug severity. CodeBERT fine-tuning improves the bug severity prediction results significantly in the range of 29%-140% for several evaluation metrics, compared to the best classic prediction model on source code metric. Finally, we integrate source code metrics into CodeBERT as an additional input, using our two proposed architectures, which both enhance the CodeBERT model effectiveness1.  © 2023 IEEE.","Bug severity prediction; Code metrics; Code representation; CodeBERT; Large Language Models (LLMs)","Computational linguistics; Computer programming languages; Decision trees; Large dataset; Program debugging; Bug severity prediction; Code metrics; Code representation; CodeBERT; Evaluation metrics; Language model; Large language model; Research efforts; Source code metrics; Source code representations; Forecasting","Mashhadi E., EhsanMashhadi/ISSRE2023-BugSeverityPrediction: 0. 1. 0, version 0. 1. 0, (2023); Kafura D., Reddy G.R., The use of software complexity metrics in software maintenance, IEEE Transactions on Software Engineering, 3, pp. 335-343, (1987); Borstler J., Paech B., The role of method chains and comments in software readability and comprehension-an experiment, IEEE Transactions on Software Engineering, 42, 9, pp. 886-898, (2016); Bennett K.H., Rajlich V.T., Software maintenance and evolution: A roadmap, Proceedings of the Conference on the Future of Software Engineering, pp. 73-87, (2000); Kondo M., German D.M., Mizuno O., Choi E.-H., The impact of context metrics on just-in-time defect prediction, Empirical Software Engineering, 25, 1, pp. 890-939, (2020); Shin Y., Meneely A., Williams L., Osborne J.A., Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities, IEEE transactions on software engineering, 37, 6, pp. 772-787, (2010); Tosun A., Bener A., Turhan B., Menzies T., Practical considerations in deploying statistical methods for defect prediction: A case study within the Turkish telecommunications industry, Information and Software Technology, 52, 11, pp. 1242-1257, (2010); Zhou Y., Xu B., Leung H., On the ability of complexity metrics to predict fault-prone classes in object-oriented systems, Journal of Systems and Software, 83, 4, pp. 660-674, (2010); Mashhadi E., Hemmati H., Applying codebert for automated program repair of Java simple bugs, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), IEEE, pp. 505-509, (2021); Le Goues C., Nguyen T., Forrest S., Weimer W., Genprog: A generic method for automatic software repair, Ieee transactions on software engineering, 38, 1, pp. 54-72, (2011); Long F., Rinard M., Automatic patch generation by learning correct code, Proceedings of the 43rd Annual ACM SIGPLANSIGACT Symposium on Principles of Programming Languages, pp. 298-312, (2016); Shamshiri S., Just R., Rojas J.M., Fraser G., McMinn P., Arcuri A., Do automatically generated unit tests find real faults. An empirical study of effectiveness and challenges (t), 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), IEEE, pp. 201-211, (2015); Wong W.E., Gao R., Li Y., Abreu R., Wotawa F., A survey on software fault localization, IEEE Transactions on Software Engineering, 42, 8, pp. 707-740, (2016); Pearson S., Campos J., Just R., Et al., Evaluating and improving fault localization, 2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE), IEEE, pp. 609-620, (2017); Neysiani B.S., Babamir S.M., Aritsugi M., Efficient feature extraction model for validation performance improvement of duplicate bug report detection in software bug triage systems, Information and Software Technology, 126, (2020); Yang G., Zhang T., Lee B., Towards semi-automatic bug triage and severity prediction based on topic model and multi-feature of bug reports, 2014 IEEE 38th Annual Computer Software and Applications Conference, IEEE, pp. 97-106, (2014); Chaturvedi K.K., Singh V., Determining bug severity using machine learning techniques, 2012 CSI sixth international conference on software engineering (CONSEG), IEEE, pp. 1-6, (2012); Tan Y., Xu S., Wang Z., Zhang T., Xu Z., Luo X., Bug severity prediction using question-and-answer pairs from stack overflow, Journal of Systems and Software, 165, (2020); Zhou Y., Leung H., Empirical analysis of object-oriented design metrics for predicting high and low severity faults, IEEE Transactions on software engineering, 32, 10, pp. 771-789, (2006); Shatnawi R., Li W., The effectiveness of software metrics in identifying error-prone classes in post-release software evolution process, Journal of systems and software, 81, 11, pp. 1868-1882, (2008); Singh S., Mittal P., Kahlon K.S., Empirical model for predicting high, medium and low severity faults using object oriented metrics in mozilla firefox, International journal of computer applications in technology, 47, 2-3, pp. 110-124, (2013); Shihab E., Hassan A.E., Adams B., Jiang Z.M., An industrial study on the risk of software changes, Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering, pp. 1-11, (2012); Pascarella L., Palomba F., Bacchelli A., On the performance of method-level bug prediction: A negative result, Journal of Systems and Software, 161, (2020); Grund F., Chowdhury S., Bradley N.C., Hall B., Holmes R., Codeshovel: Constructing method-level source code histories, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), IEEE, pp. 1510-1522, (2021); Hata H., Mizuno O., Kikuno T., Bug prediction based on finegrained module histories, 2012 34th international conference on software engineering (ICSE), IEEE, pp. 200-210, (2012); Replication package of the paper; Feng Z., Guo D., Tang D., Et al., Codebert: A pre-trained model for programming and natural languages, (2020); Lu S., Guo D., Ren S., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Tufano M., Palomba F., Bavota G., Et al., When and why your code starts to smell bad, 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, IEEE, 1, pp. 403-414, (2015); Polo M., Piattini M., Ruiz F., Using code metrics to predict maintenance of legacy programs: A case study, Proceedings IEEE International Conference on Software Maintenance. ICSM 2001, pp. 202-208, (2001); Ferenc R., Ban D., Grosz T., Gyimothy T., Deep learning in static, metric-based bug prediction, Array, 6, (2020); Okutan A., Yldz O.T., Software defect prediction using Bayesian networks, Empirical software engineering : An international journal, 19, 1, pp. 154-181, (2014); Koru A., Liu H., Building effective defect-prediction models in practice, IEEE Software, 22, 6, pp. 23-29, (2005); Zimmermann T., Premraj R., Zeller A., Predicting defects for eclipse, Third International Workshop on Predictor Models in Software Engineering (PROMISE'07: ICSE Workshops 2007), IEEE, pp. 9-9, (2007); Giger E., D'Ambros M., Pinzger M., Gall H.C., Method-level bug prediction, Proceedings of the 2012 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement, IEEE, pp. 171-180, (2012); Ferenc R., Gyimesi P., Gyimesi G., Toth Z., Gyimothy T., An automatically created novel bug dataset and its validation in bug prediction, The Journal of systems and software, 169, (2020); Chowdhury S., Uddin G., Holmes R., An empirical study on maintainable method size in Java, 19th International Conference on Mining Software Repositories, (2022); Mo R., Wei S., Feng Q., Li Z., An exploratory study of bug prediction at the method level, Information and software technology, 144, (2022); Wattanakriengkrai S., Thongtanunam P., Tantithamthavorn C., Hata H., Matsumoto K., Predicting defective lines using a model-agnostic technique, (2020); Steidl D., Hummel B., Juergens E., Incremental origin analysis of source code files, Proceedings Working Conference on Mining Software Repositories (MSR), pp. 42-51, (2014); Servant F., Jones J.A., Fuzzy fine-grained code-history analysis, Proceedings of the International Conference on Software Engineering (ICSE), pp. 746-757, (2017); Gil Y., Lalouche G., On the correlation between size and metric validity, Empirical Software Engineering, 22, 5, pp. 2585-2611, (2017); El Emam K., Benlarbi S., Goel N., Rai S.N., The confounding effect of class size on the validity of object-oriented metrics, IEEE Transactions on Software Engineering, 27, 7, pp. 630-650, (2001); Landman D., Serebrenik A., Vinju J., Empirical analysis of the relationship between cc and sloc in a large corpus of Java methods, 2014 IEEE International Conference on Software Maintenance and Evolution, IEEE, pp. 221-230, (2014); Ralph P., Tempero E., Construct validity in software engineering research and software metrics, Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018, pp. 13-23, (2018); McCabe T.J., A complexity measure, IEEE Transactions on software Engineering, 4, pp. 308-320, (1976); McClure C.L., A model for program complexity analysis, Proceedings of the 3rd international conference on Software engineering, pp. 149-157, (1978); Kasto N., Whalley J., Measuring the difficulty of code comprehension tasks using software metrics, Proceedings of the Fifteenth Australasian Computing Education Conference, 136, pp. 59-65, (2013); Alenezi M., Akour M., Al Sghaier H., The impact of co-evolution of code production and test suites through software releases in open source software systems, International Journal of Innovative Technology and Exploring Engineering (IJITEE), 9, 1, pp. 2737-2739, (2019); Zaw K.K., Hnin H.W., Kyaw K.Y., Funabiki N., Software quality metrics calculations for Java programming learning assistant system, 2020 IEEE Conference on Computer Applications (ICCA), IEEE, pp. 1-6, (2020); Hindle A., Godfrey M.W., Holt R.C., Reading beside the lines: Indentation as a proxy for complexity metric, 2008 16th IEEE International Conference on Program Comprehension, IEEE, pp. 133-142, (2008); Buse R.P., Weimer W.R., Learning a metric for code readability, IEEE Transactions on software engineering, 36, 4, pp. 546-558, (2009); Halstead M.H., Elements of Software Science (Operating and programming systems series)., (1977); Oman P., Hagemeister J., Metrics for assessing a software system's maintainability, Proceedings Conference on Software Maintenance 1992, IEEE Computer Society, pp. 337-338, (1992); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Liu Y., Ott M., Goyal N., Et al., Roberta: A robustly optimized bert pretraining approach, (2019); Vaswani A., Shazeer N., Parmar N., Et al., Attention is all you need, Advances in neural information processing systems, 30, (2017); Husain H., Wu H.-H., Gazit T., Allamanis M., Brockschmidt M., Codesearchnet challenge: Evaluating the state of semantic code search, (2019); Pan C., Lu M., Xu B., An empirical study on software defect prediction using codebert model, Applied Sciences, 11, 11, (2021); Zhang F., Yu X., Keung J., Et al., Improving stack overflow question title generation with copying enhanced codebert model and bimodal information, Information and Software Technology, 148, (2022); Just R., Jalali D., Ernst M.D., Defects4j: A database of existing faults to enable controlled testing studies for Java programs, Proceedings of the 2014 International Symposium on Software Testing and Analysis, pp. 437-440, (2014); Saha R.K., Lyu Y., Lam W., Yoshida H., Prasad M.R., Bugs. jar: A large-scale, diverse dataset of real-world Java bugs, Proceedings of the 15th international conference on mining software repositories, pp. 10-13, (2018); Martinez M., Durieux T., Sommerard R., Xuan J., Monperrus M., Automatic repair of real bugs in Java: A large-scale experiment on the defects4j dataset, Empirical Software Engineering, 22, 4, pp. 1936-1964, (2017); Saha R.K., Lyu Y., Yoshida H., Prasad M.R., Elixir: Effective object-oriented program repair, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), IEEE, pp. 648-659, (2017); Jira; Robustscaler; Classification metrics; Matthews B.W., Comparison of the predicted and observed secondary structure of t4 phage lysozyme, Biochimica et Biophysica Acta (BBA)-Protein Structure, 405, 2, pp. 442-451, (1975); Sklearn evaluation metrics; Buitinck L., Louppe G., Blondel M., Et al., Api design for machine learning software: Experiences from the scikit-learn project, (2013); Hugging face; Hu Y., Ding J., Dou Z., Chang H., Short-text classification detector: A bert-based mental approach, Computational Intelligence and Neuroscience, 2022, (2022); Tian Y., Lo D., Sun C., Information retrieval based nearest neighbor classification for fine-grained bug severity prediction, 2012 19th Working Conference on Reverse Engineering, IEEE, pp. 215-224, (2012); Ramay W.Y., Umer Q., Yin X.C., Zhu C., Illahi I., Deep neural network-based severity prediction of bug reports, IEEE Access, 7, pp. 46846-46857, (2019); Zhang T., Chen J., Yang G., Lee B., Luo X., Towards more accurate severity prediction and fixer recommendation of software bugs, Journal of Systems and Software, 117, pp. 166-184, (2016); Izadi M., Akbari K., Heydarnoori A., Predicting the objective and priority of issue reports in software repositories, Empirical Software Engineering, 27, 2, (2022)","","IEEE Computer Society","IEEE; IEEE Computer Society; IEEE Computer Society Technical Committee on Software Engineering (TCSE); IEEE Reliability Society; RESTART","34th IEEE International Symposium on Software Reliability Engineering, ISSRE 2023","9 October 2023 through 12 October 2023","Florence","194273","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85178028189"
"Zhu J.; Li L.; Yang L.; Ma X.; Zuo C.","Zhu, Jie (57425641800); Li, Lingwei (57847892400); Yang, Li (57208731132); Ma, Xiaoxiao (57214757730); Zuo, Chun (35876113700)","57425641800; 57847892400; 57208731132; 57214757730; 35876113700","Automating Method Naming with Context-Aware Prompt-Tuning","2023","IEEE International Conference on Program Comprehension","2023-May","","","203","214","11","0","10.1109/ICPC58990.2023.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166367405&doi=10.1109%2fICPC58990.2023.00035&partnerID=40&md5=2a7fa2f5fdf6fdd096be1cd3cfa934a3","Method names are crucial to program comprehension and maintenance. Recently, many approaches have been proposed to automatically recommend method names and detect inconsistent names. Despite promising, their results are still suboptimal considering the three following drawbacks: 1) These models are mostly trained from scratch, learning two different objectives simultaneously. The misalignment between two objectives will negatively affect training efficiency and model performance. 2) The enclosing class context is not fully exploited, making it difficult to learn the abstract functionality of the method. 3) Current method name consistency checking methods follow a generate-then-compare process, which restricts the accuracy as they highly rely on the quality of generated names and face difficulty measuring the semantic consistency.In this paper, we propose an approach named AUMENA to AUtomate MEthod NAming tasks with context-aware prompt-tuning. Unlike existing deep learning based approaches, our model first learns the contextualized representation(i.e., class attributes) of programming language and natural language through the pre-training model, then fully exploits the capacity and knowledge of large language model with prompt-tuning to precisely detect inconsistent method names and recommend more accurate names. To better identify semantically consistent names, we model the method name consistency checking task as a two-class classification problem, avoiding the limitation of previous generate-then-compare consistency checking approaches. Experiment results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7% on four datasets of method name recommendation, surpassing the state-of-the-art baseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively. And our approach scores 80.8% accuracy on method name consistency checking, reaching an 5.5% outperformance. All data and trained models are publicly available.  © 2023 IEEE.","Inconsistent Method Name Checking; Method Name Recommendation; Prompt Tuning","Deep learning; Learning systems; Consistency checking; Context-Aware; Inconsistent method name checking; Learn+; Method name recommendation; Modeling performance; Program comprehension and maintenances; Prompt tuning; Training efficiency; Training model; Semantics","Rajlich V., Wilde N., The role of concepts in program comprehension, 10th International Workshop on Program Comprehension (IWPC 2002), pp. 271-278, (2002); Ko A.J., Myers B.A., Coblenz M.J., Aung H.H., An exploratory study of how developers seek, relate, and collect relevant information during software maintenance tasks, IEEE Trans. Software Eng., 32, 12, pp. 971-987, (2006); Roehm T., Tiarks R., Koschke R., Maalej W., How do professional developers comprehend software?, 34th International Conference on Software Engineering, ICSE 2012, pp. 255-265, (2012); Arnaoudova V., Eshkevari L.M., Penta M.D., Oliveto R., Antoniol G., Gueheneuc Y., REPENT: Analyzing the nature of identifier renamings, IEEE Trans. Software Eng., 40, 5, pp. 502-532, (2014); Lawrie D.J., Morrell C., Feild H., Binkley D.W., What's in a name? A study of identifiers, 14th International Conference on Program Comprehension (ICPC 2006), pp. 3-12, (2006); Butler S., Wermelinger M., Yu Y., Sharp H., Relating identifier naming flaws and code quality: An empirical study, 16th Working Conference on Reverse Engineering, WCRE 2009, pp. 31-35, (2009); Peruma A., Mkaouer M.W., Decker M.J., Newman C.D., An empirical investigation of how and why developers rename identifiers, Proceedings of the 2nd International Workshop on Refactoring, IWoR@ASE 2018, pp. 26-33, (2018); Liu K., Kim D., Bissyande T.F., Kim T., Kim K., Koyuncu A., Kim S., Traon Y.L., Learning to spot and refactor inconsistent method names, Proceedings of the 41st International Conference on Software Engineering, ICSE 2019, pp. 1-12, (2019); Arnaoudova V., Penta M.D., Antoniol G., Gueheneuc Y., A new family of software anti-patterns: Linguistic anti-patterns, 17th European Conference on Software Maintenance and Reengineering, CSMR 2013, pp. 187-196, (2013); Higo Y., Kusumoto S., How often do unintended inconsistencies happen? deriving modification patterns and detecting overlooked code fragments, 28th IEEE International Conference on Software Maintenance, ICSM 2012, pp. 222-231, (2012); Kim S., Kim D., Automatic identifier inconsistency detection using code dictionary, Empir. Softw. Eng., 21, 2, pp. 565-604, (2016); Wang S., Wen M., Lin B., Mao X., Lightweight global and local contexts guided method name recommendation with prior knowledge, ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 741-753, (2021); Pantiuchina J., Zampetti F., Scalabrino S., Piantadosi V., Oliveto R., Bavota G., Penta M.D., Why developers refactor source code: A mining-based study, ACM Trans. Softw. Eng. Methodol., 29, 4, pp. 291-2930, (2020); Scalabrino S., Bavota G., Vendome C., Linares-Vasquez M., Poshyvanyk D., Oliveto R., Automatically assessing code understandability, IEEE Trans. Software Eng., 47, 3, pp. 595-613, (2021); Tufano R., Masiero S., Mastropaolo A., Pascarella L., Poshyvanyk D., Bavota G., Using pre-trained models to boost code review automation, 44th IEEE/ACM 44th International Conference on Software Engineering, ICSE 2022, pp. 2291-2302, (2022); Han X., Tahir A., Liang P., Counsell S., Luo Y., Understanding code smell detection via code review: A study of the openstack community, 29th IEEE/ACM International Conference on Program Comprehension, ICPC 2021, pp. 323-334, (2021); Yonai H., Hayase Y., Kitagawa H., Mercem: Method name recommendation based on call graph embedding, 26th Asia-Pacific Software Engineering Conference, APSEC 2019, pp. 134-141, (2019); Alon U., Zilberstein M., Levy O., Yahav E., Code2vec: Learning distributed representations of code, Proc. ACM Program. Lang., 3, pp. 401-4029, (2019); Alon U., Brody S., Levy O., Yahav E., Code2seq: Generating sequences from structured representations of code, 7th International Conference on Learning Representations, ICLR 2019, (2019); Nguyen S., Phan H., Le T., Nguyen T.N., Suggesting natural method names to check name consistencies, ICSE '20: 42nd International Conference on Software Engineering, Seoul, South Korea, 27 June - 19 July, 2020, pp. 1372-1384, (2020); Li Y., Wang S., Nguyen T.N., A context-based automated approach for method name consistency checking and suggestion, 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021, pp. 574-586, (2021); Liu F., Li G., Fu Z., Lu S., Hao Y., Jin Z., Learning to recommend method names with global context, 44th IEEE/ACM 44th International Conference on Soft- ware Engineering, ICSE 2022, pp. 1294-1306, (2022); Wang Y., Wang W., Joty S.R., Hoi S.C.H., Codet5: Identifier-aware unified pre-trained encoderdecoder models for code understanding and generation, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, pp. 8696-8708, (2021); Allamanis M., Barr E.T., Bird C., Sutton C., Suggesting accurate method and class names, Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pp. 38-49, (2015); Allamanis M., Peng H., Sutton C., A convolutional attention network for extreme summarization of source code, Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, 48, pp. 2091-2100, (2016); Xu S., Zhang S., Wang W., Cao X., Guo C., Xu J., Method name suggestion with hierarchical attention networks, Proceedings of the 2019 ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation, PEPM@POPL 2019, pp. 10-21, (2019); See A., Liu P.J., Manning C.D., Get to the point: Summarization with pointer-generator networks, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, 1, pp. 1073-1083, (2017); Ge F., Kuang L., Keywords guided method name generation, 29th IEEE/ACM International Conference on Program Comprehension, ICPC 2021, pp. 196-206, (2021); Qu Z., Hu Y., Zeng J., Cai B., Yang S., Method name generation based on code structure guidance, IEEE International Conference on Software Analysis, Evolution and Reengineering, SANER 2022, pp. 1101-1110, (2022); Host E.W., Ostvold B.M., Debugging method names, ECOOP 2009 - Object-Oriented Programming, 23rd European Conference, 5653, pp. 294-317, (2009); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Zhou M., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Tufano M., Deng S.K., Clement C.B., Drain D., Sundaresan N., Yin J., Jiang D., Zhou M., Graphcodebert: Pre-training code representations with data flow, 9th International Conference on Learning Representations, ICLR 2021, (2021); Li Z., Lu S., Guo D., Duan N., Jannu S., Jenks G., Majumder D., Green J., Svyatkovskiy A., Fu S., Sundaresan N., Automating code review activities by large-scale pre-training, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022, pp. 1035-1047, (2022); Wang C., Yang Y., Gao C., Peng Y., Zhang H., Lyu M.R., No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence, Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2022, pp. 382-394, (2022); Alsuhaibani R.S., Newman C.D., Decker M.J., Collard M.L., Maletic J.I., An approach to automatically assess method names, Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension, pp. 202-213, (2022); Jiang L., Liu H., Jiang H., Machine learning based recommendation of method names: How far are we, 34th IEEE/ACM International Conference on Automated Software Engineering, ASE 2019, pp. 602-614, (2019); Alsuhaibani R.S., Newman C.D., Decker M.J., Collard M.L., Maletic J.I., On the naming of methods: A survey of professional developers, 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021, pp. 587-599, (2021); Wilcoxon F., Individual comparisons by ranking methods, Biometrics, 1, pp. 196-202, (1945); Raffel C., Shazeer N., Roberts A., Lee K., Narang S., Matena M., Zhou Y., Li W., Liu P.J., Exploring the limits of transfer learning with a unified text-to-text transformer, Journal of Machine Learning Research, 21, 140, pp. 1-67, (2020); Akiba T., Sano S., Yanase T., Ohta T., Koyama M., Optuna: A next-generation hyperparameter optimization framework, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, ser. KDD '19, pp. 2623-2631, (2019); Bergstra J., Bardenet R., Bengio Y., Kegl B., Algorithms for hyper-parameter optimization, Advances in Neural Information Processing Systems, 24, (2011)","","IEEE Computer Society","","31st IEEE/ACM International Conference on Program Comprehension, ICPC 2023","15 May 2023 through 16 May 2023","Melbourne","190686","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85166367405"
"Mohammadkhani A.H.; Tantithamthavorn C.; Hemmatif H.","Mohammadkhani, Ahmad Haji (57997572600); Tantithamthavorn, Chakkrit (55361007600); Hemmatif, Hadi (58605250400)","57997572600; 55361007600; 58605250400","Explaining Transformer-based Code Models: What Do They Learn? When They Do Not Work?","2023","Proceedings - 2023 IEEE 23rd International Working Conference on Source Code Analysis and Manipulation, SCAM 2023","","","","96","106","10","0","10.1109/SCAM59687.2023.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182741854&doi=10.1109%2fSCAM59687.2023.00020&partnerID=40&md5=f4972830275d6185273c507a813deca3","In recent years, there has been a wide interest in designing deep neural network-based models that automate downstream software engineering tasks on source code, such as code document generation, code search, and program repair. Although the main objective of these studies is to improve the effectiveness of the downstream task, many studies only attempt to employ the next best neural network model, without a proper in-depth analysis of why a particular solution works or does not, on particular tasks or scenarios. In this paper, using an example eXplainable AI (XAI) method (attention mechanism), we study two recent large language models (LLMs) for code (CodeBERT and GraphCodeBERT) on a set of software engineering downstream tasks: code document generation (CDG), code refinement (CR), and code translation (CT). Through quantitative and qualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the highest attention on, in terms of source code token types), on these tasks. We also show some of the common patterns when the model does not work as expected (performs poorly even on easy problems) and suggest recommendations that may alleviate the observed challenges.  © 2023 IEEE.","Attention; Code Models; Explainable AI (XAI); Interpretable; LLM; Transformer.","Neural network models; Software engineering; Attention; Code model; Down-stream; Explainable AI (XAI); Interpretable; Language model; Large language model; Learn+; Source codes; Transformer.; Deep neural networks","Shobha G., Rana A., Kansal V., Tanwar S., Code clone detection-a systematic review, Emerging Technologies in Data Mining and Information Security, pp. 645-655, (2021); Pornprasit C., Tantithamthavorn C., Jiarpakdee J., Fu M., Thongtanunam P., Pyexplainer: Explaining the predictions of just-in-time defect models, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 407-418, (2021); Humphreys J., Dam H.K., An explainable deep model for defect prediction, 2019 IEEE/ACM 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE), pp. 49-55, (2019); LeClair A., Haque S., Wu L., McMillan C., Improved code summarization via a graph neural network, Proceedings of the 28th international conference on program comprehension, pp. 184-195, (2020); Feng Z., Guo D., Tang D., Duan N., Feng X., Gong M., Shou L., Qin B., Liu T., Jiang D., Et al., Codebert: A pre-trained model for programming and natural languages, Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 1536-1547, (2020); Guo D., Ren S., Lu S., Feng Z., Tang D., Liu S., Zhou L., Duan N., Svyatkovskiy A., Fu S., Et al., Graphcodebert: Pre-training code representations with data flow, (2020); Lu S., Guo D., Ren S., Huang J., Svyatkovskiy A., Blanco A., Clement C., Drain D., Jiang D., Tang D., Et al., Codexglue: A machine learning benchmark dataset for code understanding and generation, (2021); Wang Y., Wang W., Joty S., Hoi S.C., Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation, (2021); Tantithamthavorn C., Jiarpakdee J., Grundy J., Actionable analytics: Stop telling me what it is; please tell me what to do, IEEE Software, 38, 4, pp. 115-120, (2021); Tantithamthavorn C.K., Jiarpakdee J., Explainable ai for software engineering, 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1-2, (2021); Jiarpakdee J., Tantithamthavorn C.K., Grundy J., Practitioners' perceptions of the goals and visual explanations of defect prediction models, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 432-443, (2021); Jiarpakdee J., Tantithamthavorn C.K., Dam H.K., Grundy J., An empirical study of model-agnostic techniques for defect prediction models, IEEE Transactions on Software Engineering, 48, 1, pp. 166-185, (2020); Rajapaksha D., Tantithamthavorn C., Jiarpakdee J., Bergmeir C., Grundy J., Buntine W., Sqaplanner: Generating data-informed software quality improvement plans, IEEE Transactions on Software Engineering, 48, 8, pp. 2814-2835, (2021); Wattanakriengkrai S., Thongtanunam P., Tantithamthavorn C., Hata H., Matsumoto K., Predicting defective lines using a model-agnostic technique, IEEE Transactions on Software Engineering, 48, 5, pp. 1480-1496, (2020); Pornprasit C., Tantithamthavorn C.K., Jitline: A simpler, better, faster, finer-grained just-in-time defect prediction, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 369-379, (2021); Khanan C., Luewichana W., Pruktharathikoon K., Jiarpakdee J., Tantithamthavorn C., Choetkiertikul M., Ragkhitwetsagul C., Sunetnanta T., Jitbot: An explainable just-in-time defect prediction bot, 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1336-1339, (2020); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, (2018); Pan C., Lu M., Xu B., An empirical study on software defect prediction using codebert model, Applied Sciences, 11, 11, (2021); Gu X., Zhang H., Kim S., Deep code search, 2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE), pp. 933-944, (2018); Cao K., Chen C., Baltes S., Treude C., Chen X., Automated query reformulation for efficient search based on query logs from stack overflow, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 1273-1285, (2021); Nguyen T., Rigby P.C., Nguyen A.T., Karanfil M., Nguyen T.N., T2api: Synthesizing api code usage templates from english texts with statistical translation, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering, pp. 1013-1017, (2016); Haque S., LeClair A., Wu L., McMillan C., Improved automatic summarization of subroutines via attention to file context, Proceedings of the 17th International Conference on Mining Software Repositories, pp. 300-310, (2020); Jiang S., Armaly A., McMillan C., Automatically generating commit messages from diffs using neural machine translation, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 135-146, (2017); Liu L., Hu X., Song W., Fu R., Liu T., Hu G., Neural multitask learning for simile recognition, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 1543-1553, (2018); Jiang N., Lutellier T., Tan L., Cure: Code-aware neural machine translation for automatic program repair, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pp. 1161-1173, (2021); Li Y., Wang S., Nguyen T.N., Dlfix: Context-based code transformation learning for automated program repair, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, pp. 602-614, (2020); Chen Z., Kommrusch S., Tufano M., Pouchet L.-N., Poshyvanyk D., Monperrus M., Sequencer: Sequence-to-sequence learning for endto-end program repair, IEEE Transactions on Software Engineering, 47, 9, pp. 1943-1959, (2019); Roziere B., Lachaux M.-A., Chanussot L., Lample G., Unsupervised translation of programming languages, Advances in Neural Information Processing Systems, 33, pp. 20601-20611, (2020); Svyatkovskiy A., Deng S.K., Fu S., Sundaresan N., Intellicode compose: Code generation using transformer, Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 1433-1443, (2020); Tufano R., Masiero S., Mastropaolo A., Pascarella L., Poshyvanyk D., Bavota G., Using pre-trained models to boost code review automation, Proceedings of the 44th International Conference on Software Engineering, pp. 2291-2302, (2022); Thongtanunam P., Pornprasit C., Tantithamthavorn C., Autotransform: Automated code transformation to support modern code review process, Proceedings of the 44th International Conference on Software Engineering, pp. 237-248, (2022); Liu Y., Tantithamthavorn C., Liu Y., Thongtanunam P., Li L., Autoupdate: Automatically recommend code updates for android apps, (2022); Hu X., Li G., Xia X., Lo D., Jin Z., Deep code comment generation, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC), pp. 200-20010, (2018); Papineni K., Roukos S., Ward T., Zhu W.-J., Bleu: a method for automatic evaluation of machine translation, Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311-318, (2002); Lin C.-Y., Och F.J., Orange: a method for evaluating automatic evaluation metrics for machine translation, COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, pp. 501-507, (2004); Loper E., Bird S., Nltk: The natural language toolkit, CoRR, (2002)","Moonen L.; Newman C.; Gorla A.","Institute of Electrical and Electronics Engineers Inc.","IEEE Computer Society Technical Council on Software Engineering; Semantic Designs; TradeDesk","23rd IEEE International Working Conference on Source Code Analysis and Manipulation, SCAM 2023","1 October 2023 through 2 October 2023","Bogota","195700","Conference paper","Final","","Scopus","2-s2.0-85182741854"
"Neyem A.; Alcocer J.P.S.; Mendoza M.; Centellas-Claros L.; Gonzalez L.A.; Paredes-Robles C.","Neyem, Andres (13105631200); Alcocer, Juan Pablo Sandoval (57218705105); Mendoza, Marcelo (7101729849); Centellas-Claros, Leonardo (58967859700); Gonzalez, Luis A. (57203191310); Paredes-Robles, Carlos (58967184500)","13105631200; 57218705105; 7101729849; 58967859700; 57203191310; 58967184500","Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development","2024","SIGCSE 2024 - Proceedings of the 55th ACM Technical Symposium on Computer Science Education","1","","","951","957","6","0","10.1145/3626252.3630854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189360811&doi=10.1145%2f3626252.3630854&partnerID=40&md5=a0f2c3f68a99337c3966c01c0db499a3","StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.  © 2024 ACM.","capstone courses; chatgpt; generative ai; large language models; software engineering education","Curricula; Education computing; Engineering education; Linguistics; Quality control; Software design; Capstone course; Capstone projects; Chatgpt; Generative ai; Language model; Large language model; Linguistic analysis; Project development; Software engineering course; Software engineering education; Students","The AI writing on the wall, Nature Machine Intelligence, 5, 1, (2023); Ahmed A., Ahmad S., Ehsan N., Mirza E., Sarwar S.Z., Agile software development: Impact on productivity and quality, 2010 Ieee International Conference on Management of Innovation and Technology, pp. 287-291, (2010); Alharbi W., AI in the Foreign Language Classroom: A Pedagogical Overview of Automated Writing Assistance Tools, Education Research International 2023, pp. 1-15, (2023); Aydin N., Ayhan Erdem O., A Research on the New Generation Artificial Intelligence Technology Generative Pretraining Transformer 3, 2022 3rd International Informatics and Software Engineering Conference (IISEC, pp. 1-6, (2022); Badran R., AbiGhannam N., Tehrani-Bagha A., Sfeir M., Improving Students' Soft Skills in an Engineering Lab Course: Developing and Testing a Discipline-Specific Approach, 2022 Ieee International Professional Communication Conference (ProComm, pp. 262-266, (2022); Bahrini A., Khamoshifar M., Abbasimehr H., Riggs R.J., Esmaeili M., Mastali Majdabadkohne R., Pasehvar M., ChatGPT: Applications, Opportunities, and Threats, 2023 Systems and Information Engineering Design Symposium (SIEDS, pp. 274-279, (2023); Becker B.A., Denny P., Finnie-Ansley J., Luxton-Reilly A., Prather J., Antonio Santos E., Programming is hard-or at least it used to be: Educational opportunities and challenges of ai code generation, Proceedings of the 54th Acm Technical Symposium on Computer Science Education, 1, pp. 500-506, (2023); Berry F.C., Phillips M.L., Condron J., Sanger P.A., Improving Writing Quality of Capstone Reports, Ieee Transactions on Education, 64, 4, pp. 383-389, (2021); Thirumai Chelvan I., Smith M.A., Ghosh S., Reflect, Review, and Revise: Using Checklists to Improve Students' Lab Reports, 2021 Ieee International Professional Communication Conference (ProComm, pp. 85-90, (2021); Dale R., Viethen J., The automated writing assistance landscape in 2021, Natural Language Engineering, 27, 4, pp. 511-518, (2021); Davenport T.H., Miller S.M., Intuit: AI-Assisted Writing with Writer.com, pp. 89-93, (2022); Ebert C., Louridas P., Generative AI for Software Practitioners, Ieee Software, 40, 4, pp. 30-38, (2023); Gayed J., Kristine Carlon M., Oriola A., Cross J., Exploring An AI-based Writing Assistant's Impact on English Language Learners, 3, 2, (2022); Jannach D., Manzoor A., Cai W., Chen L., A survey on conversational recommender systems, Acm Computing Surveys (CSUR, 54, 5, pp. 1-36, (2021); Koltovskaia S., Student engagement with automated written corrective feedback (AWCF) provided by Grammarly: A multiple case study, Assessing Writing, 44, 3, (2020); Kumar S., Wallace C., Instruction in software project communication through guided inquiry and reflection, 2014 Ieee Frontiers in Education Conference (FIE) Proceedings, pp. 1-9, (2014); Li J., Research on AI-assisted Hybrid Teaching for English Writing, 2021 International Conference on Computers, Information Processing and Advanced Education (CIPAE, pp. 309-312, (2021); Mahnic V., A Capstone Course on Agile Software Development Using Scrum, Education, Ieee Transactions on, 55, 2, pp. 99-106, (2012); McSkimming B.M., MacKay S., Decker A., Investigating the usage of Likert-style items within Computer Science Education Research Instruments, 2021 Ieee Frontiers in Education Conference (FIE, pp. 1-8, (2021); Neyem A., Benedetto J.I., Chacon A.F., Improving software engineering education through an empirical approach: Lessons learned from capstone teaching experiences, Proceedings of the 45th Acm Technical Symposium on Computer Science Education, pp. 391-396, (2014); Neyem A., Diaz-Mosquera J., Benedetto J.I., A cloud-based mobile system to improve project management skills in software engineering capstone courses, Mobile Information Systems 2018, (2018); GPT-4 Technical Report, (2023); Ozkan N., Ozcan Top O., Bal S., Sahin Gok M., Teaching Agile in an Agile Way: A Case from the First Iteration in a University, 2022 3rd International Informatics and Software Engineering Conference IISEC, pp. 1-6, (2022); Pikkarainen M., Haikara J., Salo O., Abrahamsson P., Still J., The impact of agile practices on communication in software development, Empirical Software Engineering, 13, 6, pp. 303-337, (2008); Pramod D., Bafna P., Conversational recommender systems techniques, tools, acceptance, and adoption: A state of the art review, Expert Systems with Applications, 203, (2022); Pu P., Chen L., Hu R., A user-centric evaluation framework for recommender systems, Proceedings of the Fifth Acm Conference on Recommender Systems, pp. 157-164, (2011); Ranalli J., Automated written corrective feedback: How well can students make use of it?, Computer Assisted Language Learning, 31, 1, pp. 1-22, (2018); Ranalli J., Yamashita T., Automated written corrective feedback: Error-correction performance and timing of delivery, Language, Learning and Technology, 26, 3, pp. 1-25, (2022); Schneider J., Eklund P.W., Lee K., Chen F., Cain A., Abdelrazek M., Adopting industry agile practices in large-scale capstone education, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training, pp. 119-129, (2020); Scott A., Kreahling W., Holliday M., Barlowe S., A Holistic Capstone Experience: Beyond Technical Ability, Proceedings of the 18th Annual Conference on Information Technology Education (Rochester, New York, USA) (SIGITE '17, pp. 1-6, (2017); Latif Siddiq M., Majumder S.H., Mim M.R., Jajodia S., Santos S.J.C., An Empirical Study of Code Smells in Transformerbased Code Generation Techniques, 2022 Ieee 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM, pp. 71-82, (2022); Srivastava A., Bhardwaj S., Saraswat S., SCRUM model for agile methodology, 2017 International Conference on Computing, Communication and Automation (ICCCA, pp. 864-869, (2017); Stray V., Sjoberg D., Dyba T., The Daily Standup Meeting: A Grounded Theory Study, Journal of Systems and Software, 114, 1, pp. 101-124, (2016); Gulliksen Stray V., Brede Moe N., Aurum A., Investigating Daily Team Meetings in Agile Software Projects, 2012 38th Euromicro Conference on Software Engineering and Advanced Applications, pp. 274-281, (2012); Terry G., Hayfield N., Clarke V., Braun V., Thematic analysis, The Sage Handbook of Qualitative Research in Psychology, (2017); Vijayakumar S., Jetcheva J.G., SMARTREC: A Conversational Recommendation System Using Semantic Knowledge Graphs, 2022 Ieee Eighth International Conference on Big Data Computing Service and Applications (BigDataService, pp. 53-60, (2022); Xin Zhao W., Zhou K., Li J., Tang T., Wang X., Hou Y., Min Y., Zhang B., Zhang J., Dong Z., Du Y., Yang C., Chen Y., Chen Z., Jiang J., Ren R., Li Y., Tang X., Liu Z., Liu P., Nie J., Wen J., A Survey of Large Language Models, (2023)","","Association for Computing Machinery, Inc","ACM SIGCSE; Association for Computing Machinery (ACM)","55th ACM Technical Symposium on Computer Science Education, SIGCSE 2024","20 March 2024 through 23 March 2024","Portland","197936","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85189360811"
"Kwon S.; Lee S.; Kim T.; Ryu D.; Baik J.","Kwon, Sunjae (57799613900); Lee, Sungu (58134179800); Kim, Taehyoun (58805853400); Ryu, Duksan (55317946600); Baik, Jongmoon (58655270000)","57799613900; 58134179800; 58805853400; 55317946600; 58655270000","Exploring LLM-based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures","2023","Journal of Web Engineering","22","6","","889","912","23","0","10.13052/jwe1540-9589.2263","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182708548&doi=10.13052%2fjwe1540-9589.2263&partnerID=40&md5=2c781bf0f7d4ba8ac31b4b8158af6e13","Edge-Cloud system requires massive infrastructures located in closer to the user to minimize latencies in handling Big data. Ansible is one of the most popular Infrastructure as Code (IaC) tools crucial for deploying these infrastructures of the Edge-cloud system. However, Ansible also consists of code, and its code quality is critical in ensuring the delivery of high-quality services within the Edge-Cloud system. On the other hand, the Large Langue Model (LLM) has performed remarkably on various Software Engineering (SE) tasks in recent years. One such task is Automated Program Repairing (APR), where LLMs assist developers in proposing code fixes for identified bugs. Nevertheless, prior studies in LLM-based APR have predominantly concentrated on widely used programming languages (PL), such as Java and C, and there has yet to be an attempt to apply it to Ansible. Hence, we explore the applicability of LLM-based APR on Ansible. We assess LLMs’ performance (ChatGPT and Bard) on 58 Ansible script revision cases from Open Source Software (OSS). Our findings reveal promising prospects, with LLMs generating helpful responses in 70% of the sampled cases. Nonetheless, further research is necessary to harness this approach’s potential fully. © 2023 River Publishers. All rights reserved.","Ansible; automated program repairing; Bard; Edge-cloud; large langue model","","Agapito G., Bernasconi A., Cappiello C., Khattak H.A., Ko I., Loseto G., Mrissa M., Nanni L., Pinoli P., Ragone A., Et al., Current Trends in Web Engineering: ICWE 2022 International Workshops, BECS, SWEET and WALS, Bari, Italy, July 5–8, 2022, Revised Selected Papers; Ahmad A., Waseem M., Liang P., Fahmideh M., Aktar M.S., Mikkonen T., Towards human-bot collaborative software architecting with chatgpt, Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering, pp. 279-285, (2023); Brown T., Mann B., Ryder N., Subbiah M., Kaplan J.D., Dhariwal P., Neelakantan A., Shyam P., Sastry G., Askell A., Et al., Language models are few-shot learners, Advances in neural information processing systems, 33, pp. 1877-1901, (2020); Buyya R., Srirama S.N., Fog and edge computing: principles and paradigms, (2019); Dalla Palma S., Di Nucci D., Palomba F., Tamburri D.A., Within-project defect prediction of infrastructure-as-code using product and process metrics, IEEE Transactions on Software Engineering, 14, 8, (2020); Guerriero M., Garriga M., Tamburri D.A., Palomba F., Adoption, support, and challenges of infrastructure-as-code: Insights from industry, 2019 IEEE International conference on software maintenance and evolution (ICSME), pp. 580-589, (2019); Hassan M.M., Rahman A., As code testing: Characterizing test quality in open source ansible development, 2022 IEEE Conference on Software Testing, Verification and Validation (ICST), pp. 208-219, (2022); Jin M., Shahriar S., Tufano M., Shi X., Lu S., Sundaresan N., Svyatkovskiy A., Inferfix: End-to-end program repair with llms, (2023); Kabir S., Udo-Imeh D.N., Kou B., Zhang T., Who answers it better? an in-depth analysis of chatgpt and stack overflow answers to software engineering questions, (2023); Kokuryo S., Kondo M., Mizuno O., An empirical study of utilization of imperative modules in ansible, 2020 IEEE 20Th international conference on software quality, reliability and security (QRS), pp. 442-449, (2020); Krippendorff K., Computing krippendorff’s alpha-reliability (2011) 12. Kwon, S., Jang, J.I., Lee, S., Ryu, D., Baik, J.: Codebert based software defect prediction for edge-cloud systems, Current Trends in Web Engineering: ICWE 2022 International Workshops, BECS, SWEET and WALS, Bari, Italy, July 5–8, 2022, Revised Selected Papers, pp. 11-21; Kwon S., Jang J.I., Lee S., Ryu D., Baik J., Codebert based software defect prediction for edge-cloud systems, Current Trends in Web Engineering: ICWE 2022 International Workshops, BECS, SWEET and WALS, Bari, Italy, July 5–8, 2022, Revised Selected Papers, pp. 11-21, (2023); Kwon S., Lee S., Ryu D., Baik J., Pre-trained model-based software defect prediction for edge-cloud systems, Journal of Web Engineering, pp. 255-278, (2023); Kwon S., Lee S., Ryu D., Baik J., Exploring the Feasibility of ChatGPT for Improving the Quality of Ansible Scripts in Edge-Cloud Infrastructures through Code Recommendation: ICWE 2023 International Workshops; Li Z., Lu S., Guo D., Duan N., Jannu S., Jenks G., Majumder D., Green J., Svyatkovskiy A., Fu S., Et al., Codereviewer: Pre-training for automating code review activities, (2022); Ma W., Liu S., Wang W., Hu Q., Liu Y., Zhang C., Nie L., Liu Y., The scope of chatgpt in software engineering: A thorough investigation, (2023); Meijer B., Hochstein L., Moser R., Ansible: Up and Running, (2022); Monperrus M., Automatic software repair: A bibliography, ACM Computing Surveys (CSUR), 51, 1, pp. 1-24, (2018); Morris K., Infrastructure as code: managing servers in the cloud, (2016); Nascimento N., Alencar P., Cowan D., Comparing software developers with chatgpt: An empirical investigation, (2023); Nguyen N., Nadi S., An empirical evaluation of github copilot’s code suggestions, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 1-5, (2022); Opdebeeck R., Zerouali A., De Roover C., Andromeda: A dataset of ansible galaxy roles and their evolution, 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), pp. 580-584, (2021); Opdebeeck R., Zerouali A., De Roover C., Smelly variables in ansible infrastructure code: detection, prevalence, and lifetime, Proceedings of the 19th International Conference on Mining Software Repositories, pp. 61-72, (2022); Pearce H., Tan B., Ahmad B., Karri R., Dolan-Gavitt B., Examining zero-shot vulnerability repair with large language models, 2023 IEEE Symposium on Security and Privacy (SP), 1, pp. 2339-2356; Sobania D., Briesch M., Hanna C., Petke J., An analysis of the automatic bug fixing performance of chatgpt, (2023); Tian H., Lu W., Li T.O., Tang X., Cheung S.C., Klein J., Bissyande T.F., Is chatgpt the ultimate programming assistant–how far is it?, (2023); White J., Hays S., Fu Q., Spencer-Smith J., Schmidt D.C., Chatgpt prompt patterns for improving code quality, refactoring, requirements elicitation, and software design, (2023); Xia C.S., Zhang L., Conversational automated program repair, (2023); Xia C.S., Zhang L., Keep the conversation going: Fixing 162 out of 337 bugs for $0.42 each using chatgpt, (2023); Xu J., Yan L., Wang F., Ai J., A github-based data collection method for software defect prediction, 2019 6th International Conference on Dependable Systems and Their Applications (DSA), pp. 100-108, (2020); Zhang Y., Rahman M., Wu F., Rahman A., Quality assurance for infrastructure orchestrators: Emerging results from ansible, 2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C), pp. 1-3, (2023)","","River Publishers","","","","","","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85182708548"
